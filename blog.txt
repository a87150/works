
    

 
 
 
 

 Trump 为什么会取胜

 
 
 
 
    

    
 
     
  

      
   
Trump 为什么会取胜

    加州和纽约那些因为 Trump 上台而去抗议游行的人，都应该想一想，既然 Trump 被媒体搞得那么臭，希拉里一副好人形象，为什么 Trump 还会比希拉里多那么多的选票？难道选票数有假吗？难道大部分美国人都是傻子，流氓或者变态吗？当然不是的！人民的眼睛是雪亮的，就像之前文章提到的那位卡车司机。大部分的美国人像他一样，是淳朴善良勤劳有教养的。



    



    人民被各种政客骗了又骗，生活每况愈下，所以他们已经不再相信任何政客了，更不要说一个早有那么多绯闻的政客。这时候来了一个 Trump，大声道出了人民需要解决的切身问题，痛骂那些伤害他们的人，所以他们很容易就选择了他。



    如果你还不理解，那我们来做一个简单的类比和推理：你现在要在两个人里选择一个，跟你一起开车去很远的地方旅行。这两个人你都不了解，甚至都没见过面，但是其中一个在你的朋友圈子里名声很差，大家都说他是傻逼流氓，而另一个人大家都说他是好人。那你会选择谁呢？当然是大家都说好的那一个对不对？然而这次美国大选的结局却不是这样，这是为什么呢？



    如果希拉里真是一个好人，关心人民疾苦，而 Trump 被媒体报道得那么差，而且没有任何政治经验，如果所有人都完全不了解这两个人，只是靠媒体的报道来投票，那投票给希拉里的肯定更多，对吧？然而这次很奇怪，选票数的压倒性差距，说明虽然媒体一边倒，人民却不只是靠媒体的好恶来决定选谁的。他们靠的是自己的亲身接触和理解，他们直接看这个人说了什么，做了什么，他是否能解决自己切身的问题。他们甚至会从他的眼神和语气，感觉到这个人是否真诚。这说明希拉里的实际表现真的非常非常差，超越了所有媒体对 Trump 的负面报道加在一起。大部分的美国人民是不喜欢希拉里的，他们已经完全不相信她，不管媒体如何报道。为什么媒体会完全倒向希拉里一边呢？这只能说明媒体是被希拉里控制的！就是这么简单。



    如果你还不理解 Trump 怎么会获胜，那你可能应该问问自己，自己是不是身处某种特殊的地方，这地方相对富裕，或者周围的人心理都不大像普通老百姓，或者脑子都有点问题，以为自己是有钱人暴发户，可以骑在别人头上，或者认为自己是技术天才，可以造出智能机器人来代替很多人的工作，所以你只需要关心全球变暖，有机食品，垃圾回收，大麻合法化，同性恋婚姻，变性人该上哪个厕所之类的无病生吟？或者这些人就是不痛不痒，根本不关心，所以只临时看看媒体报道，连别人演讲都没看，就投出选票。对的，硅谷和纽约，就是这样的地方 :)



    有几个我身边的人，在美国生活了几十年了，以前从来没投过票。这次听到希拉里在呼唤：“女同胞们，你们有力量阻止 Trump！他是一个种族主义者，性别歧视者，我们不能让他做总统，否则灾难就在眼前！” 所以不问青红皂白，也没看人家 Trump 到底说了什么，也没看希拉里的绯闻，更不可能知道维基解密。平生第一次注册投票，就这样稀里糊涂投给了希拉里。



    还有另外一些人，完全不明白什么是民主，什么才是健康的社会制度。今天我吃完午饭去外面散步，后面有两个西装革履领导模样的陌生人，在郑重其事的聊选举的事。还隔着几步路呢，嗓门大得让我以为他在我耳边说话，不得不忍受了好长一段路。其中一个人说：“选举总统的时候，公司应该被作为一个人对待，它们也应该有投票权。大小公司都没有投票权，是我们选举制度很大的一个缺陷，所以才会出现这次的不幸结局。这次我们准备提议……” 提议公司要有投票权！公司要是有了选举总统的权利，那人民还怎么活！我当时嘴都张大了。加州居然有人会这样想，他们举行抗议示威，也就不足为怪了。这些人就像卓别林在『大独裁者』最后的演讲里说的那样：想得太多，感觉太少，机器一样的人，机器一样的心……



    然而大部分其他地方的美国人并不像我们这么幸运，他们是真的出现了生存问题，这是我们身边的人没有想象到的。为什么他们会出现生存问题？因为美国的社会制度，整个系统都是有毛病的。社会福利非常差，医疗系统完全就是噩梦，房价和生活开销疯涨，利率又下调到几乎没有。再加上我们这些硅谷技术呆子们造出来的智能工具，各种 Amazon 之类的电商，Uber 之类，抢走了很多人的饭碗。实体书店商店全部濒临倒闭，出租车没生意…… 然后各大技术公司还不回报社会，各种避税，钻法律空子压低工资，把工作转移到海外，赚更多的暴利。政府还经常花上万亿的税钱拿去打仗（希拉里对伊拉克战争投了赞成票），还在叫穷说没钱发福利。最近还整出 ObamaCare 这样的害人东西，花 50 亿美元做了个 bug 无数的网站，请去的程序员三个月在那里闲着没事干，倒是拿着不菲的工资，住着高档酒店，每天 70 刀饭钱，外加每月 1000 刀拿去租跑车。穷人呢，本来不怎么生病的，被迫花不少钱买了医保，结果 deductible 太高，等于没买……



    遇到了如此严重的问题，你说人民会怎样？就像你生了疑难病症，要动很大的手术。你选择医生时，会只看网站上的好评数吗？你不仅要看别人的评语，肯定还得亲自去跟他谈，你还得看他的眼神和语气，感觉一下他会不会骗你，你还得看他以前的成功案例，甚至打电话去问那个人现在感觉如何…… 这样货比三家之后，还要想它一两个月，然后才能决定。出现了生存问题的人就是这样，他们会非常小心的研究之后，亲眼看看那个人的临场表现，进行各种背景调查，然后才做出选择。媒体说这人怎么样，他们只是作为参考而已。



    Trump 早在 35 年前就看见了美国的这些问题，最后真是看不下去了，他想解决它，这是真真切切用摄像机记录下来的（视频）。从 1980 年开始，每隔几年就有人问他想不想当美国总统，他总是说：“我不想。但我相信有其他人可以做这件事，美国有很多有才能的人……” 有一次提问者笑道：“你是嫌做总统工资不够高吧？:)”  Trump 早就知道美国有问题，然而却一直等其他人去解决它。一直等了 35 年！到 2015 年，他等的那个人还没有出现。他已经不再相信会有其他人会真的解决美国的问题，所以才决定出山，参加竞选。这跟那些从哈佛耶鲁这样的“青年政治学院”毕业的职业政客，真是天壤之别。这些人一毕业就在政界混，拉帮结派，处心积虑，不择手段争当总统，为了谋取不可告人的利益。政客的演讲都是一种表演，跟差劲的演员没什么区别。然而从 Trump 的各种演讲，你看得出来那是真心的。还有许多受到过他帮助的人，他们的亲身故事，有着非常强大的说服力。这就是为什么虽然 Trump 的嘴那么“臭”，大部分的美国人民还是选择了他。



    Trump 的胜利，显示出了民主的力量。我本来不怎么相信民主，可是它在危机的关头，还真的起了作用……


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 与希拉里支持者的对话

 
 
 
 
    

    
 
     
  

      
   
与希拉里支持者的对话

    加州可谓是希拉里和民主党的天下，大选时希拉里支持率高达 62%。民主党在加州尽做恶心事，什么 AA 法案啊，厕所法案啊…… 然而加州人对于希拉里的迷信之深，真是让我匪夷所思。现在我来记录一下我跟一些希拉里支持者的对话。这些人基本上是美籍华裔女性，在美国念的高中和本科。她们的信息来源，主要是美国各大媒体，以及微信朋友圈之类。大部分人从来没有上 YouTube 直接看过各个竞选人的整体言论，光靠道听途说和媒体宣传，就做出投票选择。


对话一


    有个女生找工作，非常艰难才找到。找到之后，公司居然钻法律空子，只给了她两年的 contractor 职位。这样就可以压低工资，而且可以不给她办医保。本来法律不允许这么长时间的 contractor 职位，两年太长了，应该给“永久职位”，必须要有医疗保险和其它福利。这属于损害雇员利益的行为，然而这公司找了一个中介 contractor 公司，把她挂靠在那个地方。这样由于美国法律的漏洞，没有人管得着。由于臭名昭著的 ObamaCare 的强制规定，虽然她身体健康不易生病，却不可以不买医保，否则年底退税的时候要罚款。由于公司不给买医保，所以只好每个月自己掏钱买。这是很大的一笔开销，而且 ObamaCare 由于 deductible 非常高，所以买了等于没有买。



    这是一个有头有面的美国大公司，名字就不提了，也这样乱整。大选时，这妹纸居然投了希拉里的票，并且动情的在朋友圈宣扬，和朋友们吃着有民主党徽标的蛋糕，说：“我们选择了她！” 可惜最后 Trump 胜利了，于是悲伤欲绝，说 Trump 会把我们都赶出美国的，怎么办！我跟她说，你被美国社会整的这么惨，怎么还去选希拉里？她代表的就是这种邪恶的大公司，大银行，剥削阶级的利益，而且她是一个战争贩子。她上台了，你们以后找工作肯定越来越困难，很难活下去的。相反，Trump 会对失业问题提出解决方案，他也许真能办成一些事情。她说：“我不可能选 Trump，因为他名声那么差，而且完全没有执政经验。选他的人都是住在美国中部，教育程度低，找不到工作的白人……”



    “找不到工作的白人”…… 她仿佛忘了，自己差点就落到那种地步，房子都租不起。她其实跟中部找不到工作的白人是一类人，跟我也是一类人，都属于中产阶级。这些人本应该团结起来，维护自己的权益。然而由于她在高中和大学受到美国式的洗脑教育，所以坚持的认为工作是衡量一个人能力的标准，找不到工作是可耻的事情。被美国教育洗脑过的人，一般都不会觉悟到，这是社会制度不公平造成的。



    世界上的工作大量的被机器取代，根本没有那么多事情给人做，而且很多美国公司为了赚取更多的暴利，把大量工作转移到海外，节省劳力开销。本来每个人都应该有工作，而且只需要工作很短的时间，可事实却是很多人失业了，剩下的人继续做长时间的工作。所以是社会制度应该改革，而不是人应该更努力。但“没工作就是可耻”这种思想，在美国如此根深蒂固，你是有理也说不清。她现在暂时有了工作，所以忽然间忘了自己是谁。于是乎，她的话在我的耳朵里就等价于：“只有可耻（找不到工作）的人，才会支持 Trump。”



    生活在社会最底层，却打心眼里认为自己是上等人，瞧不起跟她一样的普通民众。总被人欺负，居然还投票给欺负她的人做总统，这是多么可悲的事情。被她歧视的，投票给 Trump 的人是什么样子的呢？给你们看其中一位：



    



    曾经投票给奥巴马，投了两次给克林顿，却发现生活越来越困苦。这次当然不投希拉里了，因为这帮人代表着反人民的旧势力。如果这种人再次上台，他们一定会继续榨干人民身上的一切，然后无情的抛弃。我们和这位卡车司机一样，都是一样的命运。各位 IT人士，不要以为自己现在有工作，有不错的收入，就忘了自己是谁。让希拉里上台，这种恶性循环就会继续，同样的事情终究会轮到我们自己！


对话二


    另一个女生，最近老在朋友圈贴美国的暴乱事件，或者歧视华人事件的新闻，一副人心惶惶的气氛。大部分此类新闻来源不明，无法验证其真实性。其中一条新闻说：“由于某些中国人支持 Trump，所以 Trump 获胜之后，敌对 Trump 的人发动暴乱，砸了烧了这些 Trump 支持者的店铺。” 看到这里，我还以为她对希拉里有意见，因为如果真有此事的话，就应该是希拉里的支持者干的，就是一群暴徒嘛。



    可是这妹纸对此的评论，却让人大跌眼镜：“看吧，Trump 还没上台呢，美国就大乱了！他就是下一个希特勒！” 我说：“你想清楚了没有？Trump 的支持者店铺被砸，按逻辑应该是希拉里的支持者恼羞成怒，或者受人指使干的。这种流氓行为，应该说希拉里是下一个希特勒还差不多。怎么可能怪到 Trump 头上？” 结果她说：“不是 Trump 的人砸的难道是你砸的？Trump 支持者就不可以砸 Trump 支持者的店了吗！”



    我无语，无法跟她辩论，因为她不遵循理性和逻辑，被希拉里的各种媒体宣传完全的洗脑了。这就像在说，中国人砸了日本车，肯定是日本车的错一样 :P “Trump 是下一个希特勒”，这种信息在网络上到处传播，就可能进入更多类似人的头脑。这些人喜欢不经思考和取证，就直接接受别人告诉他的结论。


希拉里的真实面目


    从以上几个例子，你可能明白了，希拉里的选票是怎么来的，大部分是靠人们的无知和道听途说，散布谣言妖魔化对手。希拉里是女的，所以她利用这一点来忽悠广大女性，试图成为她们崇拜的典范，进而投票让她上台。然而希拉里其实不算是一个女人，她并不具有女性的优点：善良，诚实，有爱心。实际上她的本质正好相反。希拉里是世界上最腐败的政客之一。



    投了希拉里选票的女性，我推荐你们看看这篇文章，以及这些视频：视频1，视频2，视频3。我半夜看了这些视频，身上的毛都竖起来了！这些都揭示出希拉里这个人的本性。谁才是真正的法西斯，看完之后也许你应该有所理解…… 文章中提到的民主党 email，我已经去维基解密搜索过，文中提到的 email 全都存在，内容属实。比起 Trump 的负面报道，这才是真正可怕的。



    希拉里不可能是一个好总统，她甚至不是一个好人。所以排除一个大恶人，美国人民最好的选择只能是 Trump…… 也许是有比 Trump 嘴巴小点，心又好的人，可是谁叫你们要搞两党制而不是十党制？谁叫希拉里要不择手段搞垮 Sanders？Sanders 和 Trump，这两人任何一个上台，都要比希拉里好很多。Trump 的嘴有点讨厌，然而他说的绝大部分都是事实。



    由于 Trump 已经当选，多说也没用了。我只是想告诉这些不经大脑就接受信息的人，Trump 上台后，中国人在美国的生活状况不一定是你想的那么差，反而可能会比现在更好，因为很显然 Trump 比奥巴马和希拉里都要好。希拉里上台，我们的生活只会每况愈下。所以请不要看到未经考证的关于 Trump 的负面新闻就到处转。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 美国的新总统

 
 
 
 
    

    
 
     
  

      
   
美国的新总统

    一觉醒来，发现 Trump 已经当选成为美国的下一任总统。很多人都很吃惊，然而这却是我意料之中的事情。其实在大选一开头的时候，我就猜到很可能是 Trump，而且他也许是个不错的总统。作为一个外国人，我不是特别关心美国政治，然而打心眼里，我一直比较希望 Trump 取胜。为什么呢？原因很简单：直觉。



    凭直觉我就看出来，Trump 嘴里说的就是他心里想的，而不是按其他人给他写的稿子念的。没有煽情，没有说教。很明显，他不是政客出身，不是哈佛耶鲁毕业，不怎么会撒谎。他不缺钱不缺地位不缺女人，所以不会被各种贪得无厌的财团操纵。一开头我就觉得，这家伙是真想做一番事情的，而他的目的，是为了社会变得更好，人民更加幸福。



    美国总统这破工作，很多人都不想做，送给我都不要。成天明争暗斗的，说不定哪天就被暗杀了。可就有那么一个人，过着国王一样的奢华生活，住着宫殿一样的房子，被超级名模和选美小姐们围绕，他却忽然想要来收拾美国这烂摊子，住进监狱一样戒备森严的白房子。这是什么样的精神？这是对现状实在看不下去了，忍无可忍，只好挺身而出的精神 :P



    很多人不喜欢他，可我看了他几段视频之后，就打心眼里欣赏这人。因为他说的就是他想的，率真可爱！在叙利亚难民问题，欧洲恐怖事件，San Bernardino 枪击大屠杀出现的时候，他的反应跟奥巴马希拉里之类的伪君子，是完全不一样的。他知道如何正确地保护本国人民，从来不试图表现得“政治正确”，不怕得罪人。



    可惜讨厌他，歧视他，奚落他的人太多了，甚至有人说要在万圣节打扮成 Trump 的模样，…… 所以我在同事朋友面前，都不敢明显表现出对 Trump 的赞同，以至于他们以为我跟他们一样讨厌 Trump，这是一个多么可悲的世界。我不明白这些人为什么会讨厌 Trump。他们讨厌他，仿佛只是因为其他人讨厌他，所以就被传染了，自己也说不清楚原因。这就是所谓“无缘无故的恨”吧。



    然而，大部分美国人民终究还是厌倦了各种能说会道，挂着羊头卖狗肉的政客…… 我在看着你，奥巴马。你那名义上帮助人，其实害了人的“医疗改革计划”，甚至想让叙利亚难民进入美国而不经过严格身份审查。政客（politician）最在行的事情是什么？是说谎，是两面三刀，拉拢关系。政客都是被各种利益财团操纵，为他们的利益服务，让人民受苦的傀儡而已。



    希拉里，当然一看就是政客，他们全家都是政客。政客的本质，不会因为性别而有所不同。很多人因为希拉里是女的而选她，希望会有所不同，别做梦了。这种人只“信仰”那些可以让他赢得选举的东西，所以总是见风使舵。奥巴马是美国第一个黑人总统，他做了什么好事吗？他根本就不配做总统。第一个女总统，那又能怎样。看人要看他的本质，而不是性别，种族，年龄一类肤浅的表面特征。



    如果你想了解希拉里的本质，请参考泄露出来的民主党机密 email。据我亲自上 WikiLeaks 搜索，发现这些 email 全都存在并且内容属实。希拉里团队为了抹黑 Trump，制造虚假广告，在社交媒体散步负面谣言抹黑 Trump，操纵 NBC 和华盛顿邮报等媒体，而且对同为民主党的 Sanders 猛下黑手。Sanders 和 Trump 都维护人民权益，而希拉里代表的是黑暗的压迫阶级。当然，她的幕后指使者们不能让 Sanders 和 Trump 上台。



    奥巴马毕业于哈佛，希拉里毕业于耶鲁。哈佛耶鲁这样的大学，还有一些类似 Wellesley 的“精英学校”，就是职业撒谎者的摇篮。培养出来的就是特别会说，嘴上一套，互相勾结的傀儡政客。这些学校的所谓“教育”，也就是美国沦落到今天的地步的重要原因。美国的政界，大学和公司，充满了各种各样，能说会道的政客，全靠嘴皮子干活。什么口号能让自己升官，就喊什么口号。很多中国人还在继续膜拜这些“世界一流大学”，做梦都想把孩子送去这种学校。醒醒吧！



    我不能说我是 Trump 的支持者，但随着对他了解的增加，我越来越觉得我们是同类。他看明白了美国存在的严重问题，而且他想到了解决的方案。我觉得他很可能就是美国命运的转折点，至少是转折的开始。也许美国就是不可救药的国家，但这总比放任它不管好。选希拉里一定是错的，她跟奥巴马和其他政客不会有什么不同。他们只会空喊口号，拉拢各方面的选票，最后什么事都不会做，甚至让事情变得更糟。



    很多人讨厌 Trump 都是听了其他人歪曲的言论，不假思索就断定他是坏人。Trump 的敌人，是那些为富不仁，贪得无厌，危害社会的人。这些人为了维护他们不应有的暴利，当然要花费巨额的资金，操纵各种媒体来歪曲和污蔑 Trump，把美国大选搞成一出闹剧。所以你就在网上看到有人断章取义，说 Trump 是个疯子，Trump 是种族主义者，Trump 性别歧视…… 但你根本不知道他具体是怎么说的，他是在什么样的情况下说的。如果你仔细翻看民主党的 email，会发现这些很多都是他们一手抹黑的。



    我看了一些他有争议的言论，包括那些关于穆斯林问题的，回去找到上下文，连起来发现他说的其实一点都没错。比如在枪击屠杀发生之后，他说：“我们不要让穆斯林进入美国，直到我们搞清楚这是怎么回事！” 人家只是说那个危险情况下暂时的措施，并没有说永久不准穆斯林进入美国，结果各大媒体把后半句“直到我们搞清楚这是怎么回事”剪掉，去掉时间限制成为永久性的断言，借此歪曲 Trump 的原话，让他成为穆斯林的敌人。然后奥巴马，希拉里就出来批判 Trump，说穆斯林的好话，装好人，要“团结”…… 你们这都看不出来吗？



    所以为了全面的了解一个人的为人，我建议你们直接看看他说了什么，而不要听别人的传言。我建议大家看一下这个视屏和文章。看完之后也许你会发现，Trump 是真正关爱社会的人，他想解决美国的社会问题，已经想了 35 年，才走出竞选总统这一步。35年，也就是他的半个人生了。他不像其它政客出身的候选人，有着各种不可告人的动机和幕后操纵者。



    在这个风和日丽的日子，美国迎来了第一个不是政客的总统，一线希望。Trump，收拾美国这烂摊子任重而道远，面对强大的反人民势力，肯定有很多阻力和艰险。希望你不要辜负大家的希望，让美国人民过上幸福的日子！多保重！


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 如何赢得技术争论

 
 
 
 
    

    
 
     
  

      
   
如何赢得技术争论

    做技术的人，经常遇到这样的面试问题：“工作中如果遇到技术上的意见不一致，有人说要这么做，你却觉得应该那么做，该怎么办？” 我对此的回答一般是，友好地说出自己的看法，理由和证据，大家一起分析，找到最好的方案。



    这似乎是一个非常文明而合理的做法，然而在实行的时候，就发现我的这种做法几乎每次都失败。我亲眼看见，项目代码被固执己见的人加入越来越多不必要的东西，变得越来越乱。我亲眼看见，工作的流程被自以为是的领导改得无比繁琐，以至于大家效率减半，甚至没法工作。我预见到项目甚至整个企业的最终失败，可是我对此无能为力，只好听之任之。我对自己说，他们只付给我这么点钱，我这种没有话语权的人，就不要试图去做什么大贡献了……



    我确实坚持过，我的坚持拯救过整个的团队，不过这种事情只出现过两次。第一次，我实现了队友们以为不可能完成的 PySonar，拯救了垂死的 Google Grok 团队。另外一次，我冒着被炒鱿鱼的风险，帮助大家摆脱某公司 VP 的愚蠢作法。这人提出一个“创举”，把项目不到十万行的代码按目录切分成超过 30 个 git repo，称之为“模块化管理”，结果大家没法工作了（自己想想为什么？）。我第一个站出来，指出这种做法的严重问题，跟他争论了近半个月。幸好我赢得了好几个同事的支持，最后写了一个脚本把 30 多个 repo 合并成了一个，不然后果你可以想象。然而我发现每一次加入新的团队，都会出现类似的瞎指挥情况，所以我对这种英勇的行为越来越不感兴趣了。



    经历了这么多之后，我觉得现在是时候分析一下，为什么自己总是在技术的争论中“失败”（注意失败打了引号）。就算有深入的见解，近乎天衣无缝的逻辑和充分的实验，数据和证据，也敌不过有些人的诡辩。最后我发现，这里面的原因不在于我自己的逻辑不够充分，数据不够精确，推理不够严密。根本的问题在于，我在跟错误的人说话，我根本不应该跟这些人一起工作。一个石头打烂一锅汤，团队里只要出现一个这样的人，占据了高位，愚蠢就会开始蔓延。



    我发现跟某些人辩论问题的时候，我总会输掉，以至于项目被这种人朝着崩溃的方向推进。最后我发现问题其实在于，这些人是为了辩论而辩论，他们并不是想探索问题的究竟，他们并不依照严密的逻辑进行推理，他们甚至根本没有听你在说什么。他们跟你辩论唯一的目的，就是赢得辩论。



    这种人会不择手段，使用模糊不精确的概念，片面或者不属实的证据，利用道听途说的谣言，抬出权威的名字，反复跟你念经，甚至当场把你当小孩，质疑你对一些基础知识的理解，进行变相侮辱性质的攻击。当时弄得你无语，甚至不知所措，等你事后仔细分析，却又发现他们的说法漏洞百出。任随你有严密的逻辑，充足的证据和实验数据，也不会是他们的对手，因为这种人根本不遵循逻辑，不尊重事实，所以你就被狗咬吕洞宾，没办法让事实得到尊重。



    如果遇到这种人，我一般只好任由他们。因为他们已经下定决心要否认你的观点，所以再多的口舌也是浪费时间。这种人跟你争论，往往不是为了项目得到更好的结果，而是另有企图。当然我知道项目最后很可能会因为这些人而失败，可是我对此无能为力，只好随它去了。欢迎忽略我的看法，不过由此引来的一切的后果，你们自己承担 :P



    所以呢，虽然我今天的标题叫做『如何赢得技术争论』，然而我对这个问题其实是无解的，因为我根本没有想过去“赢得”争论。跟人争论的目的，不应该是为了能赢，能按自己的方式办事，而应该是为了弄清事实，发现最好的解决方案。如果另一个人的做法更好，以理服人，那么我会毫不犹豫地放弃自己的想法。然而不幸的是，在我的工作生涯中，充满了想要赢得争论，对别人的观点视而不见，一切按自己的想法办事，进行诡辩，甚至靠嗓门大取胜的人。所以很多时候你就只好放弃，因为你是在跟错误的人说话。



    我看见满载希望的列车，冲向悬崖的尽头，然而我却只能保全自己，因为我无法拯救愚昧。愚昧是无敌的。有个古人说得好，理性和智慧从来就没有战胜过愚昧，只有等愚昧的人都死去，它们才有被人看见的希望……


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 可恶的 C# IDisposable 接口

 
 
 
 
    

    
 
     
  

      
   
可恶的 C# IDisposable 接口

    我们 team 快被 C# 里面的各种 IDisposable 对象给折腾疯了…… 故事比较长，先来科普一下。如果你没有用过 C#，IDisposable 是 C# 针对“资源管理”设计的一个接口，它类似于 Java 的 Closeable 接口。这类接口一般提供一个“方法”（比如叫 Dispose 或者 Close），你的资源（比如文件流）实现这个接口。使用资源的人先“打开资源”，用完之后调用这个方法，表示“关闭资源”。比如，文件打开，读写完了之后，调用 close 关掉，就是这个原理。



    相比于 Java，C# 大部分时候是更好的语言，然而它并没有全面超越 Java。一个显著的不足之处就是 C# 的 IDisposable 接口引起的头痛，要比 Java 的 Closeable 大很多。经过我分析，这一方面是因为 .NET 库代码里面实现了很多没必要的 IDisposable，以至于你经常需要思考如何处理它们。另一方面是由于微软的编码规范和 Roslyn 静态分析引起的误导，使得用户对于 IDisposable 接口的“正确使用”过度在乎，导致代码无端变得复杂，导致 IDisposable 在用户代码里面传染。



    回来说说我们的代码，本来没那么多问题的，结果把 Roslyn 静态分析一打开，立马给出几百个警告，说“你应该调用 Disposable 成员的 Dispose 方法”（CA2213)），或者说“类型含有 disposable 成员，却没有实现 IDisposable 接口”（CA1001）。奇葩的是，C# 里面有些很小却很常用的对象，包括 ManualResetEvent, Semaphore, ReaderWriterLockSlim 都实现了 IDisposable 接口，所以经常搞得你不知所措。按官方的“规矩”，你得显式的调用所有这些对象的 Dispose 方法进行“释放”，而不能依赖 GC 进行回收。所以你的代码经常看起来就像这个样子：


void foo()
{
  var event = new ManualResetEvent(false);
  // 使用 _event ...
  event.Dispose();
}



    貌似没什么困难嘛，我们把每个对象的 Dispose 方法都调用一下，不就得了？然而问题远远不是这么简单。很多时候你根本搞不清楚什么时候该释放一个对象，因为它存在于一个复杂，动态变化的数据结构里面。除非你使用引用计数，否则你没有办法确定调用 Dispose 的时机。如果你过早调用了 Dispose 方法，而其实还有人在用它，就会出现严重的错误。这问题就像 C 语言里面的 free，很多时候你不知道该不该 free 一块内存。如果你过早的 free 了内存，就会出现非常严重而蹊跷的内存错误，比泄漏内存还要严重很多。举一个 C 语言的例子：


void main()
{
    int *a = malloc(sizeof(int));
    *a = 1;

    int *b = malloc(sizeof(int));
    *b = 2;

    free(a);

    int *c = malloc(sizeof(int));
    *c = 3;

    printf("%d, %d, %d\n", *a, *b, *c);    
}



    你知道这个程序最后是什么结果吗？自己运行一下看看吧。所以对于复杂的数据结构，比如图节点，你就只好给对象加上引用计数。我当年用 C 语言写计算几何算法的时候就干过这种事情，相信我，这其实挺痛苦。或者如果你的内存够用，也不需要分配释放很多中间结果，那你就干脆把这些对象都放进一个“池子”，到算法结束以后再一并释放它们……



    是的 C# 有垃圾回收（GC），所以你以为不用再考虑这些低级问题了。不幸的是，IDisposable 接口以及对于它兢兢业业的态度，把这麻烦事给带回来了。以前在 Java 里用此类对象，从来没遇到过这么麻烦的事情，最多就是打开文件的时候要记得关掉（关于文件，我之后会细讲一下）。我不记得 Java 的等价物（Closeable 接口）引起过这么多的麻烦，Java 的 Semaphore 根本就没有实现 Closeable 接口，也不需要在用完之后调用什么 Close 或者 Dispose 之类的方法。作为一个眼睛雪亮的旁观者，我开始怀疑 C# 里的那些像 Semaphore 之类的小东西是否真的需要显式的“释放资源”。



    为了搞明白 C# 库代码里面为什么这么多 IDisposable 对象，我用 JetBrains 出品的反编译器 dotPeek （好东西呀）反编译了 .NET 的库代码。结果发现好些库代码实现了完全没必要的 IDisposable 接口。这说明有些 .NET 库代码的作者其实没有弄明白什么时候该实现 IDisposable ，以及如何有意义地实现它。这些有问题的类，包括常用的 HashAlgorithm（各种 SHA 算法的父类）和 MemoryStream。



    其中 HashAlgorithm 的 Dispose 方法完全没必要，这个类的源代码看起来是这个样子：


public abstract class HashAlgorithm : IDisposable, ICryptoTransform {
  ...
  protected internal byte[] HashValue;
  ...
  protected virtual void Dispose(bool disposing)
  {
      if (disposing)
      {
   if (HashValue != null)
Array.Clear(HashValue, 0, HashValue.Length);
   HashValue = null;
   m_bDisposed = true;
      }
  }
}



    看明白了吗？它不过是在把内部数组 HashValue 的每个元素清零，然后把指针设为 null。这个库代码作者没有搞明白的是，如果你的 Dispose 方法只是在把一些成员设为 null，那么你根本就不需要实现 IDisposable。为什么呢？因为把引用设为 null 并不等于 C 语言里面的 free，它并不能立即回收那份内存，就算你的对象里面有一个很大的数组也一样。我发现有些 C# 程序员喜欢在使用对象之后把引用赋值为 null，就像这样写代码：


void foo()
{
  BigObject x = new BigObject();
  // ...
  // 使用 x 指向的对象 ...
  // ...
  x = null;
}



    x = null 是毫无意义的。写出这样的代码，说明他们不明白 GC 是如何工作的，以为把引用设为 null 就可以释放内存，以为不把引用设为 null，内存就不会被回收！再进一步，如果你仔细看 HashAlgorithm 的源代码，就会发现 HashValue 这个成员数组其实没有必要存在，因为它保存的只是上一次调用 ComputeHash() 的结果而已。这种保存结果的事情，本来应该交给使用者去做，而不是包揽到自己身上。这个数组的存在，还导致你没法重用同一个 HashAlgorithm 对象，因为有共享的成员 HashValue，所以不再是 thread safe 的。



    其实在 C# 里面，你没有办法可以手动回收内存，因为内存是由 GC 统一管理的。就算你实现 Dispose，在里面把成员设置为 null，内存也只有等下次 GC 执行的时候才可能被回收。举一个例子：


class Foo : IDisposable
{
  private byte[] _data = new byte[1000000000];

  public void Dispose()
  {
    _data = null;    // 没用的
  }
}



    在这个例子里面，Foo 类型的 Dispose 只是在把 _data 设为 null，这是毫无意义的。如果你想释放掉这块数组，那么你只需要等不再有人使用 Foo 对象。比如：


void UseFoo()
{
  Foo foo = new Foo();
  // 使用 f...
  foo.Dispose();  // 没必要
  foo = null;     // 没必要
}



    这里的 foo.Dispose() 是完全没必要的。你甚至没必要写 foo = null，因为 foo 是一个局部变量，它一般很快就会离开作用域的。当函数执行完毕，或者编译器推断 foo 不会再次被使用的时候，GC 会回收整个 Foo 对象，包括里面的巨大数组。



    所以正确的做法应该是完全不要 Dispose，不实现 IDisposable 接口。有些人问，要是 Foo 对象被放进一个全局哈希表之类的数据结构，GC 没法释放它，就需要 Dispose 了吧？这也是一种常见的误解。如果你真要回收全局哈希表里的 Foo 对象，你只需要把 Foo 对象从哈希表里面删掉就可以了。一旦哈希表对 Foo 对象的引用没有了，GC 运行的时候就会发现它成了垃圾，里面的 _data 数组自然也是垃圾，所以一起就回收掉了。



    所以简言之，Dispose 不是用来给你回收内存用的。在 Dispose 方法里把成员设为 null，并不会导致更快的内存释放。有人可能以为 HashAlgorithm 是为了“安全”考虑，所以在 Dispose 方法里对数组清零。然而 IDisposable 是用于释放“资源”的接口，把安全清零这种事情放在这个接口里面，反而会让人误解，造成疏忽。而且从源代码里的注释看来，HashAlgorithm 的这个方法确实是为了释放资源，而不是为了什么安全考虑。这些库代码实现 IDisposable，意味着这个接口会通过这些库代码不必要的传递到用户代码里面去，导致很多不知情用户的代码被迫实现 IDisposable，造成“传染”。



    作为练习，你可以分析一下 MemoryStream 的 Dispose 方法，为什么是没必要的：


protected override void Dispose(bool disposing)
{
    try
    {
 if (disposing)
 {
     _isOpen = false;
     _writable = false;
     _expandable = false;
#if FEATURE_ASYNC_IO
 _lastReadTask = null;
#endif
 }
    }
    finally
    {
 // Call base.Close() to cleanup async IO resources
 base.Dispose(disposing);
    }
}



    另外，我发现 AutoResetEvent，ManualResetEvent，ReaderWriterLockSlim，Semaphore 这些 IDisposable 对象，里面的所谓“资源”，归根结底都是一些很小的 Windows event 对象，而且它们都继承了 SafeHandle。SafeHandle 本身有一个“析构函数”（finalizer），它看起来是这个样子：


~SafeHandle()
{
    Dispose(false);
}



    当 SafeHandle 被 GC 回收的时候，GC 会自动自动调用这个析构函数，进而调用 Dispose。也就是说，你其实并不需要手动调用这些对象（例如 ManualResetEvent, Semaphore 之类）的 Dispose 方法，因为 GC 会调用它们。这些对象占用资源不多，系统里也不会有很多这种对象，所以 GC 完全应该有能力释放它们占用的系统资源。



    很多人谈到这个问题，就会举文件的例子来反驳你，说你不应该依靠 GC 来释放 IDisposable 对象。他们说，你应该及时关闭文件，所以对于其它 IDisposable 资源，你应该做同样的事情，然而他们并没有抓住问题的关键。文件是一种很特殊的资源，你之所以需要在用完之后立即关掉它，而不能等 GC  来做这事，是因为文件是一种“全局资源”。使用文件的时候，你使用文件的名字来读写它。任何知道这个名字的进程，都可以试图访问这个文件。这使得文件成为一种“全局资源”，也就是说，它不是 thread safe 的。一般系统里面，在任何一个时刻，只能有一个进程打开文件进行写操作，然后这个文件就被锁住了，其它进程不能打开。所以如果你不关掉文件，那其它人就没法用它。



    写文件需要给它加锁，当然你必须及时进行解锁，而不能等 GC 这样的过程来帮你解。否则即使你不再引用这个文件，其他人仍然没法及时进入锁定的区域，就造成了不必要的等待。然而有另外一种资源，它不是共享的，而是分配给进程“私人使用”的。系统里面可以有任意多个这样的资源，你用任何一个都可以，它们的使用互不干扰，所以你并不需要非常及时的关闭它们。这种资源的性质，跟内存的性质几乎完全一样。像 ManualResetEvent, Semaphore, ReaderWriterLockSlim 就属于这种非共享的资源，它们的性质跟内存非常相似。就算它们实现了 IDisposable 接口，关闭它们的重要性也跟关闭文件相差非常大。实际上我通过测试发现，就算你把它们完全交给 GC 处理，也不会有任何问题。你掉不调用 Dispose，内存的使用量都一模一样。只不过如果你调用 Dispose，计算花的时间还要多一些。



    微软官方文档和 Roslyn 静态分析说一定要调用 Dispose，其实是把不是问题的问题拿出来让人心惊胆战，结果把代码给搞复杂了，进而引发更严重的问题。很多人把 Roslyn 静态分析的结果很当回事，而其实看了源代码之后，我发现 Roslyn 关于 Dispose 的静态分析实现，是相当幼稚的作法（flow analysis 都没实现），所以结果是非常不准确的，导致很多 false positive。



    另外 Roslyn 分析给出的警告信息，有严重的误导性质。比如编号为CA1001的警告对你说：“Types that own disposable fields should be disposable。” 如果你严格遵循这一“条款”，让所有含有 IDispoable 的成员的类都去实现 IDisposable，那么 IDisposable 接口就会从一些很小的对象（比如常见的 ManualResetEvent），很快扩散到几乎所有的对象里去。每个对象都实现 IDisposable 接口，却没有任何对象真正的调用 Dispose 方法。最终结果跟你什么都不做是一样的，只不过代码变复杂了，还浪费了时间和精力。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 C 编译器优化过程中的 Bug

 
 
 
 
    

    
 
     
  

      
   
C 编译器优化过程中的 Bug

    一个朋友向我指出一个最近他们发现的 GCC 编译器优化过程（加上 -O3 选项）里的 bug，导致他们的产品出现非常诡异的行为。这使我想起以前见过的一个 GCC bug。当时很多人死活认为那种做法是正确的，跟他们说不清楚。简言之，这种有问题的优化，喜欢利用 C 语言的“未定义行为”（undefined behavior）进行推断，最后得到奇怪的结果。



    这类优化过程的推理方式都很类似，他们使用一种看似严密而巧妙的推理，例如：“现在有一个整数 x，我们不知道它是多少。但 x 出现在一个条件语句里面，如果 x &gt; 1，那么程序会进入未定义行为，所以我们可以断定 x 的值必然小于或者等于 1，所以现在我们利用 x ≤ 1 这个事实来对相关代码进行优化……”



    看似合理，然而它却是不正确的，你能看出来这样的推理错在何处吗？我一时想不起来之前具体的例子了（如果你知道的话告诉我）。上网搜了一下相关话题，发现这篇 Chris Lattner (LLVM 和 Swift 语言 的设计者) 写于 2011 年的文章。文中指出，编译器利用 C 语言的“未定义行为”进行优化，是合理的，对于性能是很重要的，并且举出这样一个例子：


void contains_null_check(int *P) {
  int dead = *P;
  if (P == 0)
    return;
  *P = 4;
}



    这例子跟我之前看到的 GCC bug 不大一样，但大致是类似的推理方式：这个函数依次经过这样两个优化步骤（RNCE 和 DCE），之后得出“等价”的代码：


void contains_null_check_after_RNCE(int *P) {
  int dead = *P;
  if (false)  // P 在上一行被访问，所以这里 P 不可能是 null
    return;
  *P = 4;
}


void contains_null_check_after_RNCE_and_DCE(int *P) {
  //int dead = *P;    // 死代码消除
  //if (false) // 死代码
  //  return;  // 死代码
  *P = 4;
}



    他的推理方式是这样：



首先，因为在 int dead = *P 里面，指针 P 的地址被访问，如果程序顺利通过了这一行而没有出现未定义行为（比如当掉），那么之后 P 就不可能是 null，所以我们可以把 P == 0 优化为 false。
因为条件是 false，所以整个 if 语句都是死代码，被删掉。
dead 变量赋值之后，没有被任何其它代码使用，所以对 dead 的赋值是死代码，可以消去。




    最后函数就只剩下一行代码 *P = 4。然而经我分析，发现这个优化转换是根本错误的做法（unsound 的变换），而不只是像他说的“存在安全隐患”。现在我来考考你，你知道这为什么是错的吗？值得庆幸的是，现在如果你把这代码输入到 Clang，就算加上 -O3 选项，它也不会给你进行这个优化。这也许说明 Lattner 的这个想法后来已经被 LLVM 团队抛弃。



    我写这篇文章的目的其实是想告诉你，不要盲目的相信编译器的作者们做出的变换都是正确的，无论它看起来多么的合理，只要打开优化之后你的程序出现奇葩的行为，你就不能排除编译器进行了错误优化的可能性。Lattner 指出这样的优化完全符合 C 语言的标准，这说明就算你符合国际标准，也有可能其实是错的。有时候，你是得相信自己的直觉……



    （文中提出的两个问题，欢迎来信讨论，或者在两星期之后等待答案。）


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 对 Rust 语言的分析

 
 
 
 
    

    
 
     
  

      
   
对 Rust 语言的分析

    Rust 是一门最近比较热的语言，有很多人问过我对 Rust 的看法。由于我本人是一个语言专家，实现过几乎所有的语言特性，所以我不认为任何一种语言是新的。任何“新语言”对我来说，不过是把早已存在的语言特性（或者毛病），挑一些出来放在一起。所以一般情况下我都不会去评论别人设计的语言，甚至懒得看一眼，除非它历史悠久（比如像 C 或者 C++），或者它在工作中惹恼了我（像 Go 和 JavaScript 那样）。这就是为什么这些人问我 Rust 的问题，我一般都没有回复，或者一笔带过。



    不过最近有点闲，我想既然有人这么热衷于这种新语言，那我还是稍微凑下热闹，顺便分享一下我对某些常见的设计思路的看法。所以这篇文章虽然是在评论 Rust 的设计，它却不只是针对 Rust。它是针对某些语言特性，而不只是针对某一种语言。



    由于我这人性格很难闭门造车，所以现在我只是把这篇文章的开头发布出来，边写边更新。所以你要明白，这只是一个开端，我会按自己理解的进度对这篇文章进行更新。你看了之后，可以隔一段时间再回来看新的内容。如果有特别疑惑的问题，也可以发信来问，我会汇总之后把看法发布在这里。


变量声明语法


    Rust 的变量声明跟 Scala 和 Swift 的很像。你用


let x = 8;



    这样的构造来声明一个新的变量。大部分时候 Rust 可以推导出变量的类型，所以你不一定需要写明它的类型。如果你真的要指明变量类型，需要这样写：


let x: i32 = 8;



    在我看来这是丑陋的语法。本来语义是把变量 x 绑定到值 8，可是 x 和 8 之间却隔着一个“i32”，看起来像是把 8 赋值给了 i32……



    变量缺省都是不可变的，也就是不可赋值。你必须用一种特殊的构造


let mut x = 8;



    来声明可变变量。这跟 Swift/Scala 的 let 和 var 的区别是一样的，只是形式不大一样。


变量可以重复绑定


    Rust 的变量定义有一个比其它语言更奇怪的地方，它可以让你在同一个作用域里面“重复绑定”同一个名字，甚至可以把它绑定到另外一个类型：


let mut x: i32 = 1;
x = 7;
let x = x; // 这两个 x 是两个不同的变量

let y = 4;
// 30 lines of code ...
let y = "I can also be bound to text!";
// 30 lines of code ...
println!("y is {}", y);      // 定义在第二个 let y 的地方



    在 Yin 语言最初的设计里面，我也是允许这样的重复绑定的。第一个 y 和 第二个 y 是两个不同的变量，只不过它们碰巧叫同一个名字而已。你甚至可以在同一行出现两个 x，而它们其实是不同的变量！这难道不是一个很酷，很灵活，其他语言都没有的设计吗？后来我发现，虽然这实现起来没什么难度，可是这样做不但没有带来更大的方便性，反而可能引起程序的混淆不清。在同一个作用域里面，给两个不同的变量起同一个名字，这有什么用处呢？自找麻烦而已。



    比如上面的例子，在下面我们看到一个对变量 y 的引用，它是在哪里定义的呢？你需要在头脑中对程序进行“数据流分析”，才能找到它定义的位置。从上面读起，我们看到 let y = 4，然而这不一定是正确的定义，因为 y 可以被重新绑定，所以我们必须继续往下看。30 行代码之后，我们看到了第二个对 y 的绑定，可是我们仍然不能确定。继续往下扫，30行代码之后我们到了引用 y 的地方，没有再看到其它对 y 的绑定，所以我们才能确信第二个 let 是 y 的定义位置，它是一个字符串。



    这难道不是很费事吗？更糟的是，这种人工扫描不是一次性的工作，每次看到这个变量，你都要疑惑一下它是什么东西，因为它可以被重新绑定，你必须重新确定一下它的定义。如果语言不允许在同一个作用域里面重复绑定同一个名字，你就根本不需要担心这个事情了。你只需要在作用域里面找到唯一的那个 let y = ...，那就是它的定义。



    也许你会说，只有当有人滥用这个特性的时候，才会导致问题。然而语言设计的问题往往就在于，一旦你允许某种奇葩的用法，就一定会有人自作聪明去用。因为你无法确信别人是否会那样做，所以你随时都得提高警惕，而不能放松下心情来。


类型推导


    另外一个很多人误解的地方是类型推导。在 Rust 和 C# 之类的语言里面，你不需要像 Java 那样写


int x = 8;



    这样显式的指出变量的类型，而是可以让编译器把类型推导出来。比如你写：


let x = 8;  // x 的类型推导为 i32



    编译器的类型推导就可以知道 x 的类型是 i32，而不需要你把“i32”写在那里。这似乎是一个很方便的东西。然而看过很多 C# 代码之后你发现，这看似方便，却让程序变得不好读。在看 C# 代码的时候，我经常看到一堆的变量定义，每一个的前面都是 var。我没法一眼就看出它们表示什么，是整数，bool，还是字符串，还是某个用户定义的类？


var correct = ...;
var id = ...;
var slot = ...;
var user = ...;
var passwd = ...;



    我需要把鼠标移到变量上面，让 Visual Studio 显示出它推导出来的类型，可是鼠标移开之后，我可能又忘了它是什么。有时候发现看同一片代码，都需要反复的做这件事，鼠标移来移去的。而且要是没有 Visual Studio，用其它编辑器，或者在 github 上看代码或者 code review 的时候，你就得不到这种信息了。很多 C# 程序员为了避免这个问题，开始用很长的变量名，把类型的名字加在变量名字里面去，这样一来反而更复杂了，却没有想到直接把类型写出来。所以这种形式的类型推导，看似先进或者方便，其实还不如直接在声明处写下变量的类型，就像 Java 那样。



    所以，虽然 Rust 在变量声明上似乎有更灵活的设计，然而我觉得 C 和 Java 之类的语言那样看似死板的方式其实更好。我建议不要使用 Rust 变量的重复绑定，避免使用类型推导，尽量明确的写出类型，以方便读者。如果你真的在乎代码的质量，就会发现大部分时候你的代码的读者是你自己，而不是别人，因为你需要反复的阅读和提炼你的代码。


动作的“返回值”


    Rust 的文档说它是一种“大部分基于表达式”的语言，并且给出这样一个例子：


let mut y = 5;
let x = (y = 6);  // x has the value `()`, not `6`



    奇怪的是，这里变量 x 会得到一个值，空的 tuple，()。这种思路不大对，它是从像 OCaml 那样的语言照搬过来的，而 OCaml 本身就有问题。在 OCaml 里面，如果你使用 print_string，那你会得到如下的结果：


print_string "hello world!\n";;

hello world!
- : unit = ()



    这里，print_string 是一个“动作”，它对应过程式语言里面的“statement”。就像 C 语言的 printf。动作通常只产生“副作用”，而不返回值。在 OCaml 里面，为了“理论的优雅”，动作也会返回一个值，这个值叫做 ()。其实 () 相当于 C 语言的 void。C 语言里面有 void 类型，然而它却不允许你声明一个 void 类型的变量。比如你写


int main()
{
  void x;
}



    程序是没法编译通过的（试一试？）。让人惊讶的是，古老的 C 的做法其实是正确的，这里有比较深入的原因。如果你把一个类型看成是一个集合（比如 int 是机器整数的集合），那么 void 所表示的集合是个空集，它里面是不含有任何元素的。声明一个 void 类型的变量是没有任何意义的，因为它不可能有一个值。如果一个函数返回 void，你是没法把它赋值给一个变量的。



    可是在 Rust 里面，不但动作（比如 y = 6 ）会返回一个值 ()，你居然可以把这个值赋给一个变量。其实这是错误的作法。原因在于 y = 6 只是一个“动作”，它只是把 6 放进变量 y 里面，这个动作发生了就发生了，它根本不应该返回一个值，它不应该可以出现在 let x = (y = 6); 的右边。就算你牵强附会说 y = 6 的返回值是 ()，这个值是没有任何用处的。更不要说使用空的 tuple 来表示这个值，会引起更大的类型混淆，因为 () 本身有另外的，更有用的含义。



    你根本就不应该可以写 let x = (y = 6); 这样的代码。只有当你犯错误或者逻辑不清晰的时候，才有可能把 y = 6 当成一个值来用。Rust 允许你把这种毫无意义的返回值赋给一个变量，这种错误就没有被及时发现，反而能够通过变量传播到另外一个地方去。有时候这种错误会传播挺远，然后导致问题（运行时错误或者类型检查错误），可是当它出问题的时候，你就不大容易找到错误的起源了。



    这是很多语言的通病，特别是像 JavaScript 或者 PHP 之类的语言。它们把毫无意义或者牵强附会的结果（比如 undefined）到处传播，结果使错误很难被发现和追踪。


return 语句


    Rust 的设计者似乎很推崇“面向表达式”的语言，所以在 Rust 里面你不需要直接写“return”这个语句。比如，这个例子里面，你可以直接这样写：


fn add_one(x: i32) -&gt; i32 {
    x + 1
}



    返回函数里的最后一个表达式，而不需要写 return 语句，这是函数式语言共有的特征。然而其实我觉得直接写 return 其实是更好的作法，像这个样子：


fn foo(x: i32) -&gt; i32 {
    return x + 1;
}



    编程有一个容易引起问题的作法，叫做“不够明确”，总想让编译器自动去处理一些问题，在这里也是一样的问题。如果你隐性的返回函数里最后一个表达式，那么每一次看见这个函数，你都必须去搞清楚最后一个表达式是什么，这并不是每次都那么明显的。比如下面这段代码：


fn main() {
    println!("{}", add_one(7));
}

fn add_one(x: i32) -&gt; i32 {
  if (x &lt; 5) {
      if (x &lt; 10) {
 // 做很多事...
 x * 2
      } else {
 // 做很多事...
 x + 1
      }
  } else {
    // 做很多事...
    x / 2
  }
}



    由于 if 语句里面有嵌套，每个分支又有好些代码，而且 if 语句又是最后一个语句，所以这个嵌套 if 的三个出口的最后一个表达式都是返回值。如果你写了“return”，那么你可以直接看有几个“return”，或者拿编辑器加亮一下，就知道这个函数有几个出口。然而现在没有了“return”这个关键字，你就必须把最后那个 if 语句自己看清楚了，找到每一个分支的“最后表达式”。很多时候这不是那么明显，你总需要找一下，而且这件事在读代码的时候总是反复做。



    所以对于返回值，我的建议是总是明确的写上“return”，就像第二个例子那样。Rust 的文档说这是“poor style”，那不是真的。有一个例外，那就是当函数体里面只有一条语句的时候，那个时候没有任何歧义哪一个是返回表达式。



    这个问题类似于重复绑定变量和类型推导的问题，属于一种“用户体验设计”问题。无论如何，编译器都很容易实现，然而不同样式的代码，对于人类阅读的工作量，是很不一样的。很多时候最省人力的做法并不是那种看来最聪明，最酷，打字量最少的办法，而是写得最明确，让读者省事的办法。人们常说，代码读的时候比写的时候多得多，所以要想语言好用省事，我们应该更加重视读的时候，而不是写的时候。


数组的可变性


    Rust 的数组可变性标记，跟 Swift 犯了一样的错误。Swift 的问题，我已经在之前的文章有详细叙述，所以这里就不多说了。简言之，同一个标记能表示的可变性，要么针对数组指针，要么针对数组元素，应该只能选择其一。而在 Rust 里面，你只有一个地方可以放“mut”进去，所以要么数组指针和元素全部都可变，要么数组指针和元素都不可变。你没有办法制定一个不可变的数组指针，而它指向的数组的元素却是可变的。



    请对比下面两个例子：


fn main() {
    let m = [1, 2, 3];      // 指针和元素都不可变
    m[0] = 10;// 出错
    m = [4, 5, 6];   // 也出错
}


fn main() {
    let mut m = [1, 2, 3];  // 指针和元素都可变
    m[0] = 10;// 不出错
    m = [4, 5, 6];   // 也不出错
}


内存管理


    Rust 号称实现了非常先进的内存管理机制，不需要垃圾回收（GC）或者引用计数（RC）就可以“静态”的管理内存的分配和释放。然而仔细思考之后你就会发现，这很可能是不切实际的梦想（或者广告）。内存的分配和释放（如果要及时释放的话），本身是一个动态的过程，无法用静态分析来实现。现在你说可以通过一些特殊的构造，特殊的指针和传值方式，静态的决定内存的回收时间，真的有可能吗？



    实际上在 IU 的时候，我有一个类似的梦。我曾经向我的教授们（Friedman，Dybvig）提出过 N 多种不需 GC 和 RC 就能静态管理内存的办法，结果每一次都被他们给我的小例子给打败了，以至于我很难相信有任何人可以想到比 GC 和 RC 更好的方法。



    Rust 那些炫酷的 move semantics, borrowing, lifetime 之类的概念加在一起，不但让语言变得复杂不堪，我感觉并不能从根本上解决内存管理问题。很多人在 blog 里面为这些概念热情洋溢地做宣传，显得自己很懂一样，拿一些玩具代码来演示，可是从没看到任何人说清楚这些东西为什么可以从根本上解决问题，能用到复杂一点的代码里面去。所以我觉得这些东西有“皇帝的新装”之嫌。



    连 Rust 自己的文档都说，你可能需要“fight with the borrow checker”。为了通过这些检查，你必须用很怪异的方式来写程序，随着问题复杂度的增加，就要求有更怪异的写法。如果用了 lifetime，很简单一个代码看起来就会是这种样子。真够烦的，我感觉我的眼睛都没法 parse 这段代码了。


fn foo&lt;'a, 'b&gt;(x: &amp;'a str, y: &amp;'b str) -&gt; &amp;'a str {
}



    上一次我看 Rust 文档的时候，没发现有 lifetime 这概念。文档对此的介绍非常粗略，仔细看了也不知道他们在说些什么，更不要说相信这办法真的管用了。对不起，我根本不想去理解这些尖括号里的 'a 和 'b 是什么，除非你先向我证明这些东西真的能解决内存管理的问题。实际上这个 lifetime 我感觉像是跨过程静态分析时产生的一些标记，要知道静态分析是无法解决内存管理的问题的，我猜想这种 lifetime 在有递归函数的情况下就会遇到麻烦。



    实际上我最开头看 Rust 的时候，它号称只用 move semantics 和好几种不同的指针，就可以解决内存管理的问题。可是一旦有了那几种不同的指针，就已经复杂不堪了，比 C 语言还要麻烦，而且显然不能解决问题。Lifetime 恐怕是后来发现有新的问题解决不了才加进去的，可是我不知道他们这次是不是又少考虑了某些情况。



    Rust 的设计者显然受了 Linear Logic 一类看似很酷的逻辑的启发和熏陶，想用类似的方式奇迹般的解决内存和资源的回收问题。然而研究过一阵子 Linear Logic 之后我发现，这个逻辑自己都没有解决任何问题，只不过给对象的引用方式施加了一些无端的限制，这样使得对象的引用计数是一个固定的值（1）。内存管理当然容易了，可是这样导致有很多程序你没法表达。



    开头让你感觉很有意思，似乎能解决一些小问题。到后来遇到大一点的实际问题的时候，你就发现需要引入越来越复杂的概念，使用越来越奇葩的写法，才能达到目的，而且你总是会在将来某个时候发现它没法解决的问题。因为这个问题很可能从根本上是无法解决的，所以每当遇到有超越现有能力的事情，你就得增加新的“绕过方法”（workaround）。缝缝补补，破败不堪。最后你发现，除了垃圾回收（GC）和引用计数（RC），内存管理还是没有其它更好更简单的办法。



    当然我的意见也许不是完全准确，可我真是没有时间去琢磨这么多乱七八糟，不知道管不管用的概念（特别是 lifetime），更不要说真的用它来构建大型的系统程序了。有用来理解这些概念，把程序改成奇葩样子的时间，我可能已经用 C 语言写出很好的手动内存管理代码了。如果你真的看进去理解了，发现这些东西可以用的话，告诉我一声！不过你必须说明原因，不要只告诉我“皇帝是穿了衣服的” :P


完


    本来想写一个更详细的评价的，可是到了这个地方，我感觉已经失去兴趣了，困就一个字啊…… Rust 比 C 语言复杂太多，我很难想象用这样的语言来构造大型的操作系统。而构造系统程序，是 Rust 设计的初衷。说真的，写操作系统那样的程序，C 语言真的不算讨厌。用户空间的程序，Java，C# 和 Swift 完全可以胜任。所以我觉得 Rust 的市场空间恐怕非常狭小……



    （如果你喜欢这些内容，请付费5美元或者30人民币，谢谢！）


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 支付宝的身份验证问题

 
 
 
 
    

    
 
     
  

      
   
支付宝的身份验证问题

    我看到有人继续在向我之前的支付宝账号付费。其实现在的付费二维码已经改成了我父亲的账号，原因是因为支付宝的身份验证问题。



    我的支付宝账号是在国内的时候开通的，支付宝收到的博文付费，都是准备转给家人的。开始收费之后，向家人的账号转了一些钱。支付宝似乎有很严格的防盗验证，我开头不熟悉怕出问题，所以做了几个试验，把钱分成好几次转。最后一次的时候，发现支付宝说需要验证我的身份，还打开手机的相机，要做“人脸验证”。让我左边转一点，右边转一点…… 我的身份证是15年前办的了，当然现在不像了！最后验证没有通过，于是支付功能就被锁定了，再也无法向家人转账。解锁的方法只有联系客服，可是客服电话打了老半天，根本没人接……



    由于这个原因，我不能再用我自己的支付宝账号收费。开通新的账号又需要银行卡验证，而我的国内手机和U盾都丢了…… 国内的银行系统就是这么麻烦。



    所以没办法，只好把我父亲的支付宝二维码放了上去。请大家以后不要再向我的账号付费，直接转账给我父亲就可以了。谢谢！


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 测试的道理

 
 
 
 
    

    
 
     
  

      
   
测试的道理

    在长期的程序语言研究和实际工作中，我摸索出了一些关于测试的道理。然而在我工作过的每一个公司，我发现绝大多数人都不明白这些道理，很多团队集体性的采用错误的做法而不自知。很多人把测试当成一种主义和教条，进行过度的测试，不必要的测试，不可靠的测试，并且把这些错误的做法传授给新手，造成恶性循环。本来目的是提高代码质量，结果不但没能达到目的，反而降低了代码质量，增大了工作量，大幅度延缓工程进度。



    我也写测试，但我的测试方式比“测试教条主义者”们的方式聪明很多。在我心目中，代码本身的地位大大的高于测试。我不忽视测试，但我不会本末倒置，过分强调测试，我并不推崇测试驱动开发（TDD）。我知道该测试什么，不该测试什么，什么时候该写测试，什么时候不该写，什么时候应该推迟测试，什么时候完全不需要测试。因为这个原因，再加上高强的编程能力，我多次完成别人认为在短时间不可能完成的任务，并且制造出质量非常高的代码。


测试的道理


    现在我就把这些自己领悟到的关于测试的道理总结一下，其中有一些是鲜为人知或者被误解的。




    不要以为你处处显示出“重视代码质量”的态度，就能提高代码质量。总有些人，以为自己知道“单元测试”（unit test），“集成测试”（integration test）这样的名词，就很懂编程，就可以教育其他人。可惜，光有态度和口号是不解决问题的，你还必须有实战的技巧，深入的见解和智慧，必须切实地知道应该怎么做。代码的质量不会因为你重视它就得到提升，也不会因为你采取了措施（比如测试，静态分析）就一定会得到改善。你必须知道什么时候该写测试，什么时候不该写测试，需要写测试的时候，要写什么样的测试。其实，提高代码质量唯一可行的手段不是写测试，而是反复的提炼自己的思维，写简单清晰的代码。如果你想真的提高代码质量，我的文章『编程的智慧』是一个不错的出发点。


    真正的编程高手不会被测试捆住手脚。是的，你身边那个你认为“不很在乎测试”的家伙，也许是个比你更好的程序员。我喜欢把编程比喻成开赛车，而测试就是放在路边用来防撞的轮胎护栏……



    



    护栏有时候是很有用，可以救命的，然而一个合格的车手，绝对不会一心想着有护栏保护，测试在编程活动中的地位也应该就是这样。优秀的车手会很快看见优雅而简单的路径，恰到好处地掌握速度和时机，直奔终点而去。护栏只是放在最危险的地段，让你出了意外不要死得太惨。护栏并不能让你成为好的车手，不能让你取得冠军。绝大多数时候，你的安全只有靠自己的技术，而不是护栏，你永远有办法可以撞死自己。测试的作用也是一样，即使有了很多的测试，代码的安全仍然只掌握在你的手里。你永远可以制造出新的 bug，而没有测试可以检测到它……



    通常情况下，一个合格的车手是根本碰不到这些护栏的，他们心里想的是更高的目标：快点到达终点。相比之下，一个不合格的车手，他经常撞到赛道外面去，所以在他的心里，护栏有着至高无上的地位，所以他总是跟别人宣扬护栏的重要性。他开车的时候为了防止犯错，要在他经过的路径两边密密麻麻摆上护栏，甚至把护栏摆到赛道中间，以确保自己的转弯幅度正确。他在护栏之间跌跌撞撞，最后只能算是勉强到达终点。鼓吹测试驱动开发的人，就是这种三流车手，这种人写再多的测试也不可能倒腾出可靠的代码来。


    在程序和算法定型之前，不要写测试。TDD 的教条者喜欢跟你说，在写程序之前就应该先写测试。为什么写代码之前要写测试呢？这只是一种教条。这些人其实没有用自己的脑子思考过这个问题，而只是人云亦云，觉得这样“很酷”，符合潮流，或者以为这样做了别人就会认为自己是高手。实际上在程序框架完成，算法定型之前，你都不需要写测试。如果你想知道代码是否正确，用人工方式运行代码，看看结果足以。



    如果你发现编程初期需要保证的性质纷繁复杂，如此之多，不写测试你就没信心的话，那你还是想办法先提高下基本的编程技术吧：多做练习，简化代码，让代码更加模块化，看看我的『编程的智慧』或者『SICP』一类的东西。写测试并不能提高你的水平，正好相反，过早的写测试会捆住你的手脚，让你无法自由的修改代码和算法。如果你不能很快的修改代码，不能用直觉感觉到它的变化和结构，而是因为测试而处处卡顿，你的头脑里就不能产生所谓“flow)”，就不能写出优雅的代码来，结果到最后你什么也没学会。只有在程序不再需要大幅度的改动之后，才是逐渐加入测试的时候。


    不要为了写测试而改变本来清晰的编程方式。很多人为了满足“覆盖”（coverage）的要求，为了可以测试到某些模块，或者为了使用 mock，而把本来简单清晰地代码改成更加复杂而混淆的形式，甚至采用大量 reflection。这样一来其实降低了代码的质量。本来很简单的代码，一眼看去就知道是否正确，可是现在你一眼看过去，到处都是为了方便测试而加进去的各种转接插头，再也无法感觉到代码。这些用来辅助测试的代码，阻碍了你对代码进行直觉思维，而如果你不能把代码的逻辑完全映射在头脑里（进而产生直觉），你是很难写出真正可靠的代码的。



    有些 C# 程序员，为了测试而加入大量的 interface 和 reflection，因为这样可以在测试的时候很方便的把一片代码替换成 mock。结果你就发现这程序里每个类都有一个配套的 interface，还需要写另外一个 mock 类，去实现这个 interface。这样一来，不但代码变得复杂难以理解，而且还损失了 Visual Studio 的协助功能：你不再能按一个键（F12）就直接跳转到方法的定义，而需要先跳到对应的 interface 方法，然后再找到正确的实现。所以你不再能够在代码里面快速的跳转浏览。这种方便性的损失，会大幅度降低头脑产生整体理解的机会。而且为了 mock，每一个构造函数调用都得换成一个含有 reflection 的构造，使得编译器的静态类型检查无法确保类型正确，增加运行时出错的可能性，出错信息还难以理解，得不偿失的后果。


    不要测试“实现细节”，因为那等同于把代码写两遍。测试应该只描述程序需要满足的“基本性质”（比如 sqrt(4) 应该等于 2），而不是去描述“实现细节”（比如具体的开平方算法的步骤）。有些人的测试过于详细，甚至把代码的每个实现步骤都兢兢业业的进行测试：第一步必须做A，第二步必须做B，第三步必须做C…… 还有些人喜欢给 UI 写测试，他们的测试里经常这样写：如果你浏览到这个页面，那么你应该在标题栏看见这行字……



    仔细想一下就会发现，这种作法本质上不过是把代码（或者UI）写了两遍而已。本来代码里面明白写着：先做A，再做B，再做C。UI 描述文件里面明白写着：标题栏里面是这些内容。你有什么必要在测试里把它们全都再检查一遍呢？这根本没有增加任何可靠性：你在代码里会犯错，你把同样的逻辑换种形式再写一遍，难道就不会错了吗？



    这就像某些脑子秀逗的人，他出门时总是担心门没锁好，关门之后要推推拉拉好几次，确认门是锁上了的。还没走几步，他仍然在怀疑门没锁好，又走回去推推拉拉好几次，却始终不能放心 :P 这种做法非但不能保证代码的正确，反而给修改代码制造了障碍。理所当然，你把同一段代码写了两遍，每当要修改代码，你就得修改两次！这样的测试就像紧箍咒一样，把代码压得密不透风。每一次修改代码，都会导致很多测试失败，以至于这些测试都不得不重写。本质上就是把代码修改了两遍，只不过更加痛苦一些。


    并不是每修复一个 bug 都需要写测试。很多公司都流传一个常见的教条，就是认为每修复一个 bug，都需要为它写测试，用于确保这个 bug 不再发生。甚至有人要求你这样修复一个 bug：先写一个测试，重现这个 bug，然后修复它，确保测试通过。这种思维其实是一种生搬硬套的教条主义，它会严重的减慢工程的进度，而代码的质量却不会得到提高。写测试之前，你应该仔细的思考一个问题：这个 bug 有多大可能会在同一个地方再次发生？很多低级错误一旦被看出来之后，它就不大可能在同一个地方再次出现。在这种情况下，你只需手工验证一下 bug 消失了就可以。



    为不可能再出现的 bug 大费周折，写 reproducer，构造各种数据结构去验证它，保证它下次不会再出现，其实是多此一举。同样的低级错误就算再出现，也很可能不在同一个地方。写测试不但不能保证它不再发生，而且浪费你很多时间。这测试在每次 build 的时候都会消耗时间，每次编译都因为这些测试多花几分钟，累积起来之后，你就发现工程进度明显减慢。只有当发现已有的测试没有抓住程序必须满足的重要性质时，你才应该写新的测试。你不应该是为这个 bug 而写测试，而是为代码的性质而写测试。这个测试的内容不应该只是防止这个 bug 再次发生，而是要确保 bug 所反映出来的，之前缺失的“性质”得到保证。


    避免使用 mock，特别是多层的 mock。很多人写测试都喜欢用很多 mock，堆积很多层，以为只有这样才能测试到路径比较深的模块。其实这样不但非常繁琐费事，而且多层的 mock 往往不能产生足够多样化的输入，不能覆盖各种边界情况。如果你发现测试需要进行多层的 mock，那你应该考虑一下，也许你需要的不是 mock，而是改写代码，让它更加模块化。如果你的代码足够模块化，你不应该需要多层的 mock 来测试它。你只需要为每一个模块准备一些输入（包括边界情况），确保它们的输出符合要求。然后你把这些模块像管道一样连接起来，形成一个更大的模块，测试它也符合输入输出要求，以此类推。


    不要过分重视“测试自动化”，人工测试也是测试。写测试，这个词往往隐含了“自动运行”的含义，也就是假设了要不经人工操作，完全自动的测试。打一个命令，它过一会就会告诉你哪些地方有问题。然而，人们往往忽略了“人工测试”。他们没有意识到，人工去试验，去观察，也是一种测试。所以你就发现这样的情况，由于自动测试在很多时候非常难以构造（比如，如果你要测试一段复杂的交互式GUI代码的响应），很多人花了很多时间，利用各种测试框架和工具，甚至遥控 WEB 浏览器去做一些自动操作，花太多时间却发现各种不可靠，没法测到很多东西。



    其实换一个思路，他们只需要花几分钟的时间，就可以用人工的方式观察到很多深入的问题。过分的重视测试自动化的原因，往往在于一个不切实际的假设，他们假设错误会频繁的再次发生，所以自动化了可以省下人的力气。但是其实，一旦一个 bug 被修好，它反复出现的机会不会很大的。过分的要求测试自动化，不但延缓了工程进度，让程序员恼火，效率低下，而且失去了人工测试的精确性。


    避免写太长，太耗时的测试。很多人写测试，叽里呱啦很长一串，到后来再看的时候，他已经不记得自己当时想测什么了。有些人本来用很小的输入就可以测试到需要的性质，他却总喜欢给一个很大的输入，下意识的以为这样更加靠谱，结果这测试每次都会消耗大量的 build 时间，而其实达到的效果跟很小的输入没有任何区别。


    一个测试只测试一个方面，避免重复测试。有些人一个测试测很多内容，结果每次那个测试失败，都搞不清楚到底是哪个部件出了问题。有些人为了“放心”，喜欢在多个测试里面“附带”测某些他认为相关的部件，结果每次那个部件出问题，就发现好多个测试失败。如果一个测试只测一个方面，不重复测同一个部件，那么你就可以很快的根据失败的测试，发现出问题的部件和位置。


    避免通过比较字符串来进行测试。很多人写测试的时候，喜欢通过打印出一些东西，然后使用字符串比较的方式来决定输出是否符合要求。一个常见的做法是把输出打印成格式化的 JSON，然后对比两个文本。甚至有人 JSON 都不用，直接就比较 printf 输出的结果。这种测试是非常脆弱的。因为字符串输出的格式往往会发生微小的变化，比如有人在里面加了一个空格之类的。把这种字符串作为标准输出，进行字符串比较，很容易因为微小的改动而使大量测试失败，导致很多的测试需要做不必要的修改。正确的做法，应该是进行结构化的比较，如果你要把标准结果存成 JSON，那么你应该先 parse 出 JSON 所表示的对象，然后再进行结构化的对比。PySonar2 的测试就是这样的做法，所以相当的稳定。


    “测试能帮助后来人”的误区。每当指出测试教条主义的错误，就会有人出来说：“测试不是为了你自己，而是为了你走了以后，以后进来的人不犯错误。” 首先，这种人根本没有看清楚我在说什么，因为我从来没有反对过合理的测试。其次，这种“测试能帮助后来人”，其实是没有经过实践检验，站不住脚的说法。如果你的代码写得很乱，就算你测试再多，后来人也无法理解，反倒被莫名其妙的测试失败给弄得更糊涂，不知道是自己错了还是测试错了。我已经说过了，测试不能完全保证代码不被改错，实际上它们防止代码被改错的作用是非常弱的。无论如何，后来人都必须理解原来的代码的逻辑，知道它在做什么，否则他们不可能做出正确的修改，就算你有再严密的测试也一样。





       举一个亲身的例子。我在 Google 做出 PySonar 之后，最后一个测试都没写。第二次我回到 Google，我的上司 Steve Yegge 对我说：“你走了之后，我改了一些你的代码，真是太清晰，太好把握了，修改你的代码是一种快乐！” 这说明什么问题呢？我并不是说你可以不写测试，但这个例子说明，测试对于后来人的作用，并不是你有些人想象的那么大。创造清晰的代码才是解决这个问题的关键。



       这种怕人突然走了，代码无法维护的想法，导致了一些人对测试过分的重视，但测试却不能解决这种问题。相反，如果测试太繁琐，做不必要的测试，反而容易让员工不满，容易走人，去加入在这方面更加有见地的公司。有些公司以为有了测试，就可以随便打发人走，这种想法是大错特错的。你需要明白的一个事情是，代码永远是属于写出它的那个人的，就算有测试也一样。如果核心人物真的走了，就算你有再多的测试也没用的，所以解决的方法就是把他们留住！一个有远见的公司总是通过其他的手段解决这个问题，比如优待和尊重员工，创造良好的氛围，使得他们没那么快想走。另外，公司必须注意知识的传承，防止某些代码只有一个人理解。


案例分析


    有人会疑问，我凭什么可以给别人讲这些经验，我自己为此有什么成功的案例呢？所以现在来讲讲我做过的几个东西，以及我亲眼目睹的测试教条主义者们的失败案例。


Google


    很多人可能听说过我在 Google 做的 PySonar。当时 Google 的队友们战战兢兢，说这么高难复杂的东西要从头做起，几乎是不可能的。特别是某位队友，一开头就吵着要我写测试，一直吵到最后，烦死我了。他们为什么这么担心呢？因为对 Python 做类型推导是非常高难度的代码，需要相当复杂的数据结构和算法，需要精通 Python 的语义实现。



    作为一个训练有素的专家，我没有在乎他们的咋呼，没有信他们的教条。我按照自己的方式组织代码，进行精密的思考，设计和推理，最终在三个月之内做出了非常优雅，正确，高性能，而又容易维护的代码。PySonar 到现在仍然是世界上最先进的 Python 类型推导和索引系统，被多家公司采用，用于处理数以百万计的 Python 代码。，



    如果我当时按照 Google 队友的要求，采用已有的开源代码，或者过早的写了测试，别说无法在三个月的实习时间之内完成这个东西，就算折腾好几年也没有可能。


Shape Security


    这种思维方式最近的成功实例，是给 Shape Security 做的一个先进的 JavaScript 混淆器（obfuscator）和对集群（cluster）管理系统的改进。不要小看了这个 JS 混淆器，它的混淆能力要比 uglify 之类的开源工具强很多，也快很多。它不但包含了 uglify 的变量换名等基本功能，而且含有专门针对人类和编译器的复杂化，使得没人能看出一点线索这个程序到底要干什么，让最先进的 JS 编译器也无法把它简化。



    其实这个混淆器也是一种编译器，只不过它把 JavaScript 翻译成不可读的形式。在这个项目中，由于失之毫厘就可以差之千里，我采用了从 Chez Scheme 编译器学过来的，非常严密的测试方法。对每一个编译器的步骤（pass），我都给它设计一些正好可以测到这个步骤的输入代码（比如，具有函数定义的，for循环，try-catch的，等等）。Pass 输出的代码，经过 JavaScript 解释器执行，把结果跟原来程序的执行结果对比。每一个测试程序，经过每一个 pass，输出的中间结果都跟标准结果进行对比，如果错了就表明那个 pass 有问题，出错的小程序会指出大概是哪一个部分出了问题。遵循小巧，不冗余，不重复的原则，我总共只写了40多个非常小的 JavaScript 程序。由于这些测试涵盖了 JavaScript 的所有构造而且几乎不重复，它们能够准确的定位到错误的改动。最后，这个 JS 混淆器能够正确的转换像 AngularJS 那么大的项目，确保语义的正确，让人完全无法读懂，而且能有效地防止被优化器（比如 Closure Compiler）简化掉。



    相比之下，过度鼓吹测试和可靠性的人，并没能制造出这么高质量的混淆器。其实在我进入团队之前，里面的两三位高手已经做了一个混淆器，项目延续了好多个月。这片代码一直没能发布给客户用，因为它的换名部件总是会在某些情况下输出错误的代码，修改了好多次仍然会出错。不是100%的正确，这对于程序语言的转换器来说，是不可接受的。换名只是我的混淆器里的一个步骤，它还包含大概十个类似的步骤，可以把代码进行各种转换。



    在实现换名器的时候，队友们让我直接拿他们以前写的换名代码过来，把 bug 修好就可以。然而看了代码之后，我发现这代码没法修，因为它采用了错误的思路，缝缝补补也不可能达到100%的正确，而且明显效率低下，所以我决定自己重写一个。由于轻车熟路，我只花了一下午的时间，就完成了一个正确的换名器，它完全符合 JavaScript 的语义，各种奇葩的作用域规则，而且结构非常简单。说白了，这个换名器也是一种解释器。对解释器的深刻理解，让我可以很容易的写出任何语言的换名器。



    不幸的是，历史再次重演了 ;) 队友们听说我花一下午重写了一个换名器，非常紧张，咋呼地跟我说：“你知道我们的换名器是花了多少个月的时间做出来的吗？你知道我们写了多少测试来保证它的正确性吗？你现在一下午做出来一个新的，你如何能保证它的正确！” 我不知道他们怎么好意思说出这样的话来，因为事实是，他们花了这么多个月，耗费这么多人力，写了这么多的测试，做出来的换名器却仍然有 bug，没法用。当我把我写的测试和几个大点的 open source 项目（AngularJS, Backbone 等）放进他们的换名器之后，就发现有些地方出问题了，而所有的测试和 open source 项目通过我的换名器，却得到完全正确的代码。另外经过性能测试，我的换名器速度要快四倍的样子。所以就像 Dijkstra 所说：“最优雅的程序往往也是最高效的。”



    结束这个项目之后，我换了一个团队（cluster团队），这个团队的人要好很多，低调而且幽默。Shape Security 的产品（Shape Shifter）里面包含一个高可靠（HA）集群管理系统，它可以通过网络，选举 leader，构建一个高容错的并行处理集群。这个集群管理系统一直以来都是公司里很复杂，却是可靠性要求最高的一个部件，一旦出问题就可能有灾难性的后果。确实，它当时可靠性非常高，从来没出过问题。但由于历史原因，它的代码过度复杂而缺乏模块化，以至于很难扩展来应付新的客户需求。我进入这个新团队的任务，就是对它进行大规模的简化，模块化和扩展，让它满足新的需求。



    在这个项目中，由于代码的改动幅度很大，在同事和部门领导的理解，信任和支持下，我们决定直接抛弃已有的测试，完全靠严格而及时的 code review，逻辑推理，推敲讨论，手工试验来保证代码的正确。在我修改代码的同时，一位更熟悉已有代码的队友一直通过 git 默默监视着我的每一次改动，根据他自己的经验来判断我的改动是否偏离了原来的语义，及时与我交流和讨论。由于这种灵活而严格的方式，工程不到两个月就完成了。改进后的代码不但更加模块化，更可扩展，适应了新的需求，而且仍然非常可靠。假设部门领导是“测试教条主义者”，不允许抛弃已有的测试，这样的项目是绝对不可能如期完成的。然而在当今世界遇到这样领导的机会，恐怕十个人里面不到一个吧。


Coverity


    最后，我举一个由于测试方式不当而非常失败的案例，那就是 Coverity 的 Java 静态分析产品。我承认 Coverity 的 C 和 C++ 分析器也许是非常好的，然而 Java 的分析器，很难说。当我进入 Coverity 的时候，同事们已经忍受了整整一年的管理层的威逼和高压，超时过劳工作，写出了基本的新产品和很多的测试。可是由于技术债太多，再多的测试也没能保证产品的可靠性。



    我的任务就是利用我深入的 PL 知识，不停的修补前人留下来的各种蹊跷 bug。有些 bug 需要运行20多分钟之后才出现，一次还看不出是怎么回事，所以修起来非常耗时。有时候我只好趴在电脑前面养神，时不时的睁眼看看结果。Coverity 是如此的在乎测试，他们要求每修复一个 bug 你就必须写出新的测试。测试必须能够如实的重现 bug 的现象，修复之后测试必须能够通过。这看似一个很在乎代码质量的做法，然而它不但没能保证产品的稳定可靠，而且大幅度的减慢了工程进度，并且造成员工的疲惫和不满。



    有一次他们分配给我一个 bug：在分析一个中型项目的时候，分析器似乎进入了死循环，好几个小时都不能完成。因为 Coverity 的全局静态分析，其实就是某种图遍历算法。当这个图里面有回路的时候，你就必须小心，如果不问青红皂白就递归进去，就可能进入死循环。避免死循环的办法很简单，你构造一个图节点的集合（Set），然后把它传递到函数里面作为参数。 每当访问一个节点，你先检查这个节点是否已经在这个集合里，如果在你就直接返回，否则你就把这个节点加入到集合里，然后递归处理这个节点的子节点。它的 C++ 代码大概就像这个样子：


void traverse(Node node, Set&lt;Node&gt; &amp;visited)
{
  if (visited.contains(node)) {
    return;
  } else {
    visited.add(node);
    process_node(node, visited);   // 里面会递归调用 traverse
  }
}



    查看代码之后我发现，代码其实没有进入“死循环”，而是进入了指数复杂度的计算，所以很久都不能完成。这是因为写这函数的人不小心，或者没有理解 C++ 的函数参数缺省是传值（做拷贝）而不是传引用，所以他忘了打那个“&amp;”，所以函数被递归调用的时候不是传递原来的集合，而是做了一个拷贝。每一次递归调用traverse，visited 都得到一个新的拷贝，所以返回之后，visited 的值就恢复到之前的状态，就像 node 被自动 remove 了一样。所以这个函数仍然会在某种情况下再次访问这个节点。这样的代码不会进入死循环，然而在某种特殊的图结构下，这会造成指数级的时间复杂度（请想一下这是什么样的一种图）。



    本来很明显的一个图论算法问题，加一个“&amp;”就修好了，手工试验也发现问题消失了。然而 Coverity 的测试教条主义者们（包括写出这 bug 的那人自己），吵着闹着，严肃命令我必须写出测试，构造出可以造成这种后果的数据结构，确保这个 bug 不会再重新出现。



    为一个我根本不会犯的错误写测试，而且它不可能再次发生，这不是很搞笑吗？就算你写了测试，也不能保证同样的事情不再发生。如果你不小心漏掉“&amp;”，下次同样的问题还会发生，并且发生在另外的地方，而你却没有给那块代码写测试，所以给这个 bug 写测试，并不能防止同样的问题再次发生。这就像一个技术不过关的赛车手，他在别人不大可能撞车的地方撞了车，然后就要求赛场在那个地方装上轮胎护栏。可是下一次，这个车手又会在另一个其他人都不会撞车地方撞车……



    稍微有点图论常识，熟悉 C++ 基本概念的人，都不会犯这种错误。防止这种问题，只有靠个人的技术和经验，而不能靠测试。防止它再次发生的最好办法，恐怕是开个会把这个问题讲清楚，让大家理解，下次不要再犯。所以给这个 bug 写测试，完全是多此一举。跟队友们讲解了这个原理，他们听了之后，仿佛什么都没有听到一样，仍然强硬的要求：“可是你还是得写这个测试，因为这是我们的规定！你知道要是出了 bug，送一个销售工程师去客户那里，要花多少钱吗……” 无语了。



    Coverity 的 Java 分析，就是经常因为这种测试教条主义，使得项目进展及其痛苦和缓慢，却仍然 bug 百出。Coverity 的其他的问题，还包括我上面指出的，写重复的测试，一个测试测太多东西，使用字符串比较来做测试，等等。你恐怕很难想象，一个制造旨在提高代码质量的产品的公司，自己代码的质量是这样维护的 :P


完


    由于绝大多数人对测试的误解如此之深，测试教条主义的流毒如此之广，导致许许多多优秀的程序员沉沦在繁琐的测试驱动开发中，无法舒展自己的长处。为了大家有一个轻松，顺利又可靠的工作环境，我希望大家多多转发这篇文章，改变这个行业的陋习。我希望大家在工程中理性的对待测试，而不是盲目的写测试，只有这样才能更好更快的完成项目。



    （由于这篇文章包含了我很多年的经验和深入的见解，希望你觉得有收获的话为此付费。建议价格是5美元，或者30人民币。【付费方式】）


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 Tesla autopilot 引起致命车祸

 
 
 
 
    

    
 
     
  

      
   
Tesla autopilot 引起致命车祸

    好一段时间没关心 Tesla 了，今天才发现他们的 autopilot 终于引起了致命的车祸。这场 Model S 撞上18轮大卡车的车祸，发生于5月7号，距今已经两个月了。 Tesla 把这事隐瞒了两个月之久，直到现在美国国家公路交通安全管理局（NHTSA）开始调查此事，才迫不得已公之于众。由于 Tesla 没有及时向政府监管部门报告事实，政府正在考虑对 Tesla 公司采取法律行动。



    本来都懒得再提 Tesla 这公司的名字，但是由于 Tesla 对于这起车祸态度极不端正，不但隐瞒事实，而且继续找各种借口为 autopilot 开脱罪名，让这玩具级别的技术继续危害无辜开车人的安全，很多人（包括新闻机构）对此的分析很多都抓不住关键，所以我不得不再出来说几句。



    死者名叫 Joshua Brown，40岁，曾作为炸弹专家，服役美国海军11年之久。退役以后成立了自己的技术公司，近段时间热衷于 Tesla 的电动车技术，还建立了一个 YouTube 频道，用于演示自己的 Tesla 车子。所以可以说，Joshua 对 Tesla 的 autopilot 使用方法已经很熟悉了。然而这不幸的事件，恰恰就发生在这个专家用户和热心人身上。



    Tesla 方面称，那天 Joshua 行驶在佛罗里达州一条中间有隔离带的公路上，符合规定的启用了 autopilot。行车途中，前方有一辆18轮卡车左转，由于卡车车厢是白色的，后面的天空也是白色，所以 autopilot 没发现这个卡车，没有进行刹车，最后 Model S 撞上卡车，车主身亡。白色卡车衬托在白色天空上，所以 autopilot 就把卡车当成空气，这是个什么情况……



    先不说这技术有什么问题，出了这种事情，Tesla 对此反应让人非常的失望。不但没有基本的自我检查，反而各种狡辩，把责任全都推到用户身上。首先，他们从统计的角度，说明 Tesla 车引起死亡的比例，比其它车子小很多。然后旁敲侧击地想说明，就算是那人自己开车，也不能避免这种车祸。最后他们再三的强调，autopilot 的说明书已经声明，功能还不成熟，如果看到要出事而没有及时接管，你们自己负责！



    这些都是 Tesla 老一套的诡辩方法。首先，Tesla 的死亡比例比其它车要小，并不能掩盖 autopilot 存在严重问题的事实。死亡比例小可能跟 Tesla 的技术没有很大关系，Tesla 是新公司，车都很新所以不容易出机械故障，而且买 Tesla 的都是有钱人，受过良好的教育，懂技术，所以一般不会乱开。那这种死亡比例，跟老牌子的车比是不公平的。其他牌子的车总数比 Tesla 多太多了，很多车子都十几二十年老掉牙，开车的各种人都有，酒鬼也有，老汉也有，罪犯也有，当然事故比例就上去了。如果你只看其它牌子最近几年的新车和豪华车，死亡比例拿来算一下，就很小。



    如果你光看 autopilot 导航的总里程数，事故比例恐怕就上去了，因为很多 Tesla 用户可能没有启用 autopilot，或者用的很少。Autopilot 不是第一次引起车祸了，之前我的另一篇文章已经提到，由于它的视觉技术不成熟，引发了许多险些发生车祸的情况，而且最近引起了好多次真正的车祸。要知道微小的比例落在一个人头上，就等于100%的不幸。等你因为 autopilot 而受害，才会发现 Tesla 摆出来的那些统计数字，对你其实毫无意义。也许，它确实造福了全人类，可惜死伤的人是你或者你的家人，而且那是因为 autopilot 极其弱智的判断错误…… 你会因为统计数字很安全而饶了 Tesla 吗？



    另外 Tesla 喜欢旁敲侧击的指出 autopilot 的驾驶能力高于人类，而事实并不是那样。你怎么能证明人开车不能避免这车祸？Tesla 说：“驾驶员和 autopilot 都没有看到卡车。” 你们怎么知道驾驶员没有看见卡车？那可是18轮的大卡车！说白色的侧面车厢映在白色的天空，所以人看不见它，这不是搞笑吗。



    一个东西是白色的，不等于它是看不见的，一个不透明的东西会挡住后面的景物，这一点人是很清楚的。白色的物体也会有反光，纹理会跟天空不一样，人可以通过这种反光感知它的存在。卡车不止有白色的侧面，还有黑色的轮子，车头上有烟囱，车窗，油箱，…… 各种其它颜色的附件。为了让其他人在夜间能看到车厢的大小，大卡车必须在车厢的八个角上都安装红色的警示灯，这些灯在白天不亮的时候也看得见的。就算天空是白色，人也是不可能看不见它，把卡车当成空气的。所以我猜真实情况是，驾驶员发现 autopilot 判断错误，想接管过来，但已经来不及了。要知道这个反应时间也许不到一秒！人死了，当然死无对证。



    从多次的事故现象中，我分析出这样一个规律，虽然 Tesla 声称 Model S 上装备了雷达和声呐，但是 autopilot 的操作却似乎仅靠摄像头的“像素”，通过神经网络进行图像分析，所以它才会连18轮大卡车这么巨型的东西都没有发现，在路上看到个树影还以为是障碍物…… 这些都是人根本不会犯的奇葩错误。我请大家不要对自动驾驶技术过于乐观，急于求成。机器视觉在某些地方是很有用的技术，然而它要能被用于自动驾车，还有非常长的路要走。



    Tesla 确实警告过人们，说这个技术还不成熟，你必须把手一直放在方向盘上，准备随时接管，然而这并不能免除 Tesla 的责任。首先，Tesla 根本就不应该把不成熟的技术发布出来，而且大肆宣传，搞得大家以为它很先进很可靠似的，争相试用。其次，说明书上的警告，在法律上也许是没有效力的。你要求别人随时接管，那么你必须在可能判断错误的时候给出警示，而且给人足够的响应时间，才能算是合理。



    Autopilot 的设计是有严重问题的。它操纵着车子，却不给人解释自己看见了什么，准备进行什么操作，在道路情况超越了自己能力的时候，也不给人提示，以至于人根本不知道它出了问题，不能及时接管。要知道，车在直走的时候，autopilot 是否判断正确，人往往是看不出来的。一辆没有 autopilot（只有普通  cruise  control）的车子，跟一辆启用了  autopilot 的车子，在匀速直线运动的时候，人是无法察觉出任何区别的。可是人知道 autopilot 会自动刹车，而普通的  cruise  control 不能，所以人就会期望有 autopilot 的车子会刹车。等你发现它一声不吭，前面有障碍物却没有刹车，才会知道它有判断错误，可是那个时候就已经晚了。



    所以在这种情况下，Tesla 虽然事先有“免责声明”，把责任全都推在用户头上，在法庭上其实仍然可以败诉，因为他们对用户提出的要求是不切实际的，没有人能够在上述 autopilot 判断错误情况下及时的接管过来。我建议这起车祸死者的家属把 Tesla 告上法庭，要求巨额赔偿。我也建议所有 Tesla 的车主，为了对自己和他人的生命负责，请关闭 autopilot 这个功能！Tesla 根本就不懂如何设计自动驾驶系统，技术不过硬，设计有缺陷，基本就是个玩具。生命很宝贵，用自己的生命来给所谓的“新技术”做试验品，是不值得的。



    珍爱生命，远离 autopilot！


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 Google Maps的设计问题

 
 
 
 
    

    
 
     
  

      
   
Google Maps的设计问题

    我开车的时候喜欢用 Google Maps 导航。虽然我对 Google 这公司挺有意见，然而 Google Maps 确实是好东西。比较过其他几个导航软件（Waze，Scout Maps）之后，我发现 Google Maps 在大部分时候还是表现最好的一个。



    然而这并不等于它的设计是没有问题的。Google Maps 时不时的会改变设计，有些地方改进了，另外一些地方却可能被改得还不如以前。我已经不止一次的向 Google Maps team 提出反馈意见。



    现在我就把最近烦扰我的一个问题讲一下。我已经通过 app 给 Google Maps team 发送了 feedback，但我希望这种设计问题引起足够的重视，所以也在这里说一下。



    这个最近发现的问题是，Google Maps 显示的公路号码字体太小。它把州际公路（interstate）之类的公路号码，显示成路牌上的样式。比如下面的这个 Interstate 880，被显示成带有弧形花边，红蓝底色的路牌样式。



    



    这看似美观，平时在手机上看貌似没什么问题，然而在开车的时候你就会发现，里面的号码很难看清楚。其原因是：




    把带有这个花边的路牌嵌入到导航提示里面之后，由于整个路牌的高度和旁边字体的高度一样，公路号码“880”的字体，比旁边的字小了很多（请比较“880”和“North”的大小）。


    在开车的时候，手机架在机座上，离眼睛有一定距离，而且由于车速很快，你只有不超过一秒钟的安全时间可以去瞄手机。所以我经常发现瞄一眼是根本没法看清楚这个花边里面的号码（880）的，你得盯着手机看好一会儿。有时候我把头凑近手机，都很不容易看清楚。这对于开车的人是一个不小的干扰，可能会引起交通事故。


    湾区的很多高速公路号码只差一个数字，比如 280，380，680，880…… 这么小的字体，很容易看不清楚这号码到底是哪一个！





    实际上你观察一下真正的路牌，就会发现公路号码的字体，跟旁边文字的比例，并不是像 Google Maps 上那个样子。请观察下图中的路牌，号码“280”和“101”的字体，和旁边的文字“SOUTH”，“TO”，“NORTH”，“San Francisco”其实是一样大，甚至更大一些。加上 INTERSTATE 的盾形花边，这个标志的尺寸比旁边的文字要大很多。



    



    所以 Google Maps 一片好心，想把公路号码做得很“形象”和“直观”，做得像路牌的样子，结果比例不对，帮了倒忙。对此我提出的建议是：



    方式1：不要把公路号码显示为路牌的样式，直接使用像“I-440”这样的文本来显示路名。很少有人会在乎公路号码的样式是否美观，他们只在意是否能清楚地看到号码，所以这可能是最好的选择。很多其他导航软件和专用 GPS 设备（比如 Waze，Garmin）都是直接采用文本显示公路号码。



    方式2：保留路牌样式，但是需要把路牌的尺寸增加到真正的路牌字体比例，也就是说让路牌里的号码跟旁边的字体大小一样。这个方式放到 Google Maps 的导航提示里面，恐怕会让导航提示的宽度变大，占用更多屏幕空间，所以虽然也许可行，但可能不如第一种方式。


其它一些问题


    当然，字体大小并不是我发现的 Google Maps 唯一的问题。它还有其他一些小问题，有一些我已经向 Google Maps 的 team 提供了反馈，已经修复，还有一些仍然存在。现在我把这些小问题指出来，其中一些相当的讨厌：




    [已修复] Google Maps 曾经在一段时间采用这样一种设计：当它通过对交通信息进行分析，得知有另一条时间更短的路线，它会弹出一个窗口，询问用户是否要选择这条更快的路（Yes/No?）。这个窗口有十几秒的延时，到时间之后如果你没有按屏幕，窗口会自动消失，并且自动选择新的路线。



    缺省选择新的路线，是一个很不合理的设计。在开车的时候，你必须集中注意力在路上，几乎没有时间去相应弹出的窗口。而且这个窗口字体和按钮都很小，开车人可能根本没时间去读里面的内容，即使读了也不容易按中正确的按钮。到时间没有动作，导航系统自动切换到新的路线，而不是保留用户最初的选择。未经允许改变用户的路线选择，可以说是一个反人类的设计。



    我及时向 Google Maps 团队提供了强烈的反馈，这个问题已经改变。现在缺省的选择是保留原来的路线。


    [还存在] Google Maps 有时候会忽然重新计算并且改变原来的路线。改变的原因也许是因为开车人没有按原路线走，然而这有可能不是开车人的意愿。举一个例子，从南湾地区去三藩市方向，有两条高速公路可以走：280 和 101。白天我一般会选择 280，因为 280 车不多，而且风景优美一些。我会在 Google Maps 界面选择 280 的路线。



    然而当我开出停车场，在第一个路口由于 GPS 的方向还未适应过来，我有可能转错方向。这个时候 Google Maps 会根据我的方向重新计算路线，这时候它很有可能自动把整个路线换成走 101，而不再是 280。由于最初的方向错误而换掉整体要走的高速公路，是非常不合理的。你以为它会按你原来的选择走 280，结果最后发现它把你带到了 101 的入口……




   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 养生节目带来的危害

 
 
 
 
    

    
 
     
  

      
   
养生节目带来的危害

    国内总是流行各种各样的“养生节目”，深受中老年人的欢迎。比如我爸妈，有时无聊了，就会转发给我一些养生节目，比如这个：『多喝白开水带来的危害』。这节目说，有人得了过敏性鼻炎，喷嚏鼻涕不断，严重脱发，头都半秃了，虚弱无力，性能力衰退…… 最后专家得出结论，是因为他每天早上喝一杯凉水导致的！



    据我观察，这些养生节目里面的理论，基本可以归为两种：好的和新的。可惜好的理论都不新，新的理论都不好。


好的理论


    第一类理论，就是把人们早已熟悉的，久经考验的常识，比如早晚要刷牙之类的，拿来包装成“新理论”。这些理论当然错不到哪里去，然而却是每个人从小都已熟知的。现在挂着“专家”头衔的人出来一宣传，这些斯通见惯的常识，忽然间被老人家们当成了最新的研究成果。



    我遇到的这种例子挺多的。有时候父母给我发个信息，说你要注意这个那个习惯啊，不然会得什么什么样的病…… 这本来就是我从小就已经知道并且照办的事情，而且我还记得当年这东西就是我爸妈教给我的。现在让这帮“养生专家”一忽悠，倒像个新鲜事，又拿出来讲一遍，好像别人不知道一样…… “专家”的威力就是这么强大 :P


新的理论


    第二类理论，就是胡编乱造出一些“新理论”，却没有经过科学实验证实。『多喝白开水带来的危害』就属于这一种情况。通常这种理论把问题的原因归结为某一个生活习惯（比如早上喝一杯凉水），而忽略所有其它引起问题的因素。这些理论的问题在于，它们通过臆断，得出错误的“因果关系”。



    据我了解，过敏性鼻炎，脱发等问题，很多都是因为基因遗传，跟人平时的生活习惯几乎没有关系。现在有一个人出现了过敏性鼻炎和脱发，而且碰巧这人早上起来喜欢喝一杯凉水，于是专家就得出一个可笑的结论：一定是喝凉水引起了过敏性鼻炎和脱发。



    养生专家们很喜欢把健康问题跟某些不起眼的习惯挂钩，这样就可以创造一些惊人的理论，却无法验证其真实性。他们可以说，就是因为你这个小小的习惯，导致了如此严重的健康问题。这样一来，他们就可以告诉你吃什么，不吃什么，做什么，不做什么。每过一段时间，这些人都会换一套不同的说法，让你感觉有新东西出来，却没发现这些其实跟之前的说法自相矛盾。老年人记性不好，看不出破绽，有些人为了健康不惜一切，仿佛活着就是为了不停地研究如何才能继续活着…… 这就是这帮养生专家和养生节目得以生存的关键。



    得出喝凉水引起了鼻炎，脱发，身体虚弱这样的结论，且不说它看起来有没有可能，你必须先经过科学实验。你不能只看一个人，因为数据量太小，很可能是偶然巧合，没法建立因果关系。所以实验必须要有两组人进行对照，就是所谓“对照实验”。一组人早上喝一杯凉水，另外一组人不喝。过一段时间，分析这两组人里面出现上述问题的人的比例，如果喝凉水的人大部分出现了问题，而不喝凉水的人大部分没有出现问题，你才有可以得出“喝凉水导致鼻炎和脱发”这样的结论。



    显然，这个节目里的专家并没有经过实验，而是引用（滥用）『黄帝内经』里面的各种阴阳理论。说早上阳气上升，喝一杯凉水把阳气给浇灭了，怎么能不得病哪！这显然是完全不科学，不负责任的说法。实际上这套阴阳理论是如此的模棱两可，跟占星学如出一辙，你可以利用这些说法来解释世界上的几乎任何现象！不管遇到好事还是坏事，同样的一句话，可以同时支持两种完全相反的结果。为什么它可以这样呢？因为这些说法本来模棱两可，所以不同的人从不同的角度去解释它，发现都是说得通的。



    这些养生节目，经常把严重身体问题的起因，归结为某些生活上的小习惯，吃什么，不吃什么之类，很容易让人忽略真正的起因，更加严重的因素，这属于一种误导。中老年人看了这些节目，往往盲目的认为坚持或者改变生活上的一些小习惯，就可以避免或者修正一些严重的身体疾患，结果耽误了真正科学研究出来的补救办法。在这种意义上，养生节目是有危害性的。我建议中老年人少看这种节目，多跟真正的医生了解科学的医疗知识。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 欧盟草拟法案，对机器人征税

 
 
 
 
    

    
 
     
  

      
   
欧盟草拟法案，对机器人征税

    据路透社报道，欧盟正在草拟一个关于机器人的法案。由于机器人以及智能机器的使用，可能带来空前严重的失业问题，这项法案要求所有使用智能机器人的公司，如实向政府汇报由于机器人的使用，而节省下来的人的工资，然后政府据此征收社会安全税，给人发放相应的福利。这个法案跟我的一个想法类似：每当机器人取代一个人的工作，使用机器人的公司就有义务要养活那个人。



    很多机器人公司在抱怨，说这会阻碍机器人行业的发展，然而我觉得这正是欧盟关爱人民的表现。对机器人的使用进行征税，对于社会的安全和幸福是非常有必要的。用机器人代替人的劳动，导致人失业，却不安顿好失业者的生活，属于一种掠夺或者抢劫的行为。这不但会大幅度降低社会幸福感，而且会导致社会安全问题，比如犯罪率上升等等。



    人的权益应该是崇高致上的，所有损害人的切身利益的做法，都应该付出代价，哪怕这会阻碍技术的发展。要记住，技术是为人服务的。如果技术给人和社会带来的不是幸福，而是困苦甚至灾难，那我们就应该理智的延缓甚至取消技术的发展，或者为此征税来维护人的权益。



    世界上聪明人太多了，却缺乏智慧的人。欧盟的这一法案让我看到了希望。我希望世界上所有国家，特别是美国和中国，都意识到这个问题。大部分的社会财富集中在极少数人手中，这样的社会是不会幸福的。就算你钱再多也一样，你只会看到一片荒凉，到处是饥饿而势利的人。你不再会有朋友，只有对你的钱感兴趣的人…… “独乐乐，与人乐乐，孰乐乎？不若与人。” 我们都应该明白这个道理。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 两个计划的变动

 
 
 
 
    

    
 
     
  

      
   
两个计划的变动

    我有两个计划的变动，一个是关于离开美国，另一个是关于写书计划。


离开美国计划的推迟


    有些人可能发现了，之前写的『关于离开美国的决定』，其实算是一时冲动的结果。我对美国的意见不会变化，然而生活还是需要折中考虑，一步一步的来。我不喜欢美国的制度，绝大部分原因是因为过去几年的经历，以及亲眼目睹作为“美国人”的女朋友的一些经历。



    美国在对于劳动者的福利和保护方面确实很不好，很多时候可以说是任凭雇主欺压员工，没有法律保障。然而一个现实的问题是，我们现在没有能力改变它。我离开中国十年了，一点都不了解现在的中国社会，也没有任何现实可行的计划让我的生活有所保障。父母对此也不大支持。在这样的情况下回国，就有点像没有带好降落伞就跳出一架引擎发出怪响的飞机 :P



    前几年的遭遇虽然很惨，觉得根本不应该发生在我身上的事情，居然都发生了，可是我毕竟已经度过了最困难的时候。老实说，现在这个公司其实对人挺好，特别是现在的团队的同事特别好。我在这里其实已经有了一些同类的朋友，我有女朋友，女朋友的爸爸妈妈，弟弟妹妹，…… 他们都很关心我，这是很宝贵的财富。过度的思考以前的不幸，让我没有看到离开的代价，这个代价是非常大的。



    所以在看好前面的每一步之前，我不得不推迟所谓的“离开美国计划”，不能冲动行事。当然我会继续观察国内和其它国家的情况，看好了之后也许会有动作。当然我感谢大家的支持。由于这篇文章和之前的『未来计划』，有一些现在和以前的同事都表示很关心，我也新结识了一些有相似经历和思想的人。他们找我聊天，表示关心和支持，聊得挺投机的。



    所谓同类相吸，我觉得这些人和我，已经建立起一种互相支持的氛围。所以如果你喜欢我的想法，也可以联系我。也许有一天，我们这些意气相投的人会走到一起来……


写书计划的取消


    之前我有感于计算机科学教育不求甚解，以讹传讹的现状，想写本书来传播我所掌握的精华。然而面对社会的现状，我不得不取消这个计划。取消的原因不是因为写不出来或者没有时间写，而是因为我发现并不是每个人都应该得到真知。卖知识是一种非常不划算的生意。有些信息太过宝贵，远不是一本书的价钱可以买得到的，甚至不是大学四年的学费可以付得起的。我不愿意让它们落到阴险的人或者敌对势力手里。



    这里面是有一个故事的…… 曾经有个人看了我的文章联系我，加了我的 QQ。他对 PL 的东西很感兴趣，我觉得他挺聪明又好学，就给他讲了很多。不过我也看出来，他并不是科班出生，没经过名师指导，民科一样瞎弄，所以很多概念都是乱的，喜欢把问题搞复杂，但我还是耐心地给他解释。后来他的问题越来越多，暴露出的知识缺陷和误解也越来越多，始终没有说出有价值的见解。



    直到一天，有个朋友跟我说，这人在知乎上黑我，我才恍然大悟。原来他一边在 QQ 上请教我，同时却背地里在知乎上评论我，说：“王垠就是吹得厉害，某些很基本的东西他其实都不懂。有一次我问他那什么什么，结果他吹了一通，最后也没说清楚……”



    事实是，由于一段时间以来他不停地问问题，从我这得到了太多有价值的信息，却没有任何付出。这人是敌是友还不知道呢，所以我决定对他留一手。没想到他一边跟我虚心请教的样子，一边却在知乎上跟小白们显示牛逼，背地里黑我，把我没告诉他的事情，说成是我不懂，把我没给他看的代码，说成是我不会写……



    这个人在知乎上很有名。为了给他留点面子和醒悟的机会，我就不点名了。然而我奉劝这类人，请不要在知乎上制造自己的名气，贬损其它人了。在网络上的名气和真实世界里的地位，是有非常大差别的。人们不会因为你在知乎上排名很高，就在现实工作中给你重要的职位。只有在真实的人际关系中踏踏实实做事，诚实为人，得到现实中人们的认可，才会得到真正的尊重。



    出现了这样的人，让我非常的心寒，我深刻地认识到，并不是所有人都是我想象中那么善良。我无偿的把经过千辛万苦，跋山涉水得来的宝贵财富，给了一个阴险的小人。这种人很聪明，然而却缺乏洞察力和深刻的思维。让他们得到了这样的东西，这些人就会到处张扬，最后不知情的人还以为是什么天才。我用自己泛滥的爱心和拯救世界的愿望，帮助了一些别有用心的人，结果只会让世界变得更糟。



    我不止一次的遇到这样的人，所以现在要分析什么技术问题，都得很小心点，不让人轻易得到背后的思想。鉴于这个原因，我决定取消写书的计划。我不愿意把深刻的思想用书的形式送给所有人，可是我又不会像某些作者那样随便写点肤浅的东西，所以我只好不写了。



    就像武林高手不把绝招轻易传授一样，在技术的领域也是一样。真正的精华，只能在完全确信对方的身份和人品之后，在互惠互利的情况下，才能部分的指点。只有这样才能够平衡世界上的善恶两种势力，让强大的力量只帮助那些善良的人，最终达到一个更好的世界。我的几个教授，包括 Dan Friedman 和 Kent Dybvig 都是这样做的，对未经深入了解的人保留很多秘密，我现在终于理解了为什么。



    这就是为什么有陌生人发 email 问我深入的问题，一般都没有回复。就算是同事我也会在潜意识里分成不同的信任级别，并不是每个人我都会跟他畅谈技术。你必须认识我，而且人品必须好，我才有可能跟你探讨问题。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 IT业给世界带来的危机

 
 
 
 
    

    
 
     
  

      
   
IT业给世界带来的危机

    昨天写了文章之后，回忆起这几年在湾区的经历，觉得自己是一个很不幸的人。然而就在今天，我的自怜奇妙的转换成了另一种感情，因为我看到了更不幸的人……



    正在女朋友 Cinny 的父母家吃饭，忽然窗外来了一个人。仔细一看，是个约莫十来岁年纪的漂亮白人女孩，她说：“亲爱的，你们想要一些刚从树上摘下来的新鲜李子吗？” 据女朋友妈妈介绍，她是邻居的女儿。之后我尝了一个李子，颜色已经黑透了，非常新鲜非常甜！



    随后我和 Cinny 出去散步。在她家的对面，耸立着两栋高大华丽的豪宅，看那样子，价值恐怕超过200万美元。两栋豪宅的中间，夹着一间样式非常不搭调的便宜小矮屋。这屋子周围被篱笆围了起来，可以看见里面种了很多的植物。在那门口的无花果树下，赫然出现这样的一个牌子：



    



    它说：“请不要摘我的无花果。我失去了我的工作，需要依靠自己种的食物为生。我是一个生物学家，如果你知道有任何的工作，请告诉我。谢谢！” 这树上还挂着好几个类似的牌子，从它们看来，这位生物学家已经失业一年了……



    



    Cinny 说，吃饭时给我们送果子来的女孩，就是这家的孩子。我想起她甜美的笑容，不禁一阵心酸！哎，谁才是真正可怜的人？我之前在无病呻吟些什么啊……



    这些年来湾区的 IT 业大量的扩张，Apple，Google 等公司不停地在附近建新的办公楼。IT 业的过度发展，导致了其它行业的衰落，让附近土生土长的居民生存困难。本来公司的扩张应该引起经济的流通，社区的繁荣，人气的高涨，结果每当像 Google 这样的公司提供免费餐饮，附近就会有多少店铺关门，又有多少人失业，成为一片荒漠……



    是的，大家节省外出买饭的时间能为公司赚很多钱，自己也节省了不少开支。但是这些公司真的回报了社会吗？新闻早已经曝光，这些大公司利用美国税法的漏洞，每一家每年都导致政府少收上亿美元的税钱。没有收到税，就没法给这些丢了工作的人发福利，以至于他们落魄到这种地步。



    Cinny 告诉我，这家人可能也要卖掉房子，搬到别州去了。之前有好些邻居已经搬走了，其中有一些以前在附近开小店，卖很好吃的东西。现在这些儿时的美好回忆，都已经不在了……



    我们一直盲目的以为技术会改善人们的生活，很多人总是试图做一些 O2O 服务，甚至研制机器人和自动车，这样可以代替许多人的劳动。如果这些技术真的能代替繁重或者危险的劳动，那确实好。可是如果发明这些技术的公司不回报社会，反而想办法钻法律的漏洞避税，那就变得有害了。在创造这些技术的同时，我们有想过因为它们而失去工作，而又因为公司不交税，不回报社会而变卖房产，颠沛流离的无辜人们吗？



    作为一个 IT 人，我们不得不思考，这是不是一种无情的掠夺，我们是不是害虫？当我们帮助雇主掠夺了别人的工作之后，我们自己会不会就是下一个被社会抛弃，丢掉工作的人？“独乐乐，与人乐乐，孰乐乎？不若与人。” 我们在思考如何发展自己事业的同时，也应该思考如何回报社会了。否则我们面对的将是一片毫无生气的荒原，我们不会再看到幸福的笑脸……



    有人说这一切都是资本主义造的孽，而不能怪 IT 业。不过由于 IT 存在高度的“智能”和“自动”，它已经开始给资本主义的社会关系带来灾难性的影响。有位大胡子说，无产阶级是资本主义的掘墓人，那么我说，IT 业就是资本主义的定时炸弹，它离爆炸的那一天已经不远了。



    我想我们应该都能做点什么…… 话说，如果你知道湾区有招生物学家的工作，请联系我！


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 关于离开美国的决定

 
 
 
 
    

    
 
     
  

      
   
关于离开美国的决定

    很多人看了我的『未来计划』之后联系我，热心的给我提供线索和帮助。记得差不多两年以前，我因为某些人的卑鄙作法而突然丢了工作，导致签证出现问题。在那个危机关头，也有很多人伸出援助之手。在此我对这些人一并表示由衷的感谢。



    虽然我口头上自嘲，实际上生活过得并不差，吃好穿好住好，还有漂亮妹纸陪 :) 只是由于美国社会的不合理，我没法发挥自己的能力，没有得到我应有的回报。由于我深入的洞察力和卓越的实现能力，一个建议就可以避免团队走很多弯路，我给曾经任职的每个公司提供的价值都超过百万美元，可是我没有看到合理的回报。所以现在的生活跟我的实际能力，显然差距太远。



    我觉得现在是该离开美国的时候了。虽然我拿着某知名低调大公司一个不错的 offer，其实我早已对美国彻底失望了，我不准备接受这个工作。一个具有卓越才能的人，在这个国家有过如此悲催的遭遇，才能一直得不到发挥，处处被压制，只能说明这个国家存在非常严重的问题。美国不再是一个尊重人才的国家，它已经被野心家和吹牛扯淡的官僚政客所控制。这次很多人推荐给我美国公司的工作，各种热门公司都有。可是简单了解他们的“文化”之后，我都失去了兴趣，放弃了跟他们面试的机会。我感谢这些人，然而我的心已经不在美国。



    对美国的失望不止因为事业的不顺，我已经彻底厌倦了美国的生活。人们都说美国是个大农村，好山好水好寂寞，这是千真万确的。一个人的时候很无聊，两个人的时候也没有好到哪里去。我交往了一年多的新女朋友从小在美国长大，是个“融入了美国文化”的，漂亮时尚的 ABC 妹纸。跟她在一起久了，也没有感觉好到哪去。到后来约会都不知道该干什么了，因为想不到附近还有什么有意思的地方值得常去的！同事们所谓的休闲，也就是爬山一类的事情，爬一次还好，多两次就发现没意思了，正所谓好山好水好寂寞嘛 :) 在这个文化和人心的沙漠，无论你是否单身，都无法摆脱那黑压压的孤独感。



    在中国吃个夜宵，穿上短裤拖鞋走过两个灯火通明，人行道宽敞的路口，就发现人来人往，什么都有。在美国吃个夜宵？在黑洞洞的大马路上开十几分钟的车，若隐若现的 plaza 中间忽然出现一家还亮着灯的饭店，旁边的商店饭店都早已关门，鬼屋一样的死寂。你朋友圈出现的烤串照片，说“咱美国也有吃夜宵的地方啦”，就是这样的背景，没有气氛和文化，只有味道一般般的烤串。这还是近两年才出现的，不知道哪天又因为某大公司为鼓励员工熬夜工作在内部开设夜宵而倒闭也说不准。到了荒漠中的夜宵店，走近一看，门口停着几辆车，站着十几个人。店家没好气的对你说：“等待时间大概是半小时！”



    整个国家的设施和道路被设计来方便开车，大片的面积被停车场占据，拉大了人与人的距离，也许是美国如此无聊的一个原因。你不可能悠闲的牵着女友散个步，然后顺便买点东西吃。商店和饭店都被道路分成一小块一小块的，人行道非常狭窄，只能走一个人，或者干脆没有人行道，旁边的车以每小时40英里的速度在你耳边呼啸而过。近在眼前的商店你也没法步行到达，必须钻进那铁盒子才能安全地开到另一个地方，然后又得经过一番找车位的折腾。有时候车位全满，你还需要绕来绕去的“蹲坑”甚至“跟踪行人”，看别人走了你才能趴进去。这样一番折腾之后，本来休闲的心情，全都因为各种紧张而消失殆尽。



    当然生活缺乏休闲精神，只是美国生活的一方面。最不满意的其实还是工作的不如意。有些人跟我说，等有了绿卡之后就会感觉自由一些了，然而我很怀疑这种说法。要说绿卡，我得来可以很容易的，我的女朋友从小就是美国公民，而且她很愿意跟我结婚 :P 我不是那么喜欢结婚的人，所以肯定不会为了绿卡而结婚。然而就算我拿到了绿卡，那又能怎样呢？美国公司混进管理层的人，往往不是靠能力，而是靠关系，而且对于中国人相当的排斥，就算你有绿卡，有美国公民身份也一样。有真知灼见的人的意见，往往被下层和中层领导所掩盖，完全得不到被上层领导赏识的机会。



    绿卡，可以说是美国用于敲诈外国人，让他们提供廉价劳动的强有力工具。很多人为了绿卡，连续好几年忍辱负重，拿着低廉的薪水，扛着巨大的压力，做着比美国人繁重的工作，到后来人都老了，头都秃了。可是绿卡会给你自由吗？有了绿卡你就不再能去其它国家定居，否则绿卡会被收回，而且在另一个国家赚的钱还得给美国缴税。美国政府这如意算盘打得可真好，利用绿卡把别人套牢在自己国家做苦力。我看到许多有绿卡，甚至有美国公民身份的华人，我并不觉得他们过得很好。一个很实在的例子，我的女朋友就是美国公民，我知道美国政府和公司对她并不好。美国不是一个关爱人民的国家，实际上它跟奴隶社会非常的接近，所以就算你成为美国公民又能怎样？很多人跟我提到要先解决“身份问题”，我很讨厌“身份问题”这个词。身为中国的主流社会，跑到这里来跟偷渡客难民似的，没有“身份”，好像没有自己的国家一样……



    来了美国十年了，基本上受了十年的罪。开头受了美国教育的欺骗，以为在美国能够静心的做研究，然后以为在美国可以发展自己的事业。可是到如今，一场场的骗局都已经揭穿，这一切都已经看透了。并不是我不能“融入”美国社会，而是我根本不屑于融入它。跟美国人聊天感觉就两个字，假和蠢。一百年前罗素（Bertrand Russell）就说过，美国是商人开的国家，美国的大学教授只是商人的仆人而已，商人只知道竞争，直到不需要竞争的时候还仍然在竞争，为所谓“生存压力”惶惶不得终日。他的话直到今天都还是对的。哈佛，斯坦福之类的学校尽培养一些商人和政客，吹牛的本事大。利用别人的劳动和发明，把功劳挂在自己头上，然后别人就以为自己是“成功人士”。



    美国人深深地为自己的文化感到自卑，所以一有机会就附庸风雅，显示自己跟欧洲的渊源关系。星巴克的咖啡中杯不叫“medium”，非要用个意大利词叫“grande”。从法语引进的词，非得要古板的按法语发音，漱喉咙一样，你按英语发音他们还指证你说这是法语~ 美国人互相之间的关怀，比起世界上很多其他国家都要差很多，特别是比欧洲国家要差非常多，甚至比日渐势利的中国都要差一些。中国社会的一些倒退作法，包括利益熏心，学术腐败，都是被美国传染而来的。



    美国人的教育和意识形态里鼓吹的贪婪，导致了这个国家的人民生活越来越艰难，所以就算它科技再发达，总体再有钱又能怎样？这个国家的财富对你已经不再有意义。亿万富翁们可以合法避税，收入过十亿的大公司利用税收法漏洞，把巨额收入报在不收企业税的百慕大一类的小国，结果总共只交不到3%的税，反倒让挣血汗钱的工薪阶层缴税超过收入的35%。90%以上的财富集中在10%的极少数人手里，社会最底层的人没有工作，政府却利用各种借口（比如因为你仍然有自己的房子）不提供社会福利和医疗保障。当技术的进步导致的不是人民的安逸和享受，而是进一步的失业率扩大，人民工作更辛苦，压力更大，生活困苦，医疗，福利和下一代的教育条件恶化，技术再发展又有什么意义？我怎么总觉得美国在走苏联或者纳粹德国的老路…… 我不能让自己的下一代诞生于这样的国家！



    很多中国人不理解欧洲国家的悠闲，觉得欧洲人太懒，在技术上落后于美国，真是天大的误解。很多欧洲人看到了技术发展会带来这样的后果，所以他们很明智的决定，不要研究什么智能机器了，继续让人去干很多事情。没工作的人也有很好的福利，养小孩上大学都不要钱，无忧无虑。上班的人就算是饭店服务员，都有各种法律保障，工作条件有保证，休息时间有保证，最低工资有保证，根本不用像美国的服务员一样，需要靠小费为生。欧洲劳动法不承认美国社会流行的所谓“at-will employment”，即雇主或者雇员都可以在任何时候无条件终止雇佣关系而无需提前通知或者警告，所以雇员不用担心随时会被炒鱿鱼。这就是为什么欧洲人过得比美国人开心，在欧洲国家生活比美国有趣。



    所以我已经决定要离开美国，这是思考了很久很久以后才做出的决定。我的下一站，当然是我的家。我会歇至少半年不工作，陪伴我的父母，会见我的老友。同时我可能静下心来思考未来的事业。我目前的想法是做一个自由职业者。我不再愿意成为某个公司的正式员工，继续做底层的编程工作。由于我的造诣和深入见解，我更愿意给一些公司做“顾问”性质的指导和初期的建模设计，而不成为那些公司的一员。由于我对各种技术深入精髓的理解，以及对于设计的见解，我可能会成立自己的咨询公司，面向企业，对各种 IT 技术提供分析和指导，或者对企业提供技术培训服务，就像著名的 Nielsen Norman Group。同时我也会花时间来发展自己的核心技术，包括 Yin 语言和最近对于数据库系统和存储系统的深度探索。



    总是有人跟我说国内的环境不好，说得跟水深火热似的，可是我觉得那只是片面观察和危言耸听。我觉得我还不至于在国内活不下去。我喜欢中国，并不因为它是我的国家，或者被政治书教的，这是通过与美国和其它国家比较得出的结论。中国的文化更加接近欧洲，而不像美国。这些国家经历了历史与战火，经历了无产阶级革命，就算失败之后，社会平等关爱的思想已经进入了很多人的心。两年前在国内待了两个月，我过街可能被车撞，在地摊上可能吃到地沟油或者毒牛奶，可是我却显然过得舒心很多，轻松很多，浪漫很多。我一点也不贪恋美国的秩序和设施的高质量。社会分配制度的不合理，文化的贫瘠，压迫，剥削，歧视和人心的险恶，使得那一切的安逸都失去了意义。当然将来我也可能周游世界其他国家，比如热爱休闲的欧洲各国，然而中国会永远是我的根据地和故乡。



    由于回国会带来一笔不小的安家开支，在这里我再次鼓励大家为一些高价值的文章付款，比如『怎样写一个解释器』，『编程的哲学』等。每篇文章的收费大概是5美元。之前已经付费的人就不用了，如果你不喜欢或者觉得没有收获的话也请不要付费，我不想欠别人人情。请注意你的付款并不是在无偿募捐或者施舍，这也不是在进行众筹投资，这只是你在为你使用了的好东西付款。我的文章比起很多教科书都要精辟，价值显然比5美元大很多。所以如果你从中收获了益处，按照经济学的原理，你确实是应该付费的。这种费用只针对特定的文章，付费之后并不等于我以后所有的作品你都应该免费获得。付费时请注明是在为哪篇文章付费。谢谢你的理解和支持！



    【PayPal付款链接】



    支付宝二维码：



    


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 美国社会的信息不平等现象

 
 
 
 
    

    
 
     
  

      
   
美国社会的信息不平等现象

    在美国工作过的人都知道，进入一个公司之前，雇员都要经过一种“背景调查”（background check）。这种调查一般由专门的“背景调查公司”来协助进行，他们可以通过各种渠道来获取你的信息，包括身份，住址，犯罪记录，学位信息，之前雇主信息，职位，工资，工作时间，离职原因等等。很多公司还要求你提供几个“联系人”（reference）和他们的联系方式，有些甚至要求其中有一个是你之前的 manager，这样他们可以去询问你的表现……



    在美国大学读研究生，进去之前都需要找几个认识的教授写推荐信。进去之后每隔一段时间，教授们会召开一种八卦会议，讨论各个学生的表现。你之前对任何一个教授说的话，都可能传到别的教授耳朵里。教授们用这种机制来打探学生的底细，所以如果你在一个教授那里表现不好（当然其实可能是教授的人品问题）或者发生了矛盾，去找另一个教授的时候很可能立即吃闭门羹，或者找借口回避。在这种会议上，教授们还会决定哪些学生会被“请离学校”……



    这表面上看上去是为了防止有问题或者不合格的人进入公司或者学校，久而久之你才发现，这种“背景调查”并不是什么好东西。它造成的“信息不平等”，导致了雇员和学生在自身权益保护上处于劣势，陷入被控制，被压迫的地位。雇员和学生如果有问题，公司和学校使用联盟的力量来解决；可是如果公司和教授有问题，学生们却没有相应的机制来维护自己的权益。



    所以你经常发现教授欺负学生的情况，最后反而是学生被迫离开。如果一个教授人品有问题导致了矛盾，他总是会推到学生头上。学生只能默默的忍着，绝不会有另一个学生或者教授来维护你的权益，伸张正义。正如中国的一句古话，官官相护，教授和教授之间都是互相庇护的。在美国，教授和研究生是两个地位完全不同的阶级。不要以为在美国你可以对教授直呼其名，在地位上你们就是平等的，那些都是美国一直以来的广告宣传（包括电影，电视，GRE 文章……）在你头脑里产生的幻觉。



    你发现没有，公司和学校可以调查你之前的表现和不良记录，你却没有可靠的办法来调查公司的内部情况和不良底细。如果没有熟人在公司，你是没法知道公司内部的一些龌龊做法的。某些公司里面的情况是多么龌龊，从我之前的文章你应该已经有所了解。你不但不容易找到说真话的“内线”，而且当你进入公司之后会被要求签署一种叫 NDA 的东西，也就是 Non-Disclosure Agreement。这种 NDA 很多不但要求你不能暴露公司的商业和技术机密，而且要求你不能公开公司内部的“做法”（practice）。当然做法就包括了内部的各种压榨，政治斗争，勾心斗角，领导瞎指挥，等等。



    签了这样 NDA 的人，除非你跟他是很好的朋友，他才有可能在不被抓到证据（无记录）的情况下，亲口告诉你公司内部的真实情况。很多时候，情况要比你从外面看起来糟很多，就算它是世界知名的“伟大”公司也一样。本来你认识公司内部员工的机会就不是很多，再除去本来就精通政治斗争的人，那些喜欢晒幸福显牛逼的人，那些由于签了 NDA 而三缄其口的人，就没有很多机会听到另外方面的信息。



    你可以从 Glassdoor 之类的网站了解一些公司的负面信息，然而经验告诉我，Glassdoor 并不是没有“审查”的。你大体上说一下不好的感觉可以，然而如果你说到具体的地方，review 就会被 Glassdoor 封锁，理由是里面有脏话，或者违反“社区规则”（community guidelines）。你以为真是因为脏话吗？等你删掉所有的脏话和用星号替换的脏话（比如 s**t），会发现仍然无法通过审查。他们不会告诉你为什么，只是反复的跟你说违反了社区规则。至于怎么违反了，你是永远琢磨不出来的。



    到底哪里有问题呢？问题就在于你的 review 太具体了，包含了确凿的证据，别人一看就知道那是真的。Glassdoor 的所谓社区规则，让你无法显示出具体的证据，以至于人们看到你的反面 review 也无法确信你说的是实话。有些甚至可能以为你是个人性格问题，要求太高，对公司不满而已。当你忽略了这些反面 review，进入公司一看，才发现他们说的都是真的…… 所以像 Glassdoor 这种试图朝 LinkedIn 竞争者方向发展，目的在于盈利的公司，它们其实是不敢让这样的 review 存在的。否则得罪了某些牛气的公司或者投资者，自己可就吃不了兜着了。要记住 Glassdoor 也是一家公司，然而能够给公司提供公正 review 的地方，它自己绝对不应该是一家公司。



    由于新的工作都需要背景调查，甚至要求给你之前的上司打电话，所以知道这一点的人都会在工作中唯唯诺诺，不敢得罪任何人，就算你的上司人品非常差也一样。这样一来，背景调查和推荐制度，就成为了管理层控制工薪阶层和学生强有力的工具。你的上司比较放心，无论他如何瞎指挥，如何欺负陷害你，你都得在他面前笑嘻嘻的，不敢当面冒犯。如果他对你不满意，就算你离开这个公司，将来的工作也不好找。因为之后的公司可能要求打电话跟他询问你的情况，到时候他可以在背地里狠狠黑你一番，然后还跟你说自己高度的赞扬了你。等你过五关斩六将，到了最后却莫名其妙没有拿到以为可以顺手拈来的工作，才发现他也许是一只笑面虎。



    我在 Google 和 Coverity 的两个上司都是这样的人。其中 Coverity 的上司曾经在 2013 年直接导致我失去一个很好的工作机会，幸好本来要给我 offer 的公司里一个好心人事后告诉了我原因——Coverity 的 manager 提供了“让人震惊的负面信息”！在那之前我一直以为，虽然这人帮着公司压榨我们，但平时又跟我哭诉说是被迫的，所以也许还有点人性。当新公司要求之前公司的联系人中包含一个 manager 的时候，由于只有 Google 的那家伙和他可以选，我写了他的名字。结果呢，同事给了我好评，然后这个 manager 本来的面目就显示出来了…… 现在你知道美国的人际关系可以多么的微妙和复杂了吧，一个人在背后戳你一刀，你也许直到最后都没有发现，而且很多时候你的新公司明确要求你提供让别人捅你一刀的机会……



    这就是中国人心目中简单纯朴善良的美国人，他们制造了世界上最强大的无形锁链，根本不需要政府出手，利用整个社会的集体力量来操控和挟制每个人的行为，使得他们不敢有不服从的举动，不敢公开公司和学校的不良做法。我之所以在博文里曝光一些公司的行为，就是为了抵抗这种信息的不平等，为了破坏这种无形的锁链。



    有些人每次看到我批评前任雇主，就觉得我是大嘴巴，说得好像我在欺负雇主一样。我这种资产为负数的区区小民（负人阶级），哪里能动得了牛逼哄哄的 Google，不可一世的 Coverity 的汗毛呢？可是你发现没有，被我曝光的全都是强权势力，而且它们都对我的身心健康和切身利益产生了严重的危害。我从来没有说过我前女友，我前同事的故事，就算他们有些做法相当的不好，也绝对不会公开出来。因为他们没有像公司那样强大的权力和危害，可以伤害大量的人却不受惩罚，可以导致整个社会文明的败坏。所以就算我受到很大的伤害，也要保护这些人的隐私，因为他们还有醒悟和改进自己的机会。



    然而对于公司和大学这样的强权，如果出现严重侵害切身利益的恶劣行为，我就会毫不留情的揭露。就算 NDA 禁止透露某些信息也一样，我不会让 NDA 阻碍我对伤害自己的恶劣行径进行披露。就像你被别人打了，打人者逼你签字画押，让你保证不说出去，不然上法院告你。你去遵循这种条款不是很可笑吗？本来该被告上法庭的是打人者，到头来打人者却要挟上法院告你，试图封你的嘴，掩盖真相。写 GRE 作文的时候大家都分析过如何对待“unjust law”（不正义的法律），现在是拿出来用的时候了，用于掩盖公司丑恶行径的 NDA 条款是不正义的法律，所以我们应该联合起来废除它！当然这里说要揭露的，不包括商业和技术机密。



    这里我应该强调一下，并不是所有问题都属于“严重侵害”，都需要进行揭露。这些侵害只包括那种对人的身心健康，切身的基本利益，也就是所谓“人权”产生危害的。比如利用高压甚至威胁剥夺员工休息时间，危害员工生命安全和健康，暴力谩骂等行为，缺乏对人的基本尊重的行为，才列入被揭露之列。其它的常见问题，比如节奏太慢，工作缺乏挑战性，process 太繁琐，同事比较笨，…… 由于没有造成伤害，所以不包括在内。



    一些典型的公司恶劣行径例子：



Coverity 故意对任务设置过短的时间，然后通过解雇相威胁，导致员工严重超时工作，无耻剥夺员工的休息时间。
Sourcegraph 在员工短时间完成重大贡献之后，使用无理借口解雇，收回早期员工的大额股票份额。这是相当于抢劫的犯罪行为。
Amazon 被多次曝光的极度压榨的工作环境，对怀孕女员工的不公正待遇，等等……




    有人跟我说我这么曝光以前的雇主，新的公司会对我有所顾忌，这样的行为等于自杀。我其实一点都不担心这个事情。虽然恶劣的行径是一定会被揭穿的，然而胸怀坦荡，对人友好，心里没有鬼的公司却大可不必担心。对我有所顾忌是应该的，我理所应当有自己的威严——公司都应该知道，王垠不是好惹的，但他却是非常讲理的。你可以看到，被曝光的雇主都有非常严重的恶劣行为，甚至可以告上法庭，要求赔偿。我对这样的公司躲都来不及，如果类似的不地道的公司看到了我的文章而回避我，那正好！因为我正想很有效的过滤掉这样的公司，省得浪费时间去跟他们聊。剩下的有良心的公司，自然会发现我是朋友，而且是非常有价值的人，从而愿意跟我合作。



    如果你被公司欺负了，却担心曝光了公司的恶劣行为会导致以后找不到工作，那你就助长了这种公司的气焰。他们就会打着假面具继续害人，把大家都蒙在鼓里。这样坏人就会横行霸道，导致整个社会环境的恶化。所以这些人对我的做法的担心，说我是在自杀，不但是多余的，而且是有害的，甚至可以被视为一种恐吓行为。我希望广大的劳动群众都能有如此的勇气，勇于站出来说真话，世界才能得到信息的平等。只有在信息上平等，公司的不良行为才能受到节制，有良心的公司才能得以发扬光大，人类才有可能得到物质上平等的机会，最终消灭人压迫人，人剥削人的制度。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 Java 有值类型吗？

 
 
 
 
    

    
 
     
  

      
   
Java 有值类型吗？

    有人看了我之前的文章『Swift 语言的设计错误』，问我：“你说 Java 只有引用类型（reference type），但是根据 Java 的官方文档，Java 也有值类型（value type）和引用类型的区别的。比如 int，boolean 等原始类型就是值类型。” 现在我来解释一下这个问题。



    Java 有值类型，原始类型 int，boolean 等是值类型，其实是长久以来的一种误解，它混淆了实现和语义的区别。不要以为 Java 的官方文档那样写就是权威定论，就可以说“王垠不懂” :) 当你认为王垠不懂一个初级问题的时候，都需要三思，因为他可能是大智若愚…… 看了我下面的论述，也许你会发现自己应该怀疑的是，Java 的设计者到底有没有搞明白这个问题 :P



    胡扯结束，现在来说正事。Java，Scheme 等语言的原始类型，比如 char，int，boolean，double 等，在“实现”上确实是通过值（而不是引用，或者叫指针）直接传递的，然而这完全是一种为了效率的优化（叫做 inlining）。这种优化对于程序员应该是不可见的。Java 继承了 Scheme/Lisp 的衣钵，它们在“语义”上其实是没有值类型的。



    这不是天方夜谭，为了理解这一点，你可以做一个很有意思的思维实验。现在你把 Java 里面所有的原始类型都“想象”成引用类型，也就是说，所有的 int, boolean 等原始类型的变量都不包含实际的数据，而是引用（或者叫指针），指向堆上分配的数据。然后你会发现这样“改造后”的 Java，仍然符合现有 Java 代码里能看到的一切现象。也就是说，原始类型被作为值类型还是引用类型，对于程序员完全没有区别。



    举个简单的例子，如果我们把 int 的实现变成完全的引用，然后来看这段代码：


int x = 1;    // x指向内存地址A，内容是整数1
int y = x;    // y指向同样的内存地址A，内容是整数1
x = 2; // x指向另一个内存地址B，内容是整数2。y仍然指向地址A，内容是1。



    由于我们改造后的 Java 里面 int 全部是引用，所以第一行定义的 x 并不包含一个整数，而是一个引用，它指向堆里分配的一块内存，这个空间的内容是整数 1。在第二行，我们定 int 变量 y，当然它也是一个引用，它的值跟 x 一样，所以 y 也指向同一个地址，里面的内容是同一个整数：1。在第三行，我们对 x 这个引用赋值。你会发现一个很有意思的现象，虽然 x 指向了 2，y 却仍然指向 1。对 x 赋值并没能改变 y 指向的内容，这种情况就跟 int 是值类型的时候一模一样！所以现在虽然 int 变量全部是引用，你却不能实现共享地址的引用能做的事情：对 x 进行某种操作，导致 y 指向的内容也发生改变。



    出现这个现象的原因是，虽然现在 int 成了引用类型，你却并不能对它进行引用类型所特有（而值类型没有）的操作。这样的操作包括：



deref。就像 C 语言里的 * 操作符。
成员赋值。就像对 C struct 成员的 x.foo = 2 。




    在 Java 里，你没法写像 C 语言的 *x = 2 这样的代码，因为 Java 没有提供 deref 操作符 *。你也没法通过 x.foo = 2 这样的语句改变 x 所指向的内存数据（内容是1）的一部分，因为 int 是一个原始类型。最后你发现，你只能写 x = 2，也就是改变 x 这个引用本身的指向。x = 2 执行之后，原来数字 1 所在的内存空间并没有变成 2，只不过 x 指向了新的地址，那里装着数字 2 而已。指向 1 的其它引用变量比如 y，不会因为你进行了 x = 2 这个操作而看到 2，它们仍然看到原来那个1……



    在这种 int 是引用的 Java 里，你对 int 变量 x 能做的事情只有两种：



读出它的值。
对它进行赋值，使它指向另一个地方。




    这两种事情，就跟你能对值类型能做的两件事情没有区别。这就是为什么你没法通过对 x 的操作而改变 y 表示的值。所以不管 int 在实现上是传递值还是传递引用，它们在语义上都是等价的。也就是说，原始类型是值类型还是引用类型，对于程序员来说完全没有区别。你完全可以把 Java 所有的原始类型都想成引用类型，之后你能对它们做的事情，你的编程思路和方式，都不会因此有任何的改变。



    从这个角度来看，Java 在语义上是没有值类型的。值类型和引用类型如果同时并存，程序员必须能够在语义上感觉到它们的不同，然而不管原始类型是值类型还是引用类型，作为程序员，你无法感觉到任何的不同。所以你完全可以认为 Java 只有引用类型，把原始类型全都当成引用类型来用，虽然它们确实是用值实现的。



    一个在语义上有值类型的语言（比如 C#，Go 和 Swift）必须具有以下两种特性之一（或者两者都有），程序员才能感觉到值类型的存在：



deref 操作。这使得你可以用 *x = 2 这样的语句来改变引用指向的内容，导致共享地址的其它引用看到新的值。你没法通过 x = 2 让其他值变量得到新的值，所以你感觉到值类型的存在。
像 struct 这样的“值组合类型”。你可以通过 x.foo = 2 这样的成员赋值改变引用数据（比如 class object）的一部分，使得共享地址的其它引用看到新的值。你没法通过成员赋值让另一个 struct 变量得到新的值，所以你感觉到值类型的存在。




    实际上，所有的数据都是引用类型就是 Scheme 和 Java 最初的设计原理。原始类型用值来传递数据只是一种性能优化（叫做 inlining），它对于程序员应该是透明（看不见）的。那些在面试时喜欢问“Java 是否所有数据都是引用”，然后当你回答“是”的时候纠正你说“int，boolean 是值类型”的人，都是本本主义者。


思考题


    有人指出，Java 的引用类型可以是 null，而原始类型不行，所以引用类型和值类型还是有区别的。但是其实这并不能否认本文指出的观点，你可以想想这是为什么吗？


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 Swift 语言的设计错误

 
 
 
 
    

    
 
     
  

      
   
Swift 语言的设计错误

    在『编程的智慧』一文中，我分析和肯定了 Swift 语言的 optional type 设计，但这并不等于 Swift 语言的整体设计是完美没有问题的。其实 Swift 1.0 刚出来的时候，我就发现它的 array 可变性设计存在严重的错误。Swift 2.0 修正了这个问题，然而他们的修正方法却没有击中要害，所以导致了其它的问题。这个错误一直延续到今天。



    Swift 1.0 试图利用 var 和 let 的区别来指定 array 成员的可变性，然而其实 var 和 let 只能指定 array reference 的可变性，而不能指定 array 成员的可变性。举个例子，Swift 1.0 试图实现这样的语义：


var shoppingList = ["Eggs", "Milk"]

// 可以对 array 成员赋值
shoppingList[0] = "Salad"


let shoppingList = ["Eggs", "Milk"]

// 不能对 array 成员赋值，报错
shoppingList[0] = "Salad"



    这是错误的。在 Swift 1.0 里面，array 像其它的 object 一样，是一种“reference type”。为了理解这个问题，你应该清晰地区分 array reference 和 array 成员的区别。在这个例子里，shoppingList 是一个 array reference，而 shoppingList[0] 是访问一个 array 成员，这两者有着非常大的不同。



    var 和 let 本来是用于指定 shoppingList 这个 reference 是否可变，也就是决定 shoppingList 是否可以指向另一个 array 对象。正确的用法应该是这样：


var shoppingList = ["Eggs", "Milk"]

// 可以对 array reference 赋值
shoppingList = ["Salad", "Noodles"]

// 可以对 array 成员赋值
shoppingList[0] = "Salad"


let shoppingList = ["Eggs", "Milk"]

// 不能对 array reference 赋值，报错
shoppingList = ["Salad", "Noodles"]

// let 不能限制对 array 成员赋值，不报错
shoppingList[0] = "Salad"



    也就是说你可以用 var 和 let 来限制 shoppingList 这个 reference 的可变性，而不能用来限制 shoppingList[0] 这样的成员访问的可变性。



    var 和 let 一旦被用于指定 array reference 的可变性，就不再能用于指定 array 成员的可变性。实际上 var 和 let 用于局部变量定义的时候，只能指定栈上数据的可变性。如果你理解 reference 是放在栈（stack）上的，而 Swift 1.0 的 array 是放在堆（heap）上的，就会明白array 成员（一种堆数据）可变性，必须用另外的方式来指定，而不能用 var 和 let。



    很多古老的语言都已经看清楚了这个问题，它们明确的用两种不同的方式来指定栈和堆数据的可变性。C++ 程序员都知道 int const * 和 int * const 的区别。Objective C 程序员都知道 NSArray 和 NSMutableArray 的区别。我不知道为什么 Swift 的设计者看不到这个问题，试图用同样的关键字（var 和 let）来指定栈和堆两种不同位置数据的可变性。实际上，不可变数组和可变数组，应该使用两种不同的类型来表示，就像 Objective C 的 NSArray 和 NSMutableArray 那样，而不应该使用 var 和 let 来区分。



    Swift 2.0 修正了这个问题，然而可惜的是，它的修正方式是错误的。Swift 2.0 做出了一个离谱的改动，它把 array 从 reference type 变成了所谓 value type，也就是说把整个 array 放在栈上，而不是堆上。这貌似解决了以上的问题，由于 array 成了 value type，那么  shoppingList 就不是  reference，而代表整个 array 本身。所以在 array 是 value type 的情况下，你确实可以用 var 和 let 来决定它的成员是否可变。


let shoppingList = ["Eggs", "Milk"]

// 不能对 array 成员赋值，因为 shoppingList 是 value type
// 它表示整个 array 而不是一个指针
// 这个 array 的任何一部分都不可变
shoppingList[0] = "Salad"



    这看似一个可行的解决方案，然而它却没有击中要害。这是一种削足适履的做法，它带来了另外的问题。把 array 作为 value type，使得每一次对 array 变量的赋值或者参数传递，都必须进行拷贝。你没法让两个变量指向同一个 array，也就是说 array 不再能被共享。比如：


var a = [1, 2, 3]

// a 的内容被拷贝给 b
// a 和 b 是两个不同的 array，有相同的内容
var b = a   



    这违反了程序员对于数组这种大型结构的心理模型，他们不再能清晰方便的对 array 进行思考。由于 array 会被不经意的自动拷贝，很容易犯错误。数组拷贝需要大量时间，就算接收者不修改它也必须拷贝，所以效率上有很大影响。不能共享同一个 array，在里面读写数据，是一个很大的功能缺失。由于这个原因，没有任何其它现代语言（Java，C#，……）把 array 作为 value type。



    如果你看透了 value type 的实质，就会发现这整个概念的存在，在具有垃圾回收（GC）的现代语言里，几乎是没有意义的。有些新语言比如 Swift 和 Rust，试图利用 value type 来解决内存管理的效率问题，然而它带来的性能提升其实是微乎其微的，给程序员带来的麻烦和困扰却是有目共睹的。完全使用 reference type 的语言（比如 Java，Scheme，Python），程序员不需要思考 value type 和 reference type 的区别，大大简化和加速了编程的思维过程。Java 不但有非常高效的 GC，还可以利用 escape analysis 自动把某些堆数据放在栈上，程序员不需要思考就可以达到 value type 带来的那么一点点性能提升。相比之下，Swift，Rust 和 C# 的 value type 制造的更多是麻烦，而没有带来实在的性能优势。



    Swift 1.0 犯下这种我一眼就看出来的低级错误，你也许从中发现了一个道理：编译器专家并不等于程序语言专家。很多经验老到的程序语言专家一看到 Swift 最初的 array 设计，就知道那是错的。只要团队里有一个语言专家指出了这个问题，就不需要这样反复的修改折腾。为什么 Swift 直到 1.0 发布都没有发现这个问题，到了 2.0 修正却仍然是错的？我猜这是因为 Apple 并没有聘请到合格的程序语言专家来进行 Swift 的设计，或者有合格的人，然而他们的建议却没有被领导采纳。Swift 的首席设计师是 Chris Lattner，也就是 LLVM 的设计者。他是不错的编译器专家，然而在程序语言设计方面，恐怕只能算业余水平。编译器和程序语言，真的是两个非常不同的领域。Apple 的领导们以为好的编译器作者就能设计出好的程序语言，以至于让 Chris Lattner 做了总设计师。



    Swift 团队不像 Go 语言团队完全是一知半解的外行，他们在语言方面确实有一定的基础，所以 Swift 在大体上不会有特别严重的问题。然而可以看出来这些人功力还不够深厚，略带年轻人的自负，浮躁，盲目的创新和借鉴精神。有些设计并不是出自自己深入的见解，而只是“借鉴”其它语言的做法，所以可能犯下经验丰富的语言专家根本不会犯的错误。第一次就应该做对的事情，却需要经过多次返工。以至于每出一个新的版本，就出现一些“不兼容改动”，导致老版本语言写出来的代码不再能用。这个趋势在 Swift 3.0 还要继续。由于 Apple 的统治地位，这种情况对于 Swift 语言也许不是世界末日，然而它确实犯了语言设计的大忌。一个好的语言可以缺少一些特性，但它绝不应该加入错误的设计，导致日后出现不兼容的改变。我希望 Apple 能够早日招募到资深一些的语言设计专家，虚心采纳他们的建议。BTW，如果 Apple 支付足够多的费用，我倒可以考虑兼职做他们的语言设计顾问 ;-)


Java 有 value type 吗？


    有人看了以上的内容，问我：“你说 Java 只有 reference type，但是根据 Java 的官方文档，Java 也有 value type 和 reference type 的区别的。” 由于这个问题相当的有趣，我另外写了一篇文章来回答这个问题。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 我的 tweet 系统

 
 
 
 
    

    
 
     
  

      
   
我的 tweet 系统

    有时候灵光乍现，却又不想写成完整的文章，所以尝试过使用 twitter 和微博，然而最终我发现它们有各种缺点。所以我想出一个圡办法：自己手动整理一个列表，把想说的放进去，加上日期，就算是我的 tweet 系统。



    这个系统有一系列强大的功能：无法 follow 或订阅，不能评论，不方便转载。可以随意修改，随意排序，不限字数。不能随时随地增加内容，防止成瘾。心诚的人必须主动来这里看，理解更深入，自动过滤心理不正常的人，等等…… 这是迄今为止最好最完善的 social network 系统。本系统的座右铭是：我想写 tweet，所以我就写了。你们想看就看，不想看就算了。



    请点击这里访问我的 tweet 系统。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 正面思维的误区

 
 
 
 
    

    
 
     
  

      
   
正面思维的误区

    有些人喜欢宣扬所谓“正面思维”（positive thinking），而不顾事实真相。每当你批评一些事情，他们就会拿出正面思维这个万能法宝来压制你，说：“你这人怎么这么 negative？要 positive，要看到事物好的方面才对！”



    比如这次有人说：“你把之前每个东家都喷了一遍。这里面难道就没有你自己的问题吗？” 我只能说，如果它们真的就是那么恶劣，那我有什么办法呢？由于没来得及选择，连续进入好几家问题公司，其实很正常。我不是一个完美的人，然而在公司的人际关系上，我可以说是仁至义尽了。我没架子，容易相处，这点很多同事都知道，甚至厨师和扫地大妈都知道。然而我绝对不是好欺负的。



    像 Coverity，Sourcegraph 这类极品，欺压员工，无耻利用，行为极其恶劣，难道我还能说它们好话不成？我的心理不知道要扭曲到什么程度，才能发掘出他们好的地方来。这些公司的恶劣行径，严重损害了员工的身心健康，伤害了他们的事业发展，在某种程度上可以说是犯罪行为，没有把这些人告上法庭就已经不错了。关于这些公司，有很多骇人听闻的细节我还没有说出来，我保留对这些进行进一步揭露的权利。



    然而这不是今天的主题，我今天想谈的是所谓“正面思维”。很多人没有意识到，盲目的正面思维，其实是一个很严重的问题。正面并没有什么问题，快乐是好事，然而它们应该是结果，而不应该是目的。如果一个社会需要刻意去提倡“正面”和“快乐”，去宣扬它们，通过舆论压力或者暴力，迫使每个人都“正面思维”，那就有严重问题了。文化大革命的时候，人们的思维可真是很正面啊，各种歌颂…… 你要是敢说任何不好听的话，立即被打成反革命右派。可是今天，我发现这种文革似的“正面思潮”，又有抬头之势。其实，它在美国已经泛滥成灾，以至于有人专门写了一本书来批判这种“正面思维”：



    




    当你遇到困难的时候，美国人喜欢说：“别担心，一切都会好起来的……”，“要专注于事物好的方面……”，“只要你努力，就会有好结果……”，“困难是临时的，面包会有的，Go 语言会改进的……”，“危机会过去的，经济会持续增长的⋯⋯”，“美国是世界上最伟大的国家，上帝保佑美利坚……” 看看这本书，你就知道这些说法有多大的欺骗性。整个美国，其实都沉浸在人们不切实际的“正面幻想”之中。



    “正面思维”跟美国的剥削制度和资本主义，是密不可分的。美国总是宣称自己是民主自由的国家。听到这个，比美国民主和自由很多的国家，都笑了。一个真正民主自由的国家，有什么必要反复的宣称自己是民主和自由的呢？事实上，美国是一个剥削和压迫非常严重的国家，美国人民并不幸福。实际上，正面思维就是剥削者想出来，用于安抚人民，让人安心做廉价劳动力的工具。一些所谓“成功人士”，总是鼓励大家要上进，要看到事物好的方面，说失业是一种福分，要安于现状，一步一步奋斗，往上爬！然后呢，自己却在背后玩弄权术，利用人们的正面不设防的心理，招摇撞骗，投机取巧，贬低人的价值，压低雇员工资，让别人加班加点，动作慢了随时开掉。自己却不劳而获，靠着一口官腔（所谓“领导才能”）飞黄腾达。



    在美国，正面思维是一个产业。号称“快乐民族”的美国人，每年消耗掉世界上三分之二的抗抑郁症药物。美国出产层出不穷的正面思维和“成功学”书籍，DVD，以及其他产品：『人性的弱点』，『心灵的鸡汤』，『谁动了我的奶酪』，『秘密)』…… 出产成千上万的所谓人生导师，职场教练，宗教领袖，知心大妈，心理医生，鸡汤和蛇油贩子…… 他们的谋生方式，就是训练你如何正面思维，抑制负面情绪。这些人不能给你任何切实可行改善生活的办法，而只是告诉你，如何才能把生活的挫折，社会的不合理，不公平，都想成自己的思想有问题，或者自己不够努力，不够好。不论遇到什么样的不幸或者不公正待遇，你都不能抱怨抗议，反而还得“心存感激”，因为你活着就是上帝最好的恩赐。这也就是为什么美国有个节日叫“感恩节”，除了美国及其附庸加拿大，世界上没有其它国家庆祝感恩节。



    美国的正面思维产业是如此的发达，甚至产生了一门学科，叫做“正面心理学”。哈佛大学还开设了红极一时的『正面心理学』课程（所谓“幸福课”）。我当年看了一阵子这课的视频，发现它真的很不寻常。课程进行到将近一半，教授仍然在做一般课程第一堂课的那种“动员工作”。没有传授任何切实可行的方法，只是反反复复地试图说服你，为什么你应该学正面心理学…… 老师啊，我坐在你课堂上半学期了，你还在告诉我为什么应该上你的课？！后来我发现，这个学科很像传销。它并不能让人快乐起来，然而它确实能教会你如何说服别人来上这门课，能把你训练成跟老师一样的“幸福课推销员”，然后你又可以去训练下一代的推销员…… 最后大家都成了推销员，然而推销员自己并不快乐，因为他们没有真正的产品和客户。



    你知道为什么自从小布什做总统以来，美国的正面思维产业越来越红火了吗？因为小布什本来就是拉拉队长（cheerleader）出生，他以前的工作就是给大家加油鼓气的。小布什要求美国人民，一定要正面，一定要认为美国是世界上最伟大的国家，一定要认为美国人民是上帝的宠儿！;-)



    



    在 Cornell 和 Google 的时候，我饱尝了盲目的正面思维所带来的危害。Cornell 这学校有个奇怪的现象，跟同学聊天时，如果你想打听某个教授的学术或者为人，得到的回应必然是：“他好牛！” “好厉害！” “非常聪明！” 之类的语言。你听不到任何人说不好的方面，比如：“他讲课像是背书”，“他的研究没有实质意义”，“他的学生都很累”之类的负面信息。所以在 Cornell，你无法从同学那里得到任何信息，每个人都饱尝了与某些教授打交道的辛酸，可是每个人都把那些秘密藏在心底。他们对你说：“嗯，他很厉害，他的研究很伟大……”



    这种铺天盖地的正面信息，是无益甚至有害的。如果你只听到正面的声音，那你就无法做出正确的决定。这就像你在网上买东西，如果只看正面的评价，那你很可能买到有问题的商品。正确的作法，应该是正面负面的信息都看。特别是负面的信息，必须仔细看。它们可以告诉你，这个产品有哪些烦扰其他人的缺陷，会不会影响到你的使用。一般我在网上如果被一个产品吸引，我首先看的是一颗星的评价，因为给一颗星的人，一般是恨透了这个产品。当然里面有些无知或者不知好歹的人，你可以忽略，但是大部分人会告诉你，他们不喜欢这个产品的具体原因。我很会分析这些评价，这就是为什么我家里的很多产品，都是非常好用的。



    Cornell 这个学校，就是缺乏这种有益的负面评价。你总是听说每个教授都很牛，人都很好，…… 然而当你真正跟他们接触，就发现事实并非如此。你一次次的跳入火坑，然后才开始希望，要是开头的时候听到一些负面的信息，该多好。可是每个人表面上都是那么的 positive，每个人都认为 negative 是错误的心理，每个人都在强装笑容。这是一个多么可怕的地方！



    Google 的气氛非常类似于 Cornell。Google 员工吃饭时，谈论每个项目或者团队，都带着玫瑰色的光环，仿佛 Google 做的一切都是美好的，先进的，有前途的。在每个星期的 TGIF（Tell Googlers It's Friday）大会上，founder 们都在大讲台上宣布各种好消息，而对坏消息闭口不提或者一笔带过。下面的 Google 员工们群情激昂，对一些小不点的事情各种欢呼鼓掌尖叫，跟传销大会似的。事实上，Google 内部有许多穷途末路的项目。表面看上去很厉害的样子，等你进去才发现是死路一条，垂死挣扎。项目领导平时紧紧张张，生怕上面来人调查，把自己的项目杀掉。在公司内部搞各种政治，东拉西扯建立各种依赖关系，这样自己的项目才得以生存。



    这种虚伪的正面氛围，存在于很多的美国公司，员工每个星期都被领导打各种鸡血针，保持激昂向上的状态。我曾经跟英国，法国，德国，意大利，瑞典，波兰等国家的同事聊天，他们都暗自嘲笑美国人，说过度正面，传销式的群情激昂，吃错药了一样，确实是美国文化的一大特色。欧洲人比较务实，不搞这套，好的就说好，坏的就批评或者嘲笑，直率坦荡。当然，我不能说所有美国公司都有这种问题，所以我仍然存在希望，找到稍微实在点的公司。



    盲目的正面思维，忽略问题，并不能解决问题。你必须看到负面的事实，才有可能避免困难，得到好的结果。正面思维和浮夸的气氛，正在侵蚀 Google 和很多其它美国公司。为了看清楚正面思维的危害性，我推荐你看看这本书，名叫『负面思维的威力』：



    



   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 未来计划

 
 
 
 
    

    
 
     
  

      
   
未来计划

    生活就像一出戏，一环扣着一环。很多人对我说，我是一个非常有才华的人，只是没有被放到合适的位置。他们说的是实话。虽然我通过努力，得到了精华的知识和独立深入的思维能力，然而由于一些早期的错误抉择，再加上遇到一些错误的人，我的生活一度陷入困境。直到现在缓过气来，我才可以开始考虑一个更好的未来。


曲折的过去


    我的第一个错误，来自于一个不切实际的浪漫幻想。我把爱情看得太简单，太容易，太伟大。我错误地改变了我爱的女孩的生活轨迹。这一个错误，我用了十年的时间来偿还，同时又导致了另外一系列的错误，以至于我颠沛流离。



    我的第二个错误，是进入 Google 做实习。本来就不喜欢那里，为了养家糊口挣点小钱，下一年却还去同一个地方，结果弄得自己很不舒服，而且失去了其它更好的机会。



    我的第三个错误，在于离开 Indiana 大学之后，进入 Coverity 工作。虽然 Glassdoor 上面恶评如潮，说那里“氛围有毒”，我却因为 Coverity 似乎有很强的技术实力，拥有像 NASA，Boeing，Lockheed Martin 一类的高大上客户，而对这个公司产生了尊敬。结果呢，我花了几个月的时间，修补别人过去一年里留下来的各种蹊跷 bug。加班加点的工作，人家却完全不拿你当个东西。一知半解的所谓 architect，从来不写代码，却指手画脚，不切实际地给你设置每个任务的“时间上限”。拿着低廉的薪水，还被 manager 各种蛮横威胁，慢一点就要炒你鱿鱼的味道。



    离开 Coverity 之后，困境却远远没有结束。我饱尝了三藩市区各种 startup 面试的肤浅和无理。也有些公司（比如 Twitter）面试一切都很顺利，最后却莫名其妙没有 offer。以至于两个月过去了，一个 offer 都没有拿到。学生签证毕业后的“OPT”，最多只能有三个月没有工作。Coverity 的 founder 倒不是个坏人，在他的介绍帮助下，我找到了下一份工作，在一个做语音 app 的公司。这公司也是个肤浅小店，而且人家连“Software Engineer”的职位都没给我，让我去做被公司里的 iOS 和 Android developer 都看不起的“Data Engineer”的工作。于是饱尝了所谓“Data Scientist”的辛酸，折腾 Neo4J 这类垃圾数据库的痛苦。每次跟那些 app 程序员聊天，别人都显示出一副“你会写代码吗？”一样的神情……



    最后就遇到了 Sourcegraph 的两位 founder。开头受到如此“三顾茅庐”的礼遇，采用了我精深的代码，而且两位貌似比较懂行，所以以为能得到应有的尊重。哪知道花了两个月把 RubySonar 做完之后才发现，人家可没把你当回事，反而说你 performance 有问题，说你做这东西“居然花了两个月”，找借口开掉！我让你们自己做，做个两年看能不能做出来？不理解，不满意，也不能用正确的方式表达出来，却在我背后把键盘敲得猛响发泄。我察觉到有人不爽，还礼貌的问，我是不是有些地方做得不够好？结果跟我说没事，然后继续在背后使闷气……



    其实这两位 founder 都是 Go 语言的拥鳖。整个 server 是 Go 语言写的，乱得不成样子，各种 bug，却仍然因为自己用 Go 语言而自豪，鄙视 Python，Ruby，Java 和所有其它语言。自己选错了工具，却写 blog 把 AngularJS 骂了一顿，说换用了 Go 的 HTML template 之后很开心，而其实 Go HTML template 其实是个烂东西。开源会议的时候去给 Go 语言的团队捧场，使用“live blog”的方式给 Go 语言团队各种有失身份的吹牛拍马。每次有 Stanford 学生来面试，founder 们可真是兴奋异常，校友来校友去的。虽然我的职位叫做“Lead Researcher”，可经常是面试的“Stanford校友”来了，跟我连个正式的介绍都没有。有次一个 Stanford 本科生来面试，跟 founder 们说：“我上过一门 CSxxxx 的课。” 我在旁边听到了，好奇这是什么有趣的课，就问：“CSxxxx 是什么？” 本科生瞟了我一眼，答：“哦，这是 Stanford 的一门课，叫做‘算法’”。言下之意就是我们 Stanford 的人会算法，算法是什么，你知道么？最后招了一个 Stanford 的学生来实习，想给 Clojure 做一个类似 PySonar 的类型推导，也不虚心请教，自以为是，最后一筹莫展，连门都没有摸到就结束了。



    Sourcegraph founder 们的忽然翻脸，最后才导致了我第一次使用自己的 blog 发出求救信息。跟 OPT 不一样，H1-b 签证有苛刻的限制，一旦工作突然中止，外国人不可能有足够时间找到下一份工作，他们必须在很短时间内离境。美国名牌大学的学生，做出如此卑劣的事情，由此可见美国的“世界一流大学”，树造的是什么样的人。罗素（Bertrand Russell）在一百年前就说，美国是商人开的国家，美国的教授只不过是商人的仆人。在美国待得越久，我对此的感悟就越深。



    幸好当时许多的同胞，伸出了援助的双手，让我感觉到中华民族作为一家人的温暖。在此我要感谢在那段时间帮助和鼓励过我的所有人，才让我顺利走到了今天。



    由于时间紧迫，我迅速拿到两个 offer 之后，就从其中选择了一个，却仍然没能避免必须飞回国内重新签证的麻烦。谁知我到了国内感觉很好，就不想再回到美国，可惜当时有重任在身，不得已又回来了。这在当时看来是一个不错的 offer，它解决了我的燃眉之急，我顺利的完成了为前女友付完学费的任务。


更好的未来


    所以很多人说，我没有处于合适的地位，确实是这样。一方面我有天赋才能，有名师指点。另一方面我的生活却支离破碎，没有自由。有谁知道在这“天才”的光环下，有多少的苦楚。虽然解决了危机，然而我的生活却远远没有开始。我的收入远远落后于跟我同等水平，甚至刚毕业的人。收入除去美国的重税和高房租，欠下的车贷，基本的生活费用，过了一年我的账上仍然是负数。现有的收入远远无法满足在这个地区过上基本生活的需要，连房子的首付都付不起。有些人期望我对社会做出“贡献”，可是社会给了我什么呢？这样的生活还怎么做贡献？谁是社会？什么是贡献？



    我很感谢帮助我找到现在工作的人，我也喜欢我的队友们，但是由于各种原因，我不觉得现在的公司能够发挥我应有的作用。虽然有深入的见解，我却没有处于让它们可以被采纳的地位。做出了大的贡献，也没有得到相应的奖励和加薪。这就是我的现状，也许你没有想到。



    所以我决定在世界范围之内寻找新的机会和合作伙伴。我已经拿到不错的 offer，但我可能漏掉了考虑某些很好的公司。所以还是希望扩展一下搜索范围，开阔一下眼界，走出更好的下一步。如果你理解我说的一些东西，你有一颗类似的心，自知却不傲慢，踏踏实实做事，你有比较好的机会或者合作项目，请联系我。



    由于这么多次的惨痛经历，我不再想为 startup 公司工作，除非是作为 founder。我尊敬一些成熟低调的大公司，比如 IBM，Intel，AMD，微软，Oracle（Sun）…… 对 Google 和 Tesla 这样年轻浮躁的公司不感兴趣。我感兴趣的领域包括系统平台，数据库，程序语言，编译器，运行时系统（比如 JVM），并行和分布式计算，硬件设备，以及一切跟性能相关的问题。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 关于博文的自愿付费方式

 
 
 
 
    

    
 
     
  

      
   
关于博文的自愿付费方式

    曾经有很多人跟我建议，给我的博文里面加上付款的链接，这样我花费的时间可以得到一些回报。我一直很高尚的样子，不愿意为此收费。然而，根据经济学的原理，这是有害社会的 :P 经济的原理是这样，有价值的事物，应该在经济上受到相应的支持，这样好的东西才能受到鼓励，发扬光大，不好的东西才可能被人忘记。



    所以现在我决定，给我觉得价值比较大的文章加上大概的价格，这样喜欢文章的人可以自愿付费，当然也可以不付费。谢谢你的支持！



    【PayPal付款链接】



    支付宝二维码（收款人是我父亲的名字王文荣）：



    


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 到底是谁在欺负我们读书少？

 
 
 
 
    

    
 
     
  

      
   
到底是谁在欺负我们读书少？

    发表了之前的文章《我为什么不再做PL人》之后，我发现有人在知乎上发表文章诬蔑我。本来不想理知乎上的东西，但作者把各种刚从论文上学来的术语，似懂非懂，照本宣科列了一大堆，挺能唬人的，说起来很像那么回事儿，所以我只好破例回应一下，但是下不为例。



    现在我把这篇文章，题名『王垠，请别再欺负我们读书少』的链接放在这里，供大家观看。评论的第4，第6页有我的回复，技术性比较强，不过有兴趣的人可以看看。为了方便，我也把评论整理和拷贝到这篇文章第二节。


历史和事实


    文章作者彭飞自称导师是Jens Palsberg，我还没能验证这个事实。Palsberg似乎曾在CFA领域做过一点研究，但我印象不深，我也从来没有在批评CFA的时候点过Palsberg的名。但由于我指出了CFA领域的弊病，彭飞可能就是一心研究这个的，所以觉得“祖业”受到了攻击，想要反驳我，支持CFA的“先进性”，这样以后可以在学术界更好的混下去。这可以理解，然而彭飞的文章，其实破绽很多，处处显示出他自己的一知半解和本本主义。



    CFA领域的理论从来没有成功实现，展示过它的功效。CFA最强大的版本，CFA2的作者Dimitris Vardoulakis，当年在Mozilla实习的时候试图在JavaScript上实现CFA2算法。最后的产物叫做“DoctorJS”，还做了一个网站让人试用。可是在不久之后DoctorJS不了了之，消失了。Dimitris这人也挺喜欢吹嘘的，自己的主页上和简历上，都在很靠近自己姓名的地方自豪的写着“CFA2的发明者”字样，仿佛CFA2是什么众所周知的伟大发明一样。



    后来跟Mozilla的research director聊天时，他告诉我DoctorJS其实根本不好用，理论过度复杂，实现起来非常困难，而且达不到号称可以达到的效果，所以以后不想再赞助相关的项目了。Mozilla现在已经不再维护DoctorJS的代码，这两封email就是我们能找到的关于Mozilla+DoctorJS最后的信息:



    




    当然了，Dave Herman是很会说套话的。要让别人接手这样的项目，你不可能说它不好用或者很难维护，所以当然要假装它有价值。然而字里行间你却可以看出来，这理论其实非常难以实现，实现了也很容易出错，不知道到底是否正确。最后没人敢碰这样的代码，所以就不了了之了。



    之前在Sourcegraph的时候，两位founder也试图采用DoctorJS来做JavaScript的分析，后来发现不好用，改用了Tern，才产生了有用一点的信息。



    PySonar2（写于2010年）是跟CFA2差不多的时间出现的，而P4F的发表比PySonar2晚了好几年。可是PySonar2到今天仍然比CFA2，P4F都要强大。原因很简单，因为它根本没有CFA所用的continuation passing style（CPS变换）所带来的所谓“call/return匹配问题”。所有的call和它们的return，被抽象解释器（abstract interpreter）自然而然的匹配好了，根本不可能错位。



    我很惊讶的是CFA领域研究了20年，就在解决这种根本不存在的问题，把简单的问题搞复杂，然后又让它简单一些，来来回回的。PySonar2一开头就很简单，从来没出现过CFA那些乱七八糟的问题，直接就把问题给解决了。彭飞抓住PySonar2表面上的一些小问题指指点点，貌似好大个事情，而其实很多都是由于他自己理解不够深入。详情请见我的评论。



    另外，我真的对Python，Ruby，JavaScript这些动态语言做type inference不感兴趣了。PySonar2虽然比CFA2和P4F都简单和强大，但是我从来没想维护PySonar2的“先进性”，我从来没想推广PySonar2。因为我根本不在乎Python，也没把PySonar2当回事。给Python这样的语言做一个很好的类型推导工具，有什么意义吗？未来的方向是直接写上type annotation，就像Java和C#那样，让类型检查简单，迅速又准确。所以PySonar2和CFA领域做的其实都是无用功，只不过我没花20年时间研究CFA，只用了加起来几个月时间，而且还比他们做得更好。



    我在2014年末的样子给CFA的“祖师爷”Olin Shivers写了封email，寻找合作机会。我跟他讲述了PySonar2的做法，而且问他为什么他的call/return match用那么复杂的方法来做，然而他没有回我的email。这是一个不祥的预兆，因为我一直在犹豫是否应该告诉这些人，有简单很多倍的办法，可以达到同样的目的。他们完全可以“借鉴”我的做法，然后写进论文里面发表。所以如果他们的2016论文加入了我的想法，也不足为怪。但是真的不在乎这些了，学术界随便胡搞就胡搞呗，反正也不可能有什么大的用处。这些东西，其实做static analysis的人早就明白，CFA远远落后，只能在自己的圈子里发表点paper。



    彭飞错误地认为我很把PySonar2当回事，然而它只是我曾经做过的一个小玩具。我一直在探索和展望更加实在，对人可以产生真正效益的领域。只是随便提了一下CFA，就得到如此强烈而具体的攻击，我对PL人士的自我保护意识真的很惊讶。


技术部分


    以下是针对彭飞提出的pysonar的“技术缺陷”的逐一回应。说成什么“命门缺陷”，其实只有最后第4个例子发现了一个小bug，被我改了几行代码就修好了。


关于命门缺陷1


    



    （注意上面的夸大其词 ;-）



    回复：推导出的 int -&gt; int | bool -&gt;bool 表示的确实是一个intersection type，而不是union type。只不过我中间用的|记号跟union type一样，所以看起来比较混淆，然而内部实现确实是intersection type，而不是union type。



    现在我把中间的分隔符改成了unicode字符∧，跟intersection type的论文上一样。我想这下他该满意了吧？也就是个表面现象而已。



    



    我怀疑彭飞到底明不明白什么是intersection type。这个type表示这个函数(id)“同时”是int-&gt;int和bool-&gt;bool，而不是表示它“有时”是int-&gt;int，而另外的时候是bool-&gt;bool。所以如果你调用id(1)，推导出的输出一定是int。如果你输入id(True)，它推导出的一定是bool。



    如果这是一个union type的话，调用id(1)会报错，因为id的类型有可能是bool-&gt;bool，不能接受int的输入。调用id(True)也会报错，因为id的类型也有可能是int-&gt;int，不能接受bool的输入。所以就左右不是人。



    其实如果彭飞仔细看那两个变量a和b的类型，就会发现这是intersection type，而不是union type。



    



    



    可能有人对这里的intersection type有所误解。int -&gt; int ∧ bool -&gt;bool，在这里其实不是表示这个函数只能接受int或者bool的输入，而只是表示这个函数在某些调用的地方输入了int或者bool，然后分别输出了int和bool。所以在“官方意义”下，这并不是这个函数的类型。那么这个函数的类型是什么呢？pysonar的哲学是这样：每一个函数的类型，就是这个函数本身。没有比函数本身更能够描述函数的特征的类型，这就是静态分析领域跟类型理论（type theory）领域的区别。虽然pysonar的分析标记出的类型并不是函数的“本质类型”，然而这并不会削弱对类型错误的检测，反而会增强它。这是因为pysonar直接通过对函数体进行分析，找到类型错误。函数体比通常的类型包含更精确的信息，所以pysonar的类型分析，其实比普通的类型系统更加精确。所以可以说，静态分析是比类型理论更加细致和精华的领域。



    另外，pysonar本来就是放弃了他所谓的“Haskell那种polymorphic type inference”，故意要用“concrete type inference”，因为Haskell那种type inference其实对于Python是不能用的。有些人很喜欢随口冒出术语，可是Haskell那种其实不叫“polymorphic type inference”，而叫Hindley-Milner类型系统（HM）。这种类型系统最早出现在SML，后来也被OCaml和Haskell借鉴。我不知道彭飞为什么抓住“polymorphic”这个词不放，pysonar的type inference其实也是polymorphic的，因为它允许函数接受多种类型的输入。



    彭飞指出函数id可以推导出类似HM系统的forall a. a -&gt; a这样的类型。对于id这么简单的函数是可以，然而对于稍微复杂点的Python代码，HM系统是不可行的。PySonar早在2009年的第一版，就做过HM那样的系统，确实能把id推出forall a. a -> a那样的类型，但是后来发现遇到复杂点的Python代码就不行了。所以后来我干脆把HM系统去掉了，只留下正向的跨过程（interprocedual）类型推导。



    HM类型系统的问题是根本性的，早在ML之类的语言里面出现过了，然后出现了一系列变通（workaround），比如所谓“let-polymorphism”，“value restriction”等等，却不能从根本上解决问题。彭飞似乎没有看过相关的内容，或者把这些丑陋的变通，当成了博大精深的发明吧？:)



    举个简单的例子好了。下面这段完全合法的Python代码，你就没法用HM那样的系统推导出类型：



def foo(f):
    return f(1), f(True)

def id(x):
    return x

a = foo(id)
print(a)  # prints "(1, True)"




    这段代码会毫无问题的打印出(1, True)，然而它却不能通过HM系统的类型检查。如果你不信，那你可以写出等价的Haskell代码：



foo f = (f 1, f True)
a = foo id




    你把这段代码交给Haskell的编译器，它会报错：


No instance for (Num Bool) arising from the literal ‘1’
In the first argument of ‘f’, namely ‘1’
In the expression: f 1
In the expression: (f 1, f True)



    这是因为Haskell所用的HM系统，无法知道foo的参数f是一个什么样的函数，它是同时能接受int和bool，还是其实能接受所有类型，也就是forall a. a-&gt;a呢？类型推导不能确定这个范围，所以只能假设f不可以是一个polymorphic的函数，所以发现f被同时输入了1和True，就报错了。



    这是一个HM系统根本无法解决的问题。SML，OCaml和Haskell里面所谓的“let-polymorphism”，就是一个对此的非常局限的变通。



    相比之下，pysonar的类型推导，却可以正确判断出这个代码其实没有问题。它能准确地推断出a的类型是tuple类型(int, bool)。



    



    



    所以说得倒容易，我们请有本事的彭飞同学用CFA家族的算法，给我们show一下推导出forall类型？:)


关于命门缺陷2：


    



    回复：打开错误报告的开关（-report），彭飞这个例子里的类型错误就会被标记出来。



    



    像所有动态语言的类型推导器一样，pysonar的类型推导会出现false positive，所以pysonar现在主要用于代码检索，而不是报告类型错误。为了防止这些类型错误信息干扰视线，pysonar现在并不缺省在demo中标记类型错误，因为demo只是作为一个indexer提供信息。然而打开错误报告的开关（-report）之后，彭飞这个例子里的类型错误还是可以被发现的。



    目前的UI会在有类型错误的地方放上一个下划线，鼠标移上去之后，会显示那里的问题。然而现在的Web UI有个问题，因为下划线离变量的链接太近，所以鼠标指到变量之上，就会提示变量的类型，而不是错误。如果你打开浏览器的inspector，就可以看到报告的错误：“warning: attribute not found in type: A”。



    我知道报错链接的放置位置不是很合理，而且鼠标UI设计不大好，不过这只是一个粗糙的demo，也许以后有时间再改进吧。然而这并不是什么“命门缺陷”，因为类型错误确实是被发现了的。


关于缺陷3：


    



    回复：有一个链接没有指向，是因为当时在Sourcegraph，由于UI和数据库存储的限制，他们需要HTML里面的链接只跳转到一个地方，所以UI上同时指向两个地方的功能就被去掉了。然而内存里面的reference其实都是可以有多个的，这个你只需要看看pysonar的内部数据结构就可以发现。或者用更简单的办法，你只需要看一下a的类型：



    



    a的类型是{B | A}，这说明什么呢？这说明pysonar完全知道a.x可能引用两个地方，A.x和B.x。



    为了这么点UI的事情，就说“作者没有理解静态分析的本质”，然后拿各种术语，什么“抽象值”（abstract value），或者引用书本上的定义来吓唬人，这说明他根本没有试图搞明白pysonar的工作原理。“抽象值”是非常基础的概念，觉得我连这个都不理解，这种人还真以为自己学会了点术语了 :)



    pysonar运行的时候，里面到处跑的都是抽象值，就没有几个东西不是抽象值的。小朋友可能从来没实现过类似的东西，所以很是把这些基础概念当回事。死记硬背了点书本知识，就自以为了不起。从来没有试图了解实情，有了疑惑也不来信虚心请教。抓到一点肤浅的“疑似把柄”，就背地里拿出来说成天大的事。


关于缺陷4：


    



    回复：这个“看似很严重的bug”确实是一个bug，然而它不像他说的那么严重。而且不像他说的那样，需要另外一遍“语义分析”。pysonar是一个强大的抽象解释器，它完全可以只做一遍分析就找到这些名字，引用和类型。



    所以，只改了几行代码之后，现在已经能显示所有变量n的类型为int。pysonar大的原理和结构都是非常好的，这些小问题真是不值一提，很容易fix。



    



    反复的提到“语义分析”（semantic analysis）这些空洞的名词，显示了彭飞刚入道不久，学艺肤浅。“把每个变量和它的定义联系起来”，这种做法其实是所谓data flow analysis常用的。Data flow analysis速度快，可是非常的粗略，不精确。JavaScript的分析器Tern就是用的这种方法。这种做法根本不可能达到pysonar的带有控制流信息的分析精确程度。



    另外，彭飞还有一些闭着眼睛肆意的歪曲，比如说pysonar的代码冗长复杂。他恐怕根本就没看过pysonar的代码，不然他可以发现pysonar的类型分析器，总共只有1200行代码，而且结构非常简单干净。



    他说pysonar不是sound的，而CFA2是sound的，可我从来没说过PySonar2是sound的。其实CFA2和P4F，对于Python也不可能是sound的，因为对这样的语言做类型推导，本来就是undecidable的问题。这些工具能做的，只是最大限度的发现类型错误而已。它们并不能完全排除类型错误。它们的类型推导都有很多false positive，所以不可能用在编译器优化等方向。



    不得不引用一下Linus的话（虽然我鄙视这句话）：Talk is cheap. Show me some code。我请彭飞把P4F实现出来，给我们展示一下它能生成什么样的结果？哈哈。CFA2的发明人已经在Mozilla试过了不是吗？过度复杂的理论，根本不能实现和产生实际效果。实话说吧，CFA家族的算法恐怕要再发展好几年，仔细研究PySonar2的实现，才有可能达到PySonar2的地步。


到底是谁在欺负你们书读得少？


    彭飞的文章标题为『王垠，请别再欺负我们读书少』，我现在想问问大家，到底是谁在显示他读书多，欺负大家读书少？我有强调过我读书多吗？我告诉大家的是，我脑子里的东西大部分都不是看书学来的，书本知识是不可靠的，每本书里面都只有一两章好点的地方。我的知识大部分是自己动手学会的，所以我才能做到融会贯通。



    通过这些他对pysonar技术细节的分析，我看得出来彭飞看过一些PL领域的书和论文，记住了一些皮面知识和吓人的术语。满口的术语，可是却没有深刻的理解它们后面的涵义。他读书确实也够少的，见识太少，不知道天外有天。恐怕动手能力也不高，没动手实现过CFA领域任何一个算法。拿别人的代码来随便摆弄两下，也没有深入试验和观察，就以为自己可以造出一个大新闻：看，王垠是个大骗子！



    看了一下彭飞的知乎专栏，他似乎喜欢显示一些鸡毛蒜皮的东西，把一些刚看过，没经过实践检验的理论，当成宝一样给给其它人讲，传道授业解惑一样，试图用这种方式树立自己的“权威地位”，让大家以为他是大牛人。他的文章经常出现一些比如“牛逼到爆”，“巅峰之作”一类的词汇，跟国内小编吹嘘国外大公司差不多的语气。他当然希望大家继续崇拜PL界的权威们，这样他们就可以瞎蒙混骗，写一些看不懂，实现不了，无法验证真伪的理论，继续高高在上，高深莫测的样子。所以，到底是谁在欺负我们读书少呢？



    知乎的民科们班门弄斧，拿起石头砸了自己的脚，已经不止第一次了。我劝这些人还是好自为之。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 我为什么不再做PL人

 
 
 
 
    

    
 
     
  

      
   
我为什么不再做PL人

    我不做程序语言（PL）的工作已经半年了。在这半年里，我变得快乐了很多，对世界也有了新的观点。现在我想来讲一讲，我为什么不想再做PL的工作和研究。我只希望这些观点可以给正在做PL，或者考虑进入这个领域的人们，作为一份参考。


学校里的PL人


    PL看似计算机科学最精髓的部分，事实确实也是这样的。没有任何一个其它领域，可以让你对程序的本质形成如此深入的领悟，然而这并不等于你就应该进入PL的博士班。这是为什么呢？


炒冷饭


    PL这个领域几十年来，已经发展到了非常成熟的阶段。这里面的问题，要么在20年前已经被人解决掉了，要么就是类似“停机问题”一样，不可能解决的问题。然而，博士毕业却要求你发表“创新”的论文，那怎么办呢？于是你就只有扯淡，把别人已经解决的问题换个名字，或者制造一些看似新鲜却不管用的概念，在大会上煞有介事的宣讲。俗话说就是“炒冷饭”。



    最开头进入这个领域的时候，你可能不觉得是这样，因为似乎有那么多的东西可以学习，那么多的大牛可以瞻仰，那么多的新鲜名词，什么“lambda calculus”啊，“语义”啊，各种各样的“类型系统”啊，这样那样的“逻辑”…… 可是时间久了，看透了，你就发现一些这个圈子里的规律。


崇拜古人


    几乎每篇PL领域的论文，里面必有一页弯弯曲曲，让人看花眼的逻辑公式。程序语言的论文，不是用程序来描述，而是用一些老古董的逻辑符号，像这样：



    



    绝大部分PL领域的专家们，似乎都酷爱逻辑符号，视逻辑学家高人一等。这种崇尚古人的倾向，使得PL专家们看不见这些符号背后，类似电路一样的直觉。他们看不见逻辑学的历史局限，所以他们也许能够发展和扩充一个理论，却无法创造一个新的。



    说到古人，却并不是所有古人都这么晦涩。如果你考古一下就会发现，其实现代逻辑学的鼻祖Gottlob Frege最初的论文里，是没有这些稀奇古怪的符号的。他整篇论文都在画图，一些像电路一样的东西。比如下图，就是Frege的创始论文《Begriffsschrift》里最复杂的“公式”之一：



    



    你可以把这里的每根线理解成一根电线。图1里那些诡异的逻辑符号，都是一些好事的后人（比如Gentzen）加进去的，最后搞得乌七八糟，失去了Frege理论的简单性。所以PL专家们虽然崇尚古人，却没有发现大部分古人，其实并没能获得鼻祖Frege的真传。



    如果你看透了那些公式，自己动手实现过各种解释器，就会发现PL论文里的那些公式，其实相当于解释器的代码，只不过是用一种叫做“XX逻辑”的晦涩的语言写出来的。逻辑，其实本质上是一种相当落伍的程序语言。如果你精通解释器的代码，也许就会发现，这些公式其实用非常蹩脚的方式，实现了哈希表等数据结构。逻辑语言只运行于逻辑学家的脑子里面，用它写出的代码一样可能有bug，而且由于这语言如此障眼难读，而且没有debugger，所以bug非常难发现。逻辑学家们成天为自己的设计失误和bug伤透了脑筋，PL专家们却认为他们具有数学的美感，是比自己聪明的高人 :)



    所以当你看透了所有这些，就会发现PL的学术界，其实反反复复在解决一些早已经解决了的问题，只不过给它们起了不同的名字，使用不同的方式来描述。有时候好几个子领域，其实解决的是同一个问题，然而每个子领域的人，却都说自己的问题在本质上是不一样的，号称自己是那个子领域的鼻祖。甚至有人在20多年的时间里，制造出一代又一代的PhD和教授职位。他们的理论一代代的更新，最后却无法解决实际的问题。所谓的“控制流分析”（control-flow analysis，CFA），就是这样的一个子领域。


不知道谁是真的高人


    进入一个领域做研究，你总该知道那些人是真正厉害的。可惜的是，PL这个领域里，你往往不知道谁是真正掌握了精髓的学者，甚至好几年之后你仍然蒙在鼓里。我的历史教训是，写教科书的人，往往不是最聪明，最理解本质的。真正深刻的PL研究者，你可能根本没听说过他们的名字。



    一般程序员提到PL，就会跟“编译器”这个领域混淆在一起，就会想起大学时候上编译器课，看《龙书》时焦头烂额的情景。然后由于斯德哥尔摩综合症，他们就会崇拜龙书的作者们。直到遇到了真正厉害的PL专家，你才发现编译器这个领域，跟PL根本是两回事，它其实比PL要低一个档次，里面充满了死记硬背的知识甚至误导。龙书的作者，其实也不是最厉害的编译器作者，他们更不是合格的PL专家。



    上过“正统”的PL课程的学生，往往用一本经典大部头教材叫《TAPL》，然后就会误认为此书的作者是最厉害的PL专家，然而他们再一次被名气给蒙蔽了。TAPL这书其实不但照本宣科，没有揭示实质，而且冗长没有选择，有用的没用的过时的理论，一股脑的灌输给你。等你研究到了所谓“交集类型”（intersection types），看到TAPL作者当年的博士论文才发现，其实他把简单的问题搞复杂了，而且那些理论几乎完全不能实用。真正厉害的intersection types专家，其实默默无闻的待在Boston University，而且研究到最后，intersection types这个领域其实被他们证明为完全不能实用。



    由于TAPL这本书，以及ML)，Haskell等语言在PL界的“白象”地位，于是很多人又对Hindley-Milner类型系统（HM）充满了崇敬之情，以为HM系统的发明者Robin Milner是最厉害的PL学者。他的确不错，然而等你随手就能实现出HM系统，看清了它的实质，就会发现所有这样能够“倒推”出类型的系统，其实都具有很大的局限性。



    HM系统的“unification)”机制，依赖于数学上的“等价关系”，所以它不可能兼容子类型（subtyping）关系。原因很简单：因为子类型没有交换性，不是一个等价关系。而子类型关系却是对现实世界进行直观的建模所必不可少的，于是你就发现Haskell这类基于HM系统的语言，为了弥补这些缺陷而出现各种“扩展”，却永远无法达到简单和直观。一开头就错了，所以无论Haskell如何发展，这个缺陷也无法弥补。如果没有了HM系统，Haskell就不再是Haskell。



    Robin Milner的另外一个贡献π-calculus，虽然看起来吓人，其实看透了之后你发现它里面并没有很多东西。π-calculus对并发进行“建模”，却不能解决并发所带来的各种问题，比如竞争（race condition）。实际上普通的语言也能对并发进行简单的建模，所以π-calculus其实只停留于纸面上，不可能应用到现实中去。跟π-calculus类似的一个概念CSP也有类似的问题，属于“白象理论”。很多语言（比如Go）扯着CSP的旗号，引起很多人无厘头的膜拜，可见白象的威力有多大 :)



    我在学校研究PL的时候就是这样，每天都发现天外有天，每天都发现曾经的偶像其实很多时候是错觉。最后我发现，PL领域其实最后就剩下那么一点点实质的内容，其它的都是人们造出来的浮云。所以每当有人问我推荐PL书籍，我都比较无语，因为我的PL知识只有非常少数是看书得来的。自己动手琢磨出来的知识，才是最管用的。


没人知道你是谁


    PL的学生还有一个问题，那就是毕业后工作不好找。只有极少数公司（像微软，Intel，Oracle）里的少数团队，可以发挥PL专家的特殊才能。绝大部分其它公司根本不知道PL是什么，PL专家是干什么的。你跟他们说你的专业是“程序语言”，他们还以为你只是学会了“编程”而已，还问你想做“前端”还是“后端” :) 诚然，PL学生一般都有很好的编程能力，然而公司往往只关心自己的实际需求。PL学生毕业之后，很容易被普通公司作为没有任何专长的人对待。



    另外，PL的圈子相当的小，而且门派宗教观念严重，所以就算你从名师手下毕业，想进入另一个老师的门徒掌权的公司，很可能因为两个门派的敌视而无法被接纳，就算进去了也经常会因为对于PL的理念不同而发生冲突。所以，学习PL最精髓的理论是有好处的，然而进入PhD投身PL的研究，我觉得应该三思。


公司里的PL人：过度工程


    PL人在学校里跟着教授炒冷饭，毕业进入了公司之后，他们的行为方式还是非常类似。他们喜欢在公司里做的一件事情，叫做“过度工程”。本来很直接，很容易解决的一个问题，非要给你扯到各种炫酷的PL名词，然后用无比复杂的方案来解决。



    有一些PL人喜欢推广他们认为高大上的语言，比如Haskell，OCaml，Scala等。这些语言在PL学术界很受尊重，所以他们以为这些语言能够奇迹般的解决实际的问题，然而事实却不是这样的。事实是，这些学术界出来的语言，其实缺乏处理现实问题的机制。为了能够在学术上证明程序的所谓“正确性”，而且由于类型系统本身的局限性，这些语言往往被设计得过于简单，具有过度的约束性，以至于表达能力欠缺。



    最后，你发现用这些语言来写代码，总是这也不能做，那也不能做，因为你要是那么做了，编译器就无法发现“类型错误”。到最后你发现，这些语言的约束，其实是无需有的。如果放宽这些约束，其实可以更优雅，更简单的对问题进行建模。对正确性的过分关注，其实导致了PL人选择蹩脚的语言，写出绕着弯子，难以理解的代码。



    还有一类PL人，喜欢设计不必要存在的语言。因为他们认为设计语言是PL人的特异功能，所以随时随地都想把问题往“语言设计”的方向上靠。这样的趋势是非常危险的，因为有原则的PL人，其实都明白一条重要的道理：不到万不得已的时候，千万不要制造语言。



    很多PL人在公司里盲目的制造新的语言，导致的问题是，到最后谁也无法理解这种新语言写出来的代码。这一方面是新语言必然导致的结果，另一方面是由于，并不是每一个PL人都有全面的知识和很好的“品味”。每个PL学生毕业，往往只深入研究了PL的某个子领域，而对其它方面只是浮光掠影，所以他们有可能在那上面犯错。有些PL人喜欢照猫画虎，所以可能盲目的模仿Go语言，Haskell或者Python的特性，设计出非常蹊跷难用的语法。这些新的语言，其实让其他人苦不堪言。最后你发现，他们声称新语言能解决的问题，其实用像Java一样的老语言，照样可以很容易的解决。



    喜欢钻牛角尖，把问题搞复杂，就是很多公司里的PL人的共同点。制造语言是PL人应该尽量避免的事情，这恰恰跟PL人的专长是矛盾的。所以有原则的PL人，生活怎么可能不苦 :)


PL人的天才病


    很多研究PL的人喜欢看低其它程序员，认为自己能设计实现程序语言，就是天之骄子。我之所以从Dan Friedman那里学到了好东西，却没有成为他的PhD学生，一方面就是因为看不惯围绕在他身边那些自认为是“天才”的人。



    总是有那么一群本科生，自认为掌握了Friedman所讲授的精髓，所以高人一等。其实呢，他们的水平比起我这样的，其实差的天远。于是我就经常无奈的看着他们，吵吵闹闹的宣讲他们解决的“新问题”，貌似什么了不起的发明一样，受到Friedman的肯定就受宠若惊的样子。而其实呢，那些都是我几年前就已经试过并且抛弃的方案……



    其它的PL人，包括PhD学生，也有一样的毛病。不管在三流大学，还是在Harvard，Princeton，MIT这样的“牛校”出来的，只要是PL人，几乎必然有这种天才作风。另外你可能不知道的是，牛校往往并不产出优秀的PL人才。像Stanford，Berkeley，MIT这样的传统CS牛校，其实在PL方面是相当差的。



    这种天才病的危害在于，它蒙蔽了这些人的眼睛。他们不再能设计出让“普通人”可以容易使用的产品。如果你不会用，他们就会嘲笑你笨，而其实呢，是因为他们的设计不好。他们喜欢用含混晦涩的方式（所谓“函数式”）的写法来构造代码，让其它人阅读和修改都极其困难，……



    这些所谓天才，看不到简单直观的解决方案，为了显示自己的聪明而采用繁复的抽象，其实是一种愚蠢。真正的天才，必须能够让事情变得简单。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 Go语言，Docker和Kubernetes

 
 
 
 
    

    
 
     
  

      
   
Go语言，Docker和Kubernetes

    当我嘲笑Go语言的时候，有些人跟我说，你说Go语言是垃圾，可是你看像Docker和Kubernetes之类的云计算项目，为什么是Go语言写的呢？



    其实答案很简单：这些东西并不是非得用Go语言写才可以，用其他语言实现它们其实并没有什么问题，只不过它们碰巧是用Go语言写的而已。Docker和Kubernetes之类的项目，其实只依赖于操作系统的构架细节，对语言没有特别的要求，而且也没什么性能需求，所以它们其实可以用任何语言（包括Shell，Perl，Python，Ruby，C，Java……）来实现。只因为有人跟风，用Go语言写了这些东西，并不能说明Go语言是好东西。在当今混乱的IT业界，随便你做个东西都会有人拿来用，更不要说是挂着Go-ogle的羊头的语(go)言(rou) ;)



    如果你不相信我，可以看看这个叫“Bocker”的项目，它只用了100行shell script，就实现了Docker最重要的功能。 说白了，Docker的原理就是建立一些目录，把系统文件和相关库代码拷贝进去，然后chroot，这样你的代码在里面运行的时候，就以为自己独占一个Linux系统。Shell语言之恶劣，我已经有专文介绍，所以就不多说了。本来可以用shell脚本实现的项目，现在有人用Go来做，能说明Go是一个好的语言吗？



    另外也许很多人不知道的是，Docker和Kubernetes，虽然很火，但其实并不是什么了不起的技术。Docker并不能解决Unix的根本问题。Unix从来就不是一个具有良好模块化设计的系统。各种稀奇古怪的配置文件，设计缺乏条理和章法。各种模块之间，版本逻辑依赖关系错综复杂，纠缠不清。所以不管你事后怎么补救，其实都难以变成结构清晰的设计。很多项目做成了container之后，它们之间用REST和HTTP进行通信，其实让系统模块之间的通信变得更加困难和复杂。



    使用了Docker之后，你也许会发现，Unix的狂热分子们其实重新折腾出了Windows一开头就有的应用程序构架，然而这些应用程序之间的通信方式，却远远没有达到COM和.NET的成熟程度。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 为什么自动车完全不可以犯错误

 
 
 
 
    

    
 
     
  

      
   
为什么自动车完全不可以犯错误

    有人跟我讲，我对Google的自动车要求太苛刻了。人无完人，所以Google的产品也不需要是完美的，只要“够好用”就有市场。世界上有那么多糟糕的司机，酒后驾车的，开车时发短信的，打瞌睡的，判断失误的…… 导致了那么多的车祸，可比Google的自动车差多了。所以自动车不需要完美，只要99.9%的情况下可以正确工作，能大幅度减少车祸率，就是人类的福气了。



    首先，现在的情况是，Google自动车现在只能在非常局限的情况下出来：白天，天气好，交通简单，而且就算是这样理想的条件下，一年之中仍然会发生270多起需要“人工干预”的事件，所以自动车的“驾驶技术”最后能不能超过最低级别的人类驾驶员，其实还很值得怀疑。其次，就算我们抛开这个问题不谈，假设自动车能够超过绝大部分人类驾驶员，能在99.9%的情况下判断正确，那么它也是不可行的。其实自动车必须能在100%的情况下做出正确的判断，不能犯任何错误，才有可能被人接受。这是为什么呢？



    这其实是因为伦理和法律的原则。法律上的责任，并不是从宏观角度出发的。也就是说，法律不会因为自动车在99.9%的情况下判断正确，就免除那0.1%的情况下，Google对车祸的责任。法律的原则很简单，谁犯错误导致了车祸，谁就得负责，不管它是人还是机器都一样。是的，自动车也许不需要完美就可以用，但如果它犯错误引起了事故，责任就必须完全由Google，而不是车主来承担。因为如果车主是驾驶员，他开车引起车祸，那么车主就得负责。现在车主不是驾驶员，Google的软件才是驾驶员，所以如果自动车引起车祸，Google就得负完全的责任。



    如果你还没有明白，我们来设想一个实例好了。假设Google自动车在99.9%的情况下，判断都是正确的，可就那么0.1%的情况下，它会判断失误而导致车祸。现在你就是这些不幸的人其中之一，你乘坐的Google自动车由于软件判断失误，导致车祸，让你双腿截肢，终生残疾。你把Google告上法庭。Google对法官讲，因为我们的自动车在99.9%的情况下都是可靠的，大幅度降低了社会的总体车祸率，对人类做出了巨大贡献。这个人很不幸，遇上了这0.1%判断失误的情况，所以Google对此不负责任。你觉得这可以接受吗？ ;)



    0.1%的出错概率，落到一个人的头上，就等于100%的不幸。如果你本来是一个安全的驾驶员，那就更加不幸，因为如果是你自己开车，其实完全不会犯那样的错误。在这种情况下，就算自动车使得社会的总体车祸率急剧降低，对你来说其实毫无意义，因为残废的人是你。这就是为什么从伦理上讲，对机器和人，我们必须有两种不同的标准。自动车的判断力，并不是超越了大部分的驾驶员就可以的，它必须超过所有人！有些人开车时会犯的那些错误，自动车却完全不可以犯。因为坐了这辆犯错的自动车，导致身体残疾的人，他可以说：“如果是我自己开车，根本就不可能犯这样的错误。诚然，其它人在这种情况下可能会犯错，但我不会！所以Google的自动车对此负有严重的责任。”



    明白了吗？只是能从宏观上减少车祸是不够的。自动车的驾驶技术，必须超越世界上最安全的驾驶员，它完全不可以犯错误。现在世界上虽然有许多的车祸，可是因为人是驾驶员，所以责任分摊在很多当事人的头上，谁犯错误谁负责。可是如果Google的自动车进入市场，代替了大部分的驾驶员，以后自动车引起的车祸的责任，全都会落到Google的头上。所以这样的生意，是非常困难而不切实际的。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 Google的眼光

 
 
 
 
    

    
 
     
  

      
   
Google的眼光

    你知道吗，Google（Alphabet）要卖掉Boston Dynamics，一个它收购才没多久的机器人公司。这也意味着，Google准备完全退出机器人的领域。新闻传言说，是因为Google觉得这些机器人太吓人了，把它踢倒在地，居然能像终结者一样爬起来！还有舆论说Google研究机器人，是想抢走人类的饭碗，所以现在Google为了人类的幸福，放弃了这个计划。呵呵，这借口多么美妙呀！你们真以为Google有这么好心，会为你们的生存着想吗？


Boston Dynamics


    卖掉Boston Dynamics（以下简称BD）真正的原因，其实是因为BD的机器人，只是一些研究性质的原型。它们离能够投入实用，其实差的老远。研究经费的需求，却是一个无底洞。你们只要仔细看看这些BD机器人的视频（视频1，视频2），就会发现虽然貌似很先进的样子，跟科幻片里的很像，然而由于人工智能和机器视觉的局限性，它们其实仍然处于玩具阶段。



    特别是从第一个视频中你可以看到，这机器人头部旋转着一个很大的光学雷达（Lidar），虽然能拿起箱子，然而它只能在很简单，理想化的环境下才能做到，而且动作相当的缓慢和笨拙。箱子必须是方形的，而且必须有特殊的记号或者二维码在上面，这样机器人才能知道从哪里下手。拿起箱子的时候，它并不像人那样，可以感受到箱子的重心在哪里，所以它只是随意的把“手”（其实是两个橡胶垫）夹上去。箱子重心不稳，所以摇摇晃晃的，很容易滑落下来。至于机器人推门出去雪地上走的镜头，其实是有人遥控的，它并不能完全独立的探索外面的世界。被人踢倒在地，它真的是像“终结者”一样爬起来的吗？不是的。它爬起来的动作，很像一只蚂蚱，而且很慢。我很难想象，这样的机器人在战场上被人踹倒之后，能够及时爬起并且活下来。



    所以BD的机器人，其实是拿来做搬运工都不合格的，更不要说做士兵了。它们的“智能”，其实跟家用的机器人吸尘器，没有很大的差别。在如此理想化的条件下，普通的工业机器人其实就能搬运箱子，而且效率高很多。看看这些Amazon配送中心的机器人就知道，制造人形的机器人来做一些事情，完全是多此一举。只要你简化环境，就可以让普通没有智能的机器人，做很多有用的事情。



    BD之前是由美国国防部和和海军陆战队投资，进行机器人的研究。我们都知道，军方的钱是非常容易骗，可以放心大胆的烧。到时候东西做出来能不能用，就是另外一回事。拿军方的钱多舒服，没压力，所以这样的公司不拿军方的钱，把自己卖给Google，说明军方已经不想资助这样的项目了。Google的眼光有问题，买下来才发现这些个玩具，离能够投入实际使用，恐怕还需要几十年上百年。于是暗自惊呼上当，赶快转手。



    另外一种谣言是说，Google早就知道BD的机器人是不能用的。买下这公司，其实是拿来给Android的创始人Andy Rubin做玩具（圣诞礼物）的。因为Rubin很喜欢机器人，从小就梦想做自己的机器人，却壮志未酬。哪知道Rubin后来离开了Google，所以这玩具公司也就没必要留着了。Google创始人对高层领导的宠幸和溺爱，由此可见一斑。


D-Wave量子计算机


    Google似乎总是喜欢做这种吸引眼球的项目，显得自己高大上，却不能真正的成功。Google投资的另外一个泡沫项目，叫做D-Wave量子计算机。D-Wave是一个加拿大公司，号称利用低温超导技术，制造出了具有上千个qubit的量子计算机，能解决NP-Complete的问题。Google图着量子计算的虚名，花了很大的价钱买了一台D-Wave的机器，于是时不时的要冒出一些新闻。比如这个新闻说，Google声称经过自己测试，D-Wave的计算速度，是普通计算机的一亿倍！



    然而，真正的量子计算专家，比如Scott Aaronson，早就揭露过，由于环境对量子的干扰，要实现一千个qubit的量子计算机，难度是非常大，甚至是不可能的。D-Wave所谓的“量子计算机”，其实并不具有正确的“量子态”，不具有真正的量子计算能力，它其实最多算是一台“模拟计算机”。对于模拟计算机，其实研究已经很多了。模拟计算机确实可以在某些非常特殊的问题上，比数字计算机快几个数量级。然而，由于模拟计算机与生俱来的“误差问题”，它不能用于通用的计算，更不能用来解决NP-Complete的问题。实际上没有任何研究表明，量子计算机是可以解决NP-Complete问题的。



    Google声称D-Wave的机器比普通计算机快一亿倍，用的是什么样的测试呢？他们的测试并不是一个全面的benchmark，它其实只包括一个问题：模拟退火。望文生义你就可以知道，退火这问题，本来就是非常适合用模拟计算机来解决的。D-Wave是个模拟计算机，它做退火的速度，当然比数字计算机快很多了。解决一个问题快了一亿倍，可是它却不能以同样的速度解决其它的问题，甚至无法解决普通计算机能解决的那些问题。一个机器要被叫做“计算机”，它应该具有比较全面的解题能力。如果只能解决一个问题，那它根本就不算是一个计算机，最多算是个物理实验 :P



    再来看看，D-Wave解决了量子计算机本来应该可以解决的问题吗？没有。否则的话，一千个qubit的机器，应该能实现著名的“Shor算法”，从而可以很快的分解很大的整数，从而就能破解相当长度的RSA秘钥！Google为何不用D-Wave来破解RSA，引起全球轰动和震惊呢？因为它做不到。D-Wave压根就不是量子计算机，所以不能实现快速的大数分解。



    其实很多人早就知道，D-Wave不是真正的量子计算机，而Google却堂而皇之的以讹传讹，打着“量子计算”的招牌，发布自己的测试结果。我不知道他们是真的不知道，还是故弄玄虚，吸引外行的眼球，长自己的威风。


Google Glass


    世界忘不了你，Google Glass。当它刚出现的时候，Google可秀了不少神奇的视频。要查地图导航，滴滴滴，Glass直接把导航路线投射到地面上，指引你前进！在书店里说想找的书名，刷刷，Glass在空气中划出一条明亮的路线，在书架之间蜿蜒穿行，指引你到摆放它的位置，…… 多么神奇，多么美好！



    可是到最后，Google Glass做到了这些炫酷的功能吗？门都没有摸到！一开头Google就应该意识到，这样的视网膜光学投影，把虚拟的线条和人眼看到的实际物体合并在一起，是非常难办的问题。电影特效倒好做，实现起来就发现按照Google Glass的硬件能力，完全不可能。而且Google怎么可能有时间和精力，去输入书店里摆放书的位置。这年头还有多少人逛书店，这功能不是吃饱了撑着是什么 :P



    这教训就是，一开头牛皮不要吹得太大，不然会摔得很惨。最后的Google Glass，感觉就是一个戴在头上的手机屏而已，并没有发挥头戴设备的任何特点。电池寿命不到半小时，而且它的镜腿还不能折叠，取下来就不知道该放哪里了。所以买了的人都发现没什么用处，可是价格不菲啊，只想把它转手倒卖出去。



    Google Glass吹够了牛皮，忽然人间蒸发了。可惜的是，粉丝们仍然没有看透Google的一贯作风，他们仍然相信Google夸出的各种海口，盼望这位“巨人”制造出伟大的新产品。


自动车


    关于Google的自动车，我已经有专文介绍了。自动车是一个美好的幻想，可是物体识别等AI问题，却很难解决。



    有人可能以为这种自动车“够好用”就可以，因为世界上有那么多糟糕的司机，酒后驾车的，意外情况判断失误的，…… 所以Google的自动车也不需要完美，能大幅度减少车祸概率，就是人类的福气了。然而从道德和法律意义上来讲，自动车却必须要接近完美才可以。可能有人会犯的错误，它却不可以犯。这是为什么呢？原因在于，坐这辆犯了错误的自动车，导致身体残疾的人，如果是他自己开车，他可能根本不会烦这样的错误。诚然，其它人可能在这种情况也会犯错误，但其他人会犯错误，跟这个受害的人毫无关系。他会告上法庭，说：“如果是我开车，肯定不会导致车祸，以至于我自己变成残疾。所以Google的自动车对此负有严重的责任。” 明白了吗？只是能从“宏观”意义上减少车祸是不够的。自动车的驾驶技术，必须超过世界上最安全的驾驶员，它完全不可以犯错误。



    所以Google的自动车，离能够实用差的天远，却喜欢到处游说，甚至要求政府监管部门大开绿灯。Google为何如此执着？我的猜测是，Google并不是真的想让自动车能够投入实用。显然，研究这些东西，可以显得自己很高大上，技术实力强。这样一来，recruiter们就可以对刚毕业的学生们说：“看那，我们Google有各种刺激的，开创未来的项目。快加入我们吧！” 等你进去，才发现那些炫酷的项目，其实根本没机会进去。虽然拿着机器视觉的PhD，却无法进入自动车的项目。只有老老实实写些JavaScript，改进一下Adwords，给Gmail加个小不点的功能进去，…… 然后你走出Google的时候，就不小心变成了这个样子：



    



    其实完全无人控制的自动车，且不说能不能实现，它真的有必要吗？现在很多汽车公司（Subaru，本田，奔驰，……）都可以实现自动防撞刹车功能，这才是人们最需要的，而且难度不是特别高。一旦人们发现满足了基本的安全需求，就不会想要完全自动的车了。所以我预测，Google自动车很可能再过一阵子就会跟Google Glass一样，人间蒸发掉。我们走着瞧吧 :)


Chromecast


    再来看看Chromecast吧。Chromecast刚出现的时候，有些人也是热情高涨，甚至有国内朋友托我帮他买一个寄回国。我说这玩意比起Apple TV有什么特色吗？回答说：这是Google造的，肯定很牛，比Apple TV牛很多，一定要帮我买！于是等我要帮他买的时候，发现已经供不应求断货了。



    直到我自己用过Chromecast，才发现这东西就像一个未完工的intern项目，根本不能用！我当然不会去买个Chromecast。我用它是因为有天买了个投影机，免费附送了一个Chromecast。心想免费送的就试试呗，结果用了几次之后，发现简直bug百出。虽然我的是免费附送，但是这东西单独卖也要$35。这样质量的东西，Google你也好意思拿出来卖钱吗？！



    放YouTube视频的时候，它可以把视频加入播放队列，或者可以立即播放。可是队列播放和立即播放的逻辑，却是混乱的。有时候你本来想让它立即播放，它却把你之前放进去的视频给放了出来，仿佛你是在队列播放。所以我后来发现，这东西总是不放我现在想看的视屏，烦死人了。



    更搞笑的是它的Chrome插件，有时候播放列表里面，忽然出现“[object Object]”这样的东西。显然是某些初级JavaScript码工，把某个对象给直接“+”到了一个字符串上面。试试吧，在浏览器里打开开发界面，输入""+{x:1}，你就得到"[object Object]"。连这么低级的bug都放进去了，我就怀疑他们到底自己有没有用过自己的产品。



    我永远无法理解人们对这类Google产品的热情。最后，由于我对那个投影机也不是很满意，所以把投影机和Chromecast一起退给了Amazon。后来买了Apple TV，发现跟Chromecast比起来，简直天壤之别，好用顺畅很多，一点问题没有。



    可能因为退货比例太高，Chromecast现在已经从Amazon下架了。


Go语言


    Go语言，也是Google最爱炫耀的技术之一。我之前的文章已经分析的很清楚了，Go语言就是一坨屎。每个研究过PL的人，都在嘲笑Go语言的设计，笑掉了大牙。



    Google对于真正的计算机科学，程序语言的研究，远远不如微软，Intel，Oracle（Sun），IBM，Cisco。基本就是业余水平。很可惜的是，Google仍然可以靠着自己在网络界的影响力，面对专家们的嘲笑，明目张胆在业界推广Go这个大垃圾，祸害其他人。你说我们这些PL人士，怎么可能不鄙视Google？



    对了，Google还有另外一个垃圾语言，叫做Dart。Google内部还有一个自用的垃圾语言，叫做Sawzall。Sawzall的创造者，后来创造了Go。此人之前设计了Plan 9操作系统，自以为超越了Unix，而其实呢继承了Unix的所有糟粕，只含有一些肤浅的界面改动，而且还不怎么好用，所以后来根本没人用。不是我有偏见哈，可我发现的规律就是，制造垃圾的自大狂，永远都只会制造垃圾。



    因为内行人都知道Google对于语言的造诣和态度之肤浅，所以几乎没有科班出生的程序语言专家愿意去Google工作。大部分最好的PL人员进入了微软，少数去了其它地方。


Google的水平


    另外，Google的无线路由器OnHub，出来的时候大家也是热情高涨。最后一看Amazon的review，恶评如潮。自称“speak human”，可怎么就那么不人性化，那么难用呢！



    别忘了Blogger，别忘了Orkut，Chrome OS, Chrome book，…… 哎，Google还有其它一系列失败的的产品和项目，公司里很多人做着一些穷途末路的项目，我就不多说了……



    所以总的来说，Google有它的特长。它是一个不错的互联网公司，Google的搜索引擎做得很好，Gmail，收购来的YouTube，地图，Android什么的，也比较好用。但是Google的特长，也就停留在那里了。做其他事情，几乎全都是业余水准，却自以为了不起，喜欢宣传自己，制造高大形象。最近AlphaGo搞得沸沸扬扬，也是一样的用意，煽风造势，以此吸引懵懂没经验的年轻人，进去为它做一些琐碎的杂活，帮助它赚更多的广告钱。



    这就是我眼里的Google。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 AlphaGo与人工智能

 
 
 
 
    

    
 
     
  

      
   
AlphaGo与人工智能

    



    在之前的一篇文章中我指出，自动驾驶所需要的“视觉识别能力”和“常识判断能力”，对于机器来说是非常困难的问题。至今没有任何机器可以在视觉方面达到驴的水平，更不要说和人比。可是最近Google的AlphaGo战胜了围棋世界冠军，挺闹腾的，以至于对AI的误解又加深了。



    本来玩个游戏而已，恁要吹成是“历史性的人机大战”，说得好像是机器挑战了人类的智能，伤了人类的自尊似的。这整个项目打着一个相当高大上的招牌，叫做“Deep Mind”。当然，其中的技术也有一些吓人的名字，什么“神经网络”啊，“深度学习”啊……



    听到这些，总有一知半解的人，根据科幻电影的情节开始展望，这样厉害的技术，应该可以用来做更加“智能”的事情，然后就开始对“人类的未来”作出一些猜想，比如自动车就要实现，人的工作很快都要被机器取代，甚至Skynet)就要控制人类，云云。



    我只想在这里给这些人提个醒：还是别做科幻梦了，回到现实吧。


棋类是相对容易的AI问题


    一个常见的外行想法，是以为AlphaGo真的具有“人类智能”，所以Google利用同样的技术，应该可以实现自动车。这些人不但大大的高估了所谓“AI”的能力，而且他们不明白，不同的“AI问题”的难度，其实有着天壤之别。



    围棋是简单的，世界是复杂的。机器视觉和自动车，难度比围棋要大许多倍，根本不在一个量级。要达到准确的视觉判断能力，机器必须拥有真正的认知能力和常识，这并不是AlphaGo所用的树搜索和神经网络，就可以解决的。由于需要以极高的速度处理“模拟信号”，这根本就不是人们常用的“数字计算机”可以解决的问题。也就是说，不是写代码就可以搞定的。



    很早以前，人工智能专家们就发现一个很有趣的现象，是这样：



对于人来说很难，很烦的事情（复杂的计算，下棋，推理……），对于计算机来说，其实算是相对容易的事情。
对于人来说很容易的事情（认人，走路，开车，打球……），对于计算机来说，却非常困难。
计算机不能应付复杂的环境，只能在相对完美的环境下工作，需要精确的，离散的输入。
人对环境的适应能力很高，擅长于处理模糊的，连续的，不完美的数据。




    从以上几点你可以看出，棋类活动正好符合了计算机的特点，因为它总是处于一种隔离的，完美的环境，具有离散的，精确的，有限的输入。棋盘上就那么几十，几百个点，不是随便放在哪里都可以的。一人走一步，轮流着走，不能乱来。整个棋盘的信息是完全可见的，没有隐藏和缺损的信息。棋局的“解空间”虽然很大，却非常规整，有规律可循。如果完全不靠经验和技巧的话，围棋的第一步可以有361种情况，第二步有360种情况，……



    这对机器是非常有利的情况，因为计算机可以有计划有步骤，兢兢业业的把各种可能出现的情况算出来，一直到许多步以后，然后从中选择最有优势的走法。所以下棋归根结底，就是一个“树搜索”问题，只不过因为规模太大，需要加入一些优化。围棋的解空间虽然大，却是一个已知数，它最多有250150种情况。AlphaGo使用所谓“神经网络”，就是为了在搜索的时候进行优化，尽早的排除不大可能取胜的情况，免得浪费计算的时间。



    这种精确而死板的活动，就跟计算一个比较大的乘法算式（比如2463757 x 65389）的性质类似，只不过规模大很多。显然，人做这类事情很繁，很累，容易出错，计算机对此却任劳任怨，因为它本来就是个机器。当年“深蓝”战胜国际象棋世界冠军的时候，我就已经预测到，计算机成为围棋世界冠军是迟早的事，所以没必要玩这些虐待自己脑子的游戏了。可惜的是，挺多人仍然把精通棋艺作为一种荣耀（因为“琴棋书画剑”嘛）。很多中国人认为，中国人下围棋总是输给韩国人，是一种耻辱。现在看来这是多么可笑的事情，这就像心算乘法不如韩国人快，就觉得是耻辱一样 :)


认知是真正困难的AI问题


    现在来对比一下人们生活中的琐事，就说倒水端茶吧。



    



    让一个机器来给你倒水，有多难呢？意想不到的难！看看这个场景，如果你的电脑配备有摄像头，那么它怎么知道茶壶在哪里呢？要知道，茶壶的材料，颜色，形状，和角度，可以有几乎无穷多的变化。甚至有些茶壶跟哈哈镜一样，会把旁边的物体的形状都扭曲反射出来。桌上的物品附近都有各种反光和阴影，不同材料的反光特性还不一样，这些都会大幅度的影响机器对物品的识别。



    为了识别物体，机器需要常识，它的头脑里必须有概念，必须知道什么样的东西才能叫做“茶壶”和“茶杯”。不要小看这一步的难度，这意味着机器必须理解基本的“拓扑结构”，什么叫做“连续的平面”，什么叫做“洞”，什么是“凹”和“凸”，什么是“里”和“外”…… 另外，这机器必须能够分辨物体和阴影。它必须知道水是什么，水有什么样的运动特性，什么叫做“流动”。它必须知道“水往低处流”，然后它又必须知道什么叫“低”和“高”…… 它必须知道茶杯为什么可以盛水，茶壶的嘴在哪里，把手在哪里，怎样才能拿起茶壶。如果一眼没有看见茶壶的把手，那它在哪里？茶壶的哪一面是“上面”，要怎样才可以把水从茶壶的嘴里倒出来，而不是从盖子上面泼出来？什么是裂掉的茶杯，它为什么会漏水，什么是缺口的茶杯，它为什么仍然可以盛水而不漏？干净的茶杯是什么样子的，什么是脏的茶杯，什么是茶垢，为什么茶垢不算是脏东西？如何控制水的流速和落点，什么叫做“水溅出来了”，要怎么倒水才不会溅出来？……



    你也许没有想到，倒茶这么简单的事情，需要用到如此多的常识。所有这些变数加在一起，其实远远的大于围棋棋局的数量，人却可以不费力的完成。这能力，真是应该让人自己都吓一跳，然而人却对此不以为然，称之为“琐事”！因为其他人都可以做这样的事情，甚至猴子都可以，怎么能显得出我很了不起呢？人的自尊和虚荣，再一次的蒙蔽了他自己。他没有意识到，这其实是非常宝贵，让机器难以匹敌的能力。他说：“机器经过大量的学习，总有一天会做到的。看我们有神经网络呢，还有深度学习！”


机器学习是什么


    有些人喜欢拿“机器学习”或者“深度学习”来吓唬人，以为出现了“学习”两个字，就可以化腐朽为神奇。而其实所谓机器学习，跟人类的学习，完全是两回事。机器的“学习能力”，并没有比石头高出很多，因为机器学习说白了，只不过是通过大量的数据，统计拟合出某些函数的参数。



    



    比如，你采集到一些二维数据点。你猜测它们符合一个简单的函数 y = ax3 + bx2 + cx + d，但不知道a, b, c和d该是多少。于是你就利用所谓“机器学习”（也就是数学统计），推断出参数a, b, c和d的值，使得采集到的数据尽可能的靠近这函数的曲线。可是这函数是怎么来的呢？终究还是人想出来的。机器无论如何也跳不出y = ax3 + bx2 + cx + d这个框子。如果数据不符合这个范式，还是只有靠人，才能找到更加符合数据特性的函数。



    所谓神经网络，其实也是一个函数，它在本质上跟y = ax3 + bx2 + cx + d并没有不同，只不过输入的参数多一些，逻辑复杂一些。“神经网络”跟神经，其实完全没有关系，却偏喜欢说是受到了神经元的启发而来的。神经网络是一个非常聪明的广告词，它不知道迷惑了多少人。因为有“神经”两个字在里面，很多人以为它会让机器具有智能，而其实这些就是统计学家们斯通见惯的事情：拟合一个函数。你可以拟合出很好的函数，然而这跟智能没什么关系。


AlphaGo并不是人工智能历史性的突破


    这次AlphaGo战胜了围棋冠军，跟之前IBM的“深蓝”电脑战胜国际象棋世界冠军，意义其实差不多。能够写出程序，在这些事情上打败世界冠军，的确是一个进步，它肯定会对某些特定的应用带来改善。然而，这并不说明AI取得了革命性的进步，更不能表明电脑具有了真正的，通用的智能。恰恰相反，电脑能够在棋类游戏中战胜人类，正好说明下棋这种活动，其实并不需要很多的智能。从事棋类活动的能力，并不足以衡量人的智力。



    著名的认知科学家Douglas Hofstadter（《GEB》的作者），早就指出AI领域的那些热门话题，比如电脑下棋，跟真正意义上的人类智能，几乎完全不搭边。绝大部分人其实不明白思考和智能到底是什么。大部分所谓AI专家，对人脑的工作原理所知甚少，甚至完全不关心。



    AlphaGo所用的技术，也许能够用于其它同类的游戏，然而它并不能作为解决现实问题的通用方法。特别是，这种技术不可能对自动车的发展带来突破。自动车如果只比开车技术很差的人强一点，是不可接受的。它必须要近乎完美的工作，才有可能被人接受，然而这就要求它必须具有人类级别的视觉认知能力。比如，它必须能够察觉到前面车上绑了个家具，没绑稳，快要掉下来了，赶快换车道，超过它。可惜的是，自动车的“眼睛”里看到的，只是一个个的立方块，它几乎完全不理解身边到底发生着什么，它只是在跟随和避让一些线条和方块…… 我们多希望马路都是游戏一样简单，清晰，完美，没有意外的，可惜它不是那样的。每一个细节都可能关系到人的生死，这就是现实世界。



    



    为AlphaGo热血沸腾的人们，别再沉迷于自动车和Skynet之类的幻想了。看清AI和“神经网络”的实质，用它们来做点有用的东西就可以，没必要对实现“人类智能”抱太大的希望。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 不要去SeaWorld

 
 
 
 
    

    
 
     
  

      
   
不要去SeaWorld

    



    很多人喜欢海洋动物，比如海豚和“杀人鲸”（orca），但是我建议不要去海洋世界看它们。海豚和杀人鲸都是有灵性的，跟人类的智慧很接近，而且对人极其友好的动物。“杀人鲸”名字吓人，但是其实根本不吃人，野生的杀人鲸从来没有伤过人。



    事实是，像SeaWorld之类的所谓“海洋世界”，无情的把这些动物绑架，把它们从小与自己的父母分离。在SeaWorld里，这些动物如同坐牢。住的，吃的，都比它们原来的生活差很多，更是没有父母的关爱，兄弟姐妹的温暖。本来可以活上百年的杀人鲸，在SeaWorld里只能活一二十年。



    花钱去SeaWorld之类的地方，等同于给绑架者送钱，请不要再带着小孩子去赞助这些绑架者了！如果你真的爱这些动物，请坐船去海里拜访他们吧。如果你还不明白我在说什么，建议你看看一些关于杀人鲸的片子，比如《Blackfish》和《Free Willy》。



    



   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 我看自动驾驶技术

 
 
 
 
    

    
 
     
  

      
   
我看自动驾驶技术

    这段时间，Google的自动车，Tesla的autopilot，经常出现在新闻头条。人们热烈的讨论自动驾驶技术，对这“科幻般”的技术充满了憧憬，好奇，甚至恐惧。Google说：“自动车很安全。人类是糟糕的驾驶员。” 很多人不假思索就接受了这种观点，以为自己不久以后就会被自动车所代替，所以我今天想谈谈对这些“自动车”的看法。



    从我的另一篇文章，你应该已经看到，Tesla的autopilot其实根本不算是“自动驾驶”，它完全不能和Google的自动车相比。Tesla把这种不成熟的软件推送到用户的车里，为的只是跟Google抢风头，塑造自己的高大形象。看，我们先出了自动车！可是呢，Tesla那东西顶多算一个“adaptive cruise control”，离真正的自动驾驶还很遥远。可惜的是，Tesla为了自己的名声，拿用户的性命当儿戏，还有些人为它叫好。



    然而就算是Google的自动车，离能够投入使用，其实还差得很远。我这里说的“很远”，不是像某些人预测的10年，20年，而是至少100年，1000年…… 甚至永远无法实现。这是为什么呢？Google不是声称，每天都要让它的自动车“学习”上百万mile的行驶记录吗？难道学习了如此的“大数据”，不能让这车子变得跟人一样聪明吗？



    如果你这么想，那你可能根本不了解人工智能（AI）。需要“学习上百万mile”，并不能说明自动车很聪明。恰恰相反，这说明它们很笨。只需要问自己一个问题：一个人要学会开车，需要开多少里程？普通人从完全不会，到能安全上路，一般只需要12节课，每节课1小时。就算这一个小时你都在高速公路上开，也就80 mile的样子。12个小时就960 mile。也就是说，普通人只需要小于1000 mile的驾驶，就能成为比较可靠的司机。



    对比一下Google的自动车，它们每天“分析”和“学习”一百万mile的“虚拟里程”，而且经常在外面采集数据，累计上百万的mile。然而这些自动车，仍然只能在白天，天气好的时候，在道路环境非常简单的Mountain View行驶。Mountain View就是一个小镇子，总共就没几条路，路上几乎没有行人。我从未在时速超过50mph的公路上，或者交通复杂的大城市，见到过Google的自动车。



    另外据最近的报道，Google的自动车在过去一年时间里，发生了272起需要“人工干预”的错误情况。如果人不及时抢过控制权，不少情况会出现车祸。在如此简单的条件下，还需要如此多的人工干预。如果环境稍微复杂一些，自动车恐怕就完全不知所措了。



    这里还有一个“特殊关照”的问题，由于Google的自动车身上有着明显的标志，行人和其它驾驶员看到它，其实都有点提心吊胆的，不敢轻举妄动，怕它犯傻撞了自己，这也变相的降低了自动车的环境复杂度。一旦Google把车身上的标志去掉，大家看不出来谁是自动车，不对它们进行特殊的关照，我行我素，事故率恐怕就上去了。



    所以Google的自动车，离能够投入真正的使用，差距还非常远。在这种情况下就妄言“自动车很安全”，“人类是糟糕的驾驶员”，…… 未免也太早了些吧？自动车跟人类差距到底有多远呢？天壤之别。普通人只需要开1000 mile就能学会开车，而这些自动车学习了几百万，几千万，几亿mile，仍然门都没有摸到。这说明自动车跟人类的运动神经，有着根本的区别。



    人在运动的时候看见一个物体，他的头脑里会立即闪现与之相应的“概念”，然后很快浮现出这种东西的运动特点，以及相应的对策。相比之下，自动车看到物体，它并不能准确的判断它是什么东西：它是一个车，一个人，一棵树，一个施工路障，一个大坑，还是前面的车掉下来的床垫呢？所以自动车就像一个智障儿童，学了这么久连什么是什么都不知道，却有人指望它们在十年之内能开车穿越美国。



    对的，自动车配备了GPS，激光，雷达，…… 它的“感官”接收到很多的数据，有些是人类无法感觉到的。然而自动车的“头脑”（电脑），是没有认知能力的，所以就算收集到了大量的数据，它仍然不知道那东西是什么，它们之间是什么关系。电脑没有这些“常识”，所以它无法为人做出正确的判断。在危急的关头，它很可能会做出危及乘客安全的决定。“认知”是一个根本性的问题，AI领域至今没有解决它，甚至根本没有动手去研究它。



    自动车使用的所谓“机器学习”的技术，跟人类的“学习”，完全是两回事。举个例子，一个小孩从来没见过猫，你只需要给她一只猫，告诉他这是“猫咪”。下一次，当她见到不管什么颜色的猫，不管它摆出什么姿势，都知道这是“猫咪”。现在的电脑，认知能力其实比小孩子，甚至其它动物都差很多。你先让电脑分析上百万张猫的照片，各种颜色，各种姿势，各种角度，拿一只猫摆在它的摄像头面前，让它看整整一年…… 最后它仍然不理解猫是什么，不能准确的判断一个东西是否是猫。如果说电脑有智商，那么它的级别就像一个蠕虫，甚至连蠕虫都不如。电脑没有认识和适应环境的能力，所以就算它再用功，“学习”再多的数据，都是白费劲。



    很多人听说“人工智能”（AI），或者“机器学习”（machine learning），“深度学习”（deep learning）这类很酷的名词，就想起科幻小说里的智能机器人，就以为科幻就要成为现实。等你真的进入“机器学习”这领域，才发现一堆堆莫名其妙，稀里糊涂的做法，最后其实不怎么管用。这些大口号，包括所谓“深度学习”，其实跟人的思维方式，几乎完全不搭边。所谓“机器学习”，不过是一些普通的统计方法，拟合一些函数参数。吹得神乎其神，倒让统计专业的人士笑话。



    人工智能在80年代出现过一次热潮。当时人们乐观的相信，电脑在不久就会拥有人类的智能。日本还号称要动员全国的力量，制造所谓“第五代计算机”，发展智能的编程语言（比如Prolog）。结果最后呢？人们意识到，超越人类（动物）的智能，比他们想象的困难太多太多。浮夸的许诺没能实现，AI领域进入了冬天。最近因为“大数据”，“自动车”和“Internet of Things”等热门话题的出现，“AI热”又死灰复燃。然而当今的AI，其实并没有比80年代的进步很多。人们对于自己的脑子以及感官的工作原理，仍然所知甚少，却盲目的认为那些从统计学偷来的概念，改名换姓叫“机器学习”，就能造出跟自己的头脑媲美的机器。这些人其实大大的低估了自己身体的神奇程度。



    视觉和认知能力，是动物（包括人类）特有的，卓越的能力。它们让动物能够准确的感知身边复杂的世界，对此作出适合自己生存的计划。一辆能够穿越整个国家的自动车，它必须适应各种复杂的环境：天气，路况，交通，意外情况…… 所以它需要动物的认知能力。我并不是说机器永远不可能具有这种能力，然而如果你根本不去欣赏，研究和理解这种能力，倒以为所谓“机器学习”就能办到这些事情，张口闭口拿“人类”说事，你又怎么可能用机器实现它呢？我的预测是，直到人类能够完全的理解动物的脑子和感官如何工作，才有可能制造出能够接近人类能力的自动车。



    诚然，有少数人开车不小心，甚至酒后驾车，导致了很多的车祸。然而因此就声称“人类是糟糕的驾驶员”，那就是以偏概全了。大部分的人还是遵纪守法，注意安全的。很多人开车几十年，从没出过车祸。另外，我们必须把“态度”和“能力”区分开来看。酒后驾车的人，不是技术不够好，而是态度有问题。电脑当然没有态度问题，然而它的技术确实难以达到人的水平。就算那些酒后驾车的人，他们的能力其实也远远在电脑之上。我无法想象当今的电脑技术，要如何才能超越驾驶技术好的人，以及职业赛车手。



    如果你还没明白，也许下面这个图片可以把你拉回到现实世界：



    



    一个机器，如何能知道旁边的车上正在发生什么，即将可能发生什么样的危险情况呢？它如何知道，需要赶快避开这辆车呢？它不能。一个没有认知能力的机器，是难以应付复杂多变的现实世界的。



    现在人们对于自动车技术的关注，热情，盲目乐观和浮夸，感觉跟文化大革命，“大跃进”年代的思维方式类似。只不过现在“毛泽东”换成了Google或者Tesla，“每亩产量十万”换成了“两年之内自动驾驶穿越美国”…… 我觉得与其瞎折腾自动驾驶技术，不如做点脚踏实地，在短期内能够见效，改善人们生活的东西。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 给Java说句公道话

 
 
 
 
    

    
 
     
  

      
   
给Java说句公道话

    有些人问我，在现有的语言里面，有什么好的推荐？我说：“Java。” 他们很惊讶：“什么？Java！” 所以我现在来解释一下。


Java超越了所有咒骂它的“动态语言”


    也许是因为年轻人的逆反心理，人们都不把自己的入门语言当回事。很早的时候，计算机系的学生用Scheme或者Pascal入门，现在大部分学校用Java。这也许就是为什么很多人恨Java，瞧不起用Java的人。提到Java，感觉就像是爷爷那辈人用的东西。大家都会用Java，怎么能显得我优秀出众呢？于是他们说：“Java老气，庞大，复杂，臃肿。我更愿意探索新的语言……”



    某些Python程序员，在论坛里跟初学者讲解Python有什么好，其中一个原因竟然是：“因为Python不是Java！” 他们喜欢这样宣传：“看Python多简单清晰啊，都不需要写类型……” 对于Java的无缘无故的恨，盲目的否认，导致了他们看不到它很重要的优点，以至于迷失自己的方向。虽然气势上占上风，然而其实Python作为一个编程语言，是完全无法和Java抗衡的。



    在性能上，Python比Java慢几十倍。由于缺乏静态类型等重要设施，Python代码有bug很不容易发现，发现了也不容易debug，所以Python无法用于构造大规模的，复杂的系统。你也许发现某些startup公司的主要代码是Python写的，然而这些公司的软件，质量其实相当的低。在成熟的公司里，Python最多只用来写工具性质的东西，或者小型的，不会影响系统可靠性的脚本。



    静态类型的缺乏，也导致了Python不可能有很好的IDE支持，你不能完全可靠地“跳转到定义”，不可能完全可靠地重构（refactor）Python代码。PyCharm对于早期的Python编程环境，是一个很大的改进，然而理论决定了，它不可能完全可靠地进行“变量换名”等基本的重构操作。就算是比PyCharm强大很多的PySonar，对此也无能为力。由于Python的设计过度的“动态”，没有类型标记，使得完全准确的定义查找，成为了不可判定（undecidable）的问题。



    在设计上，Python，Ruby比起Java，其实复杂很多。缺少了很多重要的特性，有毛病的“强大特性”倒是多了一堆。由于盲目的推崇所谓“正宗的面向对象”方式，所谓“late binding”，这些语言里面有太多可以“重载”语义的地方，不管什么都可以被重定义，这导致代码具有很大的不确定性和复杂性，很多bug就是被隐藏在这些被重载的语言结构里面了。因此，Python和Ruby代码很容易被滥用，不容易理解，容易写得很乱，容易出问题。



    很多JavaScript程序员也盲目地鄙视Java，而其实JavaScript比Python和Ruby还要差。不但具有它们的几乎所有缺点，而且缺乏一些必要的设施。JavaScript的各种“WEB框架”，层出不穷，似乎一直在推陈出新，而其实呢，全都是在黑暗里瞎蒙乱撞。JavaScript的社区以幼稚和愚昧著称。你经常发现一些非常基本的常识，被JavaScript“专家”们当成了不起的发现似的，在大会上宣讲。我看不出来JavaScript社区开那些会议，到底有什么意义，仿佛只是为了拉关系找工作。



    Python凑合可以用在不重要的地方，Ruby是垃圾，JavaScript是垃圾中的垃圾。原因很简单，因为Ruby和JavaScript的设计者，其实都是一知半解的民科。然而世界就是这么奇怪，一个彻底的垃圾语言，仍然可以宣称是“程序员最好的朋友”，从而得到某些人的爱戴……


Java的“继承人”没能超越它


    最近一段时间，很多人热衷于Scala，Clojure，Go等新兴的语言，他们以为这些是比Java更现代，更先进的语言，以为它们最终会取代Java。然而这些狂热分子们逐渐发现，Scala，Clojure和Go其实并没有解决它们声称能解决的问题，反而带来了它们自己的毛病，而这些毛病很多是Java没有的。然后他们才意识到，Java离寿终正寝的时候，还远得很……



    Go语言



    关于Go，我已经评论过很多了，有兴趣的人可以看这里。总之，Go是民科加自大狂的产物，奇葩得不得了。这里我就不多说它了，只谈谈Scala和Clojure。



    Scala



    我认识一些人，开头很推崇Scala，仿佛什么救星似的。我建议他们别去折腾了，老老实实用Java。没听我的，结果到后来，成天都在骂Scala的各种毛病。但是没办法啊，项目上了贼船，不得不继续用下去。我不喜欢进行人身攻击，然而我发现一个语言的好坏，往往取决于它的设计者的背景，觉悟，人品和动机。很多时候我看人的直觉是异常的准，以至于依据对语言设计者的第一印象，我就能预测到这个语言将来会怎么发展。在这里，我想谈一下对Scala和Clojure的设计者的看法。



    Scala的设计者Martin Odersky，在PL领域有所建树，发表了不少学术论文（ 包括著名的《The Call-by-Need Lambda Calculus》），而且还是大名鼎鼎的Niklaus Wirth的门徒，我因此以为他还比较靠谱。可是开始接触Scala没多久，我就很惊讶的发现，有些非常基本的东西，Scala都设计错了。这就是为什么我几度试图采用Scala，最后都不了了之。因为我一边看，一边发现让人跌眼镜的设计失误，而这些问题都是Java没有的。这样几次之后，我就对Odersky失去了信心，对Scala失去了兴趣。



    回头看看Odersky那些论文的本质，我发现虽然理论性貌似很强，其实很多是在故弄玄虚（包括那所谓的“call-by-need lambda calculus”）。他虽然对某些特定的问题有一定深度，然而知识面其实不是很广，眼光比较片面。对于语言的整体设计，把握不够好。感觉他是把各种语言里的特性，强行拼凑在一起，并没有考虑过它们是否能够“和谐”的共存，也很少考虑“可用性”。



    由于Odersky是大学教授，名声在外，很多人想找他拿个PhD，所以东拉西扯，喜欢往Scala里面加入一些不明不白，有潜在问题的“特性”，其目的就是发paper，混毕业。这导致Scala不加选择的加入过多的特性，过度繁复。加入的特性很多后来被证明没有多大用处，反而带来了问题。学生把代码实现加入到Scala的编译器，毕业就走人不管了，所以Scala编译器里，就留下一堆堆的历史遗留垃圾和bug。这也许不是Odersky一个人的错，然而至少说明他把关不严，或者品位确实有问题。



    最有名的采用Scala的公司，无非是Twitter。其实像Twitter那样的系统，用Java照样写得出来。Twitter后来怎么样了呢？CEO都跑了 :P 新CEO上台就裁员300多人，包括工程师在内。我估计Twitter裁员的一个原因是，有太多的Scala程序员，扯着各种高大上不实用的口号，比如“函数式编程”，进行过度工程，浪费公司的资源。花着公司的钱，开着各种会议，组织各种meetup和hackathon，提高自己在open source领域的威望，其实没有为公司创造很多价值……



    Clojure



    再来说一下Clojure。当Clojure最初“横空面世”的时候，有些人热血沸腾地向我推荐。于是我看了一下它的设计者Rich Hickey做的宣传讲座视频。当时我就对他一知半解拍胸脯的本事，印象非常的深刻。Rich Hickey真的是半路出家，连个CS学位都没有。可他那种气势，仿佛其他的语言设计者什么都不懂，只有他看到了真理似的。不过也只有这样的人，才能创造出“宗教”吧？



    满口热门的名词，什么lazy啊，pure啊，STM啊，号称能解决“大规模并发”的问题，…… 这就很容易让人上钩。其实他这些词儿，都是从别的语言道听途说来，却又没能深刻理解其精髓。有些“函数式语言”的特性，本来就是有问题的，却为了主义正确，为了显得高大上，抄过来。所以最后你发现这语言是挂着羊头卖狗肉，狗皮膏药一样说得头头是道，用起来怎么就那么蹩脚。



    Clojure的社区，一直忙着从Scheme和Racket的项目里抄袭思想，却又想标榜是自己的发明。比如Typed Clojure，就是原封不动抄袭Typed Racket。有些一模一样的基本概念，在Scheme里面都几十年了，恁是要改个不一样的名字，免得你们发现那是Scheme先有的。甚至有人把SICP，The Little Schemer等名著里的代码，全都用Clojure改写一遍，结果完全失去了原作的简单和清晰。最后你发现，Clojure里面好的地方，全都是Scheme已经有的，Clojure里面新的特性，几乎全都有问题。我参加过一些Clojure的meetup，可是后来发现，里面竟是各种喊着大口号的小白，各种趾高气昂的民科，愚昧之至。



    如果现在要做一个系统，真的宁可用Java，也不要浪费时间去折腾什么Scala或者Clojure。错误的人设计了错误的语言，拿出来浪费大家的时间。


Java没有特别讨厌的地方


    我至今不明白，很多人对Java的仇恨和鄙视，从何而来。它也许缺少一些方便的特性，然而长久以来用Java进行教学，用Java工作，用Java开发PySonar，RubySonar，Yin语言，…… 我发现Java其实并不像很多人传说的那么可恶。我发现自己想要的95%以上的功能，在Java里面都能找到比较直接的用法。剩下的5%，用稍微笨一点的办法，一样可以解决问题。



    盲目推崇Scala和Clojure的人们，很多最后都发现，这些语言里面的“新特性”，几乎都有毛病，里面最重要最有用的特性，其实早就已经在Java里了。有些人跟我说：“你看，Java做不了这件事情！” 后来经我分析，发现他们在潜意识里早已死板的认定，非得用某种最新最酷的语言特性，才能达到目的。Java没有这些特性，他们就以为非得用另外的语言。其实，如果你换一个角度来看问题，不要钻牛角尖，专注于解决问题，而不是去追求最新最酷的“写法”，你就能用Java解决它，而且解决得干净利落。



    很多人说Java复杂臃肿，其实是因为早期的Design Patterns，试图提出千篇一律的模板，给程序带来了不必要的复杂性。然而Java语言本身跟Design Patterns并不是等价的。Java的设计者，跟Design Pattern的设计者，完全是不同的人。你完全可以使用Java写出非常简单的代码，而不使用Design Patterns。



    Java只是一个语言。语言只提供给你基本的机制，至于代码写的复杂还是简单，取决于人。把对一些滥用Design Patterns的Java程序员的恨，转移到Java语言本身，从而完全抛弃它的一切，是不明智的。


结论


    我平时用着Java偷着乐，本来懒得评论其它语言的。可是实在不忍心看着有些人被Scala和Clojure忽悠，所以在这里说几句。如果没有超级高的性能和资源需求（可能要用C这样的低级语言），目前我建议就老老实实用Java吧。虽然不如一些新的语言炫酷，然而实际的系统，还真没有什么是Java写不出来的。少数地方可能需要绕过一些限制，或者放宽一些要求，然而这样的情况不是很多。



    编程使用什么工具是重要的，然而工具终究不如自己的技术重要。很多人花了太多时间，折腾各种新的语言，希望它们会奇迹一般的改善代码质量，结果最后什么都没做出来。选择语言最重要的条件，应该是“够好用”就可以，因为项目的成功最终是靠人，而不是靠语言。既然Java没有特别大的问题，不会让你没法做好项目，为什么要去试一些不靠谱的新语言呢？


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 Tesla Autopilot

 
 
 
 
    

    
 
     
  

      
   
Tesla Autopilot
以下内容是《Tesla Model S的设计失误》一文中新加入的小节。由于写作时间相距太远，而且由于它的时效性，现在也把它单独提出来，独立成文。




    两个月前，Tesla通过“软件更新”，使Model S具有了初级的“自动驾驶”（autopilot）功能。这个功能可以让Model S自动地，沿着有“清晰边界线”的车道行驶，根据前后车辆的速度相应的加速和减速。



    这貌似一个很新很酷的功能，咋一看跟Google的自动车有的一拼（其实差得天远）。然而在推出后不久，YouTube上出现了一些视频（视频1，视频2，视频3，视频4，视频5）。它们显示，autopilot在某些情况下有可能进行错误的判断和操作，有些险些造成严重的迎面车祸。



    





    特别是视频1显示，在路面线条清晰，天气很好的路上，autopilot忽然向左，试图转向反方向的车道，差点导致严重的对撞车祸。仔细观察autopilot转向之前的情况，是由于路面上有阳光投下来的树影。Autopilot误以为那是一个障碍物，所以试图把车转上反方向的车道！



    从这个简单的视频我们可以看出：




    Autopilot没有对图像进行基本的“阴影消除”，它不能区分阴影和障碍物。阳光强烈，阴影明显的时候，autopilot可能把阴影当成障碍物。阴影消除在计算机视觉已经研究挺多了，这说明Tesla有可能没有进行基础的计算机视觉研究。缺乏分辨阴影和障碍物的能力，这样的自动驾驶系统是完全不可接受的。


    道路中间有明显的，表示“禁止超车”的双黄线，对面有来车。Autopilot为了避开“障碍”，冒着对撞的危险，左转跨越双黄线。这表示autopilot连基本的交通规则，紧急情况下的正确操作方式都搞不清楚。或者也许这软件里面连双黄线都没有识别，甚至连这个概念都没有。



    对于一个有经验的驾驶员来说，如果发现前方有障碍物，正确的作法不应该是猛烈地转弯避开，而应该是紧急刹车。从视频上我们看出，车子没有刹车减速（保持在37~38），而是猛烈地左转。而且是等树影到了面前，才忽然进行操作，没有计算提前量。这说明设计autopilot的人，连基本的开车常识都不明白。





    让我感到悲哀的是，这些视频的很多评论，大部分都在谩骂车主是傻逼：“这是车主自己的责任！”，“Autopilot只能在高速公路上使用”，“只能在车道上有明确的边界线的时候使用！”，“不能在有很多弯道的地方“，“只能在能够看见前方300米道路的地方使用”，“谁叫你不看说明书的！”…… Elon Musk也在一次采访中明确的告诉记者：“如果用户因为使用autopilot而导致了车祸，是用户自己的责任！” 他反复地声明：“autopilot还处于beta版本……” 意思是，你们小心着用！



    我对这些说法持不同的观点。首先，Tesla根本就不应该把一个处于"beta状态"的功能，自动推送到所有Model S的系统里面。实际上，像autopilot这种功能，关系到人的生命安全，根本就不应该有"beta版本"或者“测试版本”之说。Tesla把这样不成熟的系统，强制推送给用户，然后又说如果出了事故，用户负所有责任，这是一种推卸责任的做法。要知道，没有任何人愿意拿自己的生命给Tesla做“beta测试”。



    另外，就算是用户没有仔细阅读autopilot的使用说明，在“不该”用它的地方（比如路面线条不清晰的地方）使用了autopilot，如果出了车祸，Tesla也应该负完全的责任。理由如下：




    作为用户，他们没有义务阅读并且深刻的理解autopilot的局限性。在软件行业，存在一种习惯性的“责备用户”的不良风气。如果软件的设计有问题，用户没记住它的毛病，没能有效地绕过，那么如果出了问题，一般被认为是用户的错。Tesla想把软件行业的这种不正之风，引入到人命关天的汽车行业，那显然是行不通的。


    Tesla的autopilot实现方式幼稚，局限性实在太多。天气不好的时候不行，路面上的边界线不清晰也不行，光线不好或者有阴影不行，路上有施工的路桩不行，高速出口不行，…… 实际上，在如此苛刻的限定条件下，任何一个汽车厂商都可以做出Tesla那种autopilot。



    我自己的便宜Honda车，就有偏离车道时发出警告的功能（Lane Drift Warning，LDW）。装个摄像头，来点最简单的图像处理就搞定。在Indiana大学的时候，我们有一门本科级别的课程，就是写代码控制一辆高尔夫球车（也是电动车呢），沿着路面上的线条自动行驶。这根本没什么难度，因为它能正确行驶的条件，实在是太苛刻了。



    其它汽车厂商很清楚这种功能的局限性，所以他们没有大肆吹嘘这种“线检测”的技术，或者把它做成autopilot。他们只是把它作为辅助的，提示性的功能。这些汽车厂商理解，作为一个用户，他们不可能，也不应该记住autopilot能正确工作的种种前提条件。


    用户没有足够的能力来“判断”autopilot正常工作的条件是否满足。比如，路上的线还在，但是被磨损了，颜色很浅，那么autopilot到底能不能用呢？谁也不知道。把判断这些条件是否满足的任务推给用户，就像是在要求用户帮Tesla的工程师debug代码。这显然是不可行的。如果autopilot能够在检测到道路条件不满足的情况下，自动警告用户，并且退出自动驾驶模式，那还稍微合理一些。


    用户也许没有足够的时间来响应条件的改变。Autopilot自动驾驶的时候，车子有可能最初行驶在较好的条件下（天气好，路面线条清晰），然而随着高速行驶，路面条件有可能急速的变化。有可能上一秒还好好的，下一秒路面线条就不再清晰（视频5貌似这种情况）。路面条件的变化突如其来，驾驶员没有料到。等他们反应过来，想关闭autopilot的时候，车祸已经发生了。这种情况如果上诉到法庭，稍微明理一点的法官，都应该判Tesla败诉。


    Autopilot显摆出的“高科技”形象，容易使人产生盲目的信任，以至于疏忽而出现车祸。既然叫做“autopilot”，这意味着它能够不需要人干预，自动驾驶一段时间。既然用户觉得它能自动驾驶，那么他们完全有理由在到达高速路口之前（比如GPS显示还有一个小时才到出口），做一些自己的事情：比如看看手机啊，看看书啊，甚至刷刷牙…… 不然，谁让你叫它是“autopilot”的呢？我坐飞机时，就见过飞行员打开autopilot，上厕所去了。如果启用了autopilot还得一秒钟不停地集中注意力，那恐怕比自己开车还累。自己开车只需要看路，现在有了autopilot，不但要看路，还要盯着方向盘，防止autopilot犯傻出错……


    Tesla把“beta版”的autopilot推送给所有的Model S，是对社会安全不负责任的做法。你要明白Murphy's Law：如果一个东西可能出问题，那么就一定会有人让它出问题。Autopilot的功能不成熟，限制条件很多，不容易被正确使用，这不但对Model S的车主自己，而且对其他人也是一种威胁。汽车不是玩具，随便做个新功能，beta版，让人来试用，是会玩出人命的。我觉得Tesla的autopilot，跟无照驾驶的人一样，应该被法律禁止。由于autopilot的复杂性和潜在的危险性，使用autopilot的用户，应该经过DMV考核，在驾照上注明“能正确使用Tesla autopilot”，才准上路。


    关系到人的生命安全的“免责声明”和“用户协议”，在法律上是无效的。在美国，到处都存在“免责声明”之说。比如你去参加学校组织的春游活动，都要叫你签一个“waiver”，说如果出了安全事故或者意外，你不能把学校告上法庭。这种免责声明，一般在法律上都是无效的。如果由于学校的过错而致使你的身体受了损伤，就算你签了这种waiver，照样可以把学校告上法庭。我估计Tesla的autopilot在启动时，也有这样的免责声明，说如果使用autopolit而出现车祸，Tesla不负责任。由于autopilot直接操控了你的车子，如果真的出了车祸，这跟其它的waiver一样，都是无效的。你照样可以上法庭告他们。





    由于意识到这个问题，知道出了问题自己是逃不掉责任的，Tesla最近又通过强制的软件更新，对autopilot的功能进行了一些限制，说是为了防止用户“滥用”autopilot做一些“疯狂”的事情。Tesla很疯狂，反倒指责用户“滥用”和“疯狂”。这让人很愤慨。



    对autopilot进行限制的同时，Tesla又推出了beta版的“自动趴车”和“召唤”（summon）功能。这些功能貌似很酷，然而它们也附带了许多的限制条件。你只能在某些地方，满足某种特定条件，才能用这些功能。如果你违反这些条件，出了事故，Tesla声称不负责。



    这些能够让车子自己移动的功能，跟autopilot一样，同样会给社会带来安全隐患。比如，有人在不该使用自动趴车和summon功能的地方用了它，就可能会导致车祸。这不是用户的问题，而是Tesla根本不应该发布这些不成熟的技术来哗众取巧。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 给Las Vegas的差评

 
 
 
 
    

    
 
     
  

      
   
给Las Vegas的差评

    新年的旅行，大部分是浪漫而快乐的，然而也有不如人意的一两天。这一两天的不如意，来自于一个错误的，类似“朝圣”的理念：要去赌城Las Vegas看看，人生才算完整。其实本来没什么兴趣的，但因为一路开车观光，欣赏风景和美食，走得比较近了，就想顺路去Vegas看看也无妨，不看也许会后悔。哪知道这一失足，差点毁了整个旅行的心情。旅程完成之后，我只有一个遗憾——我希望自己没去过Vegas这鬼地方。



    不知道为什么，Vegas仿佛是很多中国人在美国旅游，必去的一个“胜地”。对于在国内从没见过赌场的人，它充满了神秘。对于在美国的各种小村子里面（比如大学啊，硅谷啊）待久了，无聊了，想去“城里逛逛”的中国人，它充满了魅力。电视上总是看到这里灯红酒绿，街上熙熙攘攘的人群，club里激情洋溢的艳影，疯狂的party，各种“有名”的show，遍地散发漂亮小姐的广告，甚至还可以去赌场里感受一下……



    然而真的到了Vegas，却发现那些朦胧的幻想，被扫得一干二净。如果你来Vegas的目的不是赌钱，那么你多半会失望的。如果你来了却没失望，那你的脑子恐怕患了某种神奇的疾病 :)



    下面我就把自己对Vegas的感受简要说一下。


自然环境恶劣


    Vegas真的是在沙漠里。去Vegas的路，从沙漠中间穿过。风呼呼的吹呀，如果不好好扶稳方向盘，恐怕车子就会被风吹到路边去。Vegas的冬天又冷又干，本来鲜活的一个人，到了Vegas，整个人都不好了。夜里相对湿度低于20%，到的当天晚上就舌头干，喉咙干，鼻子干，咳嗽不止，嘴唇干裂疼痛，各种不爽……



    然而再恶劣的自然条件，都不能跟恶劣的人心相比。Vegas最让人厌恶的，其实是这里的人。


服务人员素质低下


    我评价一个地方的生活质量，最重要的指标，在于它的服务业人员是否对所有人发自心底的友好，而不只是对有钱人点头哈腰。在我看来，Vegas是一个虚伪势利，对人极其不友好的城市。它就像一只哈巴狗，只对又有钱又傻的人摇尾巴。当然它摇尾巴的目的，不过是想从这些傻人身上榨取最大的利润。



    酒店里西装革履的招待员，对你貌似彬彬有礼，可是眼神对视的时候，你却能感觉到他们高冷的气势。那笑容不是发自心底的，你看得到他们内心的傲慢，居高临下的态度，甚至歧视。这些服务人员，仿佛随时在上下打量你是什么人种，穿的衣服是否名牌，口袋里是否有钱可以拿出来。当你来的时候，你感觉她的眼睛不是在说“欢迎你来到Vegas！”，而是在说：“OK，我们开恩让你住这里了，好自为之吧！”当你走的时候，他的眼睛打量一下你，仿佛在说：“就这样？没赌钱就走人了？”



    态度生硬的酒店服务员还算是好点的了，商店和饭店里，服务人员态度恶劣露骨的，实在多的去了。那态度，仿佛你花了高价，反倒是来跟他们要饭的一样。在Vegas，我算是开了眼界了，这是我一生中见过服务态度最差的地方。我可以说，Vegas 60%以上的服务人员，素质低下，态度恶劣和虚假，对人冷眼相对，非常没有礼貌。这里面感觉到的委屈和歧视，真是不忍回首，一天要被各种各样的服务人员坏好几次心情。


吃的东西很难找，排长队


    Vegas的餐厅非常少，质量非常低。在街上走老半天也看不到什么吃的东西。每次走进看似商场的地方，清一色的奢侈品：LV，GUCCI，…… 然后就进到赌场了。恁是看不到吃的东西！



    好不容易看到点吃的，大家排着长队，服务态度还非常差。跟纽约，三藩，洛杉矶不一样，Vegas似乎没有任何本地人开的，受好评的餐厅。可以吃的东西，基本上都是在别的地方都有的连锁店快餐。



    去吃排名Top 10的“Vegas自助餐”，付了不菲的价钱，排了两个小时，拐了5道弯的长队。店员像学校食堂大妈一样满脸的鄙夷，吆喝着叫你进去，像是赏给你吃的。最后吃到的东西还不如公司的免费午餐，进餐环境还不如嘲杂拥挤的广东dimsum店。



    



    这现象恐怕只有在Vegas才能遇到。按照普通的标准，排队一小时的餐厅，必然非常好。排队两个小时的餐厅，一定要超级好才行。洛杉矶最好的韩国烧烤，才有可能在过年的时候排两小时的队。在Vegas，这套标准行不通了！而且这些buffet被设计来，在排队的时候，你没法看到里面的食物。等你等了几个小时排到了，进去才发现是那样的质量，后悔已经来不及了。



    所有价格合理一点的地方，全都排长队，这包括各种有名的“Vegas自助餐”，Outback Steakhouse, Cheesecake Factory一类的连锁店。Vegas的自助餐名气大，质量差。不要以为排长队，价钱高就是好东西，因为大家到处找不到吃的，只好排长队吃自助了，吃的竟是一些残羹冷炙，连新鲜水果都没有，还不如别的地方的China Buffet。



    当然，如果你肯花大价钱去吃某轮胎公司给评了级的餐厅，巨大的盘子里放一勺子东西那种，就另当别论了。反正我是不会给这种谋暴利的人送钱去的，又不想排长队，所以最后发现只有Panda Express和Chipotle之类的快餐可以吃了。如果这些地方都关门了，那就只有到Walgreens里面买块三明治了。如果怕冷不想去Walgreens，那就在房间里吃泡面吧。哦对了，我告诉过你，Vegas的酒店房间里是没有咖啡机的吧？所以也没有开水给你泡面了。



    吃的东西质量是如此的差，队是如此的长，以至于M&amp;M's和Hershey's这些摆在超市里都没人买的巧克力品牌，居然都可以在大街上开店。各个Starbucks和Walgreens也经常排长队，因为游客找不到吃的，所以跑到这些地方来买三明治和面包当晚餐了。



    



    在Vegas，我第一次遇到Starbucks的店员，为了15美元之小的买卖，要求我出示身份ID，还“指导”我在收据上签字，显示出一副“你会用信用卡吗？”的神色。由于我的信用记录和可靠性极好，从来没丢过信用卡，在其它城市的类似Starbucks的大店，我刷卡是根本不需要签字的，更不要说出示ID了。刷了卡收据也不要，就去等咖啡了，利索得很。一般说来，贫穷地区的小店里使用信用卡，店员要求出示身份ID的几率要大一些，因为如果是被盗的信用卡，他们赔不起。现在这居然发生在了Vegas大街上的Starbucks。这绚丽的霓虹灯之下，到底是什么穷地方，破地方啊，我真的很无语。



    Sigh，来到Vegas就意味着营养不良，外带各种心酸……


想钱想疯了


    到了Vegas，你不是被当成一个人，而是被当成了用来宰割的牛羊。你感觉各种服务设施，不仅是在骗钱，而且是在抢钱。天然条件恶劣的地方，人们一般都特别友好和温暖，乐于助人，然而Vegas是一个例外。它不但是自然界的沙漠，而且是人性的沙漠。你自己要到这沙漠里来，那么所有东西我们都要卖高价，因为你不得不买！



    从酒店，商场，到外面的饭店，交通工具，各种show，人们都想给垃圾标上大价钱，不是让虚荣心驱使你去买，就是让“求生”的欲望逼你去买。我是一个不吝惜钱的人，我用的东西都是高质量的。我愿意出大价钱买东西，然而我要求它必须值那个钱，我要求的是优质的产品和服务。Vegas的几乎所有东西都很贵，然而花了钱，你却买不到相应质量的产品和服务。



    看似高档的四星级酒店，房间里连咖啡机这么基本的设施都没有。我走遍美国这么多的地方：纽约，波士顿，奥兰多，迈阿密，旧金山，西雅图，夏威夷…… 高中低档的酒店都住过，这是唯一一个没有咖啡机的酒店。连最便宜的Motel，全都有咖啡机。夏威夷海边的高档resort，有咖啡机。唯独Vegas的四星级酒店没有。咖啡机是一个重要的东西，不是因为它可以做咖啡，而是因为它可以用来烧热水。Vegas的自来水，喝起来味道很不好，貌似水质很硬。晚上又冷又干，却只能去售货机买$3一瓶的冷冻瓶装水，喝得直打哆嗦。因为气候实在太干，不一会儿又渴了……



    收了每天$30的所谓“Resort Fee”，几乎跟夏威夷设施完善的resort一个价，却没见到酒店为此提供了什么服务。去游泳池泡泡居然还要按天收费，每人每天$17。房间里缺少本来该有的设施，是为了逼迫你到外面去花钱。饿了出去找不到吃的，点个汉堡到房间，20美元！起床稍微晚了一点，回到酒店，发现房间都没有打扫，毛巾都没有换！



    路上堵得一塌糊涂，开车还不如走路快。没有通畅的公交工具，只有一个叫“monorail”的架空单轨电车，可以载你经过少于2英里的路程。这个monorail的车子，也不知是哪个城市淘汰的产品，开起来摇摇晃晃，嘎吱的响，仿佛要从半空中掉下去似的。短短不到2英里的路程，单程票价是$5。比较一下，其它城市好几十英里的地铁，也只收$2。



    本来这种架空电车应该是用来观光的，然而如此的高价之下，车身窗户上还遮上障眼的纱网，印上巨幅的广告，导致车内光线暗淡，没法畅快的看到外面的风景，像是在坐囚车。



    



    作为这个交通工具的消费者，付了高价却不受尊重，被剥夺了一览窗外景物的基本权利。现在世界上的东西，一般是免费的靠广告赚钱，收费的就不会在上面打广告。可是Vegas的monorail既要收高额票价，又要里外打上广告，妨碍视线，真是什么钱都赚。谁叫你没有别的交通工具可以用呢？


赌场，赌场，还是赌场


    本来对赌场没有什么反感的，觉得小赌娱乐一下也无妨。到了Vegas，却真的对赌场产生了严重的反感。



    在Vegas，你被完全剥夺了回避赌场的权利，你无法不经过赌场而到达任何地方。不管多么高大上的酒店，要进到房间，必须走过狭长的赌场过道。要去坐monorail？必须穿过赌场。要买吃的，喝的，穿的？必须穿过赌场。要买show的票？必须穿过赌场。



    赌场里空气很不好，充满了烟味，二氧化碳严重超标，氧气不足，所以一进去就觉得胸闷，呼吸不畅，嗓子发痒，甚至头晕目眩。想想吧，你支付着高昂的酒店费用，却被剥夺了直接进入自己房间，而不呼吸污浊空气的基本权利。在这种情况下，本来想小赌一把的我，就打消了这个念头。



    到了房间，整装出门逛街。回到酒店，却又不知道客房电梯在哪个旮旯里了。看路牌说“Guest Elevator走这边”，走到一半，发现还是没看见电梯，却没了路牌。不得不找赌场工作人员问（当然，他们态度也不怎么好），才找到回房间的电梯。每一次进酒店，都要经过这么一番摸索折腾，累不累，烦不烦呀。



    有些酒店里有看show的剧场，你找到了剧场，却发现剧场旁边找不到售票处（box office）。你需要穿过赌场，跑到另外一边，才能找到box office。如果你用了ticket master之类的服务，还会发现ticket master的取票机不在剧场旁边，也不在box office旁边，而是在赌场的不知道哪个旮旯里……



    这其实是赌场老板故意针对人的心理设计的。Vegas的酒店，几个重要设计原则就是：




    设计一定要没有组织，没有逻辑，让人摸不着头脑，容易迷路。这可以最大限度的迫使人接收到赌场的诱惑。


    迫使你必须经过赌场的诱惑，才能回到自己的房间。途中还会听到一些人歇斯底里的叫声：“哇！赢钱啦！”


    赌场里换气设施故意不做好。这样空气里氧气含量低，二氧化碳和烟味重，可以使人在赌钱的时候头脑不清醒，不能有效地控制自己的行为，以至于输了钱还不赶快撤退。





    这样的设计，使得你不得不经受很大的诱惑，或许有些人本来不赌钱的，就开始赌，最后输得精光。说真的，你把空气弄好一点，也许我还真的上钩了，可惜就是空气太差，再大的赚钱诱惑对我来说也是白搭。遇到我这么珍惜自己的生命和健康的人，算你们倒霉 :P


丑陋的Vegas人


    Vegas路上走着的人，除了少数游客，大多穿着老气过时，粗人酒鬼模样。很少看到打扮有格调，有教养的人。不然就是怒目相向，不然就是鬼鬼祟祟的神情。



    Vegas是妓女合法化的地方，在这里找小姐是“规范”的，合法的。所以你就可以在大街上看到一些车，打着穿着暴露的美女照片和电话号码，招摇过市。路边也站着很多散发美女小卡片的丑陋男人。



    不要被那些靓丽性感的照片迷惑了。请看看大街上的妹纸们，有看得过去的吗？土爆了！如果大街上都没有好看点的妹纸，你觉得花了大价钱就会有漂亮妹纸陪你睡觉吗？你做梦吧。



    早就有人报道过说，在Vegas找小姐，是按“项目”收费的。给你一个类似涮涮锅点菜的单子，打几个勾，加起来随便就两三千美元。结果到时候看人，各种穷形尽相的大妈，倒贴钱都没人要的。



    所以Vegas的小姐跟其他东西一样，垃圾卖大价钱。所以欲求不满的中国同学们，还是把钱省着回咋们东莞用吧 :P



    ……还好，我自带了可人的美女来，发小广告的小混混们看到，就自惭形秽的躲开了 :)


退休明星的舞台


    Vegas最著名的另一个地方，就是它的各种show。Topless的Jubilee show，太阳马戏团的O show和其它，大卫科波菲尔魔术，Elton John演唱会，最近Britney Spears也开始在这里演出。这貌似一个文化丰富的地方？



    可是你有没有发现，这些常驻Vegas演show的，其实都不再是当红的明星？你有多少年没看过马戏表演了？你有十几年没见过大卫科波菲尔，Elton John，Britney Spears这些人了吧？能亲眼见到这些儿时崇拜的明星，是不是很激动呢？可惜，他们已经不再是当年的，英俊美丽的，身材不变形，唱歌不走调的他们了。



    花了上百的票价，看到的竟是一些人老珠黄。特别是Britney Spears，大街上放着她的广告，各种SM的场景，感觉跟Vegas跳脱衣舞的大妈们差不多了。有一个理论是，当一个明星开始在Vegas常驻现场演出，而不是在电视里面出现的时候，你就知道他已经没落了。



    在Vegas，你还会惊讶的发现，多年没在电视上见过的“吉尼斯世界纪录”之类的无聊东西，在街上开店卖票…… 不过呢说真的，那个topless的Jubilee show还真是不错的，属于Vegas比较有特色，有质量的一个show。虽然是topless两点暴露，却一点不感觉色情。还是有点舞台效果和艺术价值的。


人造风景名胜


    越是文化匮乏的地方越是喜欢附庸风雅。Vegas的酒店，喜欢人造一些“迷你版”的欧洲名胜。比如有个叫Paris的酒店门口，造了一个小型的埃菲尔铁塔…… 等等。这些所谓的名胜，让Vegas成为了一个类似国内“世界乐园”的地方。这些东西材料也不怎么好，所以看上去各种cheap。Caesar Palace门口那雕像，石料肯定不好，不然不会看起来那么脏那么旧。



    很多人在这些假的名胜旁边合影留念，让人哭笑不得，仿佛他们从来没见过好的风景。这些人完全不明白旅行的意义是什么，他们照相的目的在于表示自己“到此一游”。在某个酒店里的大厅，我看到大群的人们，对着一些假花和三流水准的圣诞装饰物照相，真是让人匪夷所思。



    


休闲设施匮乏


    Vegas的大街上，Mall里面，很少看到有椅子可以坐。少数人坐在喷水池边上，很冷，其它人都在走路或者站着。你感觉在Vegas最深刻的记忆，就是在不停地走路。这种休闲设施的缺乏，使得Vegas不适合作为休闲旅游的去处。



    唯一不缺座位，不需要排队的地方，就是赌场。


总结


    我怀着一个“朝圣”的心，结果自己颠覆了Vegas，这座很多中国人心目中的“旅游胜地”。如果你是为了赌钱来到Vegas，你也许会喜欢它，然而它绝对不是一个休闲度假的好去处。如果你希望见到热情好客的人民，温馨周到的服务，你一定是会失望的。



    如果说去Vegas旅行有它的价值的话，那就是它给了我一个反面的教材，一场心灵的洗礼。我亲眼看见并且经历了人类文明最没落地方。我清楚地知道，我不希望我的国家，我的人民变成那个样子。我不再对赌场之类的“成人游戏”有好奇心，我更加珍惜自己身边美好的人和事物。这是我第一次，也是最后一次，来Las Vegas旅行。我想它还是值得的。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 Tesla Model X的车门设计问题

 
 
 
 
    

    
 
     
  

      
   
Tesla Model X的车门设计问题

    Tesla即将推出的SUV（Model X），不但继承了以上提到的Model S的各种问题（触摸屏，门把，……），而且还制造了新的问题。Model X具有一个别出心裁的车门设计，这车子看起来像一只展翅的鸟：



    



    这样开的车门貌似更省空间，方便在狭窄的地方开门，而且看起来更酷，有点像McLaren或者Lamborghini。然而这样的设计，在我看来有以下几个问题：


安全性问题


    由于后门完全由电机控制，在车子失去电力的时候要打开后门，过程复杂得离谱。首先在失去电力的时候，无论如何是不可能在车外把门打开的。这意味着，如果出车祸着火了，消防队员可能没法很快帮你打开车门。



    如果你运气好，没有受伤，头脑还清醒，气囊和安全带也没挡住你，那么你必须完成三件复杂的操作，才能逃离Model X：



揭开车门上扬声器的盖子
扳动一个隐蔽在那里的机关
然后自己把车门举起来




    我比较无语…… 如何揭开扬声器的盖子？你需要随时在车里准备好榔头和改锥吗？螺丝藏在哪里的？要知道，用户可不是Tesla雇佣的机械师。这对于车祸逃生是非常不利的设计。如果撞坏了电源，后面的人恐怕无法在合理时间之内逃离。



    


雨雪天气的麻烦


    




    车门升起时，车的后部上方有很大的空挡。下雨或者下雪的时候，雨雪会乘着车门张开的时候，大量飘进车里。


    当车门升起来的时候，夹在门缝里的灰尘和渣滓会掉进车里。车顶上如果有积雪，也会掉进去。设想一下，下雪天开了一会车，打开后门，结果车顶上的雪都掉在后面的人头上了……


    下大雪的时候，后面的车门可能被大雪压住打不开，或者导致电动机超负荷损坏。


    由于门上的缝隙太长，这种设计更加容易出现由于密封圈老化而漏水的问题。




趴车的麻烦


    在顶棚很低的车库里可能会碰到天花板。这是一个很现实的问题，因为很多车库旁边的空间很多，顶棚却很低。比如，这次我到洛杉矶和拉斯维加斯旅游，经常遇到这样的车库：



    



    总的说来，在非常狭窄的地方开门，其实并不是什么很需要解决的事情。有钱买Model X的人，难道会经常把车停在狭窄的夹缝里吗？为了这种不常见的应用，用得着花这么大功夫设计个车门吗？就算你能开门，人出去之后挤不挤得出去，是另外一回事。如果地方实在太窄，你完全可以让后面的人先下车，然后再进车位。



    另外，滑动式的车门同样可以解决这个问题，根本用不着花大成本来实现升起来的车门。



    



    如果你知道，Model X的车身宽度为81.6英寸，比Hummer H2, Cadillac Escalade和Ford F-150这样的庞然大物还要宽，你就会发现真正的问题不在于空间不够，而是在于这车实在太宽了。有多少人愿意开这么宽的车，是一个问题。


实用性问题



    顶棚不再能安装货架。不知道滑雪板和kayak之类该绑在哪里。这降低了Model X作为一个SUV（Sport Utility Vehicle）的使用价值。



    


    后门上不再能放随身物品。这样后面的乘客会不是很方便。



    




制造和维修的问题



    这种车门机械非常复杂，容易出问题，维修起来很麻烦。制造起来也很麻烦，以至于一家很有经验的，为奔驰和通用提供配件的德国设备厂商，都没法满足Tesla的要求。请参考这篇新闻。



    




   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 写书计划

 
 
 
 
    

    
 
     
  

      
   
写书计划

    好些人问过我写书的事情。我确实该写本书了。计算机科学，其实根本不是科学，它缺乏基本的科学精神。计算机“科学”里面的少量真知灼见，已经被大量的商业动机和“天才语录”给淹没。这个领域的所谓“知识”，其实90%以上都是扯淡，或者是死板的教条和本本主义。剩下不到10%，却是非常好的东西。



    这种瞎蒙混骗的风气，从图灵那一辈就开始了，以至于好的东西和不好的东西，永远的混在了一起，没法区分开来。你可以提出一个完全没用的理论，却仍然有人相信它是伟大的发明，并且拿到图灵奖。很多经典的书籍，其实让人知其然而不知其所以然，很多甚至把简单的问题复杂化。因为它们的目的，其实在于掩盖真相，传播谬论，让人恐惧和糊涂，以至于人们以为计算机科学博大精深，有无穷无尽的东西要学。



    我希望能够改变这个格局。上次写的《编程的智慧》，其实就是这样一本书的开端。这其中的内容，真不是拿一个名校的CS PhD，当个教授或者Principle Engineer，甚至Chief Architect就能搞清楚的。之所以叫做“开端”，是因为它还没有达到我希望的组织和清晰程度。这样的内容以blog的形式出现，已经显示出它的弊端了。Blog组织内容的方式是按时间，blog的单元是文章。由于我希望写出的内容，有效性是接近“永恒”，而且由于内容比较多，需要多层的目录，逻辑组织上blog也无法应付。所以我必须用书的形式写出来。



    写这样一本书，不是什么大不了的事情，然而它对于混沌不堪的计算机科学界，恐怕具有转折性的意义，所以我必须使用一种世界上大部分人都能看懂的语言。那种语言在现在看来就是英语。我会把这本书的初稿放在网络上，供人们免费下载阅读，这样他们可以给我有益的反馈，提醒我谬误和不清晰之处。这本书会覆盖计算机科学的方方面面，从程序语言，操作系统，到数据库，网络系统，……



    有人可能以为这是一个可望而不可即的，包罗万象的宏伟目标，那只是因为他们没有看穿CS里面的迷雾。如果要面面俱到，照本宣科，把每个子领域的死知识都一股脑写进去，包括每种操作系统命令，每种语言的用法，每个数据库的API，各种乱七八糟的WEB技术，…… 那当然是一辈子也写不完的。然而如果你看透了这层迷雾，就会发现CS里面的精髓部分其实没有很多，它们完全是可以在短时间里掌握的。



    所以这本书的定位，在于精髓和创造，而不是细节和死记硬背。我希望把它们共同的精髓提取出来，而去掉其中肤浅的死知识部分。如果你希望它教会你所有的东西，包括某最新语言新加入的特性，或者某最新big data工具的API，那显然是不可能的。有太多的书籍可以教会你那些东西，所以不用我来费工夫。然而我所介绍的精髓概念，应该可以帮助你设计和创造出这样的语言特性和大数据工具，而不只是成为一个被动的使用者。



    在初期的时候，我会把书的内容放在网上，供大家免费阅读，提出宝贵意见。等到这本书达到我满意的程度之时，我也愿意让高水平的出版社，印成纸张出版。不过出版社的位置，应该处于“转载”的位置。免费下载的PDF，会一直得到更新和补充。只有这样不断地改进，这本书才能达到我满意的地步。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 Tesla Model S的设计失误

 
 
 
 
    

    
 
     
  

      
   
Tesla Model S的设计失误

    



    这幅美丽的图片，就是红极一时的Tesla电动车Model S的内景。然而你有没有发现，其中有一些不大对劲的地方？虽然我看好电动汽车，它们环保，安静，运动敏捷，然而我发现Tesla的这款Model S，其实有一些严重的设计失误。


缺少硬件开关，过度依赖软件和触摸屏


    纵观Model S的内景，你会发现这车里面怎么光溜溜的，就没看到几个按钮。确实如此，Model S内部设施的控制，基本上完全靠中间那个很大的触摸屏。



    顶棚上有一个天窗，却没看见天窗的开关。通常说来，当人们看见门或者窗户，他们期望有一个开关，设在旁边顺手的地方。然而你在Model S里面一抬头，却看不见任何可以按下或者掰动的开关。顶棚上面几乎是光溜溜的一片：



    



    有些人可能觉得这样的设计，比其它车子更加美观，简洁。然而你可能没想到，这种“美观”其实是有代价的。一个很简单的问题是：你怎么打开天窗？答案：你必须使用触摸屏！



    



    你要在触摸屏上找到一个叫“Controls”的页面，然后从左边的控制栏选择“Sunroof”，然后在右边会出现一个车子的图片，和一个滚动条。你把滚动条往下拉，天窗就打开了……


把简单的问题复杂化


    然而这种依赖于触摸屏的设计，其实是让简单的问题变复杂，变麻烦了。其它车的天窗开关都是很明显，不需要“找”的，而Tesla的天窗开关，你要找一会儿，甚至找到了还要琢磨一下，才会知道该怎么用。我现在把导致这种结果的原因，详细分析如下：




    天窗控制器不在天窗旁边。触摸屏跟天窗，处于风马不及的位置。这违反了一条基本的设计原理：控制器应该很容易找到，最好在它所控制的东西上面或者旁边。如果用户想打开天窗，他应该能够在天窗旁边，找到一个明显是用来打开它的开关。几乎所有其它车子，天窗开关都在顶棚上，不知Model S的设计者，为何要抛弃这种久经考验的设计。


    触摸屏上干扰信息太多，不容易找到正确的按钮。触摸屏太大，上面显示着所有控制器的信息。这些控制器的位置，本来可以分布在车的各个部位，现在却集中到了一个仅十几寸的屏幕上面。这当然显示不下，只有放到好几个菜单里面去。



    这些“软件控件”的位置，也不是很符合逻辑。例如，为什么有些控件（比如天窗）在tab里面藏着，而另外有些（比如门锁）直接露在外面？以至于你一眼看去，会不知所措。



    相比之下，大部分其它车的硬件天窗控制器，附近没有很多干扰信息：



    



    这个控制器在顶棚上，而且处于控制板的中央位置。旁边只有几个顶灯的开关。这些开关，对应着灯在顶棚上的位置。后面的灯，控制器在后面；前面的灯，控制器在前面；左边的灯，控制器在左边；右边的灯，控制器在右边……



    这种排列方式，在设计学上叫做“自然映射”（natural mapping）。你不需要多次的摸索和记忆，甚至不需要看开关上的标记。只根据开关的相对位置，你就知道哪一个开关控制哪一盏灯。


    查找天窗控制器的“逻辑路径”太深。从最开头的触摸屏界面，直到找到打开天窗的控件，你需要进入至少两层菜单。如果菜单之前停留在另外的状态，你还需要点击某个按钮，回到“主界面”，然后还要从上往下进入两级菜单。这种设计所需要的“逻辑路径”，长度>=3。



    这种多层的“间接访问”，很容易把人搞糊涂。对年纪大点的人，几乎是不可用的。就算是年轻人，恐怕也需要摸索一阵子。如果在紧急情况下，或者事先没熟悉过这车的情况下，需要找到控制器（比如通过天窗逃生），恐怕会不知所措。



    比较一下其它车子的设计吧。其它牌子车的顶棚上，一般有一个比较大的，明显是用来打开天窗的开关。不管车子当时处于什么状态，直接伸手就可以摸到这个开关。这种设计所需要的“逻辑路径”，长度=1，也就是说是直接的。


    触屏的界面并不直观。仔细观察触屏上的控件，它们的操作方式并不是那么直观的。看到那个滚动条一样的东西，我该是点击呢，还是拖动呢？“VENT”，“OPEN”那几个字的位置，到底表示什么呢？我如何让天窗向上倾斜通风（tilt）？真是有点莫名其妙的感觉，恐怕要看说明书，摸索一会儿才能知道这到底怎么用。



    相比之下，其它牌子汽车的硬件开关的设计，其实非常的直观。开关向后一拉，天窗就打开。向前一推，天窗就关闭。有些车子的天窗可以向上倾斜一定的角度（tilt），所以你可以把这按钮向上一推，天窗就进入倾斜通风的状态。



    这种硬件开关的设计，符合了“自然映射”的原理。天窗的开关，成为了天窗的一个“模型”（model）。开关的位置，正好跟天窗平行。开关的运动方式，跟天窗的运动方式，产生一种“自然”的对应关系。开关向后，天窗也向后。开关向前，天窗也向前。开关被向上推，天窗也向上倾斜。这是非常好的设计。




触感，力反馈和行车安全


    触摸屏缺乏触感和“力反馈”，无法进行“盲操作”。由于触摸屏是平的，所以它无法提供触觉和力反馈。你无法光靠手就摸到按钮的位置，而必须用眼睛看屏幕。当你找到并且拖动屏幕上的滚动条，你的手指不能得到任何力和振动的反馈。你不能立即感觉到，是否已经真的触发了“开天窗”这个操作。只有当天窗开始移动，你才知道刚才的操作是否成功。



    相比之下，硬件天窗开关具有很大的优势。有些车子的天窗开关，设计得符合人体工学，正好符合你的手指的形状。摸起来容易，掰起来舒服，有感觉。手往上一摸，就能找到天窗控制器，之后不用眼睛就能操作。



    像天窗开关这种“盲操作”，在开车的时候特别重要，因为开车时你的眼睛应该随时注视前方的道路。如果眼睛开小差去看屏幕了，就可能出车祸。这就跟开车时用手机发短信一样危险。触摸屏看起来很酷，而其实是降低了汽车的安全性。


系统可靠性：触摸屏是“中央薄弱环节”


    仔细观察一下Model S，你会发现它的内部几乎没有硬件的开关。几乎所有的设施：天窗，空调气孔，窗户，门，后备箱，充电盖，…… 全都是用这个触摸屏来控制。



    从系统设计的角度来看，这个触摸屏就是一个“中央薄弱环节”（single point of failure）。只要触摸屏一出问题，你就会失去对几乎所有设施的控制。根据这篇文章，有的Tesla用户报告说，他的Model S在12000英里的时候，触摸屏突然坏掉，以至于门把都没法用了！



    Just before the car went in for its annual service, at a little over 12,000 miles, the center screen went blank, eliminating access to just about every function of the car…



    相比之下，其它汽车的硬件开关位置是分散的，它们的电路逻辑是相对独立的。一个开关坏掉了，另外一个还可以用。其它车子的屏幕，一般只用来显示倒车摄像信息，以及音乐娱乐等无关紧要的东西。Tesla用这个屏幕来控制所有的配件，真的是发挥过度了。


门把的设计问题


    Model S的门把设计也有问题。它的门把是电动的，而其它车的门把，都是机械的。在停止的状态，Model S的门把会自动缩回去，不露一点缝隙：



    



    当你接近车子的时候，内部的电机会让门把伸出来，这样你就能拉开车门：



    



    按照Tesla设计师的思路：“第一次接近这部车的时候，你首先接触到的是门把：这应该是一个印象深刻的经历。在你走近的同时，门把也伸出来——就好像是这车子想起了你……”



    As you approach the car for the first time, the first contact you have with the vehicle is through the door handle: it needs to be a memorable experience […] The idea of this door handles that protrudes from the car as you approach it – [it’s like] the car is already thinking for you.



    多么诗情画意的场景，一部会想起你的车，一个朋友！可惜这美好的第一印象，是经不起现实考验的。等你买下这车，实际用起来的时候，问题就来了。首先，这个门把被人手抓握的部分，是扁平的形状。这种形状非常的不符合人体工学，捏起来会很不舒服，使不上劲。如果车门被冰冻住，或者门被撞变形了，或者有紧急情况需要很快的开门，这门把就会带来很大的麻烦，甚至可能是很危险的。



    另外，在寒冷的地区，车停在外面，缩进去的门把会被冰冻住。等你要开门的时候，才发现门把被冻住了，出不来。如果软件出了故障，也可能导致门把出不来。一旦出了这些事情，你就完全失去了打开车门的能力。如果门把是机械的，就算上面有一点冰，一拉把手，冰就碎掉，门就开了。如果实在冻得严重了，你把冰稍微凿一下，一拉就开。Tesla的设计者，貌似完全没考虑过这些“意外”的情况。



    没有任何其它牌子的汽车采用像这样的门把设计。从丰田一直到Bugatti，它们的门把全都是机械的，粗壮的，直接就可以拉的。没人在这上面耍花样。你想这应该有原因的吧？由于人的生命安全，在事故的时候依赖于快速地打开车门，门把的设计需要是坚固而可靠的。



    只有Tesla别出心裁，搞得门把完全缩进去，跟车门平齐，连个可以用力的地方都没有。门把和车门之间的缝隙很小，所以冻在里面的冰没法凿开。很多人发现这是个讨厌的问题。看看这篇讨论，你就会发现人们为了这个门把，费了多少脑筋，想出五花八门的解决方案：



提前远程启动车子，让内部温度起来，化掉把手上的冰
往门把上泼热水
放热水袋放在门把上
停车的时候在门把上贴一块透明胶，发现冻上了就把胶布撕掉
用电吹风吹
... ...




    不管这些方式可不可行，有没有效果，你都可以看到，这门把的设计，其实带来了不必要的麻烦。这样的设计，除了看起来很“未来”几乎没有任何实用价值。买了辆酷车，活得可真累。


人体工学和舒适性问题


    另外，我发现Model S的触摸屏，其实在一个很不舒服的位置。如果我靠在司机的座位上，我的手是无法顺利地碰到屏幕右边的。我必须启用我的腹肌，稍微坐起来一点，努力伸出右手，才能够得着那个位置。



    如果触摸屏的位置稍微往下放一点，倾斜度降低一些，就会方便很多。另外，这个触摸屏真的不需要做那么大。



    另外一个奇葩的地方是，触摸屏下方，座位之间，有一片很低的，光溜溜的平面，像个微型的保龄球球道……



    



    这貌似是用来放随身物品的。然而这个空间，由于位置和形状的问题，恐怕不会得到有效的利用。由于平台位置太低，几乎到了地板上，如果往里面放置物品，拿起来会非常的不顺手，甚至需要弯腰下去，而且恐怕会被不小心踢翻。因为整个平面是光滑的，中间也没有挡板，车子加减速时，东西可能会到处乱跑。从美学角度看，这个区域的边界，跟触摸屏线条错位，感觉不流畅，不美观。



    另外有用户反映，Model S的咖啡杯座，被设置在一个很容易被手肘碰翻的位置。某些Tesla的“专家用户”对此的建议是，去买“防溅”的咖啡杯。有些聪明人甚至自己设计，并且用3D打印机山寨了一个架子来放咖啡：



    



    我对此举动非常的无语。本来Tesla的设计师应该做好的东西，居然需要自己动手。很不可思议的是，这样不舒服的车，被叫做“豪华车”，价钱是其它牌子的两三倍……


可靠性问题


    虽然这篇文章里面，我只想指出Model S的设计问题，它其实也有很多可靠性的问题。



    最近的一些报道指出，由于动力系统的问题，2/3以上的早期Model S，动力系统的寿命都不会超过6万英里。Consumer Reports也报道，Model S的可靠性“低于平均水平”。报告指出，Model S存在各种质量问题：触摸屏崩溃，门把失灵，发动机故障，天窗漏水，各种部件嘎吱作响，等等。另外一篇Consumer Report的文章，对各种电动车的可靠性进行了排名，Model S名列倒数第一。


安全性问题


    2016年1月1号，在挪威的一个Tesla充电站，有一台Model S在充电的时候，莫名其妙起火燃烧（见新闻和视频）。由于着火的材料是锂金属，消防队无法用水控制火势，只能用泡沫覆盖隔离，等待烈火把车子完全融化。最后这台车被完全烧毁，幸好没有人员伤亡。事故起因正在调查之中。



    



    Elon Musk对此事故的反应比较让人失望，他说：“美国每年有上万辆汽车起火事故，没有人报道。为什么Tesla的车一起火，媒体就争相报道？” 不好好调查和检讨起火的原因，反倒笑别人“一百步”，这种态度是不可取的。



    其实媒体报道Tesla车起火，是有他们的原因的。汽油车着火，一般都是因为有人犯了严重的错误，导致严重的车祸，油箱破裂，又遇上火源或者重击。或者由于车体老化漏油，又碰上火源。而电动车起火，不需要有人犯错误，不需要有严重的车祸，莫名其妙就着火了。你有见过崭新的汽油车，在加油站加油，忽然自己着火吗？



    这不是第一辆起火的Model S。世界上只有3万多辆Model S，却已经出现过4起起火事件。之前的一个Model S，半路上底部被硬物撞击。屏幕提示说，电池出了问题，请停车并且撤离。幸好车主按照电脑的指示做了，结果撤离不久之后，车就开始燃烧。如果车主没有停车撤离，后果是相当可怕的。这种对生命危险缺乏明确警示信号，其实也是一种严重的设计问题。



    锂电池起火的原因很奇怪，波音787客机上，出现过多次锂电池起火事故，引起了很大的关注。最后分析原因在于：



日本GS Yuasa公司制造的电池存在缺陷。
波音工程师，没有考虑到worse case的电池故障。
FAA，在认证过程中没有考虑到电池的危险性问题。




    既然锂电池有这么蹊跷的潜在危险，Tesla的起火事件，当然也应该受到重视。这问题不像Elon Musk说的那么可靠，那么不值一提。


Autopilot的事故责任问题


    两个月前，Tesla通过“软件更新”，使Model S具有了初级的“自动驾驶”（autopilot）功能。这个功能可以让Model S自动地，沿着有“清晰边界线”的车道行驶，根据前后车辆的速度相应的加速和减速。



    这貌似一个很新很酷的功能，咋一看跟Google的自动车有的一拼（其实差得天远）。然而在推出后不久，YouTube上出现了一些视频（视频1，视频2，视频3，视频4，视频5）。它们显示，autopilot在某些情况下有可能进行错误的判断和操作，有些险些造成严重的迎面车祸。



    





    特别是视频1显示，在路面线条清晰，天气很好的路上，autopilot忽然向左转向迎面方向的车道，差点导致严重的对撞车祸。仔细观察autopilot转向之前的情况，是由于路面上有阳光投下来的树影。Autopilot误以为那是一个障碍物，所以把车转上了反方向的车道！



    从这个简单的视频我们可以看出：




    Autopilot没有对图像进行基本的“阴影消除”，它不能区分阴影和障碍物。阳光强烈，阴影明显的时候，autopilot可能把阴影当成障碍物。阴影消除在计算机视觉已经研究挺多了，这说明Tesla有可能没有进行基础的计算机视觉研究。缺乏分辨阴影和障碍物的能力，这样的自动驾驶系统是完全不可接受的。


    道路中间有明显的，表示“禁止超车”的双黄线，对面有来车。Autopilot为了避开“障碍”，冒着对撞的危险，左转跨越双黄线。这表示autopilot连基本的交通规则，紧急情况下的正确操作方式都搞不清楚。或者也许这软件里面连双黄线都没有识别，甚至连这个概念都没有。



    对于一个有经验的驾驶员来说，如果发现前方有障碍物，正确的作法不应该是猛烈地转弯避开，而应该是紧急刹车。从视频上我们看出，车子没有刹车减速（保持在37~38），而是猛烈地左转。而且是等树影到了面前，才忽然进行操作，没有计算提前量。这说明设计autopilot的人，连基本的开车常识都不明白。





    让我感到悲哀的是，这些视频的很多评论，大部分都在谩骂车主是傻逼：“这是车主自己的责任！”，“Autopilot只能在高速公路上使用”，“只能在车道上有明确的边界线的时候使用！”，“不能在有很多弯道的地方“，“只能在能够看见前方300米道路的地方使用”，“谁叫你不看说明书的！”…… Elon Musk也在一次采访中明确的告诉记者：“如果用户因为使用autopilot而导致了车祸，是用户自己的责任！” 他反复地声明：“autopilot还处于beta版本……” 意思是，你们小心着用！



    我对这些说法持不同的观点。首先，Tesla根本就不应该把一个处于"beta状态"的功能，自动推送到所有Model S的系统里面。实际上，像autopilot这种功能，关系到人的生命安全，根本就不应该有"beta版本"或者“测试版本”之说。Tesla把这样不成熟的系统，强制推送给用户，然后又说如果出了事故，用户负所有责任，这是一种推卸责任的做法。要知道，没有任何人愿意拿自己的生命给Tesla做“beta测试”。



    另外，就算是用户没有仔细阅读autopilot的使用说明，在“不该”用它的地方（比如路面线条不清晰的地方）使用了autopilot，如果出了车祸，Tesla也应该负完全的责任。理由如下：




    作为用户，他们没有义务阅读并且深刻的理解autopilot的局限性。在软件行业，存在一种习惯性的“责备用户”的不良风气。如果软件的设计有问题，用户没记住它的毛病，没能有效地绕过，那么如果出了问题，一般被认为是用户的错。Tesla想把软件行业的这种不正之风，引入到人命关天的汽车行业，那显然是行不通的。


    Tesla的autopilot实现方式幼稚，局限性实在太多。天气不好的时候不行，路面上的边界线不清晰也不行，光线不好或者有阴影不行，路上有施工的路桩不行，高速出口不行，…… 实际上，在如此苛刻的限定条件下，任何一个汽车厂商都可以做出Tesla那种autopilot。



    我自己的便宜Honda车，就有偏离车道时发出警告的功能（Lane Drift Warning，LDW）。装个摄像头，来点最简单的图像处理就搞定。在Indiana大学的时候，我们有一门本科级别的课程，就是写代码控制一辆高尔夫球车（也是电动车呢），沿着路面上的线条自动行驶。这根本没什么难度，因为它能正确行驶的条件，实在是太苛刻了。



    其它汽车厂商很清楚这种功能的局限性，所以他们没有大肆吹嘘这种“线检测”的技术，或者把它做成autopilot。他们只是把它作为辅助的，提示性的功能。这些汽车厂商理解，作为一个用户，他们不可能，也不应该记住autopilot能正确工作的种种前提条件。


    用户没有足够的能力来“判断”autopilot正常工作的条件是否满足。比如，路上的线还在，但是被磨损了，颜色很浅，那么autopilot到底能不能用呢？谁也不知道。把判断这些条件是否满足的任务推给用户，就像是在要求用户帮Tesla的工程师debug代码。这显然是不可行的。如果autopilot能够在检测到道路条件不满足的情况下，自动警告用户，并且退出自动驾驶模式，那还稍微合理一些。


    用户也许没有足够的时间来响应条件的改变。Autopilot自动驾驶的时候，车子有可能最初行驶在较好的条件下（天气好，路面线条清晰），然而随着高速行驶，路面条件有可能急速的变化。有可能上一秒还好好的，下一秒路面线条就不再清晰（视频5貌似这种情况）。路面条件的变化突如其来，驾驶员没有料到。等他们反应过来，想关闭autopilot的时候，车祸已经发生了。这种情况如果上诉到法庭，稍微明理一点的法官，都应该判Tesla败诉。


    Autopilot显摆出的“高科技”形象，容易使人产生盲目的信任，以至于疏忽而出现车祸。既然叫做“autopilot”，这意味着它能够不需要人干预，自动驾驶一段时间。既然用户觉得它能自动驾驶，那么他们完全有理由在到达高速路口之前（比如GPS显示还有一个小时才到出口），做一些自己的事情：比如看看手机啊，看看书啊，甚至刷刷牙…… 不然，谁让你叫它是“autopilot”的呢？我坐飞机时，就见过飞行员打开autopilot，上厕所去了。如果启用了autopilot还得一秒钟不停地集中注意力，那恐怕比自己开车还累。自己开车只需要看路，现在有了autopilot，不但要看路，还要盯着方向盘，防止autopilot犯傻出错……


    Tesla把“beta版”的autopilot推送给所有的Model S，是对社会安全不负责任的做法。你要明白Murphy's Law：如果一个东西可能出问题，那么就一定会有人让它出问题。Autopilot的功能不成熟，限制条件很多，不容易被正确使用，这不但对Model S的车主自己，而且对其他人也是一种威胁。汽车不是玩具，随便做个新功能，beta版，让人来试用，是会玩出人命的。我觉得Tesla的autopilot，跟无照驾驶的人一样，应该被法律禁止。由于autopilot的复杂性和潜在的危险性，使用autopilot的用户，应该经过DMV考核，在驾照上注明“能正确使用Tesla autopilot”，才准上路。


    关系到人的生命安全的“免责声明”和“用户协议”，在法律上是无效的。在美国，到处都存在“免责声明”之说。比如你去参加学校组织的春游活动，都要叫你签一个“waiver”，说如果出了安全事故或者意外，你不能把学校告上法庭。这种免责声明，一般在法律上都是无效的。如果由于学校的过错而致使你的身体受了损伤，就算你签了这种waiver，照样可以把学校告上法庭。我估计Tesla的autopilot在启动时，也有这样的免责声明，说如果使用autopolit而出现车祸，Tesla不负责任。由于autopilot直接操控了你的车子，如果真的出了车祸，这跟其它的waiver一样，都是无效的。你照样可以上法庭告他们。





    由于意识到这个问题，知道出了问题自己是逃不掉责任的，Tesla最近又通过强制的软件更新，对autopilot的功能进行了一些限制，说是为了防止用户“滥用”autopilot做一些“疯狂”的事情。Tesla很疯狂，反倒指责用户“滥用”和“疯狂”。这让人很愤慨。



    对autopilot进行限制的同时，Tesla又推出了beta版的“自动趴车”和“召唤”（summon）功能。这些功能貌似很酷，然而它们也附带了许多的限制条件。你只能在某些地方，满足某种特定条件，才能用这些功能。如果你违反这些条件，出了事故，Tesla声称不负责。



    这些能够让车子自己移动的功能，跟autopilot一样，同样会给社会带来安全隐患。比如，有人在不该使用自动趴车和summon功能的地方用了它，就可能会导致车祸。这不是用户的问题，而是Tesla根本不应该发布这些不成熟的技术来哗众取巧。


对待设计的态度问题


    我发现Tesla的设计团队，在态度上有一些严重的问题。Tesla的总设计师Franz von Holzhausen，在一个采访中谈到，Tesla是如何在“完全没有汽车设计经验”的背景之下，“从零开始”（from ground up）设计出了Model S，好像是非常了不起的成就似的。这位设计师提到：“Tesla是从一张白纸（clean slate）开始，没有已有的思想可以借鉴……”



    这其实是而夸大其词。世界上没有任何成功的设计，真的可以从所谓“白纸”开始的，你总是有前人的经验可以学习。不管是前人的成功还是失败，都有借鉴的意义。电动车比起汽油车，其实并不是一个全新的领域，它只不过是动力系统不一样而已。像门，窗，内饰，轮子，减震器，方向盘之类，里面的设计原理，其实都是一样的。



    仅仅因为动力不一样，就对前人的经验视而不见，甚至盲目的藐视。这样的态度给用户带来的，是潜在的麻烦甚至危险。有些人喜欢把一个领域说成是全新的，往往是因为他们想“圈地”。所以Tesla的设计师其实是在说，电动车这个领域跟其它汽车公司的都不一样，所以你们都不用跟我竞争啦。同时这也可以让用户以为，只有Tesla才能做出电动车。



    另外，我觉得人们对Elon Musk的个人崇拜，导致了很多人对Tesla的问题视而不见，盲目的以为Tesla是好车，豪华车，是最先进的技术。很多人盲目的相信Elon Musk，以为他是天才，他说的，他做的都是对的，而其实并不是这样。有传言说，Model S最早的设计，很多是Elon Musk自作聪明提出来的。后来其中特别不堪的一些，被设计师给去掉了。然而这种盲目“创新”的传统，却在Tesla遗留下来，并且利用媒体向全世界辐射，给大家洗脑。



    Tesla标榜自己重视“设计”，其实却歪曲了“设计”这个词的含义。喜欢谈论所谓“用户体验”（User Experience），然而他们所谓的用户体验，只是浮于表面。真正的用户体验，应该是在实质上方便，可靠，舒服，易用。而Tesla所谓的用户体验，强调的是一些肤浅的，没有实质意义的方面，比如让门把自动伸出来，让你感觉它是你的朋友。



    Elon Musk甚至在一次采访中提到，你应该能够给你的车子起个名字，它应该就像你的宠物一样。由此可见，他关心的是什么 :) 说实话，真的有人在乎一个车的门把吗？我怎么觉得他的vision或者价值观有问题。花费很大工夫，试图让你在买车之前产生良好的第一印象，以至于不惜重金。结果买下来之后的日子里，你就发现它的各种毛病——连最便宜的车都没有的毛病。



    汽车的设计，很多方面关系到人的生命安全。车上的各种设备，为什么是那个形状，为什么在那个位置，很多都是有理由的。不是你想它是个什么样子，就可以是什么样子的。很多这些经验甚至可能是用生命换来的，经历了战火和各种恶劣环境的考验。这真的不是一个新的公司短短几年就可以摸索清楚的。



    有些设计貌似很新，很酷，很未来，像科幻电影里面的一样。直到你开始用它，才发现是有问题的。很多人把Elon Musk比作钢铁侠，然而他们没有意识到，科幻和现实是有很大区别的。Elon Musk的背景（物理系PhD辍学），也许可以做出高性能的电动机，然而一辆汽车除了发动机，还有很多关键的方面。忘记历史就等于毁灭未来，标新立异，不吸取前人的经验教训，把好的东西学过来，这样做设计是很难成功的。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 编程的智慧

 
 
 
 
    

    
 
     
  

      
   
编程的智慧

    编程是一种创造性的工作，是一门艺术。精通任何一门艺术，都需要很多的练习和领悟，所以这里提出的“智慧”，并不是号称一天瘦十斤的减肥药，它并不能代替你自己的勤奋。然而由于软件行业喜欢标新立异，喜欢把简单的事情搞复杂，我希望这些文字能给迷惑中的人们指出一些正确的方向，让他们少走一些弯路，基本做到一分耕耘一分收获。


反复推敲代码


    既然“天才是百分之一的灵感，百分之九十九的汗水”，那我先来谈谈这汗水的部分吧。有人问我，提高编程水平最有效的办法是什么？我想了很久，终于发现最有效的办法，其实是反反复复地修改和推敲代码。



    在IU的时候，由于Dan Friedman的严格教导，我们以写出冗长复杂的代码为耻。如果你代码多写了几行，这老顽童就会大笑，说：“当年我解决这个问题，只写了5行代码，你回去再想想吧……” 当然，有时候他只是夸张一下，故意刺激你的，其实没有人能只用5行代码完成。然而这种提炼代码，减少冗余的习惯，却由此深入了我的骨髓。



    有些人喜欢炫耀自己写了多少多少万行的代码，仿佛代码的数量是衡量编程水平的标准。然而，如果你总是匆匆写出代码，却从来不回头去推敲，修改和提炼，其实是不可能提高编程水平的。你会制造出越来越多平庸甚至糟糕的代码。在这种意义上，很多人所谓的“工作经验”，跟他代码的质量，其实不一定成正比。如果有几十年的工作经验，却从来不回头去提炼和反思自己的代码，那么他也许还不如一个只有一两年经验，却喜欢反复推敲，仔细领悟的人。



    有位文豪说得好：“看一个作家的水平，不是看他发表了多少文字，而要看他的废纸篓里扔掉了多少。” 我觉得同样的理论适用于编程。好的程序员，他们删掉的代码，比留下来的还要多很多。如果你看见一个人写了很多代码，却没有删掉多少，那他的代码一定有很多垃圾。



    就像文学作品一样，代码是不可能一蹴而就的。灵感似乎总是零零星星，陆陆续续到来的。任何人都不可能一笔呵成，就算再厉害的程序员，也需要经过一段时间，才能发现最简单优雅的写法。有时候你反复提炼一段代码，觉得到了顶峰，没法再改进了，可是过了几个月再回头来看，又发现好多可以改进和简化的地方。这跟写文章一模一样，回头看几个月或者几年前写的东西，你总能发现一些改进。



    所以如果反复提炼代码已经不再有进展，那么你可以暂时把它放下。过几个星期或者几个月再回头来看，也许就有焕然一新的灵感。这样反反复复很多次之后，你就积累起了灵感和智慧，从而能够在遇到新问题的时候直接朝正确，或者接近正确的方向前进。


写优雅的代码


    人们都讨厌“面条代码”（spaghetti code），因为它就像面条一样绕来绕去，没法理清头绪。那么优雅的代码一般是什么形状的呢？经过多年的观察，我发现优雅的代码，在形状上有一些明显的特征。



    如果我们忽略具体的内容，从大体结构上来看，优雅的代码看起来就像是一些整整齐齐，套在一起的盒子。如果跟整理房间做一个类比，就很容易理解。如果你把所有物品都丢在一个很大的抽屉里，那么它们就会全都混在一起。你就很难整理，很难迅速的找到需要的东西。但是如果你在抽屉里再放几个小盒子，把物品分门别类放进去，那么它们就不会到处乱跑，你就可以比较容易的找到和管理它们。



    优雅的代码的另一个特征是，它的逻辑大体上看起来，是枝丫分明的树状结构（tree）。这是因为程序所做的几乎一切事情，都是信息的传递和分支。你可以把代码看成是一个电路，电流经过导线，分流或者汇合。如果你是这样思考的，你的代码里就会比较少出现只有一个分支的if语句，它看起来就会像这个样子：


if (...) {
  if (...) {
    ...
  } else {
    ...
  }
} else if (...) {
  ...
} else {
  ...
}



    注意到了吗？在我的代码里面，if语句几乎总是有两个分支。它们有可能嵌套，有多层的缩进，而且else分支里面有可能出现少量重复的代码。然而这样的结构，逻辑却非常严密和清晰。在后面我会告诉你为什么if语句最好有两个分支。


写模块化的代码


    有些人吵着闹着要让程序“模块化”，结果他们的做法是把代码分部到多个文件和目录里面，然后把这些目录或者文件叫做“module”。他们甚至把这些目录分放在不同的VCS repo里面。结果这样的作法并没有带来合作的流畅，而是带来了许多的麻烦。这是因为他们其实并不理解什么叫做“模块”，肤浅的把代码切割开来，分放在不同的位置，其实非但不能达到模块化的目的，而且制造了不必要的麻烦。



    真正的模块化，并不是文本意义上的，而是逻辑意义上的。一个模块应该像一个电路芯片，它有定义良好的输入和输出。实际上一种很好的模块化方法早已经存在，它的名字叫做“函数”。每一个函数都有明确的输入（参数）和输出（返回值），同一个文件里可以包含多个函数，所以你其实根本不需要把代码分开在多个文件或者目录里面，同样可以完成代码的模块化。我可以把代码全都写在同一个文件里，却仍然是非常模块化的代码。



    想要达到很好的模块化，你需要做到以下几点：




    避免写太长的函数。如果发现函数太大了，就应该把它拆分成几个更小的。通常我写的函数长度都不超过40行。对比一下，一般笔记本电脑屏幕所能容纳的代码行数是50行。我可以一目了然的看见一个40行的函数，而不需要滚屏。只有40行而不是50行的原因是，我的眼球不转的话，最大的视角只看得到40行代码。



    如果我看代码不转眼球的话，我就能把整片代码完整的映射到我的视觉神经里，这样就算忽然闭上眼睛，我也能看得见这段代码。我发现闭上眼睛的时候，大脑能够更加有效地处理代码，你能想象这段代码可以变成什么其它的形状。40行并不是一个很大的限制，因为函数里面比较复杂的部分，往往早就被我提取出去，做成了更小的函数，然后从原来的函数里面调用。


    制造小的工具函数。如果你仔细观察代码，就会发现其实里面有很多的重复。这些常用的代码，不管它有多短，提取出去做成函数，都可能是会有好处的。有些帮助函数也许就只有两行，然而它们却能大大简化主要函数里面的逻辑。



    有些人不喜欢使用小的函数，因为他们想避免函数调用的开销，结果他们写出几百行之大的函数。这是一种过时的观念。现代的编译器都能自动的把小的函数内联（inline）到调用它的地方，所以根本不产生函数调用，也就不会产生任何多余的开销。



    同样的一些人，也爱使用宏（macro）来代替小函数，这也是一种过时的观念。在早期的C语言编译器里，只有宏是静态“内联”的，所以他们使用宏，其实是为了达到内联的目的。然而能否内联，其实并不是宏与函数的根本区别。宏与函数有着巨大的区别（这个我以后再讲），应该尽量避免使用宏。为了内联而使用宏，其实是滥用了宏，这会引起各种各样的麻烦，比如使程序难以理解，难以调试，容易出错等等。


    每个函数只做一件简单的事情。有些人喜欢制造一些“通用”的函数，既可以做这个又可以做那个，它的内部依据某些变量和条件，来“选择”这个函数所要做的事情。比如，你也许写出这样的函数：


void foo() {
  if (getOS().equals("MacOS")) {
    a();
  } else {
    b();
  }
  c();
  if (getOS().equals("MacOS")) {
    d();
  } else {
    e();
  }
}



    写这个函数的人，根据系统是否为“MacOS”来做不同的事情。你可以看出这个函数里，其实只有c()是两种系统共有的，而其它的a(), b(), d(), e()都属于不同的分支。



    这种“复用”其实是有害的。如果一个函数可能做两种事情，它们之间共同点少于它们的不同点，那你最好就写两个不同的函数，否则这个函数的逻辑就不会很清晰，容易出现错误。其实，上面这个函数可以改写成两个函数：


void fooMacOS() {
  a();
  c();
  d();
}



    和


void fooOther() {
  b();
  c();
  e();
}



    如果你发现两件事情大部分内容相同，只有少数不同，多半时候你可以把相同的部分提取出去，做成一个辅助函数。比如，如果你有个函数是这样：


void foo() {
  a();
  b()
  c();
  if (getOS().equals("MacOS")) {
    d();
  } else {
    e();
  }
}



    其中a()，b()，c()都是一样的，只有d()和e()根据系统有所不同。那么你可以把a()，b()，c()提取出去：


void preFoo() {
  a();
  b()
  c();



    然后制造两个函数：


void fooMacOS() {
  preFoo();
  d();
}



    和


void fooOther() {
  preFoo();
  e();
}



    这样一来，我们既共享了代码，又做到了每个函数只做一件简单的事情。这样的代码，逻辑就更加清晰。


    避免使用全局变量和类成员（class member）来传递信息，尽量使用局部变量和参数。有些人写代码，经常用类成员来传递信息，就像这样：


 class A {
   String x;

   void findX() {
      ...
      x = ...;
   }

   void foo() {
     findX();
     ...
     print(x);
   }
 }



     首先，他使用findX()，把一个值写入成员x。然后，使用x的值。这样，x就变成了findX和print之间的数据通道。由于x属于class A，这样程序就失去了模块化的结构。由于这两个函数依赖于成员x，它们不再有明确的输入和输出，而是依赖全局的数据。findX和foo不再能够离开class A而存在，而且由于类成员还有可能被其他代码改变，代码变得难以理解，难以确保正确性。



     如果你使用局部变量而不是类成员来传递信息，那么这两个函数就不需要依赖于某一个class，而且更加容易理解，不易出错：


 String findX() {
    ...
    x = ...;
    return x;
 }
 void foo() {
   String x = findX();
   print(x);
 }




写可读的代码


    有些人以为写很多注释就可以让代码更加可读，然而却发现事与愿违。注释不但没能让代码变得可读，反而由于大量的注释充斥在代码中间，让程序变得障眼难读。而且代码的逻辑一旦修改，就会有很多的注释变得过时，需要更新。修改注释是相当大的负担，所以大量的注释，反而成为了妨碍改进代码的绊脚石。



    实际上，真正优雅可读的代码，是几乎不需要注释的。如果你发现需要写很多注释，那么你的代码肯定是含混晦涩，逻辑不清晰的。其实，程序语言相比自然语言，是更加强大而严谨的，它其实具有自然语言最主要的元素：主语，谓语，宾语，名词，动词，如果，那么，否则，是，不是，…… 所以如果你充分利用了程序语言的表达能力，你完全可以用程序本身来表达它到底在干什么，而不需要自然语言的辅助。



    有少数的时候，你也许会为了绕过其他一些代码的设计问题，采用一些违反直觉的作法。这时候你可以使用很短注释，说明为什么要写成那奇怪的样子。这样的情况应该少出现，否则这意味着整个代码的设计都有问题。



    如果没能合理利用程序语言提供的优势，你会发现程序还是很难懂，以至于需要写注释。所以我现在告诉你一些要点，也许可以帮助你大大减少写注释的必要：




    使用有意义的函数和变量名字。如果你的函数和变量的名字，能够切实的描述它们的逻辑，那么你就不需要写注释来解释它在干什么。比如：


// put elephant1 into fridge2
put(elephant1, fridge2);



    由于我的函数名put，加上两个有意义的变量名elephant1和fridge2，已经说明了这是在干什么（把大象放进冰箱），所以上面那句注释完全没有必要。


    局部变量应该尽量接近使用它的地方。有些人喜欢在函数最开头定义很多局部变量，然后在下面很远的地方使用它，就像这个样子：


void foo() {
  int index = ...;
  ...
  ...
  bar(index);
  ...
}



    由于这中间都没有使用过index，也没有改变过它所依赖的数据，所以这个变量定义，其实可以挪到接近使用它的地方：


void foo() {
  ...
  ...
  int index = ...;
  bar(index);
  ...
}



    这样读者看到bar(index)，不需要向上看很远就能发现index是如何算出来的。而且这种短距离，可以加强读者对于这里的“计算顺序”的理解。否则如果index在顶上，读者可能会怀疑，它其实保存了某种会变化的数据，或者它后来又被修改过。如果index放在下面，读者就清楚的知道，index并不是保存了什么可变的值，而且它算出来之后就没变过。



    如果你看透了局部变量的本质——它们就是电路里的导线，那你就能更好的理解近距离的好处。变量定义离用的地方越近，导线的长度就越短。你不需要摸着一根导线，绕来绕去找很远，就能发现接收它的端口，这样的电路就更容易理解。


    局部变量名字应该简短。这貌似跟第一点相冲突，简短的变量名怎么可能有意义呢？注意我这里说的是局部变量，因为它们处于局部，再加上第2点已经把它放到离使用位置尽量近的地方，所以根据上下文你就会容易知道它的意思：



    比如，你有一个局部变量，表示一个操作是否成功：


boolean successInDeleteFile = deleteFile("foo.txt");
if (successInDeleteFile) {
  ...
} else {
  ...
}



    这个局部变量successInDeleteFile大可不必这么啰嗦。因为它只用过一次，而且用它的地方就在下面一行，所以读者可以轻松发现它是deleteFile返回的结果。如果你把它改名为success，其实读者根据一点上下文，也知道它表示"success in deleteFile"。所以你可以把它改成这样：


boolean success = deleteFile("foo.txt");
if (success) {
  ...
} else {
  ...
}



    这样的写法不但没漏掉任何有用的语义信息，而且更加易读。successInDeleteFile这种“camelCase”，如果超过了三个单词连在一起，其实是很碍眼的东西。所以如果你能用一个单词表示同样的意义，那当然更好。


    不要重用局部变量。很多人写代码不喜欢定义新的局部变量，而喜欢“重用”同一个局部变量，通过反复对它们进行赋值，来表示完全不同意思。比如这样写：


String msg;
if (...) {
  msg = "succeed";
  log.info(msg);
} else {
  msg = "failed";
  log.info(msg);
}



    虽然这样在逻辑上是没有问题的，然而却不易理解，容易混淆。变量msg两次被赋值，表示完全不同的两个值。它们立即被log.info使用，没有传递到其它地方去。这种赋值的做法，把局部变量的作用域不必要的增大，让人以为它可能在将来改变，也许会在其它地方被使用。更好的做法，其实是定义两个变量：


if (...) {
  String msg = "succeed";
  log.info(msg);
} else {
  String msg = "failed";
  log.info(msg);
}



    由于这两个msg变量的作用域仅限于它们所处的if语句分支，你可以很清楚的看到这两个msg被使用的范围，而且知道它们之间没有任何关系。


    把复杂的逻辑提取出去，做成“帮助函数”。有些人写的函数很长，以至于看不清楚里面的语句在干什么，所以他们误以为需要写注释。如果你仔细观察这些代码，就会发现不清晰的那片代码，往往可以被提取出去，做成一个函数，然后在原来的地方调用。由于函数有一个名字，这样你就可以使用有意义的函数名来代替注释。举一个例子：


...
// put elephant1 into fridge2
openDoor(fridge2);
if (elephant1.alive()) {
  ...
} else {
   ...
}
closeDoor(fridge2);
...



    如果你把这片代码提出去定义成一个函数：


void put(Elephant elephant, Fridge fridge) {
  openDoor(fridge);
  if (elephant.alive()) {
    ...
  } else {
     ...
  }
  closeDoor(fridge);
}



    这样原来的代码就可以改成：


...
put(elephant1, fridge2);
...



    更加清晰，而且注释也没必要了。


    把复杂的表达式提取出去，做成中间变量。有些人听说“函数式编程”是个好东西，也不理解它的真正含义，就在代码里大量使用嵌套的函数。像这样：


Pizza pizza = makePizza(crust(salt(), butter()),
   topping(onion(), tomato(), sausage()));



    这样的代码一行太长，而且嵌套太多，不容易看清楚。其实训练有素的函数式程序员，都知道中间变量的好处，不会盲目的使用嵌套的函数。他们会把这代码变成这样：


Crust crust = crust(salt(), butter());
Topping topping = topping(onion(), tomato(), sausage());
Pizza pizza = makePizza(crust, topping);



    这样写，不但有效地控制了单行代码的长度，而且由于引入的中间变量具有“意义”，步骤清晰，变得很容易理解。


    在合理的地方换行。对于绝大部分的程序语言，代码的逻辑是和空白字符无关的，所以你可以在几乎任何地方换行，你也可以不换行。这样的语言设计是个好东西，因为它给了程序员自由控制自己代码格式的能力。然而，它也引起了一些问题，因为很多人不知道如何合理的换行。





      有些人喜欢利用IDE的自动换行机制，编辑之后用一个热键把整个代码重新格式化一遍，IDE就会把超过行宽限制的代码自动折行。可是这种自动这行，往往没有根据代码的逻辑来进行，不能帮助理解代码。自动换行之后可能产生这样的代码：


   if (someLongCondition1() &amp;&amp; someLongCondition2() &amp;&amp; someLongCondition3() &amp;&amp;
     someLongCondition4()) {
     ...
   }



       由于someLongCondition4()超过了行宽限制，被编辑器自动换到了下面一行。虽然满足了行宽限制，换行的位置却是相当任意的，它并不能帮助人理解这代码的逻辑。这几个boolean表达式，全都用&amp;&amp;连接，所以它们其实处于平等的地位。为了表达这一点，当需要折行的时候，你应该把每一个表达式都放到新的一行，就像这个样子：


   if (someLongCondition1() &amp;&amp;
someLongCondition2() &amp;&amp;
someLongCondition3() &amp;&amp;
someLongCondition4()) {
     ...
   }



       这样每一个条件都对齐，里面的逻辑就很清楚了。再举个例子：


   log.info("failed to find file {} for command {}, with exception {}", file, command,
     exception);



       这行因为太长，被自动折行成这个样子。file，command和exception本来是同一类东西，却有两个留在了第一行，最后一个被折到第二行。它就不如手动换行成这个样子：


   log.info("failed to find file {} for command {}, with exception {}",
     file, command, exception);



       把格式字符串单独放在一行，而把它的参数一并放在另外一行，这样逻辑就更加清晰。



       为了避免IDE把这些手动调整好的换行弄乱，很多IDE（比如IntelliJ）的自动格式化设定里都有“保留原来的换行符”的设定。如果你发现IDE的换行不符合逻辑，你可以修改这些设定，然后在某些地方保留你自己的手动换行。



    说到这里，我必须警告你，这里所说的“不需注释，让代码自己解释自己”，并不是说要让代码看起来像某种自然语言。有个叫Chai的JavaScript测试工具，可以让你这样写代码：


expect(foo).to.be.a('string');
expect(foo).to.equal('bar');
expect(foo).to.have.length(3);
expect(tea).to.have.property('flavors').with.length(3);



    这种做法是极其错误的。程序语言本来就比自然语言简单清晰，这种写法让它看起来像自然语言的样子，反而变得复杂难懂了。


写简单的代码


    程序语言都喜欢标新立异，提供这样那样的“特性”，然而有些特性其实并不是什么好东西。很多特性都经不起时间的考验，最后带来的麻烦，比解决的问题还多。很多人盲目的追求“短小”和“精悍”，或者为了显示自己头脑聪明，学得快，所以喜欢利用语言里的一些特殊构造，写出过于“聪明”，难以理解的代码。



    并不是语言提供什么，你就一定要把它用上的。实际上你只需要其中很小的一部分功能，就能写出优秀的代码。我一向反对“充分利用”程序语言里的所有特性。实际上，我心目中有一套最好的构造。不管语言提供了多么“神奇”的，“新”的特性，我基本都只用经过千锤百炼，我觉得值得信赖的那一套。



    现在针对一些有问题的语言特性，我介绍一些我自己使用的代码规范，并且讲解一下为什么它们能让代码更简单。




    避免使用自增减表达式（i++，++i，i--，--i）。这种自增减操作表达式其实是历史遗留的设计失误。它们含义蹊跷，非常容易弄错。它们把读和写这两种完全不同的操作，混淆缠绕在一起，把语义搞得乌七八糟。含有它们的表达式，结果可能取决于求值顺序，所以它可能在某种编译器下能正确运行，换一个编译器就出现离奇的错误。



    其实这两个表达式完全可以分解成两步，把读和写分开：一步更新i的值，另外一步使用i的值。比如，如果你想写foo(i++)，你完全可以把它拆成int t = i; i += 1; foo(t);。如果你想写foo(++i)，可以拆成i += 1; foo(i); 拆开之后的代码，含义完全一致，却清晰很多。到底更新是在取值之前还是之后，一目了然。



    有人也许以为i++或者++i的效率比拆开之后要高，这只是一种错觉。这些代码经过基本的编译器优化之后，生成的机器代码是完全没有区别的。自增减表达式只有在两种情况下才可以安全的使用。一种是在for循环的update部分，比如for(int i = 0; i &lt; 5; i++)。另一种情况是写成单独的一行，比如i++;。这两种情况是完全没有歧义的。你需要避免其它的情况，比如用在复杂的表达式里面，比如foo(i++)，foo(++i) + foo(i)，…… 没有人应该知道，或者去追究这些是什么意思。


    永远不要省略花括号。很多语言允许你在某种情况下省略掉花括号，比如C，Java都允许你在if语句里面只有一句话的时候省略掉花括号：


if (...)
  action1();



    咋一看少打了两个字，多好。可是这其实经常引起奇怪的问题。比如，你后来想要加一句话action2()到这个if里面，于是你就把代码改成：


if (...)
  action1();
  action2();



    为了美观，你很小心的使用了action1()的缩进。咋一看它们是在一起的，所以你下意识里以为它们只会在if的条件为真的时候执行，然而action2()却其实在if外面，它会被无条件的执行。我把这种现象叫做“光学幻觉”（optical illusion），理论上每个程序员都应该发现这个错误，然而实际上却容易被忽视。



    那么你问，谁会这么傻，我在加入action2()的时候加上花括号不就行了？可是从设计的角度来看，这样其实并不是合理的作法。首先，也许你以后又想把action2()去掉，这样你为了样式一致，又得把花括号拿掉，烦不烦啊？其次，这使得代码样式不一致，有的if有花括号，有的又没有。况且，你为什么需要记住这个规则？如果你不问三七二十一，只要是if-else语句，把花括号全都打上，就可以想都不用想了，就当C和Java没提供给你这个特殊写法。这样就可以保持完全的一致性，减少不必要的思考。



    有人可能会说，全都打上花括号，只有一句话也打上，多碍眼啊？然而经过实行这种编码规范几年之后，我并没有发现这种写法更加碍眼，反而由于花括号的存在，使得代码界限明确，让我的眼睛负担更小了。


    合理使用括号，不要盲目依赖操作符优先级。利用操作符的优先级来减少括号，对于1 + 2 * 3这样常见的算数表达式，是没问题的。然而有些人如此的仇恨括号，以至于他们会写出2 &lt;&lt; 7 - 2 * 3这样的表达式，而完全不用括号。



    这里的问题，在于移位操作&lt;&lt;的优先级，是很多人不熟悉，而且是违反常理的。由于x &lt;&lt; 1相当于把x乘以2，很多人误以为这个表达式相当于(2 &lt;&lt; 7) - (2 * 3)，所以等于250。然而实际上&lt;&lt;的优先级比加法+还要低，所以这表达式其实相当于2 &lt;&lt; (7 - 2 * 3)，所以等于4！



    解决这个问题的办法，不是要每个人去把操作符优先级表给硬背下来，而是合理的加入括号。比如上面的例子，最好直接加上括号写成2 &lt;&lt; (7 - 2 * 3)。虽然没有括号也表示同样的意思，但是加上括号就更加清晰，读者不再需要死记&lt;&lt;的优先级就能理解代码。


    避免使用continue和break。循环语句（for，while）里面出现return是没问题的，然而如果你使用了continue或者break，就会让循环的逻辑和终止条件变得复杂，难以确保正确。



    出现continue或者break的原因，往往是对循环的逻辑没有想清楚。如果你考虑周全了，应该是几乎不需要continue或者break的。如果你的循环里出现了continue或者break，你就应该考虑改写这个循环。改写循环的办法有多种：



如果出现了continue，你往往只需要把continue的条件反向，就可以消除continue。
如果出现了break，你往往可以把break的条件，合并到循环头部的终止条件里，从而去掉break。
有时候你可以把break替换成return，从而去掉break。
如果以上都失败了，你也许可以把循环里面复杂的部分提取出来，做成函数调用，之后continue或者break就可以去掉了。




    下面我对这些情况举一些例子。



    情况1：下面这段代码里面有一个continue：


List&lt;String&gt; goodNames = new ArrayList&lt;&gt;();
for (String name: names) {
  if (name.contains("bad")) {
    continue;
  }
  goodNames.add(name);
  ...
}  



    它说：“如果name含有'bad'这个词，跳过后面的循环代码……” 注意，这是一种“负面”的描述，它不是在告诉你什么时候“做”一件事，而是在告诉你什么时候“不做”一件事。为了知道它到底在干什么，你必须搞清楚continue会导致哪些语句被跳过了，然后脑子里把逻辑反个向，你才能知道它到底想做什么。这就是为什么含有continue和break的循环不容易理解，它们依靠“控制流”来描述“不做什么”，“跳过什么”，结果到最后你也没搞清楚它到底“要做什么”。



    其实，我们只需要把continue的条件反向，这段代码就可以很容易的被转换成等价的，不含continue的代码：


List&lt;String&gt; goodNames = new ArrayList&lt;&gt;();
for (String name: names) {
  if (!name.contains("bad")) {
    goodNames.add(name);
    ...
  }
}  



    goodNames.add(name);和它之后的代码全部被放到了if里面，多了一层缩进，然而continue却没有了。你再读这段代码，就会发现更加清晰。因为它是一种更加“正面”地描述。它说：“在name不含有'bad'这个词的时候，把它加到goodNames的链表里面……”



    情况2：for和while头部都有一个循环的“终止条件”，那本来应该是这个循环唯一的退出条件。如果你在循环中间有break，它其实给这个循环增加了一个退出条件。你往往只需要把这个条件合并到循环头部，就可以去掉break。



    比如下面这段代码：


while (condition1) {
  ...
  if (condition2) {
    break;
  }
}



    当condition成立的时候，break会退出循环。其实你只需要把condition2反转之后，放到while头部的终止条件，就可以去掉这种break语句。改写后的代码如下：


while (condition1 &amp;&amp; !condition2) {
  ...
}



    这种情况表面上貌似只适用于break出现在循环开头或者末尾的时候，然而其实大部分时候，break都可以通过某种方式，移动到循环的开头或者末尾。具体的例子我暂时没有，等出现的时候再加进来。



    情况3：很多break退出循环之后，其实接下来就是一个return。这种break往往可以直接换成return。比如下面这个例子：


public boolean hasBadName(List&lt;String&gt; names) {
    boolean result = false;

    for (String name: names) {
 if (name.contains("bad")) {
     result = true;
     break;
 }
    }
    return result;
}



    这个函数检查names链表里是否存在一个名字，包含“bad”这个词。它的循环里包含一个break语句。这个函数可以被改写成：


public boolean hasBadName(List&lt;String&gt; names) {
    for (String name: names) {
 if (name.contains("bad")) {
     return true;
 }
    }
    return false;
}



    改进后的代码，在name里面含有“bad”的时候，直接用return true返回，而不是对result变量赋值，break出去，最后才返回。如果循环结束了还没有return，那就返回false，表示没有找到这样的名字。使用return来代替break，这样break语句和result这个变量，都一并被消除掉了。



    我曾经见过很多其他使用continue和break的例子，几乎无一例外的可以被消除掉，变换后的代码变得清晰很多。我的经验是，99%的break和continue，都可以通过替换成return语句，或者翻转if条件的方式来消除掉。剩下的1%含有复杂的逻辑，但也可以通过提取一个帮助函数来消除掉。修改之后的代码变得容易理解，容易确保正确。




写直观的代码


    我写代码有一条重要的原则：如果有更加直接，更加清晰的写法，就选择它，即使它看起来更长，更笨，也一样选择它。比如，Unix命令行有一种“巧妙”的写法是这样：


command1 &amp;&amp; command2 &amp;&amp; command3



    由于Shell语言的逻辑操作a &amp;&amp; b具有“短路”的特性，如果a等于false，那么b就没必要执行了。这就是为什么当command1成功，才会执行command2，当command2成功，才会执行command3。同样，


command1 || command2 || command3



    操作符||也有类似的特性。上面这个命令行，如果command1成功，那么command2和command3都不会被执行。如果command1失败，command2成功，那么command3就不会被执行。



    这比起用if语句来判断失败，似乎更加巧妙和简洁，所以有人就借鉴了这种方式，在程序的代码里也使用这种方式。比如他们可能会写这样的代码：


if (action1() || action2() &amp;&amp; action3()) {
  ...
}



    你看得出来这代码是想干什么吗？action2和action3什么条件下执行，什么条件下不执行？也许稍微想一下，你知道它在干什么：“如果action1失败了，执行action2，如果action2成功了，执行action3”。然而那种语义，并不是直接的“映射”在这代码上面的。比如“失败”这个词，对应了代码里的哪一个字呢？你找不出来，因为它包含在了||的语义里面，你需要知道||的短路特性，以及逻辑或的语义才能知道这里面在说“如果action1失败……”。每一次看到这行代码，你都需要思考一下，这样积累起来的负荷，就会让人很累。



    其实，这种写法是滥用了逻辑操作&amp;&amp;和||的短路特性。这两个操作符可能不执行右边的表达式，原因是为了机器的执行效率，而不是为了给人提供这种“巧妙”的用法。这两个操作符的本意，只是作为逻辑操作，它们并不是拿来给你代替if语句的。也就是说，它们只是碰巧可以达到某些if语句的效果，但你不应该因此就用它来代替if语句。如果你这样做了，就会让代码晦涩难懂。



    上面的代码写成笨一点的办法，就会清晰很多：


if (!action1()) {
  if (action2()) {
    action3();
  }
}



    这里我很明显的看出这代码在说什么，想都不用想：如果action1()失败了，那么执行action2()，如果action2()成功了，执行action3()。你发现这里面的一一对应关系吗？if=如果，!=失败，…… 你不需要利用逻辑学知识，就知道它在说什么。


写无懈可击的代码


    在之前一节里，我提到了自己写的代码里面很少出现只有一个分支的if语句。我写出的if语句，大部分都有两个分支，所以我的代码很多看起来是这个样子：


if (...) {
  if (...) {
    ...
    return false;
  } else {
    return true;
  }
} else if (...) {
  ...
  return false;
} else {
  return true;
}



    使用这种方式，其实是为了无懈可击的处理所有可能出现的情况，避免漏掉corner case。每个if语句都有两个分支的理由是：如果if的条件成立，你做某件事情；但是如果if的条件不成立，你应该知道要做什么另外的事情。不管你的if有没有else，你终究是逃不掉，必须得思考这个问题的。



    很多人写if语句喜欢省略else的分支，因为他们觉得有些else分支的代码重复了。比如我的代码里，两个else分支都是return true。为了避免重复，他们省略掉那两个else分支，只在最后使用一个return true。这样，缺了else分支的if语句，控制流自动“掉下去”，到达最后的return true。他们的代码看起来像这个样子：


if (...) {
  if (...) {
    ...
    return false;
  }
} else if (...) {
  ...
  return false;
}
return true;



    这种写法看似更加简洁，避免了重复，然而却很容易出现疏忽和漏洞。嵌套的if语句省略了一些else，依靠语句的“控制流”来处理else的情况，是很难正确的分析和推理的。如果你的if条件里使用了&amp;&amp;和||之类的逻辑运算，就更难看出是否涵盖了所有的情况。



    由于疏忽而漏掉的分支，全都会自动“掉下去”，最后返回意想不到的结果。即使你看一遍之后确信是正确的，每次读这段代码，你都不能确信它照顾了所有的情况，又得重新推理一遍。这简洁的写法，带来的是反复的，沉重的头脑开销。这就是所谓“面条代码”，因为程序的逻辑分支，不是像一棵枝叶分明的树，而是像面条一样绕来绕去。



    另外一种省略else分支的情况是这样：


String s = "";
if (x &lt; 5) {
  s = "ok";
}



    写这段代码的人，脑子里喜欢使用一种“缺省值”的做法。s缺省为null，如果x&lt;5，那么把它改变（mutate）成“ok”。这种写法的缺点是，当x&lt;5不成立的时候，你需要往上面看，才能知道s的值是什么。这还是你运气好的时候，因为s就在上面不远。很多人写这种代码的时候，s的初始值离判断语句有一定的距离，中间还有可能插入一些其它的逻辑和赋值操作。这样的代码，把变量改来改去的，看得人眼花，就容易出错。



    现在比较一下我的写法：


String s;
if (x &lt; 5) {
  s = "ok";
} else {
  s = "";
}



    这种写法貌似多打了一两个字，然而它却更加清晰。这是因为我们明确的指出了x&lt;5不成立的时候，s的值是什么。它就摆在那里，它是""（空字符串）。注意，虽然我也使用了赋值操作，然而我并没有“改变”s的值。s一开始的时候没有值，被赋值之后就再也没有变过。我的这种写法，通常被叫做更加“函数式”，因为我只赋值一次。



    如果我漏写了else分支，Java编译器是不会放过我的。它会抱怨：“在某个分支，s没有被初始化。”这就强迫我清清楚楚的设定各种条件下s的值，不漏掉任何一种情况。



    当然，由于这个情况比较简单，你还可以把它写成这样：


String s = x &lt; 5 ? "ok" : "";



    对于更加复杂的情况，我建议还是写成if语句为好。


正确处理错误


    使用有两个分支的if语句，只是我的代码可以达到无懈可击的其中一个原因。这样写if语句的思路，其实包含了使代码可靠的一种通用思想：穷举所有的情况，不漏掉任何一个。



    程序的绝大部分功能，是进行信息处理。从一堆纷繁复杂，模棱两可的信息中，排除掉绝大部分“干扰信息”，找到自己需要的那一个。正确地对所有的“可能性”进行推理，就是写出无懈可击代码的核心思想。这一节我来讲一讲，如何把这种思想用在错误处理上。



    错误处理是一个古老的问题，可是经过了几十年，还是很多人没搞明白。Unix的系统API手册，一般都会告诉你可能出现的返回值和错误信息。比如，Linux的read系统调用手册里面有如下内容：



RETURN VALUE 
On success, the number of bytes read is returned...

On error, -1 is returned, and errno is set appropriately.

    
ERRORS

EAGAIN, EBADF, EFAULT, EINTR, EINVAL, ...




    很多初学者，都会忘记检查read的返回值是否为-1，觉得每次调用read都得检查返回值真繁琐，不检查貌似也相安无事。这种想法其实是很危险的。如果函数的返回值告诉你，要么返回一个正数，表示读到的数据长度，要么返回-1，那么你就必须要对这个-1作出相应的，有意义的处理。千万不要以为你可以忽视这个特殊的返回值，因为它是一种“可能性”。代码漏掉任何一种可能出现的情况，都可能产生意想不到的灾难性结果。



    对于Java来说，这相对方便一些。Java的函数如果出现问题，一般通过异常（exception）来表示。你可以把异常加上函数本来的返回值，看成是一个“union类型”。比如：


String foo() throws MyException {
  ...
}



    这里MyException是一个错误返回。你可以认为这个函数返回一个union类型：{String, MyException}。任何调用foo的代码，必须对MyException作出合理的处理，才有可能确保程序的正确运行。Union类型是一种相当先进的类型，目前只有极少数语言（比如Typed Racket）具有这种类型，我在这里提到它，只是为了方便解释概念。掌握了概念之后，你其实可以在头脑里实现一个union类型系统，这样使用普通的语言也能写出可靠的代码。



    由于Java的类型系统强制要求函数在类型里面声明可能出现的异常，而且强制调用者处理可能出现的异常，所以基本上不可能出现由于疏忽而漏掉的情况。但有些Java程序员有一种恶习，使得这种安全机制几乎完全失效。每当编译器报错，说“你没有catch这个foo函数可能出现的异常”时，有些人想都不想，直接把代码改成这样：


try {
  foo();
} catch (Exception e) {}



    或者最多在里面放个log，或者干脆把自己的函数类型上加上throws Exception，这样编译器就不再抱怨。这些做法貌似很省事，然而都是错误的，你终究会为此付出代价。



    如果你把异常catch了，忽略掉，那么你就不知道foo其实失败了。这就像开车时看到路口写着“前方施工，道路关闭”，还继续往前开。这当然迟早会出问题，因为你根本不知道自己在干什么。



    catch异常的时候，你不应该使用Exception这么宽泛的类型。你应该正好catch可能发生的那种异常A。使用宽泛的异常类型有很大的问题，因为它会不经意的catch住另外的异常（比如B）。你的代码逻辑是基于判断A是否出现，可你却catch所有的异常（Exception类），所以当其它的异常B出现的时候，你的代码就会出现莫名其妙的问题，因为你以为A出现了，而其实它没有。这种bug，有时候甚至使用debugger都难以发现。



    如果你在自己函数的类型加上throws Exception，那么你就不可避免的需要在调用它的地方处理这个异常，如果调用它的函数也写着throws Exception，这毛病就传得更远。我的经验是，尽量在异常出现的当时就作出处理。否则如果你把它返回给你的调用者，它也许根本不知道该怎么办了。



    另外，try { ... } catch里面，应该包含尽量少的代码。比如，如果foo和bar都可能产生异常A，你的代码应该尽可能写成：


try {
  foo();
} catch (A e) {...}

try {
  bar();
} catch (A e) {...}



    而不是


try {
  foo();
  bar();
} catch (A e) {...}



    第一种写法能明确的分辨是哪一个函数出了问题，而第二种写法全都混在一起。明确的分辨是哪一个函数出了问题，有很多的好处。比如，如果你的catch代码里面包含log，它可以提供给你更加精确的错误信息，这样会大大地加速你的调试过程。


正确处理null指针


    穷举的思想是如此的有用，依据这个原理，我们可以推出一些基本原则，它们可以让你无懈可击的处理null指针。



    首先你应该知道，许多语言（C，C++，Java，C#，……）的类型系统对于null的处理，其实是完全错误的。这个错误源自于Tony Hoare最早的设计，Hoare把这个错误称为自己的“billion dollar mistake”，因为由于它所产生的财产和人力损失，远远超过十亿美元。



    这些语言的类型系统允许null出现在任何对象（指针）类型可以出现的地方，然而null其实根本不是一个合法的对象。它不是一个String，不是一个Integer，也不是一个自定义的类。null的类型本来应该是NULL，也就是null自己。根据这个基本观点，我们推导出以下原则：




    尽量不要产生null指针。尽量不要用null来初始化变量，函数尽量不要返回null。如果你的函数要返回“没有”，“出错了”之类的结果，尽量使用Java的异常机制。虽然写法上有点别扭，然而Java的异常，和函数的返回值合并在一起，基本上可以当成union类型来用。比如，如果你有一个函数find，可以帮你找到一个String，也有可能什么也找不到，你可以这样写：


public String find() throws NotFoundException {
  if (...) {
    return ...;
  } else {
    throw new NotFoundException();
  }
}



    Java的类型系统会强制你catch这个NotFoundException，所以你不可能像漏掉检查null一样，漏掉这种情况。Java的异常也是一个比较容易滥用的东西，不过我已经在上一节告诉你如何正确的使用异常。



    Java的try...catch语法相当的繁琐和蹩脚，所以如果你足够小心的话，像find这类函数，也可以返回null来表示“没找到”。这样稍微好看一些，因为你调用的时候不必用try...catch。很多人写的函数，返回null来表示“出错了”，这其实是对null的误用。“出错了”和“没有”，其实完全是两码事。“没有”是一种很常见，正常的情况，比如查哈希表没找到，很正常。“出错了”则表示罕见的情况，本来正常情况下都应该存在有意义的值，偶然出了问题。如果你的函数要表示“出错了”，应该使用异常，而不是null。


    不要catch NullPointerException。有些人写代码很nice，他们喜欢“容错”。首先他们写一些函数，这些函数里面不大小心，没检查null指针：


void foo() {
  String found = find();
  int len = found.length();
  ...
}



    当foo调用产生了异常，他们不管三七二十一，就把调用的地方改成这样：


try {
  foo();
} catch (Exception e) {
  ...
}



    这样当found是null的时候，NullPointerException就会被捕获并且得到处理。这其实是很错误的作法。首先，上一节已经提到了，catch (Exception e)这种写法是要绝对避免的，因为它捕获所有的异常，包括NullPointerException。这会让你意外地捕获try语句里面出现的NullPointerException，从而把代码的逻辑搅得一塌糊涂。



    另外就算你写成catch (NullPointerException e)也是不可以的。由于foo的内部缺少了null检查，才出现了NullPointerException。现在你不对症下药，倒把每个调用它的地方加上catch，以后你的生活就会越来越苦。正确的做法应该是改动foo，而不改调用它的代码。foo应该被改成这样：


void foo() {
  String found = find();
  if (found != null) {
    int len = found.length();
    ...
  } else {
    ...
  }
}



     在null可能出现的当时就检查它是否是null，然后进行相应的处理。


    不要把null放进“容器数据结构”里面。所谓容器（collection），是指一些对象以某种方式集合在一起，所以null不应该被放进Array，List，Set等结构，不应该出现在Map的key或者value里面。把null放进容器里面，是一些莫名其妙错误的来源。因为对象在容器里的位置一般是动态决定的，所以一旦null从某个入口跑进去了，你就很难再搞明白它去了哪里，你就得被迫在所有从这个容器里取值的位置检查null。你也很难知道到底是谁把它放进去的，代码多了就导致调试极其困难。



    解决方案是：如果你真要表示“没有”，那你就干脆不要把它放进去（Array，List，Set没有元素，Map根本没那个entry），或者你可以指定一个特殊的，真正合法的对象，用来表示“没有”。



    需要指出的是，类对象并不属于容器。所以null在必要的时候，可以作为对象成员的值，表示它不存在。比如：


class A {
  String name = null;
  ...
}



    之所以可以这样，是因为null只可能在A对象的name成员里出现，你不用怀疑其它的成员因此成为null。所以你每次访问name成员时，检查它是否是null就可以了，不需要对其他成员也做同样的检查。


    函数调用者：明确理解null所表示的意义，尽早检查和处理null返回值，减少它的传播。null很讨厌的一个地方，在于它在不同的地方可能表示不同的意义。有时候它表示“没有”，“没找到”。有时候它表示“出错了”，“失败了”。有时候它甚至可以表示“成功了”，…… 这其中有很多误用之处，不过无论如何，你必须理解每一个null的意义，不能给混淆起来。



    如果你调用的函数有可能返回null，那么你应该在第一时间对null做出“有意义”的处理。比如，上述的函数find，返回null表示“没找到”，那么调用find的代码就应该在它返回的第一时间，检查返回值是否是null，并且对“没找到”这种情况，作出有意义的处理。



    “有意义”是什么意思呢？我的意思是，使用这函数的人，应该明确的知道在拿到null的情况下该怎么做，承担起责任来。他不应该只是“向上级汇报”，把责任踢给自己的调用者。如果你违反了这一点，就有可能采用一种不负责任，危险的写法：


public String foo() {
  String found = find();
  if (found == null) {
    return null;
  }
}



    当看到find()返回了null，foo自己也返回null。这样null就从一个地方，游走到了另一个地方，而且它表示另外一个意思。如果你不假思索就写出这样的代码，最后的结果就是代码里面随时随地都可能出现null。到后来为了保护自己，你的每个函数都会写成这样：


public void foo(A a, B b, C c) {
  if (a == null) { ... }
  if (b == null) { ... }
  if (c == null) { ... }
  ...
}


    函数作者：明确声明不接受null参数，当参数是null时立即崩溃。不要试图对null进行“容错”，不要让程序继续往下执行。如果调用者使用了null作为参数，那么调用者（而不是函数作者）应该对程序的崩溃负全责。



    上面的例子之所以成为问题，就在于人们对于null的“容忍态度”。这种“保护式”的写法，试图“容错”，试图“优雅的处理null”，其结果是让调用者更加肆无忌惮的传递null给你的函数。到后来，你的代码里出现一堆堆nonsense的情况，null可以在任何地方出现，都不知道到底是哪里产生出来的。谁也不知道出现了null是什么意思，该做什么，所有人都把null踢给其他人。最后这null像瘟疫一样蔓延开来，到处都是，成为一场噩梦。



    正确的做法，其实是强硬的态度。你要告诉函数的使用者，我的参数全都不能是null，如果你给我null，程序崩溃了该你自己负责。至于调用者代码里有null怎么办，他自己该知道怎么处理（参考以上几条），不应该由函数作者来操心。



    采用强硬态度一个很简单的做法是使用Objects.requireNonNull()。它的定义很简单：


public static &lt;T&gt; T requireNonNull(T obj) {
  if (obj == null) {
    throw new NullPointerException();
  } else {
    return obj;
  }
}



    你可以用这个函数来检查不想接受null的每一个参数，只要传进来的参数是null，就会立即触发NullPointerException崩溃掉，这样你就可以有效地防止null指针不知不觉传递到其它地方去。


    使用@NotNull和@Nullable标记。IntelliJ提供了@NotNull和@Nullable两种标记，加在类型前面，这样可以比较简洁可靠地防止null指针的出现。IntelliJ本身会对含有这种标记的代码进行静态分析，指出运行时可能出现NullPointerException的地方。在运行时，会在null指针不该出现的地方产生IllegalArgumentException，即使那个null指针你从来没有deference。这样你可以在尽量早期发现并且防止null指针的出现。


    使用Optional类型。Java 8和Swift之类的语言，提供了一种叫Optional的类型。正确的使用这种类型，可以在很大程度上避免null的问题。null指针的问题之所以存在，是因为你可以在没有“检查”null的情况下，“访问”对象的成员。



    Optional类型的设计原理，就是把“检查”和“访问”这两个操作合二为一，成为一个“原子操作”。这样你没法只访问，而不进行检查。这种做法其实是ML，Haskell等语言里的模式匹配（pattern matching）的一个特例。模式匹配使得类型判断和访问成员这两种操作合二为一，所以你没法犯错。



    比如，在Swift里面，你可以这样写：


let found = find()
if let content = found {
  print("found: " + content)
}



    你从find()函数得到一个Optional类型的值found。假设它的类型是String?，那个问号表示它可能包含一个String，也可能是nil。然后你就可以用一种特殊的if语句，同时进行null检查和访问其中的内容。这个if语句跟普通的if语句不一样，它的条件不是一个Bool，而是一个变量绑定let content = found。



    我不是很喜欢这语法，不过这整个语句的含义是：如果found是nil，那么整个if语句被略过。如果它不是nil，那么变量content被绑定到found里面的值（unwrap操作），然后执行print("found: " + content)。由于这种写法把检查和访问合并在了一起，你没法只进行访问而不检查。



    Java 8的做法比较蹩脚一些。如果你得到一个Optional类型的值found，你必须使用“函数式编程”的方式，来写这之后的代码：


Optional&lt;String&gt; found = find();
found.ifPresent(content -&gt; System.out.println("found: " + content));



    这段Java代码跟上面的Swift代码等价，它包含一个“判断”和一个“取值”操作。ifPresent先判断found是否有值（相当于判断是不是null）。如果有，那么将其内容“绑定”到lambda表达式的content参数（unwrap操作），然后执行lambda里面的内容，否则如果found没有内容，那么ifPresent里面的lambda不执行。



    Java的这种设计有个问题。判断null之后分支里的内容，全都得写在lambda里面。在函数式编程里，这个lambda叫做“continuation”，Java把它叫做
“Consumer”，它表示“如果found不是null，拿到它的值，然后应该做什么”。由于lambda是个函数，你不能在里面写return语句返回出外层的函数。比如，如果你要改写下面这个函数（含有null）：


public static String foo() {
  String found = find();
  if (found != null) {
    return found;
  } else {
    return "";
  }
}



    就会比较麻烦。因为如果你写成这样：


public static String foo() {
  Optional&lt;String&gt; found = find();
  found.ifPresent(content -&gt; {
    return content;    // can't return from foo here
  });
  return "";
}



    里面的return a，并不能从函数foo返回出去。它只会从lambda返回，而且由于那个lambda（Consumer.accept）的返回类型必须是void，编译器会报错，说你返回了String。由于Java里closure的自由变量是只读的，你没法对lambda外面的变量进行赋值，所以你也不能采用这种写法：


public static String foo() {
  Optional&lt;String&gt; found = find();
  String result = "";
  found.ifPresent(content -&gt; {
    result = content;    // can't assign to result
  });
  return result;
}



    所以，虽然你在lambda里面得到了found的内容，如何使用这个值，如何返回一个值，却让人摸不着头脑。你平时的那些Java编程手法，在这里几乎完全废掉了。实际上，判断null之后，你必须使用Java 8提供的一系列古怪的函数式编程操作：map, flatMap, orElse之类，想法把它们组合起来，才能表达出原来代码的意思。比如之前的代码，只能改写成这样：


public static String foo() {
  Optional&lt;String&gt; found = find();
  return found.orElse("");
}



    这简单的情况还好。复杂一点的代码，我还真不知道怎么表达，我怀疑Java 8的Optional类型的方法，到底有没有提供足够的表达力。那里面少数几个东西表达能力不咋的，论工作原理，却可以扯到functor，continuation，甚至monad等高深的理论…… 仿佛用了Optional之后，这语言就不再是Java了一样。



    所以Java虽然提供了Optional，但我觉得可用性其实比较低，难以被人接受。相比之下，Swift的设计更加简单直观，接近普通的过程式编程。你只需要记住一个特殊的语法if let content = found {...}，里面的代码写法，跟普通的过程式语言没有任何差别。



    总之你只要记住，使用Optional类型，要点在于“原子操作”，使得null检查与取值合二为一。这要求你必须使用我刚才介绍的特殊写法。如果你违反了这一原则，把检查和取值分成两步做，还是有可能犯错误。比如在Java 8里面，你可以使用found.get()这样的方式直接访问found里面的内容。在Swift里你也可以使用found!来直接访问而不进行检查。



    你可以写这样的Java代码来使用Optional类型：


Option&lt;String&gt; found = find();
if (found.isPresent()) {
  System.out.println("found: " + found.get());
}



    如果你使用这种方式，把检查和取值分成两步做，就可能会出现运行时错误。if (found.isPresent())本质上跟普通的null检查，其实没什么两样。如果你忘记判断found.isPresent()，直接进行found.get()，就会出现NoSuchElementException。这跟NullPointerException本质上是一回事。所以这种写法，比起普通的null的用法，其实换汤不换药。如果你要用Optional类型而得到它的益处，请务必遵循我之前介绍的“原子操作”写法。




防止过度工程


    人的脑子真是奇妙的东西。虽然大家都知道过度工程（over-engineering）不好，在实际的工程中却经常不由自主的出现过度工程。我自己也犯过好多次这种错误，所以觉得有必要分析一下，过度工程出现的信号和兆头，这样可以在初期的时候就及时发现并且避免。



    过度工程即将出现的一个重要信号，就是当你过度的思考“将来”，考虑一些还没有发生的事情，还没有出现的需求。比如，“如果我们将来有了上百万行代码，有了几千号人，这样的工具就支持不了了”，“将来我可能需要这个功能，所以我现在就把代码写来放在那里”，“将来很多人要扩充这片代码，所以现在我们就让它变得可重用”……



    这就是为什么很多软件项目如此复杂。实际上没做多少事情，却为了所谓的“将来”，加入了很多不必要的复杂性。眼前的问题还没解决呢，就被“将来”给拖垮了。人们都不喜欢目光短浅的人，然而在现实的工程中，有时候你就是得看近一点，把手头的问题先搞定了，再谈以后扩展的问题。



    另外一种过度工程的来源，是过度的关心“代码重用”。很多人“可用”的代码还没写出来呢，就在关心“重用”。为了让代码可以重用，最后被自己搞出来的各种框架捆住手脚，最后连可用的代码就没写好。如果可用的代码都写不好，又何谈重用呢？很多一开头就考虑太多重用的工程，到后来被人完全抛弃，没人用了，因为别人发现这些代码太难懂了，自己从头开始写一个，反而省好多事。



    过度地关心“测试”，也会引起过度工程。有些人为了测试，把本来很简单的代码改成“方便测试”的形式，结果引入很多复杂性，以至于本来一下就能写对的代码，最后复杂不堪，出现很多bug。



    世界上有两种“没有bug”的代码。一种是“没有明显的bug的代码”，另一种是“明显没有bug的代码”。第一种情况，由于代码复杂不堪，加上很多测试，各种coverage，貌似测试都通过了，所以就认为代码是正确的。第二种情况，由于代码简单直接，就算没写很多测试，你一眼看去就知道它不可能有bug。你喜欢哪一种“没有bug”的代码呢？



    根据这些，我总结出来的防止过度工程的原则如下：



先把眼前的问题解决掉，解决好，再考虑将来的扩展问题。
先写出可用的代码，反复推敲，再考虑是否需要重用的问题。
先写出可用，简单，明显没有bug的代码，再考虑测试的问题。




    创造这样的精品文章需要很多的精力和咖啡 ;) 如果你喜欢这篇文章，请付款支持。建议金额$5美元或者30人民币。付款方式请参考这里。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 图灵的光环

 
 
 
 
    

    
 
     
  

      
   
图灵的光环

    



    仿佛全世界的人都知道，图灵（Alan Turing）是个天才，是他创造了计算机科学，是他破解了德国纳粹的Enigma密码。由于他的杰出贡献，计算机科学的最高荣誉，被叫做“图灵奖”。然而根据自己一直以来对图灵机等计算模型的看法，加上一些历史资料，我发现图灵本人的实际成就，相对于他所受到的崇拜，其实相差甚远。



    由于二战以来各国政府对于当时谍报工作的保密措施造成的事实混淆，再加上图灵的不幸生世所引来的同情，图灵这个名字似乎拥有了一种扑朔迷离的光环。人们把很多本来不是图灵作出的贡献归结在他身上，把本来很平常的贡献过分地夸大。图灵的光环，掩盖了许多对这些领域做出过更加重要贡献的人。


图灵传


    



    2012年，在图灵诞辰一百周年的时候，人们风风火火的召开各种大会，纪念这位“计算机之父”，很多媒体也添油加醋地宣传他的丰功伟绩。还有个叫Andrew Hodges的人，抓住这个时机推销自己写的一本传记，叫做《Alan Turing: The Enigma》。这本书红极一时，后来还被改编成了电影。



    这本传记看似客观，引经据典，字里行间却可以感受到作者对图灵个人的膜拜和偏袒，他在倾心打造一个“天才”。作者片面地使用对图灵有利的证据，对不利的方面只字不提。仿佛图灵做的一切都是有理的，他做的不好的地方都是因为别人的问题，或者风水不好。提到别人做的东西，尽是各种缺陷和局限性，不是缺陷也要说成是缺陷；提到图灵的工作，总是史无前例，开天辟地的发明。别人先做出来的东西，生拉硬拽，硬要说成是受了图灵的“启发”，还怪别人没有引用图灵的论文。这让你感觉仿佛别人都在抄袭图灵伟大的研究成果，都在利用他，欺负他似的。如果你不想花钱买书，可以看看同一作者写的一个图灵简要生平，足以从中感受到这种倾向。



    我写这篇文章的很大一部分原因，就是因为这本传记。作者对图灵贡献的片面夸大，对其他一些学者的变相贬低，让我感到不平。图灵在计算机界的名声，本来就已经被严重的夸大和美化，被很多人盲目的崇拜。现在出了这本传记和电影，又在人们心中加重了这层误解。所以我觉得有必要澄清一些事实，让人们不再被迷惑。


密码学


    



    很多人提到二战Enigma密码的故事，就会把功劳一股脑地归到图灵头上，只字不提其他人。其实呢，破解Enigma密码是很多人共同努力的结果，图灵只是其中的一员。这些人缺少了任何一个，都可能是灾难性的后果。其中好些人的想法早于图灵，启发过图灵，贡献比图灵的大，设计的东西比图灵的先进，却很少有人听说过他们的名字。论智力和贡献，图灵在其中只是中等水平，最后说起来倒好像是他单枪匹马拯救了大家，这是不公平的。



    最初破掉Enigma密码的，其实不是英国人，而是波兰人。波兰人不但截获并且仿造了德国人的Enigma机器，而且发现了其中微妙的漏洞，发明了一种用于解密的机器叫做BOMBA，以及一种手工破解的方法叫做Zygalski sheets。BOMBA可以在两个小时之内破解掉Enigma密码。波兰人一声不吭地窃听了德国人的通信长达六年半，最后在二战爆发前夕把这技术送给了英法盟友。



    BOMBA的工作原理，其实就是模拟好几个Enigma机器，“并发”运转，这样可以加速猜出秘钥。最开头这样还行，但后来德国人改进了Enigma机器，把可选的齿轮从3个增加到了5个。5选3，有60种情况，这样秘钥的空间增大了60倍。理论上BOMBA只要运转60倍多的Enigma机器，就可以破解这增大的解空间，然而那已经超出了波兰的物资和人力。再加上德国人就要打过去，所以波兰只好请英法盟友帮忙。



    图灵最重要的贡献，就是改进波兰人的BOMBA，设计了一个更好的机器叫BOMBE。BOMBE比起BOMBA，其实并没有质的飞跃，只不过BOMBE同时模拟的Enigma机器更多，转的更快。另外它加入了一些“优化”措施，尽早排除不可行的路径，所以速度快很多。图灵最初的设计，要求必须能够事先猜出很长的文本，所以基本不能用。后来Gordon Welchman发明了一种电路，叫做diagonal board，才使Bombe能够投入实用。关于Gordon Welchman的故事，你可以参考这个BBC纪录片。



    在Bombe能够投入使用之前，有一个叫John Herivel的人，发现了一种特殊的技巧，叫做Herivel tip，这种技术在Bombe投入使用之前几个月就已经投入实用，破解掉很多德军的消息，立下汗马功劳。如果Herivel tip没有被发明，盟军可能在1940年5月就已经战败，BOMBE也就根本没机会派上用场。



    同时在Bletchley Park，还诞生了一台大型可编程电子计算机Colossus，它是由一个叫Tommy Flowers的工程师设计的。Colossus不是用来破解Enigma密码的，而是用于破解Lorenz SZ-40。那是一种比Enigma还要先进的密码机器，用于发送希特勒的最高指令。



    德国人后来又改进了他们的通信方式，使用了一种具有四个齿轮的Enigma机器。这大大的增加了破解的难度，普通的Bombe机器也破不了它了。后来是Harold Keen设计了一个叫做Mammoth的机器，后来加上美国海军的帮助，制造了更快的Bombe，才得以破解。



    所以你看到了，所有这些人的工作加起来，才改善了二战的局面。波兰人的BOMBA，已经包含了最重要的思想。图灵的工作其实更多是量的改进，而不是质的飞跃。现在很多人喜欢跟风，片面的夸大图灵在其中的作用，这是不对的。如果你对Enigma机器的技术细节感兴趣，可以参考这两个视频：[视频1][视频2]。


理论计算机科学


    



    图灵被称为“计算机之父”，计算机科学界的最高荣誉，被叫做“图灵奖”（Turing Award）。然而如果你深入的理解了计算理论和程序语言理论就会发现，图灵对于理论计算机科学，其实并没产生长远而有益的影响。在某种程度上说，他其实帮了一个倒忙。图灵的理论复杂不堪，给人们造成很大的误导，阻碍了计算机科学的发展。而且他对于发表论文，对待研究的态度让我怀疑，我觉得图灵本人其实就是当今计算机学术界的一些不正之风的鼻祖。


图灵机和lambda演算


    绝大部分计算机专业的人提到图灵，就会想起图灵机（Turing Machine）。稍微有点研究的人，可能知道图灵机与lambda演算在计算能力上的等价性。然而在“计算能力”上等价，并不等于说它们具有同样的价值，随便用哪个都无所谓。科学研究有一条通用的原则：如果多个理论可以解释同样的现象，取最简单的一个。虽然lambda演算和图灵机能表达同样的理论，却比图灵机简单，优雅，实用很多。



    计算理论（Theory of Computation）这个领域，其实是被图灵机给复杂化了。图灵机的设计是丑陋，复杂，缺乏原则的。它的读写头，纸带，状态，操作，把本来很简单的语义搞得异常复杂。图灵机的读写两种操作同时发生，这恰好是编程上最忌讳的一种错误，类似于C语言的i++。图灵机是如此的复杂和混淆，以至于你很难看出它到底要干什么，也很难用它清晰地表达自己的意思。这就是为什么每个人上“计算理论”课程，都会因为图灵机而头痛。如果你挖掘一点历史，也许会发现图灵机的原型，其实是图灵母亲使用的打字机。用一台打字机来建模所有的计算，这当然是可行的，然而却复杂不堪。



    相比之下，lambda演算更加简单，优雅，实用。它是一个非常有原则的设计。Lambda演算不但能清晰地显示出你想要表达的意思，而且有直接的“物理实现”。你可以自然的把一个lambda演算表达式，看成是一个电子线路模块。对于现实的编程语言设计，系统设计，lambda演算有着巨大的指导和启发意义。以至于很多理解lambda演算的人都搞不明白，图灵机除了让一些理论显得高深莫测，还有什么存在的意义。


历史的倒退


    图灵机比起lambda演算来说，其实是一个历史的倒退。1928年，Alonzo Church发明了lambda演算（当时他25岁）。Lambda演算被设计为一个通用的计算模型，并不是为了解决某个特定的问题而诞生的。1929年，Church成为普林斯顿大学教授。1932年，Church在Annals of Mathematics发表了一篇论文，纠正逻辑领域里几个常见的问题，他的论述中用了lambda演算。1935年，Church发表论文，使用lambda演算证明基本数论中存在不可解决的问题。1936年4月，Church发表了一篇两页纸的“note”，指出自己1935年那篇论文可以推论得出，著名的Hilbert“可判定性问题”是不可解决的。



    1936年5月，当时还在剑桥读硕士的图灵，也写了一篇论文，使用自己设计的一种“计算机器”（后来被叫做图灵机）来证明同一个问题。图灵的论文投稿，比Church最早的结论发表，晚了整整一年。编辑从来没见过图灵机这样的东西，而且它纷繁复杂，远没有lambda演算来得优雅。就像所有人对图灵机的第一印象一样，编辑很难相信这打字机一样的操作方式，能够容纳“所有的计算”。他无法确定图灵的论述是否正确，只好找人帮忙。Church恐怕是当时世界上唯一能够验证图灵的论文正确性的人。所以一番好心之下，编辑写了封信给Church，说：“这个叫图灵的年轻人很聪明，他写了一篇论文，使用一种机器来证明跟你一样的结果。他会把论文寄给你。如果你发现他的结果是正确的而且有用，希望你帮助他拿到奖学金，进入Princeton跟你学习。”



    图灵就是这样成为了Church的学生，然而图灵心高气傲，恐怕从来没把Church当成过老师，反倒总觉得Church抢先一步，破坏了自己名垂青史的机会。跟Church的其它学生不一样，图灵没能理解lambda演算的精髓，却认为自己的机器才是最伟大的发明。进入Princeton之后，图灵不虚心请教，只是一心想发表自己的论文，想让大家对自己的“机器”产生兴趣，结果遭到很大的挫折。当然了，一个名不见经传的人，做了个怪模怪样的机器，说它可以囊括宇宙里所有的计算，你不被当成民科才怪呢！



    1937年，在Church的帮助下，图灵的那篇论文（起名为《Computable Numbers》）终于发表了。Church还是很器重图灵的，他把图灵的机器叫做“图灵机”。不幸的是，论文发表之后，学术界对此几乎没有任何反响，只有两人向图灵索取这篇论文。图灵当然不爽了，于是后来就到处推销自己的图灵机，想让大家承认那是伟大的发明。有了一个锤子，看什么都是钉子。后来每到一个地方，每做一个项目（见下一节），他都想把问题往自己那篇论文和图灵机上靠，东拉西扯的想证明它的价值，甚至称别人发明的东西全都是受到了图灵机的启发…… 经过人们很长的时间的以讹传讹之后，他终于成功了。



    图灵当年的作法，其实跟当今计算机学术界的普遍现象差不多。我想发表自己的想法A，结果别人已经发表了B，解决了A要解决的问题，而且还比A简单和清晰。怎么办呢？首先，我声明自己从没看过B的论文，这样就可以被称为“独立的发现”。然后，我证明A和B在“本质”上是等价的。最后，我东拉西扯，挖掘一下B的局限性，A相对于B在某些边沿领域的优势…… 这样反复折腾，寻找A的优势，总有一天会成功发表的。一旦发表成功，就会有人给我唱高调，没用的东西也要说成是有用的。他们会在A的基础上发展他们自己的东西，最后把我推崇为大师。那发表更早，更简单优美的B，也就无人问津了。胜利！



    现在不得不说一下《图灵传》对此的歪曲。Church的论文发表，比图灵的论文投稿还早一年，而且Church使用了比图灵机更简单优雅的计算模型。Church的成果本来天经地义应该受到更多的尊重，到头来作者却说：“...and Turing was robbed of the full reward for his originality”（见第3节“The Turing machine”）。让人感觉貌似是Church用不正当的手段“抢走”了图灵的“原创性”一样。你本来没有什么原创性，还丑陋复杂，所以何谈抢走呢？我怎么觉得恰恰相反，其实是图灵抢走了Church的原创性？现在提起Hilbert可判定性问题，可计算性理论，人们都想起图灵，有谁还想得起Church，有谁知道他是第一个解决了这问题的人，有谁知道他用了更优美的办法？


Lambda演算与计算理论


    由于图灵到处推销自己的理论，把不好的东西说成是好的，把别人发明的机器硬往自己的理论上面靠，说他们受到了图灵机的“启发”，以至于很多人被蛊惑，以为它比起lambda演算确实有优势。再加上很多人为了自己的利益而以讹传讹，充当传教士，这就是为什么图灵机现在被人们普遍接受作为计算模型。然而这并不能改变它丑陋和混淆的本质。图灵机的设计，其实是专门为了证明Hilbert的可判定性问题不可解决，它并不是一个用途广泛的计算模型。图灵机之所以被人接受，很大部分原因在于人的无知和愚蠢。很多人（包括很多所谓“理论计算机科学家”）根本没好好理解过lambda演算，他们望文生义，以为图灵机是“物理的”，实际可用的“机器”，而lambda演算只是一个理论模型。



    事实恰恰相反：lambda演算其实非常的实用，它的本质跟电子线路没什么两样。几乎所有现实可用的程序语言，其中的语义全都可以用lambda演算来解释。而图灵机却没有很多现实的意义，用起来非常蹩脚，所以只能在计算理论中作为模型。另外一个更加鲜为人知的事实是：lambda演算其实在计算理论方面也可以完全取代图灵机，它不但可以表达所有图灵机能表达的理论，而且能够更加简洁和精确地表达它们。



    很多理论计算机科学家喜欢用图灵机，仿佛是因为用它作为模型，能让自己的理论显得高深莫测，晦涩难懂。普通的计算理论课本，往往用图灵机作为它的计算模型，使用苦逼的办法推导各种可计算性（computability）和复杂性（complexity）理论。特别是像Michael Sipser那本经典的计算理论教材，晦涩难懂，混淆不堪，有时候让我都怀疑作者自己有没有搞懂那些东西。



    后来我发现，其实图灵机所能表达的理论，全都可以用更加简单的lambda演算（或者任何一种现在流行的程序语言）来表示。图灵机的每一个状态，不过对应了lambda演算（或者某种程序语言）里面的一个“AST节点”，然而用lambda演算来表示那些计算理论，却可以比图灵机清晰和容易很多。在Indiana大学做计算理论课程助教的时候，我把这种思维方式悄悄地讲述给了上课的学生们，他们普遍表示我的这种思维方式更易理解，而且更加贴近实际的编程。



    举一个很简单的例子。我可以用一行lambda演算表达式，来显示Hilbert的“可判定性问题”是无解的：



    Halting(λm.not(Halting(m,m)), λm.not(Halting(m,m)))



    完整的证明不到一页纸，请看我的另外一篇文章（英文）。这也就是图灵在他的论文里，折腾了十多页纸证明的东西。



    我曾经以为自己是唯一知道这个秘密的人，直到有一天我把这个秘密告诉了我的博士导师，Amr Sabry。他对我说：“哈哈！其实我早就知道这个，你可以参考一下Neil Jones写的一本书，叫做《Computability and Complexity: From a Programming Perspective》。这本书现在已经可以免费下载。



    此书作者用一种很简单的程序语言，阐述了一般人用图灵机来描述的那些理论（可计算性理论，复杂性理论）。他发现用程序语言来描述计算理论，不但简单直接，清晰明了，而且在某些方面可以更加精确地描述图灵机无法描述的定理。得到这本书，让我觉得如获至宝，原来世界上有跟我看法如此相似，对事物洞察力如此之高的人！



    在一次会议上，我有幸地遇到了Neil Jones，跟他切磋思想。当提到这本书的模型与图灵理论的关系，老教授谦虚地说：“图灵的模型还是有它的价值的……” 然而到最后，他其实也没能说清楚这价值何在。我心里很清楚，他只是为了避免引起宗教冲突，或者避免显得狂妄自大，而委婉其词。眼前的这位教授，虽然从来没有得过图灵奖，很少有人听说过他的名字，然而他对于计算本质的理解，却比图灵本人还要高出很多。



    总的说来，图灵机也许不是一文不值，然而由于lambda演算可以更加清晰地解释图灵机能表示的所有理论，图灵机的价值相对来说几乎为零。Church在1937年给图灵论文写的Review指出，图灵机的优势，在于它可以让不懂很多数学，不理解lambda演算之类理论的人也可以看得懂。我怎么觉得图灵机对于不懂很多数学的人，理解起来其实更加痛苦呢？而且就算它真的对“外行”或者“笨人”的理解有好处，这价值貌似也不大吧？:P


电子计算机


    



    很多“理论计算机科学家”喜欢说，大家现在用的计算机，只不过是一个“Universal Turing Machine”。就算你根本不知道图灵是谁，自己辛苦设计出一个机器或者语言，他们总喜欢说：“是图灵启发了你，因为你那东西是跟图灵机等价的，是图灵完备的……”



    那么现在让我们来看看，图灵本人和他的理论，真正对电子计算机的发展起过多大的作用吧。如果一个人对一个行业起过重大的作用，那我们可以说“没有他不行”。然而事实却是，即使没有图灵，计算机技术会照样像今天一样发展，丝毫不会受到影响。看一看历史，你也许会惊讶的发现，图灵的理论不但没能启发任何计算机的设计，而且图灵亲自设计的唯一一个计算机（ACE），最后也以悲惨的失败告终。


什么是Universal Turing Machine（UTM）


    ACE失败的一个重要原因，是因为图灵过度的看重他自己发明的Universal Turing Machine（UTM）。所以我想首先来解密一下，这个被很多人吹得神乎其神的，似乎什么都可以往上面扯的UTM，到底是什么东西。



    说白了，UTM就是一个解释器，就像Python或者JavaScript的解释器一样。计算机的处理器（CPU）也是一个解释器，它是用来解释机器指令的。那这样说来，任何可编程，具有指令集的机器都是UTM了，所以图灵的理论启发了所有这些机器？你尽管跟我扯吧 :)



    你应该知道，在图灵的UTM出现以前，Church的lambda演算里面早就有解释器的概念了，所以UTM根本不是什么新东西，而且它比起lambda演算的解释器，真是丑陋又复杂。而Church其实也不是第一个提出解释器这概念的人，像这类通用的概念，已经很难追溯是谁“发明”的了。也许并不是某一个人发明了它，而是历史上的很多人。



    解释器这个概念的涵义实在是包罗万象，几乎无处不在。只要是“可编程”的机器，它本质上必然包含一个解释器。一个工程师在不知道解释器这概念的情况下，照样很有可能“不小心”设计出一个可编程的机器，所以如果你把这些全都归结成图灵或者Church的功劳，就太牵强了。


图灵与ACE的故事


    事实上，最早的电子计算机，并不是图灵设计的，而是电子工程师跟其他一些数学家合作的结果。根据老一辈工程师的叙述，图灵的工作和理论，对于现实的电子计算机设计，几乎没有任何的正面作用。很多工程师其实根本不知道图灵是谁，图灵机是什么。他们只是根据实际的需求，设计和制造了那些电路。这就是为什么我们今天看到的电子计算机，跟图灵机或者图灵的其他理论几乎完全不搭边。



    世界上最早的两台电子计算机，ENIAC和EDVAC，都是美国人设计制造的。其中EDVAC的设计报告，是冯诺依曼（von Neumann）参与并签署的。提到EDVAC的设计，《图灵传》有一段有趣的介绍，它基本是这样说的：“冯诺依曼在Princeton的时候，很了解图灵开天辟地的发明—UTM。UTM只有一根纸带，而EDVAC把指令和数据放在同一个存储空间，所以EDVAC的设计肯定是受了UTM的启发。然而EDVAC的设计报告，却只字不提图灵和UTM的名字，更没有引用图灵划时代的论文《Computable Numbers》……”



    这其实是在含沙射影的说，冯诺依曼和EDVAC团队抄袭了图灵的研究成果。照这种歪理，我洗衣服的时候，袜子和内裤放在同一个桶里洗，也是受了图灵的启发了，就因为UTM只有一条纸带？这世界上的事物，还有啥不是受了UTM启发的？这让我想起某些全靠打专利官司赚钱的公司（patent troll）…… 冯诺依曼作为一代数学大师，比UTM重大的研究成果多得是了，他会在乎抄袭图灵的东西吗？其实人家恐怕是根本没把图灵和他的论文当回事。而且其他人（比如Church）早就有跟UTM等价的想法，而且还更好，更简单。之前抢了Church的风头，现在居然欺到冯诺依曼头上来了。哎，真受不了这种一辈子只想出过一个点子的人……



    所以听说美国人造出了EDVAC，图灵开始各种羡慕嫉妒恨，感叹自己英才无用武之地。终于有一天，他的机会来了。在EDVAC诞生几个月之后，英国国家物理实验室（NPL）联系了图灵。他们想赶上美国的计算机技术发展，所以想招募图灵，让他帮忙山寨一个EDVAC的“英国特色版本”。图灵设计的机器叫做ACE（Automatic Computing Engine）。最初，图灵给NPL一个很宏伟的蓝图：ACE可以如此的强大，以至于整个英国只需要这样一台计算机就够了，我们可以把它叫做“英国国家计算机”…… 然而再大的口号，也难逃脱现实的检验，ACE项目最终以失败告终。



    《图灵传》把ACE失败的责任，推托到NPL和其它人的“近视”和“官僚”，然而ACE失败的主要责任，其实在于图灵自己：他完全没有设计一台现实的计算机的基本技能，却总是自以为是，设立高大空的目标。图灵的设计跟当时（包括现在的）所有实用的计算机都有巨大的差别。不出你所料，他最初的设计思路，是根据自己之前的论文《Computable Numbers》里提到的“Universal Turing Machine”，不过从中去掉了一些不实际的设计，比如用一根纸带来存储数据。这一点改进貌似做对了，可是呢，他又加入了一些让工程师们无语的设计，美其名曰“极简设计”（minimalism）。比如，ACE的硬件只提供AND, OR, NOT之类的逻辑运算作为“基本操作”，其它的算数操作，包括加减乘除，全部用代码来实现。图灵大师啊，你知不知道有一种重要的指标，叫做“效率”？



    这还不算…… 后来他更加异想天开，终于扯上了“思考机器”（thinking machines）—他想让ACE成为可以像人一样思考的机器，还想让这机器能够自己写自己的代码。按照图灵的原话：“在ACE的工作中，我对人脑建模的兴趣，比实际的计算应用更感兴趣。” 他显然已经把ACE当成了自己一个人的玩具，而不再是解决人们实际需求的工具。只要有人反对这想法，他就会嘲笑说，你是怕我的机器太聪明了，抢了你的饭碗吧？其实图灵对于实际的人脑工作原理所知甚少，基本处于初中生理卫生课本水平，然而他总喜欢对人说，人脑不过就是一个UTM。看吧，它有输入，输出，状态转换，就跟UTM一样…… 所谓“图灵测试”（Turing Test），就是那时候提出来的。当然了，因为他扯到了“thinking machine”，就有后人把他称为人工智能（AI）的鼻祖。其实呢，图灵测试根本就不能说明一个机器具有了人的智能，它只是在测试一些肤浅的表象。后来，“thinking machines”成为了一种通用的幌子，用于筹集大笔科研经费，最后全都血本无归。



    图灵设计了这机器，NPL当时却没有能力制造它。于是他们求助于另外两位实现过计算机的工程师：F. C. Williams和Maurice Wilkes（后来EDSAC计算机的设计者），请他们帮忙实现图灵的设计。可想而知，Williams和Wilkes都表示不喜欢ACE的设计，而且指出图灵的性格与自己的研究风格不匹配，不愿跟他合作，所以双双拒绝了NPL的邀请。最后，NPL新成立了一个电子部门，ACE的工程终于可以开始。然而，根据资深工程师们的讨论，觉得图灵提出的制造一个“电子人脑”和“智能机器”，并不是实际可行，或者在短期之内能派上用场的项目，所以决定做一些实际点的事情。图灵对此非常恼火，各种抱怨，说别人官僚啊，近视啊，没想象力啊之类的，然后开始公开的抵制NPL的决定。



    最后工程师们和管理层都受不了他了，鉴于他名声在外，又不好意思开掉他，只好提出一个破天荒的提议：由NPL资助，让图灵回到剑桥大学去度年假（sabbatical），做一些纯数学的研究。于是ACE在图灵不在的情况下，终于开工了⋯⋯1950年，ACE运行了它的第一个程序。然而工程师们实现的ACE，完全偏离了图灵的设计，以至于实际的机器和图灵的设计之间，几乎没有任何相似性。一年之后，图灵还想回到NPL，继续影响ACE的设计，然而NPL的领导们却建议他继续留在大学里做纯理论的研究，并且让曼彻斯特大学给他一个职位。最后图灵接受了这个建议，这下大家伙儿都松了一口气…… :P



    图灵设计的唯一一个计算机ACE，终究以图灵完全退出整个项目而告终。今天回头看来，如果当时图灵留下来了，NPL真的按照图灵的意思来做，ACE恐怕直到今天都造不出来。由于图灵不切实际的设计和高傲的性格，NPL失去了最优秀的人的帮助。1949年，Maurice Wilkes按照EDVAC的思路，成功制造了EDSAC，速度是ACE的两倍以上，而且更加实用。所以你看到了，图灵并不是一个实干家，他的双脚飘在半空中。他的理论，他设计的机器，他的代码，全都停留在纸上。他并没有帮助造出任何一台实际可用的计算机，他对计算机的工程实现几乎没有任何有益的影响。可惜的是，有些人喜欢把实干家们千辛万苦造出来，真正可以用的东西，牵强附会地归功于某些高谈阔论的理论家，仿佛那是理论家的功劳似的。这也许就是为什么图灵被他们称为“计算机之父”吧。



    如果对ACE和其它早期计算机感兴趣，你可以参考一下更详细的资料。你也可以看一看《图灵传》，虽然它观点荒唐，对图灵各种偏袒，然而图灵和其他人的通信，基本的史实，他应该不好意思篡改。


总结


    我说这些是为了什么呢？我当然不是想否认图灵所做出的贡献。像许多的计算机工作者一样，他的某些工作当然是有意义的。然而那种意义并不像很多人所吹嘘的那么伟大，它们甚至不包含很多的创新。



    我觉得很多后人给图灵带上的光环，掩盖了太多其它值得我们学习和尊敬的人，给人们对于计算机科学的概念造成了误导。计算机科学不是图灵一个人造出来的，图灵并不是计算机科学的鼻祖，他甚至不是在破解Enigma密码和电子计算机诞生过程中起最重要作用的人。



    许许多多的计算机科学家和电子工程师们，是他们造就了今天的计算科学。他们的聪明才智和贡献，不应该被图灵的光环所掩盖，他们应该受到像跟图灵一样的尊敬。希望大家不要再神化图灵，不要再神化任何人。不要因为膜拜某些人，而失去向另一些人学习的机会。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 谈谈Parser

 
 
 
 
    

    
 
     
  

      
   
谈谈Parser

    一直很了解人们对于parser的误解，可是一直都提不起兴趣来阐述对它的观点。然而我觉得是有必要解释一下这个问题的时候了。我感觉得到大部分人对于parser的误解之深，再不澄清一下，恐怕这些谬误就要写进歪曲的历史教科书，到时候就没有人知道真相了。


什么是Parser


    首先来科普一下。所谓parser，一般是指把某种格式的文本（字符串）转换成某种数据结构的过程。最常见的parser，是把程序文本转换成编译器内部的一种叫做“抽象语法树”（AST）的数据结构。也有简单一些的parser，用于处理CSV，JSON，XML之类的格式。



    举个例子，一个处理算数表达式的parser，可以把“1+2”这样的，含有1，+，2三个字符的字符串，转换成一个对象（object）。这个对象就像new BinaryExpression(ADD, new Number(1), new Number(2))这样的Java构造函数调用生成出来的那样。



    之所以需要做这种从字符串到数据结构的转换，是因为编译器是无法直接操作“1+2”这样的字符串的。实际上，代码的本质根本就不是字符串，它本来就是一个具有复杂拓扑的数据结构，就像电路一样。“1+2”这个字符串只是对这种数据结构的一种“编码”，就像ZIP或者JPEG只是对它们压缩的数据的编码一样。



    这种编码可以方便你把代码存到磁盘上，方便你用文本编辑器来修改它们，然而你必须知道，文本并不是代码本身。所以从磁盘读取了文本之后，你必须先“解码”，才能方便地操作代码的数据结构。比如，如果上面的Java代码生成的AST节点叫node，你就可以用node.operator来访问ADD，用node.left来访问1，node.right来访问2。这是很方便的。



    对于程序语言，这种解码的动作就叫做parsing，用于解码的那段代码就叫做parser。


Parser在编译器中的地位


    那么貌似这样说来，parser是编译器里面很关键的一个部分了？显然，parser是必不可少的，然而它并不像很多人想象的那么重要。Parser的重要性和技术难度，被很多人严重的夸大了。一些人提到“编译器”，就跟你提LEX，YACC，ANTLR等用于构造parser的工具，仿佛编译器跟parser是等价的似的。还有些人，只要听说别人写了个parser，就觉得这人编程水平很高，开始膜拜了。这些其实都显示出人的肤浅。



    我喜欢把parser称为“万里长征的第0步”，因为等你parse完毕得到了AST，真正精华的编译技术才算开始。一个先进的编译器包含许多的步骤：语义分析，类型检查/推导，代码优化，机器代码生成，…… 这每个步骤都是在对某种中间数据结构（比如AST）进行分析或者转化，它们完全不需要知道代码的字符串形式。也就是说，一旦代码通过了parser，在后面的编译过程里，你就可以完全忘记parser的存在。所以parser对于编译器的地位，其实就像ZIP之于JVM，就像JPEG之于PhotoShop。Parser虽然必不可少，然而它比起编译器里面最重要的过程，是处于一种辅助性，工具性，次要的地位。



    鉴于这个原因，好一点的大学里的程序语言（PL）课程，都完全没有关于parser的内容。学生们往往直接用Scheme这样代码数据同形的语言，或者直接使用AST数据结构来构造程序。在Kent Dybvig这样编译器大师的课程上，学生直接跳过parser的构造，开始学习最精华的语义转换和优化技术。实际上，Kent Dybvig根本不认为parser算是编译器的一部分。因为AST数据结构其实才是程序本身，而程序的文本只是这种数据结构的一种编码形式。


Parser技术发展的误区


    既然parser在编译器中处于次要的地位，可是为什么还有人花那么大功夫研究各种炫酷的parser技术呢。LL，LR，GLR，LEX, YACC，Bison，parser combinator，ANTLR，PEG，…… 制造parser的工具似乎层出不穷，每出现一个新的工具都号称可以处理更加复杂的语法。



    很多人盲目地设计复杂的语法，然后用越来越复杂的parser技术去parse它们，这就是parser技术仍然在发展的原因。其实，向往复杂的语法，是程序语言领域流传非常广，危害非常大的错误倾向。在人类历史的长河中，留下了许多难以磨灭的历史性糟粕，它们固化了人类对于语言设计的理念。很多人设计语言似乎不是为了拿来好用的，而是为了让用它的人迷惑或者害怕。



    有些人假定了数学是美好的语言，所以他们盲目的希望程序语言看起来更加像数学。于是他们模仿数学，制造了各种奇怪的操作符，制定它们的优先级，这样你就可以写出2 &lt;&lt; 7 - 2 * 3这样的代码，而不需要给子表达式加上括号。还有很多人喜欢让语法变得“简练”，就为了少打几个括号，分号，花括号，…… 可是由此带来的结果是复杂，不一致，有多义性，难扩展的语法，以及障眼难读，模棱两可的代码。



    更有甚者，对数学的愚蠢做法执迷不悟的人，设计了像Haskell和Coq那样的语言。在Haskell里面，你可以在代码里定义新的操作符，指定它的“结合律”（associativity）和“优先级”（precedence）。这样的语法设计，要求parser必须能够在parse过程中途读入并且加入新的parse规则。Coq试图更加“强大”一些，它让你可以定义“mixfix操作符”，也就是说你的操作符可以连接超过两个表达式。这样你就可以定义像if...then...else...这样的“操作符”。



    制造这样复杂难懂的语法，其实没有什么真正的好处。不但给程序员的学习造成了不必要的困难，让代码难以理解，而且也给parser的作者带来了严重的挑战。可是有些人就是喜欢制造问题，就像一句玩笑话说的：有困难要上，没有困难，制造困难也要上！



    如果你的语言语法很简单（像Scheme那样），你是不需要任何高深的parser理论的。说白了，你只需要知道如何parse匹配的括号。最多一个小时，几百行Java代码，我就能写出一个Scheme的parser。



    可是很多人总是嫌问题不够有难度，于是他们不停地制造更加复杂的语法，甚至会故意让自己的语言看起来跟其它的不一样，以示“创新”。当然了，这样的语言就得用更加复杂的parser技术，这正好让那些喜欢折腾复杂parser技术的人洋洋得意。


编译原理课程的误导


    程序员们对于parser的误解，很大程度上来自于大学编译原理课程照本宣科的教育。很多老师自己都不理解编译器的精髓，所以就只有按部就班的讲一些“死知识”，灌输“业界做法”。一般大学里上编译原理课，都是捧着一本大部头的“龙书”或者“虎书”，花掉一个学期1/3甚至2/3的时间来学写parser。由于parser占据了大量时间，以至于很多真正精华的内容都被一笔带过：语义分析，代码优化，类型推导，静态检查，机器代码生成，…… 以至于很多人上完了编译原理课程，记忆中只留下写parser的痛苦回忆。



    “龙书”之类的教材在很多人心目中地位是如此之高，被誉为“经典”，然而其实除了开头很大篇幅来讲parser理论，这本书其它部分的水准其实相当低。大部分学生的反应其实是“看不懂”，然而由于一直以来没有更好的选择，它经典的地位真是难以动摇。“龙书”后来的新版我浏览过一下，新加入了类型检查/推导的部分，可是我看得出来，其实作者们自己对于类型理论都是一知半解，所以也就没法写清楚，让人可以看懂了。



    龙书作者的水平，跟Dan Friedman，Kent Dybvig这样真正的大师比起来，其实差的老远。如果你想真的深入理解编译理论，最好是从PL课程的读物，比如EOPL开始。我可以说PL这个领域，真的是高于编译器领域的。请不要指望编译器的作者能够轻易设计出好的语言，因为他们可能根本不理解很多语言设计的东西，他们只是会按部就班地实现某些别人设计的语言。可是反过来，理解了PL的理论，编译器的东西只不过是把一种语言转换成另外一种语言（机器语言）而已。工程的细枝末节很麻烦，可是当你掌握了精髓的原理，那些都容易摸索出来。


我写parser的心得和秘诀


    虽然我已经告诉你，给过度复杂的语言写parser其实是很苦逼，没有意思的工作，然而有些历史性的错误已经造成了深远的影响，所以很多时候虽然心知肚明，你也不得不妥协一下。由于像C++，Java，JavaScript，Python之类语言的流行，有时候你是被迫要给它们写parser。在这一节，我告诉你一些秘诀，也许可以帮助你更加容易的写出这些语言的parser。



    很多人都觉得写parser很难，一方面是由于语言设计的错误思想导致了复杂的语法，另外一方面是由于人们对于parser构造过程的思维误区。很多人不理解parser的本质和真正的用途，所以他们总是试图让parser干一些它们本来不应该干的事情，或者对parser有一些不切实际的标准。当然，他们就会觉得parser非常难写，非常容易出错。




    尽量拿别人写的parser来用。维护一个parser是相当繁琐耗时，回报很低的事情。一旦语言有所改动，你的parser就得跟着改。所以如果你能找到免费的parser，那就最好不要自己写。现在的趋势是越来越多的语言在标准库里提供可以parse它自己的parser，比如Python和Ruby。这样你就可以用那语言写一小段代码调用标准的parser，然后把它转换成一种常用的数据交换格式，比如JSON。然后你就可以用通用的JSON parser解析出你想要的数据结构了。



    如果你直接使用别人的parser，最好不要使用它原来的数据结构。因为一旦parser的作者在新版本改变了他的数据结构，你所有的代码都会需要修改。我的秘诀是做一个“AST转换器”，先把别人的AST结构转换成自己的AST结构，然后在自己的AST结构之上写其它的代码，这样如果别人的parser修改了，你可以只改动AST转换器，其它的代码基本不需要修改。



    用别人的parser也会有一些小麻烦。比如Python之类语言自带的parser，丢掉了很多我需要的信息，比如函数名的位置，等等。我需要进行一些hack，找回我需要的数据。相对来说，这样小的修补还是比从头写一个parser要划得来。但是如果你实在找不到一个好的parser，那就只好自己写一个。


    很多人写parser，很在乎所谓的“one-pass parser”。他们试图扫描一遍代码文本就构造出最终的AST结构。可是其实如果你放松这个条件，允许用多pass的parser，就会容易很多。你可以在第一遍用很容易的办法构造一个粗略的树结构，然后再写一个递归树遍历过程，把某些在第一遍的时候没法确定的结构进行小规模的转换，最后得到正确的AST。



    想要一遍就parse出最终的AST，可以说是一种过早优化（premature optimization）。有些人盲目地认为只扫描一遍代码，会比扫描两遍要快一些。然而由于你必须在这一遍扫描里进行多度复杂的操作，最终的性能也许还不如很快的扫完第一遍，然后再很快的遍历转换由此生成的树结构。


    另外一些人试图在parse的过程中做一些本来不属于它做的事情，比如进行一些基本的语义检查。有些人会让parser检查“使用未定义的变量”等语义错误，一旦发现就在当时报错，终止。这种做法其实混淆了parser的作用，造成了不必要的复杂性。



    就像我说的，parser其实只是一个解码器。parser要做的事情，应该是从无结构的字符串里面，解码产生有结构的数据结构。而像“使用未定义的变量”这样的语义检查，应该是在生成了AST之后，使用单独的树遍历来进行的。人们常常混淆“解码”，“语法”和“语义”三者的不同，导致他们写出过度复杂，效率低下，难以维护的parser。


    另一种常见的误区是盲目的相信YACC，ANTLR之类所谓“parser generator”。实际上parser generator的概念看起来虽然美好，可是实际用起来几乎全都是噩梦。事实上最好的parser，比如EDG C++ parser，几乎全都是直接用普通的程序语言手写而成的，而不是自动生成的。



    这是因为parser generator都要求你使用某种特殊的描述语言来表示出语法，然后自动把它们转换成parser的程序代码。在这个转换过程中，这种特殊的描述语言和生成的parser代码之间，并没有很强的语义连接关系。如果生成的parser有bug，你很难从生成的parser代码回溯到语法描述，找到错误的位置和原因。你没法对语法描述进行debug，因为它只是一个文本文件，根本不能运行。



    所以如果你真的要写parser，我建议你直接用某种程序语言手写代码，使用普通的递归下降（recursive descent）写法，或者parser combinator的写法。只有手写的parser才可以方便的debug，而且可以输出清晰，人类可理解的出错信息。


    有些人喜欢死扣BNF范式，盲目的相信“LL”，“LR”等语法的区别，所以他们经常落入误区，说“哎呀，这个语法不是LL的”，于是采用一些像YACC那样的LR parser generator，结果落入非常大的麻烦。其实，虽然有些语法看起来不是LL的，它们的parser却仍然可以用普通的recursive descent的方式来写。



    这里的秘诀在于，语言规范里给出的BNF范式，其实并不是唯一的可以写出parser的做法。BNF只是一个基本的参照物，它让你可以对语法有个清晰的概念，可是实际的parser却不一定非得按照BNF的格式来写。有时候你可以把语法的格式稍微改一改，变通一下，却照样可以正确地parse原来的语言。其实由于很多语言的语法都类似于C，所以很多时候你写parser只需要看一些样例程序，然后根据自己的经验来写，而不需要依据BNF。



    Recursive descent和parser combinator写出来的parser其实可以非常强大，甚至可以超越所谓“上下文无关文法”，因为在递归函数里面你可以做几乎任意的事情，所以你甚至可以把上下文传递到递归函数里，然后根据上下文来决定对当前的节点做什么事情。而且由于代码可以得到很多的上下文信息，如果输入的代码有语法错误，你可以根据这些信息生成非常人性化的出错信息。




总结


    所以你看到了，parser并不是编译器，它甚至不属于编译里很重要的东西。程序语言和编译器里面有比parser重要很多，有趣很多的东西。Parser的研究，其实是在解决一些根本不存在，或者人为制造的问题。复杂的语法导致了复杂的parser技术，它们仍然在给计算机世界带来不必要的困扰和麻烦。对parser写法的很多误解，过度工程和过早优化，造成了很多人错误的高估写parser的难度。



    能写parser并不是什么了不起的事情，其实它是非常苦逼，真正的程序语言和编译器专家根本不屑于做的事情。所以如果你会写parser，请不要以为是什么了不起的事情，如果你看到有人写了某种语言的parser，也不要表现出让人哭笑不得的膜拜之情。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 数学和编程

 
 
 
 
    

    
 
     
  

      
   
数学和编程

    好些人来信问我，要成为一个好的程序员，数学基础要达到什么样的程度？十八年前，当我成为大学计算机系新生的时候，也为同样的问题所困扰。面对学数学，物理等学科的同学，我感到自卑。经常有人说那些专业的知识更加精华一些，难度更高一些，那些专业的人毕业之后如果做编程工作，水平其实比计算机系毕业的还要高。直到几年前深入研究程序语言之后，对这个问题我才得到了答案和解脱。由于好多编程新手遇到同样的困扰，所以我想在这里把这个问题详细的阐述一下。


数学并不是计算机科学的基础


    很多人都盲目的认为，计算机科学是数学的一个分支，数学是计算机科学的基础，数学是更加博大精深的科学。这些人以为只要学会了数学，编程的事情全都不在话下，然而事实却并非如此。



    事实其实是这样的：



计算机科学其实根本不是数学，它只不过借用了非常少，非常基础的数学，比高中数学还要容易一点。所谓“高等数学”，在计算机科学里面基本用不上。
计算机是比数学更加基础的工具，就像纸和笔一样。计算机可以用来解决数学的问题，也可以用来解决不是数学的问题，比如工程的问题，艺术的问题，经济的问题，社会的问题等等。
计算机科学是完全独立的学科。学习了数学和物理，并不能代替对计算机科学的学习。你必须针对计算机科学进行学习，才有可能成为好的程序员。
数学家所用的语言，比起常见的程序语言（比如C++，Java）来说，其实是非常落后而糟糕的设计。所谓“数学的美感”，其实大部分是夜郎自大。
99%的数学家都写不出像样的代码。



数学是异常糟糕的语言


    这并不是危言耸听。如果你深入研究过程序语言的理论，就会发现其实数学家们使用的那些符号，只不过是一种非常糟糕的程序语言。数学的理论很多是有用的，然而数学家门用于描述这些理论所用的语言，却是纷繁复杂，缺乏一致性，可组合性（composability），简单性，可用性。这也就是为什么大部分人看到数学就头痛。这不是他们不够聪明，而是数学语言的“设计”有问题。人们学习数学的时候，其实只有少部分时间在思考它的精髓，而大部分时间是在折腾它的语法。



    举一个非常简单的例子。如果你说cos2θ表示(cos θ)2，那么理所当然，cos-1θ就应该表示1/(cos θ)了？可它偏偏不是！别被数学老师们的教条和借口欺骗啦，他们总是告诉你：“你应该记住这些！” 可是你想过吗：“凭什么？” cos2θ表示(cos θ)2，而cos-1θ，明明是一模一样的形式，表示的却是arccos θ。一个是求幂，一个是调用反函数，风马不及，却写成一个样子。这样的语言设计混淆不堪，却喜欢以“约定俗成”作为借口。



    如果你再多看一些数学书，就会发现这只是数学语言几百年累积下来的糟粕的冰山一角。数学书里尽是各种上标下标，带括号的上标下标，x，y，z，a，b，c，f，g，h，各种扭来扭去的希腊字母，希伯来字母…… 斜体，黑体，花体，双影体，……用不同的字体来表示不同的“类型”。很多符号的含义，在不同的子领域里面都不一样。有些人上一门数学课，到最后还没明白那些符号是什么意思。



    直到今天，数学家们写书仍然非常不严谨。他们常犯的一个错误是把x2这样的东西叫做“函数”（function）。其实x2根本不是一个函数，它只是一个表达式。你必须同时指明“x是参数”，加上x2，才会成为一个函数。所以正确的函数写法其实看起来像这样：f(x) = x2。或者如果你不想给它一个名字，可以借用lambda calculus的写法，写成：λx.x2。



    可是数学家们灰常的喜欢“约定俗成”。他们定了一些不成文的规矩是这样：凡是叫“x”的，都是函数的参数，凡是叫“y”的，都可能是一个函数…… 所以你写x2就可以表示λx.x2，而不需要显式的写出“λx”。殊不知这些约定俗成，看起来貌似可以让你少写几个字，却造成了许许多多的混淆和麻烦。比如，你在Mathematica里面可以对 x2+y 求关于x的导数，而且会得到 y'(x) + 2x 这样蹊跷的结果，因为它认为y可能是一个函数。更奇怪的是，如果你在后面多加一个a，也就是对x2+y+a求导，你会得到 2x！那么 y'(x) 到哪里去了？莫名其妙……



    相对而言，程序语言就严谨很多，所有的程序语言都要求你必须指出函数的参数叫什么名字。像x2这样的东西，在程序语言里面不是一个函数（function），而只是一个表达式（expression）。即使 JavaScript 这样毛病众多的语言都是这样。比如，你必须写：


function (x) { return x * x }



    那个括号里的(x)，显式的声明了变量的名字，避免了可能出现的混淆。我不是第一个指出这些问题的人。其实现代逻辑学的鼻祖Gottlob Frege在一百多年以前就在他的论文“Function and Concept”里批评了数学家们的这种做法。可是数学界的表达方式直到今天还是一样的混乱。



    很多人学习微积分都觉得困难，其实问题不在他们，而在于莱布尼兹（Leibniz）。莱布尼兹设计来描述微积分的语言（∫，dx, dy, ...），从现代语言设计的角度来看，其实非常之糟糕，可以说是一塌糊涂。我不能怪莱布尼兹，他毕竟是几百年前的人了，他不知道我们现在知道的很多东西。然而古人的设计，现在还不考虑改进，反而当成教条灌输给学生，那就是不思进取了。



    数学的语言不像程序语言，它的历史太久，没有经过系统的，考虑周全的，统一的设计。各种数学符号的出现，往往是历史上某个数学家有天在黑板上随手画出一些古怪的符号，说这代表什么，那代表什么，…… 然后就定下来了。很多数学家只关心自己那块狭窄的子领域，为自己的理论随便设计出一套符号，完全不管这些是否跟其它子领域的符号相冲突。这就是为什么不同的数学子领域里写出同样的符号，却可以表示完全不同的涵义。在这种意义上，数学的语言跟Perl（一种非常糟糕的程序语言）有些类似。Perl把各种人需要的各种功能，不加选择地加进了语言里面，造成语言繁复不堪，甚至连Perl的创造者自己都不能理解它所有的功能。



    数学的证明，使用的其实也是极其不严格的语言——古怪的符号，加上含糊不清，容易误解的人类语言。如果你知道什么是Curry-Howard Correspondence就会明白，其实每一个数学证明都不过是一段代码。同样的定理，可以有许多不同版本的证明（代码）。这些证明有的简短优雅，有的却冗长繁复，像面条一样绕来绕去，没法看懂。你经常在数学证明里面看到“未定义的变量”，证明的逻辑也包含着各种隐含知识，思维跳跃，非常难以理解。很多数学证明，从程序的观点来看，连编译都不会通过，就别提运行了。



    数学家们往往不在乎证明的优雅性。他们认为只要能证明出定理，你管我的证明简不简单，容不容易看懂呢。你越是看不懂，就越是觉得我高深莫测，越是感觉你自己笨！这种思潮到了编程的时候就显出弊端了。数学家写代码，往往忽视代码的优雅性，简单性，模块化，可读性，性能，数据结构等重要因素，认为代码只要能算出结果就行。他们把代码当成跟证明一样，一次性的东西，所以他们的代码往往不能满足实际工程的严格要求。



    数学里最在乎语言设计的分支，莫过于逻辑学了。很多人（包括很多程序语言专家）都盲目的崇拜逻辑学家，盲目的相信数理逻辑是优雅美好的语言。在程序语言界，数理逻辑已经成为一种灾害，明明很容易就能解释清楚的语义，非得写成一堆稀奇古怪，含义混淆的逻辑公式。殊不知其实数理逻辑也是有很大的历史遗留问题和误区的。研究逻辑学的人经常遇到各种“不可判定”（undecidable）问题和所谓“悖论”（paradox），研究几十年也没搞清楚，而其实那些问题都是他们自己造出来的。你只需要把语言改一下，去掉一些不必要的功能，问题就没了。但逻辑学家们总喜欢跟你说，那是某天才老祖宗想出来的，多么多么的了不起啊，不能改！



    用一阶逻辑（first-order logic）这样的东西，你可以写出一些毫无意义的语句。逻辑老师们会告诉你，记住啦，这些是没有意义的，如果写出来这些东西，是你的问题！他们没有意识到，如果一个人可以用一个语言写出毫无意义的东西，那么这问题在于这个语言，而不在于这个人。一阶逻辑号称可以“表达所有数学”，结果事实却是，没有几个数学家真的可以用它表达很有用的知识。到后来，稍微明智一点的逻辑学家们开始研究这些老古董语言到底出了什么毛病，于是他们创造了Model Theory这样的理论。写出一些长篇大部头，用于“验证”这些逻辑语言的合理性。这些问题在我看来都是显而易见的，因为很多逻辑的语言根本就不是很好很有用的东西。去研究它们“为什么有毛病”，其实是白费力气。自己另外设计一个更好语言就完事了。



    在我看来，除了现代逻辑学的鼻祖Gottlob Frege理解了逻辑的精髓，其它逻辑学家基本都是照本宣科，一知半解。他们喜欢把简单的问题搞复杂，制造一些新名词，说得玄乎其玄灵丹妙药似的。如果你想了解逻辑学的精华，建议你看看Frege的文集。看了之后你也许会发现，Frege思想的精华，其实已经融入在几乎所有的程序语言里了。


编程是一门艺术


    从上面你也许已经明白了，普通程序员使用的编程语言，就算是C++这样毛病众多的语言，其实也已经比数学家使用的语言好很多。用数学的语言可以写出含糊复杂的证明，在期刊或者学术会议上蒙混过关，用程序语言写出来的代码却无法混过计算机这道严格的关卡。因为计算机不是人，它不会迷迷糊糊的点点头让你混过去，或者因为你是大师就不懂装懂。代码是需要经过现实的检验的。如果你的代码有问题，它迟早会导致出问题。



    计算机科学并不是数学的一个分支，它在很大程度上是优于数学，高于数学的。有些数学的基本理论可以被计算机科学所用，然而计算机科学并不是数学的一部分。数学在语言方面带有太多的历史遗留糟粕，它其实是泥菩萨过河，自身难保，它根本解决不了编程中遇到的实际问题。



    编程真的是一门艺术，因为它符合艺术的各种特征。艺术可以利用科学提供的工具，然而它却不是科学的一部分，它的地位也并不低于科学。和所有的艺术一样，编程能解决科学没法解决的问题，满足人们新的需求，开拓新的世界。所以亲爱的程序员们，别再为自己不懂很多数学而烦恼了。数学并不能帮助你写出好的程序，然而能写出好程序的人，却能更好的理解数学。我建议你们先学编程，再去看数学。



    如果你想了解更多关于数学语言的弊病以及程序语言对它们的改进，我建议你看看这个Gerald Susman的讲座。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 谈程序的正确性

 
 
 
 
    

    
 
     
  

      
   
谈程序的正确性

    不管在学术圈还是在工业界，总有很多人过度的关心所谓“程序的正确性”，有些甚至到了战战兢兢，舍本逐末的地步。下面举几个例子：




    很多人把测试（test）看得过于重要。代码八字还没一撇呢，就吵着要怎么怎么严格的测试，防止“将来”有人把代码改错了。这些人到后来往往被测试捆住了手脚，寸步难行。不但代码bug百出，连测试里面也很多bug。


    有些人对于“使用什么语言”这个问题过度的在乎，仿佛只有用最新最酷，功能最多的语言，他们才能完成一些很基本的任务。这种人一次又一次的视一些新语言为“灵丹妙药”，然后一次又一次的幻灭，最后他们什么有用的代码也没写出来。


    有些人过度的重视所谓“类型安全”（type safety），经常抱怨手头的语言缺少一些炫酷的类型系统功能，甚至因此说没法写代码了！他们没有看到，即使缺少一些由编译器静态保障的类型安全，代码其实一点问题都没有，而且也许更加简单。


    有些人走上极端，认为所有的代码都必须使用所谓“形式化方法”（formal methods），用机器定理证明的方式来确保它100%的没有错误。这种人对于证明玩具大小的代码乐此不疲，结果一辈子也没写出过能解决实际问题的代码。





    100%可靠的代码，这是多么完美的理想！可是到最后你发现，天天念叨着要“正确性”，“可靠性”的人，几乎总是眼高手低，说的比做的多。自己没写出什么解决实际问题的代码，倒是很喜欢对别人的“代码质量”评头论足。这些人自己的代码往往复杂不堪，喜欢使用各种看似高深的奇技淫巧，用以保证所谓“正确”。他们的代码被很多所谓“测试工具”和“类型系统”捆住手脚，却仍然bug百出。到后来你逐渐发现，对“正确性”的战战兢兢，其实是这些人不解决手头问题的借口。


衡量程序最重要的标准


    这些人其实不明白一个重要的道理：你得先写出程序，才能开始谈它的正确性。看一个程序好不好，最重要的标准，是看它能否有效地解决问题，而不是它是否正确。如果你的程序没有解决问题，或者解决了错误的问题，或者虽然解决问题但却非常难用，那么这程序再怎么正确，再怎么可靠，都不是好的程序。



    正确不等于简单，不等于优雅，不等于高效。一个不简单，不优雅，效率低的程序，就算你费尽周折证明了它的正确，它仍然不会很好的工作。这就像你得先有了房子，才能开始要求房子是安全的。想想吧，如果一个没有房子的流浪汉，路过一座没有人住的房子，他会因为这房子“不是100%安全”，而继续在野外风餐露宿吗？写出代码就像有了房子，而代码的正确性，就像房子的安全性。写出可以解决问题的程序，永远是第一位的。而这个程序的正确性，不管它如何的重要，永远是第二位的。对程序的正确性的强调，永远不应该高于写出程序本身。



    每当谈起这个问题，我就喜欢打一个比方：如果“黎曼猜想”被王垠证明出来了，它会改名叫“王垠定理”吗？当然不会。它会被叫做“黎曼定理”！这是因为，无论一个人多么聪明多么厉害，就算他能够证明出黎曼猜想，但这个猜想并不是他最先想出来的。如果黎曼没有提出这个猜想，你根本不会想到它，又何谈证明呢？所以我喜欢说，一流的数学家提出猜想，二流的数学家证明别人的猜想。同样的道理，写出解决问题的代码的人，比起那些去证明（测试）他的代码正确性的人，永远是更重要的。因为如果他没写出这段代码，你连要证明（测试）什么都不知道！


如何提高程序的正确性


    话说回来，虽然程序的正确性相对于解决问题，处于相对次要的地位，然而它确实是不可忽视的。但这并不等于天天鼓吹要“测试”，要“形式化证明”，就可以提高程序的正确性。



    如果你深入研究过程序的逻辑推导就会知道，测试和形式化证明的能力都是非常有限的。测试只能测试到最常用的情况，而无法覆盖所有的情况。别被所谓“测试覆盖”（test coverage）给欺骗了。一行代码被测试覆盖而没有出错，并不等于在那里不会出错。一行代码是否出错，取决于在它运行之前所经过的所有条件。这些条件的数量是组合爆炸关系，基本上没有测试能够覆盖所有这些前提条件。



    形式化方法对于非常简单直接的程序是有效的，然而一旦程序稍微大点，形式化方法就寸步难行。你也许没有想到，你可以用非常少的代码，写出Collatz Conjecture这样至今没人证明出来的数学猜想。实际使用中的代码，比这种数学猜想要复杂不知道多少倍。你要用形式化方法去证明所有的代码，基本上等于你永远也没法完成项目。



    那么提高程序正确性最有效的方法是什么呢？在我看来，最有效的方法莫过于对代码反复琢磨推敲，让它变得简单，直观，直到你一眼就可以看得出它不可能有问题。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 DRY原则的误区

 
 
 
 
    

    
 
     
  

      
   
DRY原则的误区

    很多编程的人，喜欢鼓吹各种各样的“原则”，比如KISS原则，DRY原则…… 总有人把这些所谓原则奉为教条或者秘方，以为兢兢业业地遵循这些，空喊几个口号，就可以写出好的代码。同时，他们对违反这些原则的人嗤之以鼻——你不知道，不遵循或者藐视这些原则，那么你就是菜鸟。所谓“DRY原则”（Don't Repeat Yourself，不要重复你自己）就是这些教条其中之一。盲目的迷信DRY原则，在实际的工程中带来了各种各样的问题，却经常被忽视。



    简言之，DRY原则鼓励对代码进行抽象，但是鼓励得过了头。DRY原则说，如果你发现重复的代码，就把它们提取出去做成一个“模板”或者“框架”。对于抽象我非常的在行，实际上程序语言专家做的许多研究，就是如何设计更好的抽象。然而我并不奉行所谓DRY原则，并不是尽一切可能避免“重复”。“避免重复”并不等于“抽象”。有时候适当的重复代码是有好处的，所以我有时候会故意的进行重复。


抽象与可读性的矛盾


    代码的“抽象”和它的“可读性”（直观性），其实是一对矛盾的关系。适度的抽象和避免重复是有好处的，它甚至可以提高代码的可读性，然而如果你尽“一切可能”从代码里提取模板，甚至把一些微不足道的“共同点”也提出来进行“共享”，它就开始有害了。这是因为，模板并不直接显示在“调用”它们的位置。提取出模板，往往会使得阅读代码时不能一目了然。如果由此带来的直观性损失超过了模板所带来的好处时，你就应该考虑避免抽象了。要知道，代码读的次数要比写的次数多很多。很多人为了一时的“写的快感”，过早的提取出不必要的模板，其实损失了读代码时的直观性。如果自己的代码连自己都不能一目了然，你就不能写出优雅的代码。



    举一个实际的例子。奉行DRY原则的人，往往喜欢提取类里面的“共同field”，把它们放进一个父类，然后让原来的类继承这个父类。比如，本来的代码可能是：


class A {
  int a;
  int x;
  int y;
}

class B {
  int a;
  int u;
  int v;
}



    奉行DRY原则的人喜欢把它改成这样：


class C {
  int a;
}

class A extends C {
  int x;
  int y;
}

class B extends C {
  int u;
  int v;
}



    后面这段代码有什么害处呢？它的问题是，当你看到class A和class B的定义时，你不再能一目了然的看到int a这个field。“可见性”，对于程序员能够产生直觉，是非常重要的。这种无关紧要的field，其实大部分时候都没必要提出去，造出一个新的父类。很多时候，不同类里面虽然有同样的int a这样的field，然而它们的含义却是完全不同的。有些人不管三七二十一就来个“DRY”，结果不但没带来好处，反而让程序难以理解。


抽象的时机问题


    奉行DRY原则的人还有一个问题，就是他们随时都在试图发现“将来可能重用”的代码，而不是等到真的出现重复的时候再去做抽象。很多时候他们提取出一个貌似“经典模板”，结果最后过了几个月发现，这个模板在所有代码里其实只用过一次。这就是因为他们过早的进行了抽象。



    抽象的思想，关键在于“发现两个东西是一样的”。然而很多时候，你开头觉得两个东西是一回事，结果最后发现，它们其实只是肤浅的相似，而本质完全不同。同一个int a，其实可以表示很多种风马牛不及的性质。你看到都是int a就提出来做个父类，其实反而让程序的概念变得混乱。还有的时候，有些东西开头貌似同类，后来你增添了新的逻辑之后，发现它们的用途开始特殊化，后来就分道扬镳了。过早的提取模板，反而捆住了你的手脚，使得你为了所谓“一致性”而重复一些没用的东西。这样的一致性，其实还不如针对每种情况分别做特殊处理。



    防止过早抽象的方法其实很简单，它的名字叫做“等待”。其实就算你不重用代码，真的不会死人的。时间能够告诉你一切。如果你发现自己仿佛正在重复以前写过代码，请先不要停下来，请坚持把这段重复的代码写完。如果你不把它写出来，你是不可能准确的发现重复的代码的，因为它们很有可能到最后其实是不一样的。



    你还应该避免没有实际效果的抽象。如果代码才重复了两次，你就开始提取模板，也许到最后你会发现，这个模板总共也就只用了两次！只重复了两次的代码，大部分时候是不值得为它提取模板的。因为模板本身也是代码，而且抽象思考本身是需要一定代价的。所以最后总的开销，也许还不如就让那两段重复的代码待在里面。



    这就是为什么我喜欢一种懒懒的，笨笨的感觉。因为我懒，所以我不会过早的思考代码的重用。我会等到事实证明重用一定会带来好处的时候，才会开始提取模板，进行抽象。经验告诉我，每一次积极地寻找抽象，最后的结果都是制造一些不必要的模板，搞得自己的代码自己都看不懂。很多人过度强调DRY，强调代码的“重用”，随时随地想着抽象，结果被这些抽象搅混了头脑，bug百出，寸步难行。如果你不能写出“可用”（usable）的代码，又何谈“可重用”（reusable）的代码呢？


谨慎的对待所谓原则


    说了这么多，我是在支持DRY，还是反对DRY呢？其实不管是支持还是反对它，都会表示我在乎它，而其实呢，我完全不在乎这类原则，因为它们非常的肤浅。这就像你告诉我说你有一个重大的发现，那就是“1+1=2”，我该支持你还是反对你呢？我才懒得跟你说话。人们写程序，本来自然而然就会在合适的时候进行抽象，避免重复，怎么过了几十年后，某个菜鸟给我们的做法起了个名字叫DRY，反而他成了“大师”一样的人物，我倒要用“DRY”这个词来描述我一直在干的事情呢？所以我根本不愿意提起“DRY”这个名字。



    所以我觉得这个DRY原则根本就不应该存在，它是一个根本没有资格提出“原则”的人提出来的。看看他鼓吹的其它低劣东西（比如Agile，Ruby），你就会发现，他是一个兜售减肥药的“软件工程专家”。世界上有太多这样的肤浅的所谓原则，我不想对它们一一进行评价，这是在浪费我的时间。世界上有比这些喜欢提出“原则”的软件工程专家深邃很多的人，他们懂得真正根本的原理。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 所谓软件工程

 
 
 
 
    

    
 
     
  

      
   
所谓软件工程

    很多编程的人包括我，头衔叫做“软件工程师”（software engineer），然而我却不喜欢这个名字。我喜欢把自己叫做“程序员”（programmer）或者“计算机科学家”（computer scientist）。这是为什么呢？这需要从“软件工程”（software engineering）在现实中的涵义谈起。



    有人把软件工程这个领域的本质总结为：“How to program if you cannot？”（如果你不会编程，那么你如何编程？）我觉得这句话说得很好，因为我发现软件工程这整个领域，基本就是吹牛扯淡卖“减肥药”的。软件行业的大部分莫名其妙的愚昧行为，很多是由所谓“软件工程专家”发明的。总有人提出一套套的所谓“方法论”或者“原则”，比如Extreme Programming，Design Patterns，Agile，Pair Programming，Test Driven Development（TDD），DRY principle，…… 他们把这些所谓方法论兜售给各个软件公司，鼓吹它们的各种好处，说使用这些方法，就可以用一些平庸的“软件工程师”，制造出高质量低成本的软件。这就跟减肥药的广告一样：不用运动，不用节食，一个星期瘦20斤。你开头还不以为然，觉得这些肤浅的说法能造成什么影响。结果久而久之，这些所谓“方法论”和“原则”成为了整个行业的教条，造成了文化大革命一样的风气。违反这些教条的人，必然被当成菜鸟一样的鄙视，当成小学生一样的教育，当成“反革命”一样的批斗。就算你技术比这些教条的提出者还高明不知道多少倍也一样。



    打破这些软件工程专家们制造的幻觉的一个办法，就是实地去看看这些所谓专家们自己用这些方法论做出了什么好东西。你会惊奇的发现，这些提出各种玄乎其玄的新名词的所谓“专家”，几乎都是从不知道什么旮旯里冒出来的民科，没有一个做出过什么有技术含量的东西，他们根本没有资格对别人编程的方式做出指导。这些人做出来少数有点用的东西（比如JUnit），其实非常容易，以至于每个初学编程的人都应该做得出来。可世界上就是有这样划算的职业，你虽然写不出好的代码，你对计算原理的理解非常肤浅，却可以通过一些手段，得到评价别人的“代码质量”的权力，占据软件公司的管理层位置。久而久之，别人还以为你是什么泰斗。你仔细看过提出Java Design Pattern的四个人（GoF），到底做出过什么厉害的东西吗？没有。提出“DRY Principle”的作者，做出过什么好东西吗？没有。再看看Agile，Pair Programming，TDD……的提出者？全都是一群饭桶。他们其实根本就不懂很多编程的东西，写出文章和书来也是极其肤浅，一知半解。



    所谓“软件工程”，并不像土木工程，机械工程，电机工程，是建立在实际的，科学的基础上的。跟这些“硬工程”不一样，软件弄得不好不会出人命，也不会跟做芯片的公司那样，出一个bug立即导致上亿的损失，身败名裂。所以研究软件工程，似乎特别容易钻空子，失败了之后容易找借口和替罪羊。如果你说我的方法不好，你有什么证据吗？口说无凭，我浪费了你多少时间呢？你的具体执行是不是完全照我说的来的呢？你肯定有什么细节没按我说的做，所以才会失败。总之，如果你用了我的办法不管用，那是你自己的问题！



    想起这些借口我就想起一个笑话：两夫妻睡觉发现床上有跳蚤，身上被咬了好多大包。去买了号称“杀伤率100%”的跳蚤药，撒了好多在床上。第二天早上起来，发现又被咬了好多新的大包。妻子责怪丈夫，说他没看说明书就乱撒。结果丈夫打开说明书一看，内容如下：



    本跳蚤药使用方法：



抓住跳蚤
掰开跳蚤的嘴
把药塞进跳蚤嘴里
合上跳蚤的嘴




    我发现很多软件工程的所谓方法论失败之后的借口，跟这跳蚤药的说明书很像 :)



    人都想省钱，雇用高质量的程序员不容易呀，所以很多公司还是上钩了。他们请这些“软件工程专家”来到公司，推行各种各样的软件方法论，可是发现最后都失败了。这是为什么呢？因为再高明的方法论，也无法代替真正的，精华的计算机科学教育。直到今天还有很多公司推行所谓的Agile，煞有介事的搞一些stand-up meeting, scrum之类的形式主义东西，以为这些过家家似的做法就能提高开发质量和效率。很多开发人员也很把一些软件工程的工具当回事，喜欢折腾Git，Maven等工具一些偏僻的“新功能”。他们很在乎所谓的版本控制，测试等东西，以为熟练的掌握这些就能开发出高质量，可靠的代码。可是你最后发现，无论你如何高效的使用这些工具，它们都只能起到辅助的，次要的作用。编程工具永远不是程序本身，对编程工具的熟练掌握，永远也无法代替真正的对程序和计算的理解。过分强调这些工具的使用，是本末倒置的，让工程走上失败道路的作法。



    编程真的是一门艺术，它完全符合艺术的各种特征，编程界也充满了艺术界的独有特征。有些初学艺术的人（比如10年前的我），总是挑剔手上的工具，非要用最新最炫的工具，用它们最偏僻最难用的“特性”，才觉得自己能够做出优秀的作品。很多人照不出好的照片，就怪相机不好。买了几万块钱的笨重高档相机，照出来的照片还不如别人用手机照的。这些人不明白，好的摄影师和不好的摄影师，区别在于眼睛，而不是相机。一个真正的艺术家，可以用任何在手上的工具创造出色的作品。有些甚至可以用一些废品垃圾，拙劣的工具，做出杰出的，别具风味的艺术品。因为艺术存在于人的心里，而不在他们使用的工具里面。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 编程的宗派

 
 
 
 
    

    
 
     
  

      
   
编程的宗派

    总是有人喜欢争论这类问题，到底是“函数式编程”（FP）好，还是“面向对象编程”（OOP）好。既然出了两个帮派，就有人积极地做它们的帮众，互相唾骂和鄙视。然后呢又出了一个“好好先生帮”，这个帮的人喜欢说，管它什么范式呢，能解决问题的工具就是好工具！我个人其实不属于这三帮人中的任何一个。


面向对象编程（Object-Oriented Programming）


    如果你看透了表面现象就会发现，其实“面向对象编程”本身没有引入很多新东西。所谓“面向对象语言”，其实就是经典的“过程式语言”（比如Pascal），加上一点抽象能力。所谓“类”和“对象”，基本是过程式语言里面的记录（record，或者叫结构，structure），它本质其实是一个从名字到数据的“映射表”（map）。你可以用名字从这个表里面提取相应的数据。比如point.x，就是用名字x从记录point里面提取相应的数据。这比起数组来是一件很方便的事情，因为你不需要记住存放数据的下标。即使你插入了新的数据成员，仍然可以用原来的名字来访问已有的数据，而不用担心下标错位的问题。



    所谓“对象思想”（区别于“面向对象”），实际上就是对这种数据访问方式的进一步抽象。一个经典的例子就是平面点的数据结构。如果你把一个点存储为：


struct Point {
  double x;
  double y;
}



    那么你用point.x和point.y可以直接访问它的X和Y坐标。但你也可以把它存储为“极坐标”方式：


struct Point {
  double r;
  double angle;
}



    这样你可以用point.r和point.angle访问它的模和角度。可是现在问题来了，如果你的代码开头把Point定义为第一种XY的方式，使用point.x, point.y访问X和Y坐标，可是后来你决定改变Point的存储方式，用极坐标，你却不想修改已有的含有point.x和point.y的代码，怎么办呢？



    这就是“对象思想”的价值，它让你可以通过“间接”（indirection，或者叫做“抽象”）来改变point.x和point.y的语义，从而让使用者的代码完全不用修改。虽然你的实际数据结构里面根本没有x和y这两个成员，但由于.x和.y可以被重新定义，所以你可以通过改变.x和.y的定义来“模拟”它们。在你使用point.x和point.y的时候，系统内部其实在运行两片代码，它们的作用是从r和angle计算出x和y的值。这样你的代码就感觉x和y是实际存在的成员一样，而其实它们是被临时算出来的。在Python之类的语言里面，你可以通过定义“property”来直接改变point.x和point.y的语义。在Java里稍微麻烦一些，你需要使用point.getX()和point.getY()这样的写法。然而它们最后的目的其实都是一样的——它们为数据访问提供了一层“间接”（抽象）。



    这种抽象有时候是个好主意，它甚至可以跟量子力学的所谓“不可观测性”扯上关系。你觉得这个原子里面有10个电子？也许它们只是像point.x给你的幻觉一样，也许宇宙里根本就没有电子这种东西，也许你每次看到所谓的电子，它都是临时生成出来逗你玩的呢？然而，对象思想的价值也就到此为止了。你见过的所谓“面向对象思想”，几乎无一例外可以从这个想法推广出来。面向对象语言的绝大部分特性，其实是过程式语言早就提供的。因此我觉得，其实没有语言可以叫做“面向对象语言”。就像一个人为一个公司贡献了一点点代码，并不足以让公司以他的名字命名一样。



    “对象思想”作为数据访问的方式，是有一定好处的。然而“面向对象”（多了“面向”两个字），就是把这种本来良好的思想东拉西扯，牵强附会，发挥过了头。很多面向对象语言号称“所有东西都是对象”（Everything is an Object），把所有函数都放进所谓对象里面，叫做“方法”（method），把普通的函数叫做“静态方法”（static method）。实际上呢，就像我之前的例子，只有极少需要抽象的时候，你需要使用内嵌于对象之内，跟数据紧密结合的“方法”。其他的时候，你其实只是想表达数据之间的变换操作，这些完全可以用普通的函数表达，而且这样做更加简单和直接。这种把所有函数放进方法的做法是本末倒置的，因为函数其实并不属于对象。绝大部分函数是独立于对象的，它们不能被叫做“方法”。强制把所有函数放进它们本来不属于的对象里面，把它们全都作为“方法”，导致了面向对象代码逻辑过度复杂。很简单的想法，非得绕好多道弯子才能表达清楚。很多时候这就像把自己的头塞进屁股里面。



    这就是为什么我喜欢开玩笑说，面向对象编程就像“地平说”（Flat Earth Theory）。当然你可以说地球是一个平面。对于局部的，小规模的现象，它没有问题。然而对于通用的，大规模的情况，它却不是自然，简单和直接的。直到今天，你仍然可以无止境的寻找证据，扭曲各种物理定律，自圆其说地平说的幻觉，然而这会让你的理论非常复杂，经常需要缝缝补补还难以理解。



    面向对象语言不仅有自身的根本性错误，而且由于面向对象语言的设计者们常常是半路出家，没有受到过严格的语言理论和设计训练却又自命不凡，所以经常搞出另外一些奇葩的东西。比如在JavaScript里面，每个函数同时又可以作为构造函数（constructor），所以每个函数里面都隐含了一个this变量，你嵌套多层对象和函数的时候就发现没法访问外层的this，非得bind一下。Python的变量定义和赋值不分，所以你需要访问全局变量的时候得用global关键字，后来又发现如果要访问“中间层”的变量，没有办法了，所以又加了个nonlocal关键字。Ruby先后出现过四种类似lambda的东西，每个都有自己的怪癖…… 有些人问我为什么有些语言设计成那个样子，我只能说，很多语言设计者其实根本不知道自己在干什么！



    软件领域就是喜欢制造宗派。“面向对象”当年就是乘火打劫，扯着各种幌子，成为了一种宗派，给很多人洗了脑。到底什么样的语言才算是“面向对象语言”？这样基本的问题至今没有确切的答案，足以说明所谓面向对象，基本都是扯淡。每当你指出某个OO语言X的弊端，就会有人跟你说，其实X不是“地道的”OO语言，你应该去看看另外一个OO语言Y。等你发现Y也有问题，有人又会让你去看Z…… 直到最后，他们告诉你，只有Smalltalk才是地道的OO语言。这不是很搞笑吗，说一个根本没人用的语言才是地道的OO语言，这就像在说只有死人的话才是对的。这就像是一群政客在踢皮球，推卸责任。等你真正看看Smalltalk才发现，其实面向对象语言的根本毛病就是由它而来的，Smalltalk并不是很好的语言。很多人至今不知道自己所用的“面向对象语言”里面的很多优点，都是从过程式语言继承来的。每当发生函数式与面向对象式语言的口水战，都会有面向对象的帮众拿出这些过程式语言早就有的优点来进行反驳：“你说面向对象不好，看它能做这个……” 拿别人的优点撑起自己的门面，却看不到事物实质的优点，这样的辩论纯粹是鸡同鸭讲。


函数式编程（Functional Programming）


    函数式语言一直以来比较低调，直到最近由于并发计算编程瓶颈的出现，以及Haskell，Scala之类语言社区的大力鼓吹，它忽然变成了一种宗派。有人盲目的相信函数式编程能够奇迹般的解决并发计算的难题，而看不到实质存在的，独立于语言的问题。被函数式语言洗脑的帮众，喜欢否定其它语言的一切，看低其它程序员。特别是有些初学编程的人，俨然把函数式编程当成了一天瘦二十斤的减肥神药，以为自己从函数式语言入手，就可以对经验超过他十年以上的老程序员说三道四，仿佛别人不用函数式语言就什么都不懂一样。


函数式编程的优点


    函数式编程当然提供了它自己的价值。函数式编程相对于面向对象最大的价值，莫过于对于函数的正确理解。在函数式语言里面，函数是“一类公民”（first-class）。它们可以像1, 2, "hello"，true，对象…… 之类的“值”一样，在任意位置诞生，通过变量，参数和数据结构传递到其它地方，可以在任何位置被调用。这些是很多过程式语言和面向对象语言做不到的事情。很多所谓“面向对象设计模式”（design pattern），都是因为面向对象语言没有first-class function，所以导致了每个函数必须被包在一个对象里面才能传递到其它地方。



    函数式编程的另一个贡献，是它们的类型系统。函数式语言对于类型的思维，往往非常的严密。函数式语言的类型系统，往往比面向对象语言来得严密和简单很多，它们可以帮助你对程序进行严密的逻辑推理。然而类型系统一是把双刃剑，如果你对它看得太重，它反而会带来不必要的复杂性和过度工程。这个我在下面讲讲。


各种“白象”（white elephant）


    所谓白象，“white elephant”，是指被人奉为神圣，价格昂贵，却没有实际用处的东西。函数式语言里面有很好的东西，然而它们里面有很多多余的特性，这些特性跟白象的性质类似。



    函数式语言的“拥护者”们，往往认为这个世界本来应该是“纯”（pure）的，不应该有任何“副作用”。他们把一切的“赋值操作”看成低级弱智的作法。他们很在乎所谓尾递归，类型推导，fold，currying，maybe type等等。他们以自己能写出使用这些特性的代码为豪。可是殊不知，那些东西其实除了能自我安慰，制造高人一等的幻觉，并不一定能带来真正优秀可靠的代码。


纯函数


    半壶水都喜欢响叮当。很多喜欢自吹为“函数式程序员”的人，往往并不真的理解函数式语言的本质。他们一旦看到过程式语言的写法就嗤之以鼻。比如以下这个C函数：


int f(int x) {
    int y = 0;
    int z = 0;
    y = 2 * x;
    z = y + 1;
    return z / 3;
}



    很多函数式程序员可能看到那几个赋值操作就皱起眉头，然而他们看不到的是，这是一个真正意义上的“纯函数”，它在本质上跟Haskell之类语言的函数是一样的，也许还更加优雅一些。



    盲目鄙视赋值操作的人，也不理解“数据流”的概念。其实不管是对局部变量赋值还是把它们作为参数传递，其实本质上都像是把一个东西放进一个管道，或者把一个电信号放在一根导线上，只不过这个管道或者导线，在不同的语言范式里放置的方向和样式有一点不同而已！


对数据结构的忽视


    函数式语言的帮众没有看清楚的另一个重要的，致命的东西，是数据结构的根本性和重要性。数据结构的有些问题是“物理”和“本质”地存在的，不是换个语言或者换个风格就可以奇迹般消失掉的。函数式语言的拥护者们喜欢盲目的相信和使用列表（list），而没有看清楚它的本质以及它所带来的时间复杂度。列表带来的问题，不仅仅是编程的复杂性。不管你怎么聪明的使用它，很多性能问题是根本没法解决的，因为列表的拓扑结构根本就不适合用来干有些事情！



    从数据结构的角度看，Lisp所谓的list就是一个单向链表。你必须从上一个节点才能访问下一个，而这每一次“间接寻址”，都是需要时间的。在这种数据结构下，很简单的像length或者append之类函数，时间复杂度都是O(n)！为了绕过这数据结构的不足，所谓的“Lisp风格”告诉你，不要反复append，因为那样复杂度是O(n2)。如果需要反复把元素加到列表末尾，那么应该先反复cons，然后再reverse一下。很可惜的是，当你同时有递归调用，就会发现cons+reverse的做法颠来倒去的，非常容易出错。有时候列表是正的，有时候是反的，有时候一部分是反的…… 这种方式用一次还可以，多几层递归之后，自己都把自己搞糊涂了。好不容易做对了，下次修改可能又会出错。然而就是有人喜欢显示自己聪明，喜欢自虐，迎着这类人为制造的“困难”勇往直前 :)



    富有讽刺意味的是，半壶水的Lisp程序员都喜欢用list，真正深邃的Lisp大师级人物，却知道什么时候应该使用记录（结构）或者数组。在Indiana大学，我曾经上过一门Scheme（一种现代Lisp方言）编译器的课程，授课的老师是R. Kent Dybvig，他是世界上最先进的Scheme编译器Chez Scheme的作者。我们的课程编译器的数据结构（包括AST）都是用list表示的。期末的时候，Kent对我们说：“你们的编译器已经可以生成跟我的Chez Scheme媲美的代码，然而Chez Scheme不止生成高效的目标代码，它的编译速度是你们的700倍以上。它可以在5秒钟之内编译它自己！” 然后他透露了一点Chez Scheme速度之快的原因。其中一个原因，就是因为Chez Scheme的内部数据结构根本不是list。在编译一开头的时候，Chez Scheme就已经把输入的代码转换成了数组一样的，固定长度的结构。后来在工业界的经验教训也告诉了我，数组比起链表，确实在某些时候有大幅度的性能提升。在什么时候该用链表，什么时候该用数组，是一门艺术。


副作用的根本价值


    对数据结构的忽视，跟纯函数式语言盲目排斥副作用的“教义”有很大关系。过度的使用副作用当然是有害的，然而副作用这种东西，其实是根本的，有用的。对于这一点，我喜欢跟人这样讲：在计算机和电子线路最开头发明的时候，所有的线路都是“纯”的，因为逻辑门和导线没有任何记忆数据的能力。后来有人发明了触发器（flip-flop），才有了所谓“副作用”。是副作用让我们可以存储中间数据，从而不需要把所有数据都通过不同的导线传输到需要的地方。没有副作用的语言，就像一个没有无线电，没有光的世界，所有的数据都必须通过实在的导线传递，这许多纷繁的电缆，必须被正确的连接和组织，才能达到需要的效果。我们为什么喜欢WiFi，4G网，Bluetooth，这也就是为什么一个语言不应该是“纯”的。



    副作用也是某些重要的数据结构的重要组成元素。其中一个例子是哈希表。纯函数语言的拥护者喜欢盲目的排斥哈希表的价值，说自己可以用纯的树结构来达到一样的效果。然而事实却是，这些纯的数据结构是不可能达到有副作用的数据结构的性能的。所谓纯函数数据结构，因为在每一次“修改”时都需要保留旧的结构，所以往往需要大量的拷贝数据，然后依赖垃圾回收（GC）去消灭这些旧的数据。要知道，内存的分配和释放都是需要时间和能量的。盲目的依赖GC，导致了纯函数数据结构内存分配和释放过于频繁，无法达到有副作用数据结构的性能。要知道，副作用是电子线路和物理支持的高级功能。盲目的相信和使用纯函数写法，其实是在浪费已有的物理支持的操作。


fold以及其他


    大量使用fold和currying的代码，写起来貌似很酷，读起来却不必要的痛苦。很多人根本不明白fold的本质，却老喜欢用它，因为他们觉得那是函数式编程的“精华”，可以显示自己的聪明。然而他们没有看到的是，其实fold包含的，只不过是在列表（list）上做递归的“通用模板”，这个模板需要你填进去三个参数，就可以生成一个新的递归函数调用。所以每一个fold的调用，本质上都包含了一个在列表上的递归函数定义。fold的问题在于，它定义了一个递归函数，却没有给它一个一目了然的名字。使用fold的结果是，每次看到一个fold调用，你都需要重新读懂它的定义，琢磨它到底是干什么的。而且fold调用只显示了递归模板需要的部分，而把递归的主体隐藏在了fold本身的“框架”里。比起直接写出整个递归定义，这种遮遮掩掩的做法，其实是更难理解的。比如，当你看到这句Haskell代码：


foldr (+) 0 [1,2,3]



    你知道它是做什么的吗？也许你一秒钟之后就凭经验琢磨出，它是在对[1,2,3]里的数字进行求和，本质上相当于sum [1,2,3]。虽然只花了一秒钟，可你仍然需要琢磨。如果fold里面带有更复杂的函数，而不是+，那么你可能一分钟都琢磨不透。写起来倒没有费很大力气，可为什么我每次读这段代码，都需要看到+和0这两个跟自己的意图毫无关系的东西？万一有人不小心写错了，那里其实不是+和0怎么办？为什么我需要搞清楚+, 0, [1,2,3]的相对位置以及它们的含义？这样的写法其实还不如老老实实写一个递归函数，给它一个有意义名字（比如sum），这样以后看到这个名字被调用，比如sum [1,2,3]，你想都不用想就知道它要干什么。定义sum这样的名字虽然稍微增加了写代码时的工作，却给读代码的时候带来了方便。为了写的时候简洁或者很酷而用fold，其实增加了读代码时的脑力开销。要知道代码被读的次数，要比被写的次数多很多，所以使用fold往往是得不偿失的。然而，被函数式编程洗脑的人，却看不到这一点。他们太在乎显示给别人看，我也会用fold！



    与fold类似的白象，还有currying，Hindley-Milner类型推导等特性。看似很酷，但等你仔细推敲才发现，它们带来的麻烦，比它们解决的问题其实还要多。有些特性声称解决的问题，其实根本就不存在。现在我把一些函数式语言的特性，以及它们包含的陷阱简要列举一下：



fold。fold等“递归模板”，相当于把递归函数定义插入到调用的敌方，而不给它们名字。这样导致每次读代码都需要理解几乎整个递归函数的定义。

    currying。貌似很酷，可是被部分调用的参数只能从左到右，依次进行。如何安排参数的顺序成了问题。大部分时候还不如直接制造一个新的lambda，在内部调用旧的函数，这样可以任意的安排参数顺序。


    Hindley-Milner类型推导。为了避免写参数和返回值的类型，结果给程序员写代码增加了很多的限制。为了让类型推导引擎开心，导致了很多完全合法合理优雅的代码无法写出来。其实还不如直接要程序员写出参数和返回值的类型，这工作量真的不多，而且可以准确的帮助阅读者理解参数的范围。HM类型推导的根本问题其实在于它使用unification算法。Unification其实只能表示数学里的“等价关系”（equivalence relation），而程序语言最重要的关系，subtyping，并不是一个等价关系，因为它不具有对称性（symmetry）。


    代数数据类型（algebraic data type）。所谓“代数数据类型”，其实并不如普通的类型系统（比如Java的）通用。很多代数数据类型系统具有所谓sum type，这种类型其实带来过多的类型嵌套，不如通用的union type。盲目崇拜代数数据类型的人，往往是因为盲目的相信“数学是优美的语言”。而其实事实是，数学是一种历史遗留的，毛病很多的语言。数学的语言根本没有经过系统的，全球协作的设计。往往是数学家在黑板上随便写个符号，说这个表示XX概念，然后就定下来了。


    Tuple。有代数数据类型的的语言里面经常有一种构造叫做Tuple，比如Haskell里面可以写(1, "hello")，表示一个类型为(Int, String)的结构。这种构造经常被人看得过于高尚，以至于用在超越它能力的地方。其实Tuple就是一个没有名字的结构（类似C的structure），而且结构里面的域也没有名字。临时使用Tuple貌似很方便，因为不需要定义一个结构类型。然而因为Tuple没有名字，而且里面的域没法用名字访问，一旦里面的数据多一点就发现很麻烦了。Tuple往往只能通过模式匹配来获得里面的域，一旦你增加了新的域进去，所有含有这个Tuple的模式匹配代码都需要改。所以Tuple一般只能用在大小不超过3的情况下，而且必须确信以后不会增加新的域进去。


    惰性求值（lazy evaluation）。貌似数学上很优雅，但其实有严重的逻辑漏洞。因为bottom（死循环）成为了任何类型的一个元素，所以取每一个值，都可能导致死循环。同时导致代码性能难以预测，因为求值太懒，所以可能临时抱佛脚做太多工作，而平时浪费CPU的时间。由于到需要的时候才求值，所以在有多个处理器的时候无法有效地利用它们的计算能力。


    尾递归。大部分尾递归都相当于循环语句，然而却不像循环语句一样具有一目了然的意图。你需要仔细看代码的各个分支的返回条件，判断是否有分支是尾递归，然后才能判断这代码是个循环。而循环语句从关键字（for，while）就知道是一个循环。所以等价于循环的尾递归，其实最好还是写成特殊的循环语句。当然，尾递归在另一些情况下是有用的，这些情况不等价于循环。在这种情况下使用循环，经常需要复杂的break或者continue条件，导致循环不易理解。所以循环和尾递归，其实都是有必要的。




好好先生


    很多人避免“函数式vs面向对象”的辩论，于是他们成为了“好好先生”。这种人没有原则的认为，任何能够解决当前问题的工具就是好工具。也就是这种人，喜欢使用shell script，喜欢折腾各种Unix工具，因为显然，它们能解决他“手头的问题”。



    然而这种思潮是极其有害的，它的害处其实更胜于投靠函数式或者面向对象。没有原则的好好先生们忙着“解决问题”，却不能清晰地看到这些问题为什么存在。他们所谓的问题，往往是由于现有工具的设计失误。由于他们的“随和”，他们从来不去思考，如何从根源上消灭这些问题。他们在一堆历史遗留的垃圾上缝缝补补，妄图使用设计恶劣的工具建造可靠地软件系统。当然，这代价是非常大的。不但劳神费力，而且也许根本不能解决问题。



    所以每当有人让我谈谈“函数式vs面向对象”，我都避免说“各有各的好处”，因为那样的话我会很容易被当成这种毫无原则的好好先生。


符号必须简单的对世界建模


    从上面你已经看出，我既不是一个铁杆“函数式程序员”，也不是一个铁杆“面向对象程序员”，我也不是一个爱说“各有各的好处”的好好先生。我是一个有原则的批判性思维者。我不但看透了各种语言的本质，而且看透了它们之间的统一关系。我编程的时候看到的不是表面的语言和程序，而是一个类似电路的东西。我看到数据的流动和交换，我看到效率的瓶颈，而这些都是跟具体的语言和范式无关的。



    在我的心目中其实只有一个概念，它叫做“编程”（programming），它不带有任何附加的限定词（比如“函数式”或者“面向对象”）。我的老师Dan Friedman喜欢把自己的领域称为“Programming Languages”，也是一样的原因。因为我们研究的内容，不局限于某一个语言，也不局限于某一类语言，而是所有的语言。在我们的眼里，所有的语言都不过是各个特性的组合。在我们的眼里，最近出现的所谓“新语言”，其实不大可能再有什么真正意义上的创新。我们不喜欢说“发明一个程序语言”，不喜欢使用“发明”这个词，因为不管你怎么设计一个语言，所有的特性几乎都早已存在于现有的语言里面了。我更喜欢使用“设计”这个词，因为虽然一个语言没有任何新的特性，它却有可能在细节上更加优雅。



    编程最重要的事情，其实是让写出来的符号，能够简单地对实际或者想象出来的“世界”进行建模。一个程序员最重要的能力，是直觉地看见符号和现实物体之间的对应关系。不管看起来多么酷的语言或者范式，如果必须绕着弯子才能表达程序员心目中的模型，那么它就不是一个很好的语言或者范式。有些东西本来就是有随时间变化的“状态”的，如果你偏要用“纯函数式”语言去描述它，当然你就进入了那些monad之类的死胡同。最后你不但没能高效的表达这种副作用，而且让代码变得比过程式语言还要难以理解。如果你进入另一个极端，一定要用对象来表达本来很纯的数学函数，那么你一样会把简单的问题搞复杂。Java的所谓design pattern，很多就是制造这种问题的，而没有解决任何问题。



    关于建模的另外一个问题是，你心里想的模型，并不一定是最好的，也不一定非得设计成那个样子。有些人心里没有一个清晰简单的模型，觉得某些语言“好用”，就因为它们能够对他那种扭曲纷繁的模型进行建模。所以你就跟这种人说不清楚，为什么这个语言不好，因为显然这个语言对他是有用的！如何简化模型，已经超越了语言的范畴，在这里我就不细讲了。



    我设计Yin语言的宗旨，就是让人们可以用最简单，最直接的方式来对世界进行建模，并且帮助他们优化和改进模型本身。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 智商的圈套

 
 
 
 
    

    
 
     
  

      
   
智商的圈套

    上次买了个任天堂3DS游戏机，觉得里面的游戏很无聊，所以第二天就把游戏机连同游戏一起，转手倒卖给了别人。从那天之后，我开始琢磨一个问题——到底是什么让我觉得一个游戏好玩或者不好玩。我似乎对事物有一种很特别的品味，很多别人说“好玩”，“有趣”的游戏或者电影，我一看就觉得很无趣，或者很自虐。我一生中玩过最好玩的游戏，其实没有几个，可能掰着手指头都数得出来：Braid，Limbo，Klonoa（風のクロノア door to phantomile），《纪念碑谷》，Metal Gear Solid，……



    



    如果你觉得我智商太高，所以才觉得很多游戏没有挑战性，不好玩，那么你其实并不了解我。我并不是一个“智商达人”，我不追求挑战性。我觉得很多游戏缺乏的不是挑战性和“难度”，而是设计的巧妙。很多游戏我根本没法玩过关，却只是觉得呆板，繁琐，老套，公式化。我并不会因为游戏玩不过关，作业做不出来，或者书看不懂而沮丧。恰恰相反，我认为我的智力根本就不应该是用来干这些事情的。如果有事情让我觉得沮丧，我一般都认为是这个事情有问题，而不是我有问题。如果说我也有错的话，那么我的错误就在于选择了参与这项活动，我根本不应该做这件事情。这就是为什么我大部分时候都比一般人开心。



    我觉得很多人有一种奇怪的倾向，他们喜欢挑战或者彰显自己的智商。每当我向人推荐类似Braid的游戏，他们就会认为我喜欢“解谜题”，于是他们给我推荐类似Zelda或者Antichamber之类的游戏，告诉我它们很考智力。可是这样的游戏，我一般玩不到几分钟就开始觉得无聊。这说明我并不是喜欢“解谜题”，而是因为另外一些特征而喜欢某些游戏。喜欢玩Zelda，Antichamber，或者《生化危机》一类游戏的人，往往有一种自虐倾向。这种人似乎很在乎自己的智商，所以游戏玩了不久之后，就会被“套牢”。他们会认为能够把某个游戏打通关，是对自己智商的认可。如果你跟他说这游戏太难太麻烦，他就会开始鄙视你的智力，吹嘘自己只花了多么短的时间就玩通关了。



    然而如果你退后一步，就会发现这些游戏，其实都存在某种“设计公式”。一旦掌握了这些公式，你就可以轻而易举地制造出这样的游戏。然后你就会发现，热衷于这些游戏的人，其实并不聪明，因为他们被游戏的设计者玩弄于鼓掌之中，而没能发现其中的设计公式。这些人为了得到别人的认可，检验或者训练所谓的“智力”，甚至为了“合群”，选择了这类只能叫做“自虐型”的游戏。



    这种游戏玩到后来，你就会发现这不是在娱乐，而是在完成任务，不是你在玩游戏，而是游戏在玩你。你盼望它早点结束，但却无法立即罢手，因为你对自己说：“如果现在半途而废，我就是一个懦夫，一个笨蛋，就不再是一个天才……” 你在虚拟的空间中来回的游走，摸索和寻找那些能打开机关的“钥匙”，而它们被游戏的设计者故意放在一些让人恼火的地方。你感觉到的不是快乐，而是繁琐，沮丧和空虚。



    我发现容易落入这种圈套的人，他们在日常生活和工作中也容易出现类似的倾向。总的说来，这种人正如卓别林的《大独裁者》最后的演讲所描述的，“想得太多，感觉太少”（think too much, feel too little）。这种人如果沿着这条道路发展下去，就会变成像机器一样思考的人。正是这种人，给世界带来了灾难。希特勒就是这样一种人的典型代表，他太在乎自己是否优秀和聪明，却感觉不到人间的爱和痛苦，所以他对自己认为是劣等民族的人进行残酷的屠杀。



    所以，我其实并不是因为智力上的挑战性而喜欢Braid，Limbo，Klonoa等游戏。我喜欢它们，是因为它们充满了创意和想象力，却又不让人觉得繁琐和累赘。在这样的游戏里，你能做一些你从前根本没想到过的事情，它们的设计可以用“妙不可言”来形容。这种游戏的逻辑很连贯流畅，你不需要到处瞎撞，来回跑动，而是一气呵成，行云流水，却又不乏波澜起伏和机智巧妙之处。这就像自己在演出一场出神入化的电影。你感觉到的不是沮丧，迷茫，不是对自己智力的考验和评价，而是真正的愉悦和解脱。



    当我推荐Klonoa给一个朋友的时候，我说：“玩这个游戏就感觉是在梦里……” 结果他对我说：“你知道另外一个叫什么什么的游戏里面，也有个四维空间吗？……” 其实我根本不是在跟他讨论“梦是什么”这种学术问题，而是在说“梦幻的感觉”。这位朋友就属于我前面提到的，“想得太多”的类型。我说像是在梦里，说的是一种感觉，只有心才看得见；而他所理解的“梦”，是一种很理论的东西，就像数学里的多维空间，需要用脑才分析得出来。由于过度理性，他总是忙于分析一些“深层次”的理论，而看不见我能轻松感觉到的乐趣。我对他的建议是：少想一点，少分析一点，多用心感觉。只有用心去体会，你才会理解，Klonoa这样的游戏的价值，其实不在于智力和难度，而在于它让你感觉到的梦幻，创意，自由，想象力，和艺术。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 我为什么不再公开开发Yin语言

 
 
 
 
    

    
 
     
  

      
   
我为什么不再公开开发Yin语言

    有些人可能知道我在设计一个程序语言，叫做Yin语言。最开头宣布要做这个语言的时候，很多人热血沸腾，可是过了不久，我发现自己很不喜欢这样的气氛，越来越厌倦跟人讨论，所以后来悄悄地丢掉这些人，淡出了。我现在想告诉你我是怎么想的。



    我从来没有想让Yin语言流行起来。我对程序语言的认识，其实超乎所有人的想象。我默默地看着各种新语言扯着各种幌子进行推广，可是它们的设计没有吸取历史教训，所以继续犯一些古老的错误，或者犯一些我根本不会犯的新错误，或者解决一些根本不需要解决的问题。其实程序语言已经不缺很多新的功能了，这些语言缺少的不是功能，而是简单和优雅。要达到简单和优雅，必须要有品位，而品位就像一个艺术家的心，是非常难得到的。没有经过Indiana式教育的人，是几乎不可能达到这种品位的。就算Friedman培养出来的那么多学生，也极少有人可以达到我这种地步。



    我清楚的知道，其它语言设计者是完全没法达到我的一些精华思想的。我其实很懒，我希望有其他人做出我设想的语言，这样我就不需要亲自动手了，然而至今没有发现任何人可以做到，甚至根本没有想到。这些想法，早在多年前就已经被我在多个原型中实现过，所以具体做起来不会是问题。在我的心目中，Yin语言就像原子弹的技术。我不想搞核扩散，我并不想让所有人都得到它。我曾经觉得应该把它与全世界分享，后来我发现，你越是愿意分享，别人越是不拿你的东西当回事。我觉得这个世界不配拥有这样的语言，因为人类是那么的愚蠢。最可怕的是，很多人根本不知道自己其实很愚蠢。在资本主义这种奖励贪婪人的制度下，Yin语言被所有人掌握，很可能不是在造福世界，而是一种灾难。所以即使我把Yin语言做出来了，它也只会属于少数人，我不想让这样的技术落到贪婪或者愚蠢的人手里。



    我很不喜欢人们对于一个新语言的反应。我不会因为人们对我设计的东西显示出盲目的热血沸腾而受到鼓舞，因为越是盲目热情的人，越可能脑子有问题，越可能在将来浪费我的口水，有理也说不清。我宣布开发Yin语言的第一天，就有人想把其他语言的“社区”的概念放到它身上。就像很多语言都搞得像宗教一样，一下子出现了好些想做“Yin语言传教士”的人。有些人太积极了，未经我同意就建立了IRC聊天室之类的东西，还有人立即买了个域名给Yin语言（然后控制权还没有给我）。他们其实没有想到，那些都不是我想要的。我很不喜欢其他语言的宗教性质，社区意识，阵营意识。我感觉有很多人其实只是想抢占“第一把交椅”，就像很多其他语言的狂热分子一样。他们让我感觉，从一开头我就已经失去了对这个语言的控制，仿佛它不再是我的设计。Yin语言跟其它语言不一样，它不应该有一个社区，不应该成为一个宗教，因为我是一个科学家，我的设计完全出于理性的思考。



    我也不喜欢很多人对Yin语言肤浅的赞美或者质疑。有些人激动地对我说：“美国人，日本人，都有可以设计语言的人了，我们中国终于也有了！” 有的人甚至建议让它看起来像中文，符合中国人的思维方式。这些说法显示出人们对语言设计的无知和品位的低下。日本人做出了什么语言呢？我只知道一个日本人造的语言，它是一个彻底的垃圾 :P 美国人也没几个真正设计好点的语言。而且一个程序语言本来就跟人类语言扯不上任何关系，只不过有些关键字是人类语言的单词而已。也没有所谓“符合中国人的思维方式”一说，因为人脑其实根本就不是用人类语言在思考。人脑的思维方式更像是一种程序语言，一种电路，而不是人类语言。只有需要跟另一个人交流的时候，人脑才会把内部的“数据结构”转换成人类语言，就像Java的toString()方法一样。这就是我现在正在做的事，我很清楚我现在给你们打的这些字，不可能完全符合我的思维，也就是言不达意。所以无论把一个语言设计得像中文或者像英语，最后都是一个错误，因为普通的程序语言（比如C）早就在很多方面超越了人类语言，没有人类语言特有的那些历史遗留问题。SQL和COBOL之类的语言试图设计得像英语，结果惹出更多的麻烦事，得不偿失。想要一个程序语言有“中国特色”，其实显示出国人的自卑心理，也是在贬低我的价值。“中国第一”对我来说毫无意义，这让我感觉他们其实认为Yin语言跟“国产Linux”是一类的。要知道，我是世界上最强的语言设计者之一（很可能没有之一），我的价值是不限定于任何国家的，它不需要任何人的肯定。



    还有的人开始发送各种github issue，请求他们在其他语言（比如Ruby）里用过，认为重要的“特性”。有人要求我给这个语言“定性”，一本正经的要我说明这是什么“范式”的语言。有人义正言辞的索取1.0版本的specification。有人开始质疑我的一些设计，甚至自作聪明的做了改动。有人质疑我为什么不用正则表达式来做lexer，跟我说Java的lexer多么的严谨，因为它用了正则表达式…… 这一切都让我觉得越来越傻，越来越无语，越来越浪费时间和口水。他们不知道，他们头脑里的很多概念几乎全都不存在于我的脑子里。我不喜欢有人自作聪明，觉得好像自己懂很多似的，好像还可以评价甚至教育我。每一次不耻下问都发现似乎有人真以为我不懂，以为自己是专家了。Yin语言也许根本不符合任何一种“语言范式”，然而它也不会像Scala一样弄成个大杂烩。它应该是天衣无缝的设计，就像一句名言说的：“一个设计师知道他达到了完美，并不是当他不能再加进任何东西，而是当没有任何东西可以被去掉。”



    另外，很多人认为重要的特性，很有可能是有问题的。他们不明白，现有程序语言的问题，不是没有实现某些特性，而是实现了多余的特性，有问题的特性。如果错误的特性被加了进去，一旦有人开始用这个语言，就再也没法去掉了。所以作为一个优秀的语言设计者，我的一项重要任务是防止多余或者有问题的特性进入语言里。我也很不喜欢有人拿我的语言，我的开发实力跟其它语言作对比，因为比较本身就是一种不尊重的行为。比如有些人质疑Yin语言有没有Go语言好，其实是在贬低我，因为我的水平跟Go语言的设计者根本不是一个档次的。Go语言的设计者其实基础知识都没搞清楚还自以为了不起，所以当我的学生都不合格。



    所以，Yin语言的设计开发其实仍然在缓慢地进行中，然而已经不再公开，不再开源。我觉得所谓“开源精神”纯属扯淡，很多人开源不过是为了提高自己代码扩散的速度，提高知名度，这样可以带来利益，其实没有人真的是想做什么“贡献”的。这样的虚伪行为带来了开源社区的代码质量普遍低下，各种浮夸之风盛行，有人却看不出来。我不是Paul Graham，我不会吹牛，扬言要做个叫Arc的Lisp方言，结果最后做出来的东西连退步都不是（not even a step backwards）。我是有真正的实力，受过系统的精深的教育的，然而我真的有自己的困难和自己的生活。太多不合格的程序语言设计者占据了重要的语言设计岗位，很多公司已经完全不明白谁才是真正的专家。由于没有经济支持，我的大部分时间得用来做其他工作。设计语言是一个吃力不讨好的活，我想找到其它事情，甚至进入另一个领域，利用我的特殊品味来创造更大的价值。我不是工作狂，我也需要休闲和娱乐。我已经为技术耗费了太多的生命，我觉得我的人生是不完整的。为自己工作其实仍然算是工作，工作和生活需要平衡。我需要享受生活，需要陪我的猫咪，需要跟朋友玩，所以显然是不会浪费周末明媚的阳光，蹲在家里写代码的。所以Yin语言的开发虽然在进行，进度是不会很快的。即使我完成了，可能也不会给很多人用的。所以你们还是继续忍受现有语言和系统的扯淡和煎熬吧 :)


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 设计的重要性

 
 
 
 
    

    
 
     
  

      
   
设计的重要性

    我曾经在一篇文章里谈过关于设计的问题，然而那篇文章由于标题不够醒目，可能很多人没有注意看。我觉得现在有必要把里面的内容专门提出来讲一下，因为设计在我的心目中具有至关重要的地位，却被很多计算机科学家和程序员所轻视。



    我觉得自己不但是一个计算机科学家和程序员，在很大程度上我还是一个设计师。我不但是一个程序语言的设计师，而且是其它很多东西的设计师。我设计的东西不但常常比别人的简洁好用，而且我经常直接看出其他人的设计里面的问题。我写的代码不仅自己容易看懂，而且别人也容易理解。我有时候受命修补前人的BUG，结果没法看懂他们的代码。在这种情况下，我的解决方案是推翻重写。经我重写之后的代码，不仅没有BUG，而且简洁很多。



    很多人自己的设计有问题，太复杂不易用，到头来却把责任推在用户身上，使用类似“皇帝的新装”的技巧，让用户有口难言。之前一篇文章提到的严重交通事故，就是一个设计问题，却被很多人归结为“人为错误”。这种出人命的事情都这么难引起人们对设计的关注，就更不要说软件行业那些无关性命的恼人之处了。有些人写的代码过度复杂，BUG众多，却仿佛觉得自己可以评估其他人的智商，打心眼里觉得自己是专家，看不懂他代码的人都是笨蛋。



    很多程序员有意把“用户”和自己区别开来，好像程序员应该高人一等，不能以用户的标准。所以他们觉得程序员就是应该会用各种难用的工具，难用的操作系统，程序语言，编辑器，…… 他们觉得只要你追求这些东西的“易用性”或者“直观性”，就说明你智商有问题。只要你说某个东西太复杂，另一个东西好用些，他们就会跟你说：“专家才用这个，你那个是菜鸟用的。” 这些人不明白，程序员其实也是用户，而且他们是自己的代码的用户，每一次调用自己写的函数，自己都是自己的用户。可是这种鄙视用户的风气之胜行，带来了整个行业不但设计过度复杂，而且以复杂为豪的局面。



    经常有人自豪的声称自己的项目有多少万行代码，仿佛代码的行数是衡量一个软件质量的标准，行数越多质量越好，然而事实却恰恰相反。你可能需要经历过Indiana式的教育才能真正的理解这一点。如果你拿一些引以为豪的代码给Dan Friedman看，他可能瞟一眼就说：“太长了。当年这个东西我两行代码就写出来了……” 你摸着脑袋怀疑他是不是在吹牛，怎么可能！然后过了几个星期，你把代码重写了好多遍之后，真的发现只需要两行！这时候他才会微笑着点点头，一副龟仙人的味道。就是这样的教育，让我能够在短短几个星期之内，完成Google一个小组的人花几年也没法完成的项目。看过我写的代码，你也许会理解这句《小王子》作者的名言：“一个设计师知道他达到了完美，并不是当他不能再加进任何东西，而是当没有任何东西可以被去掉。”



    如果你跟我一样关心设计，却发现身边的人喜欢显示自己能搞懂复杂的东西，跟你说容易的东西都是菜鸟用的，那么你需要一个朋友。书籍是人类最好的朋友，因为它的作者可以跨越时间和空间的限制，给你最需要的支持和鼓励。这就是当我阅读这本1988年出版的《The Design of Everyday Things》（简称DOET）时的感觉。我觉得，终于有人懂我了！有趣的是，它的作者 Don Norman 曾经是 Apple Fellow，也是《The Unix-Haters Handbook》一书序言的作者。



    



    DOET 不但包含并且支持了我的博文《黑客文化的精髓》以及《程序语言与……》里的基本观点，而且提出了比《什么是“对用户友好”》更精辟可行的解决方案。



    我觉得这应该是每个程序员必读的书籍。为什么每个程序员必读呢？因为虽然这本书是设计类专业的必读书籍，而计算机及其编程语言和工具，其实才是作者指出的缺乏设计思想的“重灾区”。看了它，你会发现很多所谓的“人为错误”，其实是工具的设计不合理造成的。一个设计良好的工具，应该只需要很少量的文档甚至不需要文档。这本书将提供给你改进一切事物的原则和灵感。你会恢复你的人性。



    值得一提的是，虽然 Don Norman 曾经是 Apple Fellow，但我觉得 Apple 产品设计的人性化程度与 Norman 大叔的思维高度还是有一定的差距的。因为我看了这书之后，立马发现了iPhone的一些设计问题。



    如果你跟我一样不想用眼睛看书，可以到 Audible 买本有声书来听。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 我为什么在乎这一个A+

 
 
 
 
    

    
 
     
  

      
   
我为什么在乎这一个A+

    我知道有些人至今仍然嘲笑和鄙视我，因为我曾经说过，我在Dan Friedman的两门课程B521（程序语言理论)和B621（高级程序语言理论）都得了A+。只要提到我，他们就会拿出这个把柄来，好像我是一个只在乎分数的肤浅的人。实际上我觉得这些人只是为了鄙视而鄙视，所以他们发现貌似一个把柄，也不搞清楚Dan Friedman是谁，也不搞清楚这个A+的分量，拿着半截就开跑，抓住不放了。所以即使我没提过这分数的事情，他们一样会找到其它话题来损我。我一直都懒得回应这些人的言论，不过今天我有兴致显示一下自己的价值，所以想花点时间告诉你，这个A+到底意味着什么。



    从我的人生历史里面，你应该很明显的看出来，课程，考试，分数，名校，权威，事业，成就，贡献，以至于图灵奖，诺贝尔奖，对于我来说真的什么都不是。你觉得一个在乎这些东西的人，会以优秀的成绩从清华，Cornell，Indiana三所大学退学吗？在漫长的学术生涯中，我上过许多的课程，很多最后结果都是A或者A+，也有几门课的分数低到C。因为我从来不觉得任何人有资格出题来考我，所以自上大学以来，我给自己定的标准就是“及格万岁”。我是一个非常不喜欢上课的人，我觉得普通的课堂讲座本身就是一种极其低效的教学方式，所以一旦觉得老师水平不够或者不懂教学就开始翘课，自己看书自学。所以，最后无论什么分数都不能衡量我的价值，反而有时候觉得高分是对我价值的侮辱——本来有时候老师教的，课本上的东西就不对，得高分意味着我得跟他们错得一样。然而，我为什么唯独在乎在一个非名校，“非名师”手里上的这门课程，并且愿意告诉你我在里面的成绩呢？



    其实，这个分数的意义远远不止是一个A+，它涵盖的内容可能超乎你的想象。也许你可以从一个很小的例子看出它到底意味着什么。在课程进行到一半的时候，我花了一个星期的时间，独立解决了曾经困扰程序语言领域十多年的难题——CPS变换。CPS变换有什么用呢？如果你写过Node.js或者其它类似的东西，就知道所谓“call back hell”的代码样式，其本质就是程序语言专家所谓的“CPS”（continuation-passing style）。“CPS变换”就是可以自动把代码变换成那种样式的过程，它在本质上就是一个编译器。实际上有些函数式语言的编译器（比如SML），其中最重要的过程就是CPS变换。CPS变换之后，你可以掌握代码中的“控制流”，实现所谓“超轻量线程”，进而可以实现最近很流行的，所谓“大规模并发”。所以你看到了，这些很流行的概念，在程序语言专家看来，并不是什么稀奇的东西，甚至不是新的想法。



    在这十几年里面，有众多的世界级专家参与过这个问题的研究，包括程序语言领域的鼻祖之一，爱丁堡大学教授，英国皇家学会院士Gordon Plotkin，天才的丹麦Aarhus大学教授Olivier Danvy，CMU的Andrzej Filinski（现在DIKU），Indiana的Dan Friedman以及他的得意门生，天才的Matthias Felleisen，Felleisen的得意门生，天才的Amr Sabry（我的导师），普林斯顿大学教授Andrew Appel（编译器教材“虎书”的作者）。这些人为这个话题发表了不知道多少论文，Andrew Appel还为此专门写了一本书，叫做《Compiling with Continuations》。我之所以会去解决这个问题，是因为Friedman耍老顽童的花样，别出心裁地把这个问题作为了一道附加题目放进了B521的作业里。我不知道这个问题有如此之难，所以愣头愣脑，真把它当成作业题给解决了。按照作业的“道德规范”，完全从问题出发，不看书不看论文不查网络，全凭自己的头脑，在一个星期之内，把代码反反复复重写了几十次，最后得到了最优的结果。这就是所谓“王垠40行代码”的含义，虽然最后只剩下40行，然而却不知道删掉了多少。为了这40行代码，一个人七天，一群人十年，我想你应该知道这是什么概念。



    当我最后把代码交给Dan Friedman的时候，他不相信我的代码是正确的，因为历史上有许多的学生声称做出了这道题目，然而他们几乎全都是错的，或者采用了效率很低的做法。只有深入到精髓，才会明白怎么写出这些代码。那么多大牛花了那么多年工夫才研究清楚，所以Friedman把这问题放在作业里面，其实根本就没指望有人能够解决。所以自然，他很难相信任何人能够做出这道题目。那天Friedman用惊讶又怀疑的眼神看着我，然后给了我一篇30多页的论文。这篇论文是历史上这个问题的一个重大突破，作者是他的好朋友，Danvy和Filinsky。可是这论文写得含混晦涩，所以我花了超过一个月才琢磨清楚这篇论文是怎么回事，我至今被那些公式弄得眼花缭乱。可是最后我发现，我的自己写出来的代码完全的实现了它最后的思想，而且还要更加优雅。所以当最后我在班上讲解这片代码是怎么回事的时候，Friedman对大家说：“你们可要听仔细了，这个值100美元！”



    我的名字叫做王垠（父亲起名含义是谐音“亡垠”，无边无垠的意思），所以我将会永不停息的完善自己，永远不会拿某一个东西自居。解决这个难题只是对我这个人内在品质的一种反映而已，而且它只是我在B521做出的好几个“课外练习”的其中一个。在短短一学期的时间里，我还进行了其它几个重量级的练习，包括重新实现miniKanren语言，加入constraint logic programming功能和一种非常强大的逻辑逆（negation）操作符，等等。这些练习，全都是独立依靠自己领悟摸索完成，没有查阅任何书籍和论文资料。从这些练习里面，我获得了让我受益终生的独立思考能力。也就是这种能力，让我可以在Google，Coverity之类的公司，轻松解决其他人咋咋呼呼，认为不可能完成的任务。这就是为什么我会讲这个课程的故事，并且告诉你我得了A+。



    有趣的是，学期结束的时候，成绩单上出现的分数其实是I（Incomplete）。这种成绩表示有课程任务没有完成，如果在一年之内不弥补，就会变成F（不及格）。我很纳闷，发信去问Friedman。他回答说：“对不起，是秘书搞错了！” 然后急忙发信给秘书说：“这个人的分数应该是A+！实际上如果可能的话，我希望给他A+++++++！”



    现在你还觉得我是因为肤浅才告诉你这个A+分数吗？B521教会我的，是一生最重要的东西，它让我真正的理解了什么叫做“简单”，它使得我去追寻它。它赋予我的独立思考能力，继续在帮助我用巧妙简单的方法解决其他人望而却步的问题。这不是一个普通的A+，这是一个把我送上世界巅峰，给予我勇气和自由思想的A+。



    就像爱因斯坦说的，任何一个傻瓜都可以把问题搞复杂，你需要一点天才，还有很多勇气，才能达到简单。很多牛人用“简单”来标榜自己设计的东西，然而我发现他们对简单的理解其实很肤浅。大部分时候他们用一种类似“皇帝的新装”的心理技巧——你如果不能理解他的东西，他就说你是傻瓜或者菜鸟，不能理解这种简单。所以没有人敢说他们设计的东西太复杂。



    你觉得世界上有几个人能够在B521上得A+呢？谦虚是一种美德，不要随便评判别人，然而当看到这么多大牛都那么不谦虚，耀武扬威的，很多人用他们作为评判其他人的依据，所以我只好冒着评判他们的风险，告诉你一些事实。其实Donald Knuth, Dennis Ritchie, Bjarne Stroustrup, Guido van Rossum, Brendan Eich, Linus Torvalds, Rob Pike, ... 这些很多人仰慕的大牛，如果上B521肯定是连A都拿不到的。有些甚至不能及格，因为有些人根本不知道他们在干什么，设计出一堆复杂的垃圾，然后仗着自己的威望和强权迫使你去“学习”。其实我对计算机的理解跟这些大牛们，早就不在一个数量级上了。我心里有数他们该得什么分数，你们自己猜猜吧。



    本来不想这么赤裸裸的跟人比较的，然而我发现我的话语权和我对事物的认识深度比起来，实在相差太多。当我说到一些事情的时候，经常有人抬出这些人的语录来压制，说得好像圣经似的，对我各种评判，所以觉得有必要特此说明一下。这些大牛在我心目中真的一点权威都没有的，我反而清楚他们肚子里到底有多少货，思维方式有哪些误区和局限性。



    也许我现在可以毫不担心的告诉你了，我在Kent Dybvig的编译器课程上得的也是A+。Kent恐怕是世界上最厉害的编译器作者，他几乎从来不给人A+，而我恐怕是他20多年来最厉害的一个学生。我们做了一个Scheme编译器，它的难度和工作量，是C语言编译器的两倍以上。由于我喜欢别出心裁，不按他的写法，我的课堂编译器的某些方面，其实超越了他的Chez Scheme。比如，我的编译器曾一度生成比他更高效的X64机器指令。然而Kent很会背地里偷学武功，闷声发大财。据课程助教说，Kent有几次偷偷在我的代码上做“侦探工作”挺久…… 再加上他几十年深藏不露的经验，所以他现在恐怕仍然比我强 :)


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 不要做聪明人

 
 
 
 
    

    
 
     
  

      
   
不要做聪明人

    世界上有三种人：聪明人，傻瓜，傻b。傻瓜和傻b的区别是，傻b是令人讨厌的傻瓜。很多人想做聪明人，比其他人都聪明，结果他们变成了傻b。为什么会这样呢？



    其实很多人所谓的“聪明”，要么是能够高效的完成一些机械化的任务，要么是能够高效的绕过一些前人的设计失误。他们的所谓“知识”，建立在一堆历史遗留的糟粕之上，他们以记得住这些脆弱的“知识”为豪。所以，这些人连聪明是什么都不知道，又怎么可能成为聪明人？有些人很傻，只会死记硬背，却自认为很聪明，所以他们让人厌恶，进而升级成为傻b。



    如果你想做聪明人，那你往往不可能成为聪明人。想做聪明人的欲望，很容易让人变成傻b。有些人随时都在担心自己不如别人聪明，随时都在比较，害怕别人比他更聪明。纳什（John Nash）因为一辈子都在跟人计较谁更聪明，结果发疯了。他还算好点的，很多“天才”因为跟人计较谁更聪明，最后自杀了。世界上最傻的事情，就是拿自己跟别人作比较。跟人比较的结果，最终都是不快乐，甚至给自己的身心带来伤害。



    想做聪明人的欲望，让人变得喜欢争执，喜欢咄咄逼人的想证明自己是对的。它也使人变得固执和盲从，仓促而盲目的相信或者排斥一些事物。有趣的是，这些人选择相信或者排斥的条件，往往在于最后的结果是否能让自己显得聪明。想做聪明人的人，往往只关心自己知道的那点东西，发现别人貌似不懂就穷追猛打，抓住小辫子不放，教育这些不懂的人！却没发现自己有多么无知。因为想证明自己比别人聪明，所以解决问题的时候，总喜欢选择更困难，更复杂，看似更高深的解决方案。结果不但劳神费力，还阻碍了技术的简化和进步。



    聪明是可遇而不可求的。聪明可能是一种结果，一种事实，却不可以是一种欲望，一种目标。想要成为聪明人的欲望，多半会让人变成傻b。世界上所有试图成为聪明人的人，终究都会悟出一个道理。他们发现，自己更愿意做一个傻瓜。很多人所谓的“聪明才智”，越来越多的被机器所代替和超越。随着科技的进步，人们赖以生存所需要的死知识，会越来越少。这个世界越来越不需要聪明人，它更需要的是可爱的人。傻瓜往往很可爱。



    未来的世界属于傻瓜。所以，我觉得每个人都应该放弃做聪明人的企图，反而应该有做傻瓜的欲望。做一个傻瓜，才能给你真正意义上的实惠和幸福。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 怎样尊重一个程序员

 
 
 
 
    

    
 
     
  

      
   
怎样尊重一个程序员

    得知一位久违的同学来到了旧金山湾区，然而我见到他时，这人正处于一生中最痛苦的时期。他告诉我，自己任职的公司在他加入之前和之后，判若两人。录取的时候公司对他说，我们对你在实习期间的表现和学术背景非常满意，你不用面试，甚至不用毕业拿学位，直接就可以加入我们公司成为正式员工。然而短短一年后的今天，这位同学已经完全感觉不到公司对自己技能的尊重。Manager让他做一些乱七八糟没技术含量的事情，还抱怨说他做事太慢，并且在他的evaluation上很是写了一笔。在人格尊严和工作安全感的双重打击之下，这位同学压力非常大，周末经常偷偷地加班，仍然无法让manager满意。



    我很了解这位同学的能力，在任何一流公司任职，肯定是绰绰有余了。他的名字我当然保密，然而他所任职的公司因为太过嚣张，我不得不直接指出来——这就是被很多人向往得像天堂一样的地方，Google。这位同学所描述的遭遇，跟我几年前在Google的实习经历如出一辙。我仍然记得，Google的队友在旁边看着我用Emacs，用小学老师似的口气对我说：“按Ctrl-k！” 我仍然记得，在提交队友完全无法写出来的高难度代码时，被指责和嘲笑不会用Perforce。我仍然记得，吃饭时同事们对所谓“Google牛人”眉飞色舞的艳羡。我仍然记得，最后我一个人做出整个团队做梦都做不出来的项目的时候，有人发出沉闷的咆哮：“快——写——测——试！” ……



    我的这位同学也算得上本领域顶尖的专家了。如此的践踏一个专家的价值，用肤浅的标准来评判和对待他们，Google并不是唯一一个这样的公司。我之前任职的好几个公司，或多或少都存在类似的问题。很多时候也不一定是公司管理层无端施加压力，而是程序员之间互斗的厉害，互相评判，伤害自尊。从最近Linus Torvalds在演讲现场公然对观众无理，你可以看出这种只关心技术，不尊重人的思潮，在程序员的社区里是非常普及的。



    后来我发现，并不是程序员故意想要藐视对方或者互相攻击，而是他们真的不明白什么叫做“尊重”，他们不知道如何说话才可以不伤害另一个程序员，所以有时不小心就让人怒火中烧。所以说，尊重他人其实是一个“技术问题”，而不是有心就可以做到的。因为这个原因，我想在下文里从心理和技术角度出发，指出IT业界不尊重人现象的起源，同时提出几点建议，告诉人们如何真正的尊重一个程序员。我希望这些建议对公司的管理层有借鉴意义，也希望它们能给与正在经受同样痛苦的程序员们一些精神上的鼓励。



    我觉得为了建设一个程序员之间互相尊重的公司文化，应该注意以下几个要点。


认识和承认计算机系统里的历史遗留糟粕


    很多不尊重人现象的起源，都是因为某些人偏执的相信某种技术就是世界上最好的，每个人都必须知道，否则他就不是一个合格的程序员。这种现象在Unix（Linux）的世界尤为普遍。Unix系统的鼓吹者们（我曾经是其中之一）喜欢到处布道，告诉你其它系统的设计有多蠢，你应该遵从Unix的“哲学”。他们仿佛认为Unix就是世界终极的操作系统，然而事实却是，Unix是一个设计非常糟糕的系统。它似乎故意被设计为难学难用，容易犯错，却美其名曰“强大”，“灵活”。眼界开阔一点的程序员都知道，Unix的设计者其实基本不懂设计，他们并不是世界上最好的程序员，却有一点做得很成功，那就是他们很会制造宗教，煽动人们的盲从心理。Unix设计者把自己的设计失误推在用户身上，让用户觉得学不会或者搞错了都是自己的错。



    如果你对计算机科学理解到一定程度，就会发现我们其实仍然生活在计算机的石器时代。特别是软件系统，建立在一堆历史遗留的糟糕设计之上。各种蹩脚脑残的操作系统（比如Unix，Linux），程序语言（比如C++，JavaScript，PHP，Go)，数据库，编辑器，版本控制工具，…… 时常困扰着我们，这就是为什么你需要那么多的所谓“经验”和“知识”。然而，很多IT公司不喜欢承认这一点，他们一向以来的作风是“一切都是程序员的错！”，“作为程序员，你应该知道这些！” 这就造成了一种“皇帝的新装现象”——大家都不喜欢用一些设计恶劣的工具，却都怕别人嘲笑或者怀疑自己的能力，所以总是喜欢显示自己“会用”，“能学”，而没有人敢说它难用，敢指出设计者的失误。



    我这个人呢，就是这种“黑客文化”的一个反例。我所受到的多元化教育，让我从这些偏激盲从，教条主义的心理里面跳了出来。每当有人因为不会某种工具或者语言来请教我时，我总是很轻松的调侃这工具的设计者，然后告诉他，你没理由知道这些破玩意儿，但其实它就是这么回事。然后我一针见血的告诉他这东西怎么回事，怎么用，是哪些设计缺陷导致了我们现在的诡异用法…… 我觉得所有的IT从业人员对于这些工具，都应该是这样的调侃态度。只有这样，软件行业才会得到实质性的进步，而不是被一些自虐的设计所困扰，造成思维枷锁。



    总之，这是一个非常重要的“态度问题”。虽然在现阶段，我们有必要知道如何绕过一些蹩脚的工具，利用它们来完成自己的任务。然而在此同时，我们必须正视和承认这些工具的恶劣本质，而不能拿它们当教条，把什么事都怪罪于程序员。只有分清工具设计者的失误和程序员自己的失误，不把工具的设计失误怪罪于程序员，我们才能有效地尊重程序员们的智商，鼓励他们做出简单，优雅，完善的产品。


分清精髓知识和表面知识，不要太拿经验当回事


    在任何领域，都只有少数知识是精髓的，另外大部分都是表面的，肤浅的，是从精髓知识衍生出来的。精髓知识和表面知识都是有用的，然而它们的分量和重要性却是不一样的。所以必须区分精髓知识和表面知识，不能混为一谈，对待它们的态度应该是不一样的。由于表面知识基本是死的，而且很容易从精髓知识推导衍生出来。我们不应该因为自己知道很多表面知识，就自以为比掌握了精髓知识的人还要强。不应该因为别人不知道某些表面知识，就以为自己高人一等。



    IT公司经常有这样的人，以为精通一些看似复杂的命令行，或者某些难用的程序语言就很了不起似的。他们如果听说你不知道某个命令的用法，那简直就像法国人不知道拿破仑，美国人不知道华盛顿一样。这些人没有发现，自己身边有些同事其实掌握着精髓的知识，他们完全有能力从自己已有的知识，衍生制造出所有这些工具，而不只是使用它们，甚至设计得更加完善和方便易用。这种能够设计制造出更好工具的人，往往身负更加重要的任务，所以他们往往会在被现有工具的用法迷惑的时候，非常谦虚的请同事帮助解决，大胆的承认自己的糊涂。



    如果你是这个精通工具用法的人，切不可以把同事的谦虚请求当成可以显摆自己“资历”的时候。这同事往往真的是在“不耻下问”。他并不是搞不懂，而是根本不屑于，也没有时间去考虑这种低级问题。他的迷惑，往往来源于工具设计者的失误。他很清楚这一点，他也知道自己的技术水平其实是高于这工具的设计者的。然而为了礼貌，他经常不直接批评这工具的设计，而是谦虚的责怪自己。所以同事向你“虚心请教”，完全是为了制造一种友好融洽的气氛，这样可以节省下时间来干真正重要的事情。这种虚心并不等于他在膜拜你，承认自己的技术能力不如你。



    所以正确的对待方式应该是诚恳的表示对这种迷惑的理解，并且坦率的承认工具设计上的不合理，蹩脚之处。如果你能够以这种谦和的态度，而不是自以为专家的态度，同事会高兴地从你这里“学到”他需要的，肤浅的死知识，并且记住它，避免下次再为这种无聊事来打扰你。如果你做出一副“天下只有我知道这奇技淫巧”的态度，同事往往会对你，连同这工具一起产生鄙视的情绪。他下次会照样记不住这东西的用法，然而他却再也不会来找你帮忙，而是一拖再拖。


不要自以为聪明，不要评判别人的智商和能力


    在IT公司里，总是有很多人觉得自己聪明，想显示自己比别人聪明。这种人似乎随时都在评判（judge）别人，你说的任何话，不管认真的还是开玩笑的，都会被他们拿去作为评估你智商和能力的依据。



    有时候你写了一些代码，自己知道时间不够，可是当时有更重要的事情要做，所以打算以后再改进。如果你提交代码时被这种人看到了，他们就会坚定地认为你一辈子只能写出那样的代码。这就是所谓“wishful thinking”，人只能看到他希望看到的东西。这种人随时都在希望自己比别人聪明，所以他们随时都在监听别人显得不如他聪明的时候，而对别人比他高明的时候视而不见。他们只能看到别人疏忽的时候，因为那是可以证明他们高人一等的有利证据。



    当然，谁会喜欢这样的人呢，可是他们在IT公司里相当的普遍。你不敢跟他们说话，特别是不敢开玩笑，因为他们会把你稀里糊涂的玩笑话全部作为你智商低下或者经验不足的证据。你不敢问他们问题，因为他们会认为你问问题，说明你不懂！我发现具有这种心理的人，一般潜意识里都存在着自卑。他们有某些方面（包括智力在内）不如别人，所以总是找机会显得高人一等。我还没有想出可以纠正这种心理问题的有效方法，但如我上节所说，意识到整个行业，包括你仰慕的鼻祖们，其实都不懂很多东西，都是混饭吃的，是一个有效的放松这种心理的手段。



    有时候我喜欢自嘲，对人说：“我们这行业的祖先做了这么多BUG来让我们修补。现在你做了一坨屎，我也做了一坨屎，我的屎貌似比你的屎香一点。”这样一来，不但显示出心理的平等和尊重，而且避免了因为谦虚而让对方产生高人一等的情绪。说真的，做这行根本不需要很高的智力，所以最好是完全放弃对人智力的判断。你不比任何人更聪明，也不比他们笨。


解释高级意图，不要使用低级命令


    随时都要记住，同事和下属是跟你智力相当的人。他们是通情达理的人，然而却不会简单地服从你的低级命令。像我在Google的队友的做法，就是一个很好的反面教材。其实这位Googler只是想告诉我：“删掉这行文本，然后改成这样……” 就是如此一个简单的事情，然而她却故弄玄虚，不直接告诉我这个“高级意图”，而是使用非常低级的指令：“按Ctrl-k！……” 语气像是在对一个不懂事的小学生说话，好像自己懂很多，别人什么都不知道似的。



    有哪个Emacs用户不知道Ctrl-k是删掉一行字呢，况且你现在面对的其实是一个资深Emacs用户。我想大家都看出来这里的问题了吧。这样的低级命令不但逻辑不清楚，而且是对另一个人的智力的严重侮辱。你当我是什么啊？猴子？如果这位Googler表明自己的高级意图，就会很容易在心理上和逻辑上让人接受，比如她可以说：“配置文件的这行应该删掉，改成……”



    在项目管理的时候也需要注意。在让人做某一件事之前，应该先解释为什么要做这件事，以及它的重要性。这样才能让人理解，才能尊重程序员的智商。


不要期望新人向自己学习


    很多IT公司喜欢把新人当初学者，期望他们“从新的起跑线出发”，向自己“学习”。比如，Google把新员工叫做“Noogler”（Newbie Googler的意思），甚至给他们发一种特殊的螺旋桨帽子，其寓意在于告诉他们，小屁孩要谦虚，要向伟大的Google学习，将来才可以飞黄腾达。



    



    这其实是非常错误的作法，因为它完全不尊重新员工早已具备的背景知识，把自己的地位强加于他们头上。并不是你说“新的起跑线”就真的可以把人的过去都抹杀了的。新人不了解你们的代码结构和工程方式，并不等于你们的方式就会先进一些。Google里面真的有很多值得学习的东西吗？学校的教育真的一文不值吗？其实恰恰相反。我可以坦然的说，我从自己的教授身上学会了最精髓的知识，而从Google得到的，只是一些很肤浅的，死记硬背就可以掌握的技能，而且其中有挺多其实是糟粕。我在Google做出的所有创新成果，全都是从学校获得的精髓知识的衍生物。很多PhD学生鄙视Google，就是因为Google不但自己技术平庸，反倒喜欢把自己包装成最先进的，超越其它公司和学校的，并且嚣张的期望别人向他们“学习”。



    一个真正尊重人才的公司会去了解，尊重和发挥新人从外界带来的特殊技能，施展他们特有的长处，而不是一味期望他们向自己“学习”。只有这样，我们才能保持这些锐利武器的棱角，在激烈的竞争中让自己立于不败之地。如果你一味的让新人“学习”，而无视他们特有的长处，最后就不免沦为平庸。


不要以老师自居，分清“学习”和“了解”


    如上文所说，IT行业的很多所谓“知识”，只不过是一些奇技淫巧，用以绕过前人设计上的失误。所以遇到别人不知道一些东西的时候，请不要以为你“教会”了别人什么东西，不要以为自己可以当老师了。以老师自居，使用一些像“跟我学”一类的语言，其实是一种居高临下，不尊重人的行为。



    人们很喜欢在获得了信息的时候用“学习”这个词，然而我觉得这个词被滥用了。我们应该分清两种情况：“学习”和“了解”。前者指你通过别人的指点和自己的理解，获得了精髓的，不能轻易制造出来的知识。后者只是指你“了解”了原来不知道的一些事情。举个例子，如果有人把一件物品放在了某个你不知道的地方，你找不到，问他，然后他告诉你了。这种信息的获取，显然不叫“学习”，这种信息也不叫做“知识”。



    然而，IT行业很多时候所谓的“学习”，就是类似这种情况。比如，有人写了一些代码，设计了一些框架模块。有人不知道怎么用，然后有人告诉他了。很多人把这种情况称为“学习”，这其实是对人的不尊重。这跟有人告诉你他把东西放在哪里了，是同样性质的。这样的代码和设计，我也可以做，甚至做得更好，凭什么你说我在向你学习呢？我只是了解了一下而已。



    所谓学习，必须是更加高级的知识和技能，必须有一种“有收获”，“有提高”的感觉。简单的信息获取不能叫做“学习”，只能叫做“了解”。分清“了解”和“学习”，不以老师自居，是尊重人的一个重要表现。


明确自己的要求，不要使用指责的语气


    有些人很怪异，他根本没告诉过你他想要什么，有什么特别的要求，可他潜意识里假设已经告诉你了。到了后来，他发现你的作法不符合要求，于是严厉指责你没有按照他“心目中的要求”办事。这种现象不止限于程序员，而且包括日常生活中的普通人。举个例子，我妈就是这种人的典型，所以我以前在家生活经常很辛苦。她心目中有一套“正确”的做事方式，如果你没猜出来就会挨骂。你为了避免挨骂，干脆什么事都不要做，然后她又会说你懒，所以你就左右不是人 :)



    IT公司里面也有挺多这样的人，他们假设有些信息他已经告诉你了，而其实根本没告诉你。到了后来，他们开始指责你没有按照要求做事。有些极其奇葩的公司，里面的程序员不但喜欢以老师自居，而且他们“传授”你“知识”的主要方式是指责。他们事先不告诉你任何规则，然后只在你违反的时候来责备你。我曾经在这样一个公司待过，名字就不提了。



    现在举一个具体的场景例子：



    A: 你push到master了？

B: 是啊？怎么了？

A: 不准push到master！只能用pull request！

B: 可是你们之前没告诉过我啊……

A: 现在你知道了？！



    注意到了吗？这不是一个技术问题，而是一个礼节（etiquette）问题。你没有事先告诉别人一些规则，就不该用怪罪的语气来对人说话，况且你的规则还不一定总是对的。所以我现在提醒各位IT公司，在技术上的某些特殊要求必须事先提出来，确保程序员知道并且理解。如果没有事先提出，就不要怪别人没按要求做，因为这是非常伤害人自尊的作法。其实，在任何时候都不应该使用指责的语气，它不但对解决问题没有任何正面作用，而且会恶化人际关系，最终导致更加严重的后果。


程序员的工作量不可用时间衡量


    很多IT公司管理层不懂得如何估算程序员的工作量，所以用他们坐在自己位置上工作的时间来估算。如果你能力很强，在很短的时间内把最困难的问题解决了，接下来他们不会让你闲着，而会让你做另外一些很低级的活。这是很不合理的作法。打个比方，能力强的员工就像一辆F1赛车，马力和速度是其他人的几十倍。当然，普通人需要很长时间才能解决，甚至根本没法解决的问题，到他手里很快就化解掉了。这就像一辆F1赛车，眨眼工夫就跑完了别人需要很久的路程。如果你用时间来衡量工作量，那么这辆赛车跑完全程只需要很短时间，所以你算出来的工作量就比普通车子小很多。你能因此说赛车工作不够努力，要他快马再加鞭吗？这显然是不对的。



    物理定律是这样：能量 = 功率 x 时间。工作量也应该是同样的计算方法。英明的，真正理解程序员的公司，就不会指望高水平的程序员不停地工作。高水平程序员由于经常能够另辟蹊径，一个就可以抵好几个甚至几十个普通程序员。他们处理的问题比常人的困难很多，费脑力多很多，当然他们需要更好的休息，保养，娱乐，…… 如果你让高水平的程序员太忙了，一刻都不停着，有趣有挑战性的事情做完了就让他们做一些低级无聊的事情，他们悟出这个道理之后，就会故意放慢速度，有时候明明很快做完了也会说没做完。与其这样，不如只期望他们工作短一点的时间，把事情做完就可以。



    当然这并不是说初级的程序员就应该过量工作。编程是一项艰苦的脑力活动，超时超量的工作再加上压力，只会带来效率的低下，质量的降低。


不要让其他人修补自己的BUG


    这个我已经在一篇专门的文章里讨论过。让一个程序员修补另外一个程序员的BUG，不但是效率低下，而且是不尊重程序员个人价值的作法，应该尽量避免。



    在软件行业，经常看到有的公司管理让一个人修补另一个人代码里的BUG。有时候有人写了一段代码，扔出来不管了，然后公司管理让其他工程师来修复它。我想告诉你们，这种方法会很失败。



    首先，让一个人修复另一个人的BUG，是不尊重工程师个人技术的表现。久而久之会降低工程师的工作积极性，以至于失去有价值的员工。代码是人用心写出来的作品，就像艺术家的作品一样，它的质量牵挂着一个人的人格和尊严。如果一个人A写了代码，自己都不想修复里面的BUG，那说明A自己都认为他自己的代码是垃圾，不可救药。如果让另一个人B来修复A代码里的BUG，就相当于是让B来收拾其他人丢下的垃圾。可想而知，B在公司的眼里是什么样的地位，受到什么样的尊重。



    其次，让一个人修复另一个人的BUG，是效率非常低下的作法。每个人都有自己写代码的风格和技巧，代码里面包含了一个人的思维方式。人很难不经解释理解别人的思想，所以不管这两人的编程技术高下，都会比较难理解。不能理解别人的代码，不能说明这人编程技术的任何方面。所以让一个人修补另一个人的BUG，无论这人技术多么高明，都会导致效率低下。有时候技术越是高的人，修补别人的BUG效率越是低，因为这人根本就写不出来如此糟糕的代码，所以他无法理解，觉得还不如推翻重写一遍。



    当我在大学里做程序设计课程助教的时候，我发现如果学生的代码出了问题，你基本是没法简单的帮他们修复的。我的水平显然比学生的高出许多，然而我却经常根本看不懂，也不想看他们的代码，更不要说修复里面的BUG。就像上面提到的，有些人自己根本不知道自己在写什么，做出一堆垃圾来。看这样的代码跟吃屎的感觉差不多。对于这样的代码，你只能跟他们说这是不正确的。至于为什么不正确，你只能让他们自己去改，或者建议他们推翻重写。也许你能指出大致的方向和思路，然而深入到具体的细节却是不可能的，而且不应该是你的职责。这就是我的教授告诉我的做法：如果代码不能运行，直接打一个叉，不用解释，不用推敲，等他们自己把程序改好，或者实在没办法，来office hours找你，向你解释他们的思想。



    如果你明白我在说什么，从今天起就对自己的代码负起责任来，不要再让其它人修补自己的BUG，不要再修补其他人的BUG。如果有人离开公司，必须要有人修补他遗留下来的BUG，那么说话应该特别特别的小心。你必须指出需要他帮忙的特殊原因，强调这件事本来不是他的错，本来是不应该他来做的，但是有人走了，没有办法，并且诚恳的为此类事情的发生表示歉意。只有这样，程序员才会心甘情愿的在这种特殊关头，修补另外一个人的BUG。


不要嚷着要别人写测试


    在很多程序员的脑子里，所谓的“流程”和“测试”，比真正解决问题的代码还重要。他们跟你说起这些，那真的叫正儿八经，义正言辞啊！所以有时候你很迷惑，这些人除了遵守这些按部就班的规矩，还知道些什么。大概没有能力的人都喜欢追究各种规矩吧，这样可以显得自己“没有功劳有苦劳”。这些人自己写的代码很平庸，不知道如何简单有效地解决困难的问题，却喜欢在别人提交代码让他review的时候叫喊：“测试很重要！覆盖很重要！你要再加一些测试才能通过我的review！”



    本来code review是让他们帮忙发现可能存在的问题，有些人却仿佛把它作为了评判（judge）其他人能力，经验，甚至智商的机会。他们根本不明白别人代码的实质价值，就知道以一些表面现象来判断。我在Google实习，最后提交了质量和难度都非常高的代码，然而一些完全没能力写出这样代码的人，不但没表示出最基本的肯定，反而发出沉闷的咆哮：“快——写——测——试！” 你觉得我会高兴吗？



    我并不否认测试的用处，然而很多人提起这些事情时候，语气和态度是非常不尊重，让人反感的。这些人不但没有为解决问题作出任何实质贡献，当有人提交解决方案的时候，他们没有表达对真正做出贡献的人的尊重和肯定，反而指责别人没写测试。好像比他高明的人解决了问题，他反倒才是那个有发言权的，可以评判你的代码质量似的：“我管你代码写得多好，我完全没能力写出来，但你没写测试就是不够专业。你懂不懂测试的重要性啊，还做程序员！”



    人际交往的问题经常不在于你说了什么，而在于你是怎么说的。所以我的意思并不是说你不该建议写测试，然而建议就该有建议的语气和态度。因为你没有做实际的工作，所以一些礼貌用语，比如“请”，“可不可以”……是必须的。经常有人说话不注意语气和态度，让人反感，却以自己是工程师，不善于跟人说话为借口。永远要记住，你没有做事，说话就应该委婉，切不可使用光秃秃的祈使句，说得好像这事别人非做不可，不做就是不懂规矩一样。



    礼貌的语言，跟人的职业完全没有关系。身为工程师，完全不能作为说话不礼貌的借口。


关于Git的礼节


    Git是现在最流行的代码版本控制工具。用外行话说，Git就是一个代码的“仓库”或者“保管”，这样很多人修改了代码之后，可以知道是谁改了哪一块。其实不管什么工具，不管是编辑器，程序语言，还是版本控制工具，比起程序员的核心思想来，都是次要的东西，都是起辅助作用的。可是Git这工具似乎特别惹人恼火。



    Git并不像很多人吹嘘的那么好用，其中有明显的蹩脚设计。跟Unix的传统一脉相承，Git没有一个良好的包装，设计者把自己的内部实现细节无情地泄露给了用户，让用户需要琢磨者设计者内部到底怎么实现的，否则很多时候不知道该怎么办。用户被迫需要记住挺多稀奇古怪的命令，而且命令行的设计也不怎么合理，有时候你需要加-f之类的参数，各个参数的位置可能不一致，而且加了还不一定能起到你期望的效果。各种奇怪的现象，比如"head detached"，都强迫用户去了解它内部是怎么设计的。随着Git版本的更新，新的功能和命令不断地增加，后来你终于看到命令行里出现了foreach，才发现它的命令行就快变成一个（劣质的）程序语言。如果你了解ydiff的设计思想，就会发现Git之类基于文本的版本控制工具，其实属于古代的东西。然而很多人把Git奉为神圣，就因为它是Linus Torvalds设计的。



    Git最让人恼火的地方并不是它用起来麻烦，而是它的“资深用户”们居高临下的态度给你造成的心理阴影。好些人因为自己“精通Git”就以为高人一等，摆出一副专家的态度。随着用户的增加，Git最初的设计越来越被发现不够用，所以一些约定俗成的规则似乎越来越多，可以写成一本书！跟Unix的传统一脉相承，Git给你很多可以把自己套牢的“机制”，到时候出了问题就怪你自己不知道。所以你就经常听有人煞有介事的说：“并不是Git允许你这么做，你就可以这么做的！Unix的哲学是不阻止傻人做傻事……” 如果你提交代码时不知道Git用户一些约定俗成的规则，就会有人嚷嚷：“rebase了再提交！” “不要push到master！” “不要merge！” “squash commits！” 如果你不会用git submodule之类的东西，有人可能还会鄙视你，说：“你应该知道这些！”



    打个比方，这样的嚷嚷给人的感觉是，你得了奥运会金牌之后，把练习用的器材还回到器材保管科，结果管理员对你大吼：“这个放这边！那个放那边！懂不懂规矩啊你？” 看出来问题了吗？程序员提交了有高价值的代码（奥运金牌），结果被一些自认为Git用的很熟的人（器材保管员）厉声呵斥。



    一个尊重程序员的公司文化，就应该把程序员作为运动健将，把程序员的代码放在尊贵的地位。其它的工具，都应该像器材保管科一样。我们尊重这些器材保管员，然而如果运动员们不懂你制定的器材摆放规矩，也应该表示出尊重和理解，说话应该和气有礼貌，不应该骑到他们头上。所以，对于Git的一些命令和用法，我建议大家向新手介绍时，这样开场：“你本来不该知道这些的，可是现在我们没有更好的工具，所以得这样弄一下……”


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 所谓“人为错误”

 
 
 
 
    

    
 
     
  

      
   
所谓“人为错误”

    昨天是一个让人悲哀的日子。旧金山湾区主要的上下班交通工具Caltrain，在24小时之内发生三次事故，撞死三人。其中一次事故发生在Menlo Park，一辆汽车被困在铁轨上，因为被前后的车辆堵塞而无法逃避，终于被飞驰而来的列车撞成一堆废铁。开车人被消防队员从残骸里切割出来，送往医院后不久死亡。(新闻视频）



    




    



    我为生命的殒灭而悲哀，然而让我更加悲哀的是，每当这样的事故发生，总有人指责说是“人为错误”。比如，Twitter上有人说这事故是因为死者没有遵守交通规则，才导致自己的汽车被困在铁轨之上，所以她死的活该。



    



    真的是因为她不遵守交通规则吗？真的有人愿意把车停在铁轨上等死吗？也许是这规则没法遵守，或者设计得让人很容易“违反”呢？



    首先，规则必须要让人理解，切实可行，才能叫做规则。



    



    但是请看看铁轨交叉路口上的指令：“不要停在铁轨上（DO NOT STOP ON TRACKS）”，“保持路口畅通（KEEP CLEAR）”。我也不想停在铁轨上啊，可是我刚开到铁轨上，前面的车就停下来了，过不去怎么办？另外什么叫做clear？一定要等到路口里面完全没有车才可以进去吗？如果路口里面虽然有车，然而它们都以每小时30英里的速度行驶？这时我还该停下来吗？如果前面车的速度不到每小时5英里呢？如果前面车辆貌似很快，结果我一进路口它就慢下来了怎么办？



    如果“不要停在铁轨上”的指令我想遵守都不可能，如果连clear这个单词都定义不清楚，这还叫什么“交通规则”呢？既然规则都不清楚，又怎么能责怪别人不遵守？我要有多么高的预知未来的能力，才能猜得到前面的车会不会正好在我开到铁轨上的时候停下来，把我堵在铁轨上呢？也许你已经看出来了，这其实不是开车人的错误，它最多算一个“判断失误”。每个人都有可能在那种模棱两可的情况下发生判断失误，因为你没法知道前面的车会怎样运动。记者在现场采访的几个开车人都说：“过那个路口要极度小心，因为你不知道前面的车会怎么样走。”



    如果你仔细看看卫星图，就会发现铁轨前方的道路狭窄，而且不远处有一个红绿灯。如果这个红绿灯变红，那么就有可能把直到铁轨处的车辆全都叫停。如果你熟悉湾区的道路，就知道红灯处是82号公路（El Camino Real），上那条路的红灯经常等很久。也就是说，可能有很多车在那里等红灯，一直到铁轨的地方！



    



    如果你再仔细一点，用Google Map的street view去实地看一下那个路口，就会发现，地面上的"KEEP CLEAR"字样，其实是用来给被堵在铁轨上的车预留后路的。然后你就发现，如果后面的车不遵守KEEP CLEAR的指令，那么它们就会断掉铁轨上的车的退路。所以，其实不是铁轨上的车自己等死，而是后面那些不遵守KEEP CLEAR指令的车，把它逼上了绝路。然而就像我之前提到的，想要遵守KEEP CLEAR又是很模棱两可的事情，后面的车有可能以为你过得去，所以才跟上的。所以你死了，不能怪火车，不能怪你自己，不能怪前面的车，还不能怪后面的车！怪谁呢？只能怪路口的“设计”！



    这种路口交通规则还有一个致命的特征，那就是后果的严重性不明显，人不会敏锐的感觉到犯了错误的结果是车毁人亡。一般人都不闯红灯，因为很显然，如果你红灯不停就会被另一个方向的车撞上。可是违反这铁道路口的规则，后果不是立显的，有可能什么事也没有，也有可能呆在那里几分钟之后才出事，到时候想逃都逃不了。这就像把活青蛙放进冷水里，然后慢火加热一样，它不会立即被烫得跳出来，而会死在里面！等你慢慢的开到铁轨上，才发现前面的车不走了（因为更前面路口亮了红灯），后面的车又抵上来。过一会儿，当当当，栏杆放下来，火车来了…… 你这是在设陷阱诱捕野生动物吗？



    如此容易出现的失误（甚至不叫做自己的失误），真的值得一个人用生命来偿还吗？按照这样的逻辑，我就可以把地雷埋在大街上，插上标志牌说：“下面有地雷，不要踩！”如果你踩了，那我就可以怪你没遵守规则，自己找死！



    如果你回头看看历史就会发现，Caltrain几乎每个月都会撞上至少一辆汽车，所以这次的事故绝不是偶然，它有更深层的原因。上一个月，我乘坐的一列Caltrain，就因为前面一趟列车撞上了汽车而延误了好几个小时。当时我就在Twitter上看到有人责备开车的人，说他脑子秀逗了，不该把车停在铁轨上。当时我就在Twitter上警告@Caltrain，说你们应该仔细分析一下这个交叉路口的设计，也许是因为设计有问题。没有人回应我。这次出了三条人命，交叉路口的设计问题才终于受到了重视。



    出了人命的大事故，也许能唤醒人们一点理智，认识到所谓的“人为错误”，其实在很多时候是设计错误。在这个例子中，交叉路口的设计是不合理的。一旦你因为判断失误把车开进去了，就有可能出现无路可逃，车毁人亡的局面。然而很多生活中的设计失误所引发的“人为错误”都是不致命的，有点像慢性毒药。这种貌似无关痛痒的设计错误，更加容易被忽视，它们就潜伏在我们的身边。



    在我所在的软件行业里，就有很多这样的设计错误。在我看来，整个软件行业基本就是建立在一堆堆的设计失误之上。做程序员如此困难和辛苦，大部分原因就是因为软件系统里面积累了大量前人的设计失误，所以我们需要做大量的工作来弥补或者绕过。举个例子，Unix/Linux操作系统就是一个重大的设计失误。Unix系统的命令行，系统API，各种工具程序，编辑器，程序语言（C，C++等），设计其实都很糟糕。很多工具程序似乎故意设计得晦涩难用，让人摸不着头脑，需要大量时间学习，而且容易出错。出错之后难以发现，难以弥补。



    然而一般程序员都没有意识到这里面的设计错误，知道了也不敢指出来，他们反而喜欢显示自己死记硬背得住这些稀奇古怪的规则。这就导致了软件行业的“皇帝的新装现象”——没有人敢说工具的设计有毛病，因为如果你说出来，别人就会认为你在抱怨，那你不是经验不足，就是能力不行。这就像你不敢说皇帝没穿衣服，否则别人就会认为你就是白痴或者不称职的人！Unix系统的同盟者和后裔们（Linux，C语言，Go语言），俨然形成了这样一种霸权，他们鄙视觉得它们难用，质疑它们的设计的人。他们嘲笑这些用户为失败者，即使其实有些“用户”水平比Unix的设计者还要高。久而久之，他们封住了人们的嘴，让人误以为难用的东西就是好的。



    我体会很深的一个例子就是Git版本控制工具。有人很把这种东西当回事，引以为豪记得住如何用一些稀奇古怪的Git命令（比如git rebase, git submodule之类）。好像自己知道了这些就真的是某种专家一样，每当遇到不会用这些命令的人，都在心底默默地鄙视他们。作为一个比Git的作者还要高明的程序员，我却发现自己永远无法记住那些命令。在我看来，这些命令晦涩难懂，很有可能是因为没设计好造成的。因为如果一个东西设计好了，以我的能力是不可能不理解的。可是Linus Torvalds的名气之大，威望之高，有谁敢说：“我就是不会用你设计的破玩意儿！你把我怎么着？”


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 创造者的思维方式

 
 
 
 
    

    
 
     
  

      
   
创造者的思维方式

    我不知道人们是怎么回事，缺乏想象力还是怎么的，所以我跟其他人对话常常遇到类似的问题。



    我：A其实不怎么好。

其他人：你说A不好，难道你要我用B？



    （对于政治爱好者，如果A是资本主义，B就是社会主义；如果A是美国，B就是中国，等等。对于IT人员，如果A是Unix，B就是Windows；如果A是Vim，B就是Emacs；如果A是关系式数据库，B就是NoSQL数据库，等等……）



    然后呢，这人就会深信我是B的拥鳖，进而产生敌意。这种对话越说越糊涂，越说越尴尬，越说我越觉得降低我的身份。



    仔细分析之后，我发现了这问题的起因，其实是因为我跟其他人的思维方式是完全不同的。我总是从一个“创造者”的角度说话，而对方却站在“使用者”的角度。站的高度不同，当然就没法沟通，鸡同鸭讲。



    创造者说“A其实不怎么好”，他的意思往往不是说你应该去“用”别的什么东西。他的意思其实是，A不怎么好，我可以把它的缺点去掉，“创造”一个更好的东西。这里的区别就在于“用”和“创造”的不同。使用者说“A不好”，是无可奈何的抱怨；创造者说“A不好”，却是对改进机遇的欣喜。可惜的是，使用者永远无法理解创造者的心，创造者的喜悦在使用者的头脑里，直接被“翻译”成了抱怨。



    创造者拥有使用者没有的能力，他能够随心所欲的制造出新的事物，而不带有现存事物设计的思维枷锁。创造者因此具有比使用者更高的安全感，更深的远见，更豁达的胸襟。他不容易陷入非此即彼的“宗教冲突”，他不需要选择任何一个“阵营”，因为他对这种冲突的解决方案很简单：创造一个全新的宗教，消灭掉冲突的双方 :)


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 人的价值

 
 
 
 
    

    
 
     
  

      
   
人的价值

    我具有世界上最先进的文明。做我的朋友本来应该是一件容易的事，可我却很不容易找到一个朋友，因为很少有人具有跟我匹配的“个人价值”。我对人的“估价”，不是取决于他拥有多少金钱或者知识，而是取决于他的内心认为自己有多大价值，取决于他有多尊重和爱戴他自己。具有高价值的人，不需要通过外在事物来凸显自己。如果A崇拜我看不起的B，那么A会被我同样的看不起。也就是说，一个人崇拜的人的价值，决定了这个人价值的上限。很多人在我面前吹捧和膜拜其它人和事物，结果是贬低了他们自己的价值，也让我感觉跟他们说话是降低了身份。



    那么是不是说藐视一切的人，在我心目中就有最大的价值呢？是的，如果他真的能发自心底的做到藐视一切。然而可惜的是，只有非常少的人能够做到这一点。很多人看似目中无人，而其实只是自欺欺人，他们的心底其实很在乎一些人和事物。这些人对自己的估价，其实在很多东西之下。比如很多人认为豪车或者名牌服饰是自己身份的象征，所以总想显示这些。一旦有了这种特征，这人的价值就被我定位在了汽车，衣服这类物品之下。有些人喜欢显示自己为某知名公司工作，穿印有公司徽标的衣服，张口闭口拍公司的马屁。这些人的价值，就被我定义在了那被我鄙视的公司之下。



    在我的心目中，物质是卑贱的，是为人服务的。所以我不怜惜钱，车子或者其它物品，不觉得穿了什么衣服或者开了什么车，就凸显了自己的价值。在我的心里，我的价值大于所有的这些：名牌车子，名牌衣服，名牌大学，知名教授，高深的理论，知名公司，亿万富翁，甚至民族传统。我的个人价值如此之大，所以我不惜抛弃名牌大学的学位，我不屑为某些知名大公司工作。我毫不在意别人怎么看我，我毫不在意别人定义的所谓“成功”。我最得意的成就，其实就是我自己。这就是我所谓的“个人价值”，这跟一个人对于其它人的“利用价值”，是完全不同的两回事。



    我多希望面前的人能够跟我一样，实际上我总是不切实际的假设他是这样的人。我会在他面前拿各种事物和权威开玩笑，因为我一般都善良的假设这个人是一个朋友，他尊重他自己胜过任何其它事物，所以我尊重他这个人，胜过他穿的衣服，胜过他待过的学校，胜过他所服务的公司。很可惜的是，只有非常少的人能够做到尊重他自己，并且能够理解我的做法。有人甚至因为我拿他们崇拜的人，学校，公司，甚至学术理论开玩笑而感到恼怒。对人的个人价值的高度尊重，反而引起了他的反感。我很遗憾，但却并不可惜，因为他贬低了他自己，而我只在乎那些具有跟我有同等价值的人。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 牛校综合征

 
 
 
 
    

    
 
     
  

      
   
牛校综合征

    我在牛校待过（清华，Cornell），也在非牛校待过（川大，Indiana）。我见过许多的牛校与非牛校学生，我感觉牛校的学生确实不一样，他们的脑子貌似有一种病。经过很长一段时间，我终于总结出了这病的基本特征，这些症状被我统称为“牛校综合症”。牛校综合症萌芽于进牛校之前的“奋斗”过程，在牛校的人群中互相传染，茁壮成长，然后在毕业后遗传到一些主要由牛校学生组成的公司。



    并不是每个牛校毕业的人都会患牛校综合症，但很多都会。我有一些很好的朋友是牛校毕业的，他们却没有类似的问题。所以如果你碰巧是某牛校毕业的，也没必要对号入座。



    牛校综合症的主要症状如下：




    舔牛校的屁股。好不容易进了牛校，结果发现不是你上了牛校，而是牛校上了你。你不但被牛校上了，而且事后为了自己的面子，还不能说它的坏话。在你后半生中的任何时候，你都会毫不留情的把这家丑外扬的人灭口。


    显示牛校的标签。读了牛校，自然想享受不一样的眼光，不一样的待遇。可是如果不贴个标签，自己跟个农民工确实看不出什么区别。所以呢，一个常用的作法就是把自己的网络 ID 加上后缀，比如 shax_thu, shax_pku 一类的。另一种作法就是穿印有巨大校徽字样的衣服（一般是T恤或者hoody）。有些人毕业十几年了还留着母校的衣服，就是因为穿上之后显得牛气一些。


    死记硬背，创造力不强。由于牛校一般都不是“为学生服务”，而是“骑在学生头上”的，所以不管哪个国家的牛校，“世界一流大学”，其实大部分都是填鸭式的教育，跟中国的高中没什么两样。在牛校里，很多教授才不管你听不听得懂呢，照本宣科马不停蹄地写黑板，不懂的话你就是笨蛋，不配待在我们学校！牛校学生一般对抄笔记，做（抄）作业，考试非常的在行，对 GPA 非常的关注，而不是很在乎直觉，精髓和思维方法。牛校学生最常见的心理状态，叫做“人心惶惶”。创造力往往是和轻松悠闲分不开的，在牛校如此的忙碌和压力下，创造力怎么可能产生呢？牛校学生往往喜欢显示自己搞得懂各种看似高深，错综复杂的理论，而不喜欢化繁为简，化难为易，因为如果事情变容易了，他们就没有什么优越感了。知识对牛校学生来说是一种负担，而不是珍贵的礼物。学习对于牛校学生来说是一种任务，而不是一种乐趣。世界上最有创造力的天才，其实很多都不是什么牛校毕业的，有些进了牛校辍学了，有很多甚至是完全自学成才，就是这个原因。


    过度重视知识，忽视人格培养。知识其实和金钱一样，是庸俗的东西。中国有句很俗的古话叫做“书中自有黄金屋，书中自有颜如玉”，其作用就是把男人都变呆子，把女人都变妓女。牛校毕业并不能说明一个人人品的任何方面，因为牛校的所谓“教育”，根本就不是用来塑造人格的，而是用来训练机器或者牛马的。我就亲自领略过毕业于哈佛，普林斯顿，斯坦福，清华，北大等学校的人渣的“风采”。徒有野心和知识，太喜欢“奋斗”，却缺乏“人性”，有些甚至连基本的做人道理都不懂。这些人到了社会上，只会跟希特勒一样，给世界带来灾难。相反，非牛校毕业的人，很多更加随和谦虚，更加有人情味，更加善良，有些在专业上也强很多。


    喜欢膜拜和谈论牛人。很多牛校学生其实自己水平一般，头脑里却都是对各种牛人的膜拜和仰慕。他们喜欢拿这些“校友”的名气为平庸的自己撑腰。他们很在乎自己的学校出过什么名人，而没有清楚的意识到他们自己是什么人。




    门户观念强，很在乎校友关系。牛校学生对校友有一种莫名的亲切感，毕业多年还喜欢组织校友会，比较排外。非牛校学生跟人交往更加随和，一般都不管你是哪个学校出来的。进入牛校，图的往往不是学识，而是“名气”和“关系”，因为这些穷孩子认为牛校是自己通向“上流社会”的阶梯。所以如果某牛校学生听说你是校友，总是喜欢问“你是几字班的？”然后刨根问底的想了解你的底细和历史。


    歧视外校来的研究生（博士生）。所谓“母校”，只是对本科生而言的。如果你本科不在牛校，而是通过考验或者保送进入了牛校，请注意了：你会被牛校的本科生歧视，融不进他们的圈子！本科生们会认为，你本科考不上这个牛校，本科毕业又没能力出国，而考研或者保送（直博）要比高考容易很多，所以你并不是跟他们一样的天之骄子。很多本科生在背地里议论外校来的博士生，都是：“这个人连XX都不会，不知道是怎么进来的！”就连你博士毕业多年以后参加校友会，别人都会问你是“几字班的？”意思是，本科哪一届的？如果你告诉他你是研究生才进牛校的，你就会受到不一样的礼遇。


    优越感强，幽默感差。牛校学生一般对自己学校的所有事情都很当回事，开不起玩笑。特别是没有自嘲精神，面对别人对自己学校，教授，或者自己公司的不重视，会非常的恼怒。牛校容易出呆子，不管什么事情，总喜欢故作高深的从“理论”上追究个所以然，而忽略自己对它的简单感受，从而显得很无趣。


    爱显示优秀。牛校学生满脑子都是“优秀”，他们太在乎自己和别人是不是优秀。他们所谓的“优秀”其实是非常世俗的，就是将来找得到好工作或者发得了财，而不是给社会带来美，快乐，和平和真正的福利。牛校的女生喜欢找“优秀”的男生做男朋友和丈夫，不顾他们长得是否帅气，是否可爱，善良，浪漫或者有趣。很多女生喜欢一些眼露凶光的“优秀男”，大概是因为她们自己太弱了，没法独立生活吧。牛校学生不关心世界的贫富分化和经济危机，因为他们自己就是这些危机的罪魁祸首。牛校学生喜欢的，其实是一个弱肉强食的野蛮世界。


    爱比较。牛校学生喜欢拿自己和别人比较，为自己制造永无止境的高标准和压力。所以牛校学生似乎永远都快乐不起来，因为他们总是这山望着那山高。如果他们嫉妒你，自己却又没法把你比下去，他们就会故意谈论另一个优秀的人，甚至当面拿你和他做比较。总之，他们所做的一切，就是不择手段的让你更加自卑。牛校学生容易跳楼，就是这个原因，因为他们总是感觉其它人都很优秀，感叹自己不如人，而其实呢他们只不过被其他人设计的假象迷惑了。


    脑子里都是数字。牛校学生满脑子都是数字：学校排名，考试分数，GPA，级别，论文引用数，会议影响因子，存款金额，年龄，身高，体重，罩杯尺寸，…… 喜欢数字的原因是他们爱比较，数字可以很方便的做比较，不像其他非数字的事物。 由于不重视感觉，他们不能理解数字不能衡量的很多东西：直觉，感觉，幽默，感情，爱，艺术……


    缺乏生活情趣和休闲精神，喜欢把娱乐当竞赛。牛校学生对待所有娱乐活动都像专业一样严肃，仿佛他们的生活里除了学习还是学习，除了竞争还是竞争。打个网球喜欢追究挥拍动作的角度，兢兢业业的练习所谓“步法”，喜欢比赛，喜欢参加“分级考试”（又一个爱数字的表现）。跑步喜欢绕着规规矩矩的椭圆或者长方形的路线，喜欢设定固定的距离，跑步时不看风景，不关注身体的感觉，关注的是“成就感”。拍照喜欢用巨大笨重的单反相机，喜欢研究各种专业摄影技巧，拍照的目的主要不是为了自己欣赏，而是为了显示给人看。爬山喜欢追求各种先进装备，拿着个 GPS 去险峻的荒山野岭暴走，不懂得欣赏和享受风景，纯粹的自虐狂。平时喜欢埋头快步走路，因为他们在学校里一般就是这样在宿舍，教室，图书馆三点一线间穿梭。遇到集体爬山郊游活动，牛校男生一般都在前面暴走，把女生远远丢在身后。


    喜欢炒作“美女”。由于牛校女生稀少得像大熊猫，所以牛校的女生宿舍一般被叫做“熊猫馆”。一旦有不戴黑框眼镜，看得顺眼些或者稍微会打扮的女生，很快就会出名，然后被男生评为班花，系花，院花，或者起各种绰号，比如“奶茶妹妹”。其实这些女生到了牛校之外真的很一般，可是由于牛校男生见过的美女太少，而且为了反驳外界关于“牛校美女少”的舆论，所以喜欢炒作她们，想让人知道“我们学校也有美女”。而其实呢，牛校的美女能出名，正好说明了那里的美女少。美女如云的地方，美女是出不了名的——天上的云朵有名字吗？牛校男生的几乎一切古怪特征（喜欢显示优秀，把娱乐当竞赛等），很多都是为了赢得那几个美女的青睐。看我 GPA 4.0，钢琴练到十级，网球都打到五级，所以你应该嫁给我！




   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 我和 Google 的故事（2015 修订版）

 
 
 
 
    

    
 
     
  

      
   
我和 Google 的故事（2015 修订版）

    2009 和 2010 年，两年的夏天我都在 Google 实习，然而最后毕业的时候我却没有为 Google 工作。虽然我心里很清楚这里面的原因，可总有些人觉得不解，为什么居然有人不想为 Google 工作？如果你是这些人其中之一，那你可能想知道我在 Google 时的切身感受。



    直到将近 2015 年新年的今天，我发现这篇文章仍然具有普遍的意义。面对 Google 的员工，我仍然是同样的感觉。他们很多人太拿自己的公司当回事了，自高自大，放弃自己的尊严来舔这个公司的屁股。这些人总觉得好像所有人都希望为 Google 工作，即使进不了 Google，都想去 Google “蹭饭”似的。如果一个人说“我很厉害”，我也许会尊敬他，可是如果他说“我为 Google 工作”，以此来显得厉害，我就会鄙视他。我只尊敬那些尊敬他们自己的人。以自己的公司名声来抬高自己的人，是最被我瞧不起的，因为他们跟仗着人势的狗没什么区别。



    


进 Google 很难吗？


    每当我告诉别人我在 Google 实习过，总有人说：“哇，你好厉害。Google 很难进的！”我说：“一点也不难啊。”他就会说：“你一定是从 MIT 之类的牛校毕业的吧？”然后我就无语了，我不屑于跟这样的人说话。首先，进 Google 的门槛真的很低。说白了，Google 只需要一些低级码农而已！世界上有很多比 Google 技术精深而且尊重个人的公司，所以 Google 并不是很多有志之士的首选。其次，我厉害并不是因为我从 MIT 或者其它什么牛校毕业，而是因为我自己的资质。这种资质不是读了 MIT 或者 Stanford 之类就可以得到的，所以其实我根本不把这些牛校当回事。相反，我看不起这些学校，觉得它们不但徒有虚名，而且相当浮躁。所以说这话的人原意是奉承，结果反倒贬低了我的个人价值，招致我的轻视。



    能进 Google 确实是因为我很厉害，但其实比我弱很多的人也可以进 Google，所以能进 Google 根本不能说明我的实力。你认为我到 Google 实习，我的导师们很高兴，很支持，觉得很荣耀吗？恰恰相反，他们觉得我贱卖了自己，我本来应该去更好的地方。当我回到学校，我发现自己成了师兄，老师们的嘲笑对象。有个在 Google，微软研究院等地方都实习过的师兄说：“Google 那种地方去一次就够了，你居然去了两次！”有新同学问道，从我们这毕业，将来能去 Google 工作吗？有个老教授笑笑说：“那个还不容易？Google 招收任何可以做出他们题目的人！”其实正当我在 Google 实习的时候，有在微软研究院的同学来找我，很不解的样子，说：“你为什么不来微软研究院？Google 根本不是搞研究的地方。”后来我才发现，微软对员工个人价值的尊重，明显好于 Google。在微软工作，你至少不需要舔微软的屁股。



    那么既然不是那么喜欢 Google，我为什么还要去 Google 实习呢？其实原因很简单很世俗，我当时需要一些钱，而 Google 是最容易进去挣点钱的地方。我这人从来不担心所谓的“前途”或者“事业”，因为我知道自己能力有多么强大。我不觉得为任何公司工作是一种荣耀，我只是有时候拿我很小的一部分技术，出去换点吃的回来。看上去很市井小民吧？但这个世界就是如此，我只是跟它做交易。我就像一个雇佣杀手，专门搞定别人都搞不定的事情。得到这些技术的公司（包括 Google，Coverity，Sourcegraph），其实都很是赚了一笔，因为我卖给他们的东西，比他们给我的工资，价值要高很多。如果没有我，他们可能永远也不会做出具有同样高品质的东西。我敢打赌！



    好了，还是来看看我在 Google 的时候都发生了些什么吧。


受命于危难


    先说说我的项目是怎么开始的吧。当我加入的时候，我的老板 Steve Yegge 的小组试图制造一个跨语言的“服务器”式的编程工具，叫做 Grok。你可以把它想象成 Eclipse, 但是 Grok 的设计目标不只是像 Eclipse 那样检索和分析本机的某一种语言的代码，而是大规模的检索和分析 Google 的所有项目，所有语言，所有代码。这包括 Google 的“四大语言”：C++, Java, JavaScript, Python，一些工具性的语言：Sawzall，protobuf 等，还有一些“build file”和所有第三方的库。Grok 的初期设计目标是一个静态的代码索引服务，只要程序员点击任何一个变量或者函数名，就能“准确”的跳转到它定义的位置。动态的编辑功能稍后也在陆续加入。



    这种检索不是像 ctags, etags 那种简单的正则表达式匹配，而是像 Eclipse 和 Visual Studio 那样的准确的“语义检索”，所以它必须真正的理解程序语言的语义。在 Grok 诞生以前，市面上和 Google 内部都没有一个工具能正确的支持所有“四大语言”，所以我不得不说，Steve 的项目比起 Google 的其它跟编程语言相关的项目，是相当先进的。



    虽然 Grok 的技术含量很高，但是 Google 的管理层对东西的评价并不是看技术含量的，而是看你有多少“影响力”(impact)，说白了也就是有多少用户。Google 当时本来就只有不到一万个程序员，一个“内部编程工具”能有多少“用户”呢？所以 Grok 比起像 CodeSearch 一类利用正则表达式来查询程序的“低端”项目来说，在管理层心目中并不占任何优势。而且由于其它项目界面好看些，用户多些，Grok 随时有被取消的危险，这使得 Steve 心理压力很大。我就是在这个“危难关头”进入他们的小组的。我当然没蠢到会自己进入这样一个组，但是 Steve 在电话面试时把一切都说得很美好的样子。当时小组里只有三个人：Steve 和另外两个组员。


不安全感，恐惧和疑惑


    在整个实习的过程中，我都感觉到我所在小组成员的不安全感，这引起了他们的恐惧和疑惑。这种不好的心理状态持续了整个实习过程，使得我在别人的怀疑当中生活了三个月！我不知道如何安慰他们或者让他们相信我的能力，就像我不知道如何安慰一个没有安全感的女朋友。这种感觉，就像是一个女生不相信自己的魅力可以招来这么好的男朋友，所以各种怀疑，纠结，蛮缠。对于 Google 来说，就是不相信自己可以招到这么厉害的实习生。



    当我开始的时候，Grok 小组已经初步完成了 Java 和 JavaScript 的检索模块。但是他们的检索并不是从头设计的，而是从 Eclipse (JDT) 和 JSCompiler 里面分别“挖取”了对 Java 和 JavaScript 语义检索的部分，修改之后插入到项目里的。Eclipse 的设计非常的不模块化，以至于项目进行了一年多，大家还在忙着解决它带来的各种 bug。



    最开头的时候 Steve 给了我两个选择：检索 C++ 或者是 Python。我觉得 C++ 的设计太繁琐，所以就选择了看起来好一点的 Python。Steve 就让我去找一个好一点的开源的 Python IDE，然后把里面的语义检索部分挖出来插入到项目里面。可是在看过十个左右的“Python IDE”之后，我发现它们没有一个能够正确的“跳转到定义”。分析其原因，是因为这些 IDE 基本上做的是正则表达式匹配，而完全不理解 Python 的语义。所以我对 Steve 说，我要自己从头写一个。但他反对这个提议，因为他觉得这是三个月的时间之内不可能完成的。不但是我不能，而且就算一个小组的高级程序员也不可能完成。就算完成了，他也不想“维护”这些代码。所以他宁愿让我去拿一个不怎么样的开源项目，因为这样“维护”的工作就转嫁到开源项目身上去了。这也许就是 Google 支持开源运动的原因吧？



    可是我很清楚的看到，这样一个语义检索，不过是一个抽象解释器 (abstract interpreter)。写解释器是我最在行的，所以我告诉他这是我可以完成的，而且由于设计上的简洁，我的代码的维护代价会比使用一个开源项目小很多。他没有说话。我同时也在进行一些内部培训，看一些视频，折腾 MapReduce 一类的内部工具教程，就这样过了一个星期。我隐约的感觉到 Steve 的不快，因为他不怎么说话了，可是我也没有太在意，仍然傻乎乎的到处凑热闹。到了周五的时候，Steve 下午很早就回家了。另一个组员还待在哪里，不时的叹气。我对她说：“Steve 是不是不高兴了？我知道我说话有点太自信，可能打击到他了。”她好像打满的气球被开了一个洞：“他怎么会被你打击到？你知道他以前做的项目有多厉害吗？他是怕你做不出来。之前有一些 intern 设的目标太高，以至于到最后没有完成他们的项目。”于是她打开 Eclipse，把 JSCompiler 的代码给我看。“你知道我们以前一个类似的项目 JSCompiler，花了多少时间才完成吗？一个小组的人，四年的时间！”她打开其中一个文件，也就是处理符号表的那个模块，说：“看这一个文件就有 9000 多行代码。你三个月能写出这么多代码吗？”我翻了一下白眼，搞笑似地说：“啊～ 怎么可能有 9000 多行？这些人真的知道怎么写这种代码吗……”



    后来具体的对话我忘记了，但是她确实给了我一些压力，再加上 Steve 那个闷声子，真是不好受。所以那个周末我没有出去玩，我下载了一个 Jython，把它的 parser 文件 (ANTLR) 拿出来。然后自己设计了一个更简单的 AST 数据结构，把这个 parser 生成的 AST 转换成我的结构。然后就开始在上面写一个抽象解释器。由于 Java 的限制，我想出了一个更简洁的用 Java 实现解释器的方法，从而避免了使用繁琐的 visitor pattern。一个周末之后，我做出了一个基本的原型。当然因为 Python 语言的复杂性，有很多细节的东西到后来才完全的实现。



    等到星期一的时候，我告诉 Steve 我做了一个原型出来，而且因为我拿了 Jython 的 parser，我们以后可以用这个理由把这代码 merge 回 Jython，给他们提供功能，让他们帮我们维护代码，对两方都有好处。他居然一点也不高兴，把我叫到一个白板前面，板着脸说：“来，给我讲一下你打算怎么做。”我就画了一个 AST 的类关系图，在里面每个类插入一个叫 interp 的方法，然后指出这个东西就是一个抽象解释器。最后他豁然开朗了一样，说：“好。我相信你知道你在干什么了。就这样做吧。”



    虽然貌似经过我自己的努力和坚持，从头做一个工程的计划被接纳了，但是这却不是说之后就没有压力了。这种感觉就像是“皇帝的新装”里的织布工一样。我扬言自己会做出精美绝伦的布料，皇帝的大臣们却看不见，所以他们就相当的小心。总是对我很敬畏的样子，有时会来问候一下，做得怎么样了。可是一旦扯到深入的话题，却又怕被看穿其实他们不懂很多东西。


陌路


    




    在 Google 的整个夏天我都觉得跟其他人没有共同语言。我感兴趣的东西，他们一点都不了解。我觉得不以为然的一些东西，却被他们捧上了天。比如，有一次几个人在谈论一个 Google 的“牛人”，说他做了一个多么了不起的项目，很快就升为了 Staff Software Engineer （“Staff”是比“Senior”高一级的职位，Steve 就是个 Staff）。我去看了一下这项目，发现不过就是 JUnit 的“C++ 版本”。JUnit 这东西技术含量本来就是相当低的，做这样一个东西就能当“Staff”，那我岂不是轻而易举就可以成为“Principal”了？哈哈。我心里这样想，但是没有说出来。一个 Staff 就如此，谈到 Google 的两个创始人的时候，有些人就简直是黑白不分了。对他们的各种武断的甚至愚蠢的做法，居然都津津乐道。创始人在他们眼里俨然就跟皇帝一样，他们做什么都是对的。这种浮夸和互相吹捧之风，恐怕是在其它公司也少见的。Google 要求员工们保持一种“Googley”的态度，原来就是这样的态度，过度“正面”和“积极”。西方所崇尚的“个人主义”和“批判性思维”，我在 Google 还真的没有见到过。



    另一些时候，我会遇到一些对某种语言或者技术有宗教情绪的人。有次一个工程师坐到我面前，像是在面试我一样，表情严肃正儿八经的开始自我介绍，后来我们就谈到 C++。我说 C++ 设计实在是太繁琐了，其实很多简单的语言效率并不比 C++ 低，C++ 最近其实在向其它高级语言学一些东西…… 后来这人就不说话了。那天以后我就发现跟他打招呼他都不理了。后来我才发现，在 Google 是不可以指出某种语言，特别是 C++ 的缺点的。C++ 在 Google 的势力之大，连 Java 都只能算二流货色。



    最让我受不了的其实是 Google 的气氛。总体感觉就是过度“和谐”，没有人说真话，以至于你不知道什么好，什么不好。很多文档，视频，活动都挂着“Google Confidential”的标签。等你去看了，却发现相当幼稚，其实是众所皆知的东西，没有什么机密可言。可是大部分的实习生们却有一种受宠若惊的感觉，或者假装有这种感觉。每个星期五，都会有一个“TGIF”，两个创始人会像主持人一样组织一个大会。本来无可非议，但是总感觉气氛过于群情激昂了，有点像文化大革命时候念红宝书的感觉。好不容易大家聚在一起，总是在听新闻发布，不然就是谈工作。真正大家一起玩的 party，却非常稀少。所以一些别的公司的人都在疑惑，Google 的员工到底有没有下班的时间。



    我就是这样度过在 Google 的每一天，以至于后来我都不怎么在饭桌上吃饭了。自己把饭端到靠墙的吧台去吃，或者坐在“冰激凌吧”跟里面的厨师聊天，省得遇到一些高谈阔论的人无语。我发现自己跟打扫卫生的大妈小妹们也谈得来，她们也喜欢跟我说话。后来我发现有这种感觉的不只是我，另外两个比较厉害的博士生也懒的在那边吃饭了。其中一个说，Google 的人太傻了，他一个星期就把组里给自己三个月的项目做完了，因为这帮人完全不知道自己在干什么。


压力


    直到有一天，我才发现 Steve 为什么这么紧张。那天有另一个“分舵”的 director 来访。他给我们做了一个关于“创新”（innovation）的演讲。基本内容就是说，技术上的创新，如果吸引不到用户，那就不算什么创新，拉得到用户的东西才叫创新。



    那天下午，这个 director 来到我们的办公室。表情严肃的“审问”Steve：“你说你每天有 5000 个用户。可是 Google 总共还不到 10000 个程序员。你是怎么算的？你把接受你的服务的那些下游项目的用户全都算进去了吧！”唉，想不到大名鼎鼎的 Steve Yegge 在这种皇帝的钦差大臣面前也只能唯唯诺诺。



    我可以说，这个 Python 的东西，虽然不费我很多力气，但却是 Google 里很少有人可以做出来的。就算 Python 的创造者 Guido van Rossum 恐怕也玄，因为这需要比设计出 Python 这样的语言高深很多的专业知识，比如类型理论（type theory）和抽象解释（abstract interpretation）。所以实际上我的这个东西在很大程度上拯救了这个濒临灭亡的项目，因为一旦 Grok 支持所有的“Google 语言”，就会有很多人注意到这个东西，从而会有“影响力”。这确实是后来发生的事，我走了之后，Grok 开始通过 API 给很多项目提供服务，包括 CodeSearch。



    可是这种“上级领导”的压力居然也间接的传到了我身上，而且是以一种不尊重的方式。这种感觉就是，你做得再多再出色，你相对于 Google 的“大拿”们，什么都不算。这也许就是 Google 为什么雇佣 Dennis Ritchie, Brian Kernighan, Ken Thompson, Rob Pike, Guido van Rossum 等大牛吧。因为它就可以说：“看我们 Google 有这些顶尖牛人，相比之下你算个什么，要不断努力！”Steve 不止一次的对我说：“你要为 Google 做出杰出的贡献啊！Google 的东西总是最好的，你要做出 Google 一贯的品质来。你知道 Python 的创造者 Guido 也在 Google 吗？我一定会在他面前给你美言几句。”这种语气，我好像在几十年前的中国听说过呢？“你要为祖国做出杰出的贡献！”他也许以为我会受宠若惊，可是我心里却不是个滋味，因为在我心里，自己的地位一点也不比这些大牛低。“宠为下”的道理，你懂吧？



    总之他们就是用这种奉承，利诱，竞争，加威胁的方式，想方设法让我多做事情。可是我心里想的是，Google 老爹，您就给了那么点钱，您想买多少东西啊？本来这系统能做出来就不错了，一个组员却一直催着我写 test。她根本不明白，一个程序并不是写了测试就会是个好程序。这个程序经过我多次的大规模修改甚至推翻重来，即使一早写了测试，那些测试也会很快作废。这种大公司给人灌输的“test-driven”编程方式，在这种创造性的程序设计里是根本就是行不通的。要写出这样一个系统，必须全神贯注，深入到语言的本质。而去写测试，往往会打乱原来的思路，所以测试应该是最后完成之后才写的。当我最后完成这个系统，可以大规模的处理 Python 代码的时候，却听见从她的桌上传来一声沉闷的咆哮：“WRITE--THE--TESTS---”这真的非常的 Googley！


结果


    最后我顺利完成了整个项目，还没少休息和玩耍。现在它仍然是世界上最精确的 Python 分析器，每天都会把 Google 所有的 Python 代码索引一遍。很多内部工具比如 CodeSearch 里面的 Python 文件上的链接，都是这东西做出来的。我所有的代码加起来才 4000 行。处理符号表的模块只有 600 行。我怎么也想不通为什么 JSCompiler 会有 9000 行来处理这么简单的东西，但是也许这就是为什么 JSCompiler 花费了四年时间。


总结


    所以你看到了，这就是我对 Google 的印象。那种文化大革命似的气氛和对个人价值的忽视，就是我（以及其他很多有志之士）至今不为 Google 工作的原因。Google 是一个年轻的公司，所以比起 IBM，微软之类成熟稳重的老牌公司，确实难免显得浮躁。也许多年以后等它成熟起来，懂得如何尊重个人价值之后，我们还有合作的机会。


参考资料


    如果你想从另一个角度看看 Google 的问题，可以参考一下 James Whittaker 的博文《Why I left Google》。这个 James 当时是 Google 的一个 director，是 Steve 的老板。我从来没跟他仔细说过话，所以我不能对他做出任何评价。这个文章仅供参考。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 在三藩的两年

 
 
 
 
    

    
 
     
  

      
   
在三藩的两年

    今天对于我和三藩市（San Francisco，旧金山），是一个特殊的日子。两年前的今天，我来到了这座城市，举目无亲，没有一个朋友。两年后的今天，我决定离开这座城市，举目无亲，没有一个朋友。



    三藩，你真是一座神奇的城市。两年的时间，竟然可以交不到一个朋友。就连连年雾霾的北京，也有好几个朋友想得起我。看看网络上的评论，我发现自己不是特殊情况。有人说：“在三藩七年了，我终于有了第一个可以叫做朋友的人！”三藩，你就是如此的特别。你被评为全美国“浪漫事件发生概率最低”的城市，可我觉得，你其实也是“普通友情发生概率最低”的城市。有人说你“社交无能”（socially incompetent），我觉得的确如此。



    当我以高昂的房租搬进这个坐落于雄伟华丽的 Bay Bridge 旁边的小区，有一个台湾来的女孩正要搬走，把她的全套家具卖给了我。她告诉我，她就要回台湾去了，三藩完全不能和台北相比，完全没有生活气息，非常无聊。两年的时间让我目睹了，她的断言一步步的被证明为事实。



    三藩，当我第一次踏上这片美丽的土地，我的心充满了阳光，就像每天照耀在你身上的，加州阳光。可是，当我自信的走进小区的小卖部，用平时的幽默和友好态度对店员说话，我第一次在美国感受到了什么叫做“种族歧视”。第一次感觉到，自己被认为是一个不懂规矩的乡巴佬。我之前已经在美国生活了六年之久，从来没有在其它地方有过这种遭遇：Ithaca, Bloomington, 西雅图，芝加哥，纽约市，迈阿密，奥兰多。第一次还无所谓，可是这种事情发生多次之后，阳光离开了我，我的心里开始填充上阴影和对这座城市的失望。



    后来我才发现在三藩，你接受的服务态度，不取决于你是否有礼貌有修养，而取决于你的穿着，你的肤色，甚至你的发型，你无时无刻不在被其他人打量和审视。我觉得我的衣着和发型都已经够典雅了，可是我的黄皮肤黑头发是不会变的。很奇怪的是，最歧视中国人的人，不是美国白人，而是三藩市的“土著广东人”。在中国城（Chinatown），百货商场，机场，你常常可以看到这种广东大妈，营养不良的样子还板着个脸，看到白人就点头哈腰，看到中国人就显示出鄙夷的神色，仿佛在说：“不是美国公民吧？”“买得起吗？” 或者就吆喝：“没看牌上写着这是头等舱入口吗？你，走那边！ ”这种广东土著，也就是三藩市最穷，最吝啬，素质最低的人群，被其他种族的人所鄙视。他们仿佛想把这些年来在美国受到的委屈，都发泄到大陆过来的人身上。



    Chinatown 就是这种广东人的集中地。不要以为 Chinatown 会有什么好吃的，我可以告诉你，除了一两家饭店味道还不错，其它饭店的级别，从“难吃”到“完全不能吃”。服务态度嘛，很有可能是这样：满脸横肉的大叔服务员，用下巴夹着手机一边跟人聊天，一边把菜单扔到你面前，看都不看你一眼。你会疑惑他到底是给你服务的，还是你老板。你想去 Chinatown 买菜？那些人直接跟你说广东话，而且态度全都跟在吵架似的。所以几次苦头之后，我就几乎不去 Chinatown 了。可是土著广东人在这里势力是如此之大，听说一次有个导游路过 Chinatown 说了一句它的坏话，结果在舆论压力之下，这位导游被炒了鱿鱼。



    有人跟我说，他们去 Chinatown 都不敢说普通话，因为会被人鄙视，所以他们说英语，让那些人以为自己是日本或者韩国人。对于这种侮辱国格的事情，我是绝对不会做的。要么我根本就不去，要么我就要让你们知道，我是中国人，所以我不会说粤语，我的英文发音也不标准！我的口音，我的语法错误，全都是我，作为一个高贵的中国人，身份的象征！我从来不按照法语的发音读英语里的“外来词”，我觉得这是美国人自卑和附庸风雅的心理。为什么法语单词到了英语里面还要按原来的发音，而不是英文的规则？每当有美国人纠正我，我都嘲笑他们。你们美国没有文化，所以喜欢按法语发音，这样显得有点文化。我本来就会一点法语的，我能说完整的法语句子，可我现在说的是英语，我就是不按法语来念这些外来词，你把我怎么着？扯远了。



    广东人并不是唯一服务态度差的人群。三藩市不管哪个种族的服务生，服务态度基本是从漠不关心，直到极其恶劣。热情好客的，我还真不记得有几个。去咖啡店，经常遇到打扮入时（有时很gay）的店员，用打量的眼神看着你，仿佛在说：我是城里人，乡巴佬，懂得什么叫做时尚么，知道我的耳环什么牌子的么，还来这里买咖啡！时尚？比起纽约，巴黎，东京，甚至成都，三藩有什么时尚吗？三藩有什么文化吗？没有自我价值的人，才会在乎自己和别人穿什么衣服！告诉你，我是世界顶尖的精英，我的智力和收入，是你的好多倍，我穿什么什么就叫做时尚！对狗有点礼貌，狗还以为它真的比你地位高了。更气人的是某些超市的收款员，一看到是中国人，看都不看你，动作好像是在拿你买的东西来发泄似的，让你有一种想揍人的冲动。来看看一个纽约人给三藩市的评价：三藩人，根本不懂得什么叫做 customer service！我越来越觉得说到了我心里。



    三藩市的“社交无能”，并不止于这些市井小民，还在于充斥在这座城市里的创业公司（startup）。有很多人认为创业公司具有创新能力，而其实大部分创业公司都非常肤浅，没有任何自己的核心技术，只是拿大公司已经做好的组件来拼拼凑凑，然后到处拉投资。为创业公司工作，往往意味着超时超量的工作，巨大的压力，不受尊重，没有自己的闲暇时间。三藩市区里的公司，大部分就属于这种公司。所以可想而知，在三藩市你会遇到什么样的人群。创业公司的 founder 们往往有了点钱就妄自菲薄，喜欢鼓吹自己的“文化”，而忽略员工的个人价值和对他们的尊重。这些缺乏自尊的人，进而试图从对别人的鄙视中获取自己心里缺失的尊重，从而导致恶性循环。这种公司可能一开头热烈欢迎你加入，你以为有了自己的组织。可是后来你发现，你并不被作为这个城市的一部分。你只是一个外地来的打工仔，就跟国内人对待一个外地来的农民工差不多。这些“城里人”认为你是来工作的，来为他们服务的，好像你不是来生活的，你没有享受的资格一样。



    纽约，北京，上海，成都，…… 是有生命的，是活着的城市。成都东郊这么偏远的地区，一直到晚上11点还有人在遛狗吃夜宵，三藩到晚上8点就几乎没有人迹了。纽约的现代艺术博物馆（MOMA），放着世界上最伟大的传世佳作（莫奈，梵高，雷诺阿……）；三藩市的现代艺术博物馆（SFMOMA），收着比纽约 MOMA 还贵的门票，却连一幅大师的作品都没有，展览着一些不知哪里来，没有美感甚至恶心或者有毒的“后现代作品”。纽约的百老汇（Broadway），演绎着世界最高水平的歌剧；三藩的 Broadway，上面全是不入流的脱衣舞馆。所以有时候你纳闷，这到底是个国际化都市，还是个刚升级的“县级市”。文化这东西，还真不是钱可以买来的。



    住三藩市的人，很多都有一种想做“城里人”的虚荣心。仿佛农民刚进城似的，觉得住在城市就多么了不起。打心眼里觉得自己是时尚人，是富人。住着完全不值那个价的设备陈旧的出租房，还口口声声说那有文化气息。他们很多对三藩市的酒吧和夜店相当热衷。可是去酒吧夜店看了看之后我发现，破败不堪，无聊之极。在小区附近遇到几个中国女生，却总是喜欢中文说到一半开始冒英语，好像在显示自己“融入”得了美国社会，吊得到美国男人，所以我都懒得理她们了。三藩市，你有一种病，也许这就叫做“幼稚病”或者“脑残”吧。



    想到下个月就要搬离三藩了，我很开心。这座城市没有任何值得我留恋的地方，因为我在这里一个朋友都没有。



    （后记：）


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 恶评《星际穿越》

 
 
 
 
    

    
 
     
  

      
   
恶评《星际穿越》

    



    （Spoiler 警告，本文含有大量具体情节！）



    上周末受朋友之邀，去看了红极一时的《星际穿越》（Interstellar）。因为是在首映的第二天，人多不说，票价也贵一些。可惜开演没多久，我就发现这片子简直跟新闻联播一般味同嚼蜡，好不容易熬过那漫长的三个小时，到后面几乎是睁一只眼闭一只眼睡过了。



    回来之后却发现人们对它好评如潮，IMDB 评价居然达到 9.0，真是让我匪夷所思。当我正庆幸自己的欣赏水平还没被好莱坞颠覆的时候，惊闻公司小头目决定组织一次 team building 活动，其内容为“八个男人集体观看 Interstellar”。我哭笑不得，遂决定请假一天 :P



    我为什么认为《星际穿越》是烂片呢？原因如下：




    Geeky，呆板。导演似乎不认为自己是个导演，而是史蒂芬·霍金，所以通篇都在炫耀自己懂得多少宇宙学原理。他忘记了电影的主要作用是娱乐，电影最重要的价值在于它的故事性和戏剧性。物理学，宇宙学，飞船术语，看上去貌似很酷，但其实让这电影成为了让人犯困的课堂。自称喜欢这部电影的人，往往在于他们可以在事后炫耀自己懂得多少黑洞的原理。


    说教和煽情。“爱是可以穿越星际的力量，你感觉到了吗？”这屁话前不沾村后不着店的冒出来，唐僧了一遍又一遍，恐怕杨过和小龙女听了都会吐吧 ;) 爱是美好而重要的，然而它的力量和作用范围是有限的，不必如此牵强和夸张吧？而且这种感情的东西最好是从情节的点滴表现出来（比较一下好片《Life Is Beautiful》或者《西雅图不眠夜》），这样直白的平铺直叙，就索然无味，起不到效果了。这体现了好莱坞一贯以来的作风，跟我党一样，喜欢对民众进行“思想品德教育”，把观众当低龄甚至弱智儿童对待。这种说教倾向在 Disney 的片子里面最为明显，然而它也贯穿了许多本来旨在给成人看的好莱坞电影。


    主题肤浅，片面追求特效。一部电影应该有一个主题，所有的情节，特效，都应该是为主题服务的。这部电影的主题貌似是关于“爱”，然而它用于支持主题的情节非常牵强扯淡，以至于完全没有力量支持它所期望的主题。“5, 4, 3, 2, 1, 点火！”，炫酷的飞船和宇航服造型，主人公在船舱中的各种装模作样的操作，…… 好像很酷的样子？可是这一切都没法掩盖剧情的苍白无味。相反，剧情的肤浅让这一切的高科技模型，都显得像小孩子玩过家家的道具一样可笑。我看着那些飞船和宇航服，越看越像是泡沫塑料做的。“人间大炮，一级准备……” 好莱坞，多拍点给成人看的片子好不好？


    故作深沉，过于安静，感觉成本很低。片中有大量独白，有好几次就两个人在那里“说真心话”。这种对白如果有好的铺垫，少量出现的话会有效果。然而本片没有做好铺垫，所以这些对白突然出现的时候，让人感觉不自然，不真实，故作深沉，煽情，冗长。搞得整个放映厅里鸦雀无声，观众面面相觑，大气都不敢出，感觉不舒服不自在。片中很多外太空画面是完全的寂静，没有背景音效，让人感觉是不是拍片时资金不足，请不起人来做音乐。整个片子感觉非常“低成本”，低到了吝啬的地步，也许几个人在一个房间里聊聊天，然后用电脑做做特效，就可以拍摄完成。


    严重的“常理漏洞”。有物理民科朋友看了此片之后兴奋的叫好：片子里的物理学，黑洞原理，居然没有破绽！可是这位朋友虽然了解高深的物理学原理，却缺乏一种重要的，普通人都明白的道理，叫做“常理”。常理决定了特定的人在特定的时候该说什么话，该有什么行为。这片中的人物有一些非常严重的，违反常理的漏洞，让人哭笑不得。其中一个就是，快到穿越 wormhole 的时候，副驾驶拿起一张纸，开始循循善诱的给机长（主角）讲解 wormhole 是什么，以及它的工作原理，仿佛机长在这次目的为“穿越 wormhole” 的任务发射升空之前，完全不明白 wormhole 是什么似的。这就像是开着 F-18 到了航母面前，才开始了解它的跑道长度一样！



     我才不管你的 wormhole 理论讲解得有多么透彻多么通俗易懂，因为这样的对话根本就不应该在那个时刻，那个地点，在那些人物之间出现。能犯这样的错误，其最终原因还是因为好莱坞把观众当小孩，喜欢说教。这一番科普，俨然是导演安排讲给观众听的，而不是讲给机长听的。银幕前的小朋友们来看那，wormhole 就是这样的，就像一张纸，被折起来了哦，咔嚓…… 某些人看电影总是很“理性”的跟踪其中所描述的“高深理论”，如果发现没有破绽，“学到了东西”，就觉得是好片。只有当你跳出“学物理，理解宇宙原理”这一思想圈套，才会明白这些人物的行为是多么的可笑，荒唐，不合情理。剧中人物还有很多类似的诡异对话和行为，有待大家进一步发掘。


    又臭又长。故事很烂就算了，如果只有一两个小时还可以忍，可是此片居然有三个小时！所以真是忍无可忍，必须喷了！





    最后，我对观看此片之后深入探讨第一个星球上的大水如何可以弄死人以及最后女宇航员去了哪个星球之类“学术问题”的朋友表示崇高的敬意和深切的慰问！我对此类问题统一的终极答案为：导演的安排！


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 RSS与三不主义

 
 
 
 
    

    
 
     
  

      
   
RSS与三不主义

    总有人来信要求我给博客增加 RSS，我都没有回答他们。其实这个博客最开头是有 RSS 的，但是后来去掉了。现在我稍微有点空，就来解释一下为什么我的博客没有 RSS 以及类似的“推送”机制。



    其实不用 RSS 和不用微博的原因类似。本来博客是用来记录我的思想的，读者应该是因为感兴趣而不请自来的。他们想得起就来看看，想不起来就算了。根据“三不主义”的原则（不主动，不拒绝，不负责），来看文章的人如果不高兴了，那是不关我的事的。谁叫他们自己要来看呢？



    可是有了 RSS 就不一样了，因为它转换了被动与主动的关系。本来读者是“主动”来看我的博客，我是“被动”的，是不需要负责的。然而一旦有了 RSS，每一次发布却感觉好像是我“主动”在推给他们看，是我很想让他们看一样，是要负责的。某些人取消关注别人的微博时，口气总是好像觉得自己关注一个人，是给了他很大的面子一样，所以他们用取消关注来表示他们的“惩罚”。这些人显然把自己看得太高贵了。



    所以为了避免这种人，以及对其他人的心理产生类似的效果，我后来决定停止使用 RSS。虽然很多人使用 RSS 是一种良性的愿望，但是一旦有了 RSS，心理的变化是不由人的初衷决定的。所以要看我的博客，就必须自己想起来，然后主动到这个网址来查看，没有任何自动的更新功能。这样才能实现真正的三不主义 :P


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 谈创新

 
 
 
 
    

    
 
     
  

      
   
谈创新

    有人告诉我，我所说的很多事情只是在已有的事物上面挑出毛病来，那不能引起真正的“创新”。这使我想到了一个很久以来思索的问题：什么是创新？创新真的那么重要吗，它的意义何在？最后我得到的结论相当的惊讶，世界上并不缺少创新，而是创新过剩了！大量的所谓“创新”，让人们的生活变得纷繁复杂，导致他们需要记住更多事物的用法，而无法专注于利用已有的设施，最大限度的享受生活的乐趣。



    最缺乏创造力的人，往往是最爱标榜创新的。这些人（或者公司）不是为了设计出好用的东西，而是为了成名，是为了创新而创新。也就是这种人，最不重视吸取历史的教训，所以他们制造出来的“新事物”不是给人们的生活带来了方便，而是带来了不必要的复杂和麻烦。这种人的创新，只不过类似于给自己染上五颜六色，形状奇怪的头发，在自己身体上最特别，最显眼的地方进行纹身或者穿孔带环。创新不等于美，而且往往是与美背道而驰的。真正的美人，视皮肤为上帝赐予的最宝贵的衣服，绝对不会让任何所谓的“艺术”玷污它无暇的美。上帝的手艺是无人能敌的，所以那些不美甚至丑陋的人嫉妒了，他们要设立新的“美学标准”，于是他们开始纹身，穿孔，染头，奇装异服…… 现代社会很多所谓的“创新”，只不过是这种现象在技术领域的再现。



    创新往往也是与良好的设计理念背道而驰的。一个好的设计，总是力求减少“新”的感觉，而着重于让整个设计浑然一体，天衣无缝，用起来顺手。最好的设计就是让设计的目标消失掉，或者感觉不到它的存在。



    下面我举几个用巧妙的设计来避免创新的例子。


房屋装修


    中国人装修房子，可谓是创新相当的丰富了。各种稀奇古怪，穷形尽相的地砖墙砖，门把手，电源开关，水龙头，淋浴器，浴缸，喷头，地漏，热水器，洗衣机，微波炉，电冰箱……



    到了美国你才发现，美国人房子里的设备根本没有这么多花样。每一种设施几乎都有固定的，经过千锤百炼的设计，所以你随便到哪个朋友家里，发现那些东西都没什么特别。因为不好用的设计早已经被淘汰掉了，剩下来最好用的，其实没有几种。



    就拿电灯开关来说吧，美国的几乎所有房子，不管是便宜的出租房，还是高档一点的所谓“别墅”，电灯开关都是最简单的，不打眼的，就像中国早年工厂车间里那种“摇杆式”开关。所有的开关都一个样，所有的摇杆都一个大小，根本没有中国的开关这么多花样。



    



    这种开关首要的特点是安全，因为你不容易由于不小心靠在开关上而把它打开或者关闭。这种开关安装时一般向上是开，向下是关，摇杆的位置很明显，所以一眼就看得清楚它到底是开着还是关着。由于有一个很明显的突起的杆，所以半夜里你摸黑也能操作这开关，而不用考虑摸到的到底是开关的哪个部分，用手摸到一个凸起，向上一拂就开了。



    其它设备也只有非常少数的变种。然而让人惊讶的是，这每一种东西都比中国家庭里的上百种不同的设计更加好用，而且是想都不用想就知道怎么用。非常不起眼的，用了十几年的投币洗衣机，也比国内最新最炫的洗衣机洗得干净。而且中国家庭里缺少一种非常重要的设备：干衣机。美国的干衣机都是与洗衣机分离的，干衣机的马力相当的大，而且有一个很粗的铝箔管（像中国的抽油烟机管子），用于把水蒸气排到室外。这种简单价格又不贵的干衣机，不知道节省了多少麻烦，让晾衣服这种繁琐的工作成为了历史。中国人爱创新，于是他们发明了“好太太晾衣架”之类的东西。最近有些人变聪明了一些，在洗衣机里面加上了一体的烘干机，价格不菲。然而他们的烘干机却没有那根排蒸汽的管子，而是靠冷凝压缩水蒸气。这比起那便宜的软管，看起来真是“先进”和“创新”，然而它的效果永远都不会比有管子的干衣机好。



    



    美国人的卫生间没有地漏这种东西，也没有防滑地砖，因为美国人的生活有先进的“水隔离”理念：房子里面可以沾水的地方，与不能沾水的地方是完全隔离的。能沾水的地方包括洗脸池，浴缸，厨房水槽。其它地方全都不沾水，包括浴室的地板。浴室的地板上根本就没有可以下水的地方，一般是用整体的聚乙烯材料做的，所以光脚踩上去也不会感觉冷。由于没有缝隙，所以不可能塞进脏东西。有人就疑惑了，要是水弄到了地板上，怎么排水呢？答案是，除非出了比较大的事故，几乎永远不可能有大量的水弄到地板上。因为洗澡站在浴缸里，拉上浴帘，浴帘的下边沿塞到浴缸里面，所以洗澡时水永远不会溅到浴缸外面。总有一张干的浴巾在伸手可以拿到的地方，洗完澡用浴巾擦干全身再出来，所以水永远不会弄到地板上。所以美国的浴室里没有防滑地砖，没有地漏，没有拖把，却异常的干净，没有异味。由于水不会乱溅，大部分美国人的浴室里没有墙砖，而是涂上颜色温馨的漆，电源开关和插座也不需要防水的盖子。大部分中国人不理解这种生活理念，他们洗澡总是把水弄得到处都是，而且喜欢拿水冲浴室的地板。所以他们创新，制造出各种先进的“防滑地砖”，“潜水艇地漏”，“快干拖把”一类的东西。再在浴室里贴满墙砖，整个浴室仿佛就是一个大马桶。他们没有想到，只需要一个10块钱的浴帘，改变很小一个生活习惯，这些所谓的创新，都可以不存在了！



    



    有人问，如果美国的浴室真的出了重大事故（比如水管爆了）怎么办呢？你需要请人拿水泵来处理。不过这种机会是非常少的。


银行


    中国的银行也爱创新。各大银行都推出一代又一代的“电子狗”或者“U盾”，号称可以保护用户的账号安全。这每个U盾都需要一个特别的浏览器插件，而且没有一个是支持 Mac 的。每次回国都发现我的U盾被淘汰不能用了，又得去花钱另外办卡。而且这U盾一旦丢失，又得亲自去网点排长队办理手续，生命就这样浪费掉了。在中国网上购物，付账时要问你，信用卡是哪家银行的金卡，银卡还是白金卡…… 列出几十个选项。银行网上转账，问你的卡是在哪个城市的那个网点办的。老天，我五年前在北京办的卡，我怎么记得是哪个网点！



    美国的网银根本没有所谓U盾这种东西，没有必要安装浏览器插件，直接用最普通的浏览器就可以上。你只需要记住用户名和密码就可以使用网银，但这并不等于不安全。美国的网银有防止盗用的安全设计。比如“安全提问”，提示你输入一些只有你自己才能回答的问题，比如你妈妈的小名，你中学的名字。还有 IP 检测，记录计算机的安全级别等等。而且这些网银能完成中国的银行无法完成的很多事情。由于这个原因，美国银行的办事处排队的人非常少（因此没有取号机这种东西），因为大部分业务都可以通过网络或者电话来完成。有些银行甚至根本没有办事处，所有操作全部通过网络，电话，邮局进行。网上购物付账，只需要选择是 VISA，Mastercard，还是 Amerian Express（选项只有不超过5种），而不需要选择发卡的银行以及卡的型号（金卡，白金卡，返现卡，里程卡……）。美国银行转账，只需要提供目标银行的 routing number（银行的标识号）和账号就行。每个银行都是一个整体，没有支行和地域的概念，所以转账也没有必要说明是哪个支行开的户。



    由于美国信用卡的先进和简单，大部分交易全都通过信用卡完成而不是现金，再加上支票的使用，所以你很惊讶的发现，美国银行的办事处没有防弹玻璃，而只有很简单的柜台，就跟旅馆的前台一样。为什么呢？因为银行网点里面根本就没有很多现金可以让你抢，你去抢饭店可能还划算一点 :P



    美国的钱没有中国多吗？美国的银行没有中国多吗？可是为什么就中国的银行喜欢创新，制造出各种U盾，浏览器插件，防弹玻璃，取号机，而美国却喜欢利用巧妙的设计，使得人们的生活返璞归真？



    补充：有人跟我说支付宝基本上已经解决了银行的U盾带来的不方便，但是我认为支付宝永远也不能解决我所提到的问题。这是因为钱最终还是从银行转入到支付宝的，为了转账到支付宝，你又需要插入U盾，所以U盾一旦丢失，你就没法用支付宝了。还有人说手机银行解决了U盾的麻烦，然而这只不过是用手机（另一种物理设备）代替了U盾。如果你把手机丢了，或者你出国旅行，或者你欠费了，急需操作网银怎么办？这貌似一个鸡和蛋的问题。


美国和中国


    在这里提到美国的优秀设计，并不是说我更喜欢美国。每次提到这些，总有朋友感觉不平，仿佛觉得我是“美帝的走狗”一样。我其实对任何国家都没有特别的感情和归属感，我的感情只针对个人，而不是国家。实际上，我认为国家这种东西是不必要存在的。美国人对我显然没有很多中国人对我好，然而技术和设计是没有国界的，好的东西不学就等于永远落后。很多中国人喜欢用所谓的“民族自豪感”来代替理性的思考，看不到自己的问题。中国为什么到现在还属于第三世界国家，恐怕就有这里面的原因。没有用心，就不能提高。中国的经济发展了，国家的总资产可以说已经很多了，然而有很多东西不是钱就可以买来的，它需要用心设计。看，我在美国受了这么多的苦和委屈才学会了这些，如果你们不理解消化，那多可惜啊。



    美国人在硬件上的设计意识，可以说是深入人心。美国人的设计能力，可以说是达到了出神入化的地步。非常不起眼的一个东西（比如门把手，水龙头），里面可能已经包含了几十几百代不同的设计。设计师们会把历史上各种不同的设计的优点吸取，而把不好的地方改善。在美国生活了很多年的人回到中国，自然感觉各种不顺手的地方，然而并不是每个在美国的中国人，都仔细的思考了我所观察到的先进设计，所以他们虽然发现不方便，却不知道为什么不方便。很多中国人在美国生活，却没有学到他们的生活习惯里面好的部分。



    然而美国人在软件，特别程序语言上的设计能力还远远不够，所以才出现了这么多程序语言。美国大公司和国防部标榜着“创新”的旗号，结果设计出的每一种语言都没有完全吸取历史的教训，反复的犯同样的错误，以至于有些语言制造的问题比它们解决的还多。其实程序语言里面哪有很多可以创新的地方呢？如果一个语言能够避免已知的所有设计问题，那它就已经可以比现有的所有语言好了，它不需要任何新的功能。


创新已经贬值


    所以创新的能力和“找毛病”的能力，我更看重后者。我觉得创新的价值和重要性，被人们过度的夸大了，以至于成为了一种吸引眼球的广告词。一味的试图创新而不仔细思考，是人们的生活由于各种“新事物”而变得复杂的重要原因。这就是为什么有人问我 Yin 语言有什么“新功能”，我都觉得可笑，无法回答他，因为对于一个语言设计者真正重要的事情，并不是创新。



    我喜欢观察人使用一种物品或者一种语言时的行为和心理状态，经过理性的分析，从而理解到底他们遇到了什么问题，到底什么才是合理的设计。没有任何设计是全新的，只有非常有必要的时候，我才会考虑加入新的功能。而且这些新的功能必须经过反复的推敲和实际的考验，确保它们不会带来新的问题。



    只有你能从已有的东西里面看到实质的问题，你才有可能达到天衣无缝的设计。设计不需要全新的，它必须最大限度的让人可以方便的生活，而不需要记忆很多不必要的指令。否则如果你不吸取历史的教训，做出所谓“全新”的设计，那么你很有可能不是解决了问题，而是制造了问题。我觉得有一句话说得好，忘记历史就是毁灭未来。


推荐读物


    鉴于中国很多东西缺乏设计思想，我建议每个中国人都看看这本书：The Design of Everyday Things，你一定会有焕然一新的感觉。



    


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 谦虚不是一种美德

 
 
 
 
    

    
 
     
  

      
   
谦虚不是一种美德

    人们常说谦虚是一种美德，然而我发现其实并不是这样。



    首先，谦虚是一种不诚实，虚伪的做法。这是因为谦虚的定义本身就意味着你要对自己的资质有所保留，直白点说就是，你要撒谎说自己其实没那么好！比如一个本来很有才华的人，做出了一个顶尖的研究成果，非要谦虚地说：“哎呀，比起某某大牛的成就，其实还差得远……”这种说法，把他自己的成果掩盖在别人的阴影之下，以至于让人难以看到它的价值，这对于世界的学术水平的提高其实是一种损失。谦虚本身就是一种谎言，你说它能是美德吗？



    其次，谦虚的产生跟嫉妒有很大的联系。中国有句古话叫“枪打出头鸟”，就是人们嫉妒情绪的写照。如果一个女人很美，或者穿得很华丽，在场的所有女人就开始嫉妒她。如果一个男人很出类拔萃，同行的男人们都开始嫉妒他。所以呢，如果你称赞一个中国女人很美，她的回答往往不是“谢谢！我也这么觉得！”而是“哪里有~不如那谁谁谁……”如果你称赞一个中国男人很聪明，他往往对你说：“不敢当不敢当！哪有领导您聪明呢~”他们之所以说这样的违心话，就是因为害怕其他人的嫉妒，害怕其他人因为嫉妒而伤害自己。嫉妒是一种极其卑劣的情感，而谦虚经常来源于对嫉妒的恐惧，你说它能是美德吗？



    所以，谦虚其实不是一种美德。它是一种虚伪，一种妥协，一种无奈。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 怎样成为一个天才

 
 
 
 
    

    
 
     
  

      
   
怎样成为一个天才

    有人说我是天才。我一直“谦虚”得很， 从来不承认。可是纵观像 John Nash，Richard Feynman 这些公认的天才的各种特征和生活遭遇，我发现自己还真是一个天才。我知道这个事实已经很久了，这一方面让我开心，另一方面又让我痛苦。可是除非洗脑技术高度发展，一旦成为了天才，就很难再还原成普通人了。所以目前我只是做一天天才撞一天钟 :)



    那么天才到底是什么呢？我想这是很多人都不明白的问题。大部分人都是人云亦云，别人说这人是天才，他们就以为是天才，也不仔细看看这人思想如何，就开始膜拜。所以现在我作为一个天才，本着学究的态度，对天才的本质做一个探讨，然后介绍一下成为天才的方法。


天才和聪明的区别


    很多人都把天才和“聪明”混为一谈，以为天才就是非常聪明，头脑特别快，或者记性特别好的人。可是天才往往并不显得聪明，想问题也并不快，而且记不住很多东西。天才的价值并不在于快，而在于他们能想出其他人都想不出来的东西。



    人们的这一误解往往是因为媒体和传记作家对天才的肆意吹捧。传说有人问过冯诺依曼一个问题：两列火车相距100公里面对面行驶，时速50公里。一只苍蝇以时速75公里在两个火车头之间来回飞，碰到一个火车头就掉头飞向另一个，如此反复。请问苍蝇被这两列火车挤死的时候飞过了多少距离？冯诺依曼眨了一下眼说：“75公里。”这人很惊讶，问冯诺依曼你是不是听说过这道题，用了捷径。 冯诺依曼说：“什么捷径？我只不过做了一个积分而已。”



    这就是一个典型的“都市传奇”（urban legend）。我觉得冯诺依曼只不过是幽默了一下，结果就被某些人永远的记录在册。这种故事的负面作用，在于它夸大了天才头脑的“硬件性能”，让其他人觉得成为天才是可望而不可即的事情，从而对其进行膜拜。能快速的心算做积分，真的是很了不起的事情吗？恰恰相反。夸大头脑的速度，其实贬低了冯诺依曼，让人误以为头脑速度快就是他的天才之处。现在如果你把这积分式子输入到 Mathematica 或者 Maple 里面，不到一秒就算出来了。这机器都能做的事情，能说明人是天才吗？冯诺依曼的天才不在于他自己的头脑速度快，而在于他提出的一些理论，导致了比任何人的头脑都要快很多的机器的产生。这些机器产生的目的，是为了帮我们偷懒，把我们从繁琐枯燥的计算活动中解脱出来。



    所以，头脑的硬件性能并不是天才的本质特征。头脑速度快的人，跟跑得快的人差不多，只是体力比较好。我欣赏跑得快，体力好的人。大自然赋予了他们其他人没有的财富，但那并不叫做天才。也许那种天赋的速度比天才还要难得，但天才往往不喜欢太快，因为过快的速度会让人变成机器，停止思考，走上歧途。天才喜欢反复审视前进的方向，所以他们经常能找到偷懒的方法。天才喜欢偷懒，并且利用巧妙的设计让大家都可以偷懒。


从动手中学习（learn by doing）


    如果你看过 John Nash 的传记《A Beautiful Mind》，就会发现他与其他人的不同。Nash 看书只看封面和开头，把这书要讲的问题了解清楚之后，就自己动手解决。最后，他完全依靠自己的“头脑暴力”创造出整本书的内容。Nash 头脑里的数学知识，绝大部分是他自己造出来的，而不是看书看会的。也就是说，他把整个的研究领域作为一道道的练习题，用这种方式独立创造出了大部分的现代数学！Learn by doing, 这就是天才最重要的特征。



    另一位天才 Richard Feynman 也有类似的特点。由于他脑子里的东西基本都是自己想出来的，所以同一个名词，在他头脑里关联的概念，其实是跟其他人很不一样的。这种现象体现在他的自传《What Do You Care What Other People Think?》里面，他说：“我不知道这个东西的名字，但我却知道这个东西是什么。”这也体现在他的一些演讲视频里。看 Feynman 演讲的时候，有时候你发现他用错专业名词，或者想不起来叫什么，跟听众确认了发明这概念的人不在场，然后说：“反正那家伙不在……所以管它叫什么呢。你们知道我在说什么就行！”



    天才往往依靠自己的直觉和想象力，而不是经验。这就是为什么爱因斯坦说“想象力比知识更重要”。天才记不住那些吓人的名词，却更深刻地知道那些名词所代表的意义。天才不喜欢显示自己知道很多，不以自己“不知道”为耻，因为虽然他可能暂时不知道一些东西，却总能在需要的时候琢磨透彻，所以知不知道一些东西，很多时候其实是无所谓的。也许这就是所谓“大智若愚”吧。


怎样成为一个天才


    现在我来讲一下，如何成为一个天才。其实说实话，我现在有点后悔自己为了成为天才费了这么大力气，放弃了那么多的乐趣。所以看过这段之后，你也许就不再想成为天才了。不过如果你执意要做天才，也许会受到一定的启发。



    人们常说，天才出于勤奋，所以首要的一点是你必须为此投入巨额的努力，甚至做出巨大的牺牲。从我的经历来看，这一点也不假。天才都是孤独的，因为只有孤独，他们才能有自己的时间和空间来进行思考。为了成为今天的自己，我放弃了很多其他人追逐的东西，可以说是经历了千辛万苦。



    仅就孤独这一点，就足以让很多人望而却步了。但仅有艰苦卓绝的勤奋，也不一定能成为天才。你必须把勤奋用在巧妙的地方。在计算机领域，很多人喜欢抱着大部头的专业书籍看，其实那是事倍功半的努力。学而不思则殆，就是这个道理。书籍让你记住了现成的“事实”，却不能让你拥有产生出这些知识的能力。它们只是把你“训练”（train）成了循规蹈矩的流水线工人，而不能让你受到真正的“教育”（education）。真正的好书都是很薄的，“把厚书读薄”这句话其实是误导的。厚书本来就不应该拿来读，最多可以拿来当字典查。所以我的建议是：如果你想成为天才，就避免去读厚书。去寻找简短的书来入门，然后就可以自己思考了。这就是我从 Nash 的故事得到的启发。



    笛卡尔（René Descartes）写过一篇文章，讲述如何成为一个天才。他说，在人生中的某个时候，他决定开始仔细检查自己头脑里的思想。他翻出自己所有的想法，寻找它们的最初的“来源”，然后审视它们。这种来源有可能是父母，有可能是传统，有可能是学术权威。当他发现某个来源有问题的时候，他就抛弃从这个来源获得所有想法。我从这篇文章得到了启发，所以我也用了很多年时间，对自己头脑里的想法做了一件差不多的事情。你可能很难想到，一个不知不觉窜到你头脑里的错误想法，会导致你永远无法发现更好的东西，甚至会毁掉你的一生。因为这个原因，我抛弃了很多未经思考就接受的权威的思想，我抛弃了很大部分的中国传统，我审视美国和世界的文化，尽一切可能的防止错误的思想进入我的头脑。所以虽然我并不富裕，我却拥有比很多富有的人更多的自由。这种自由，给了我思考的时间和机会。



    要成为天才，必须要能够打破别人设下的思维圈套。去除自己头脑里的各种权威，是非常重要的事情。你必须首先在心理上把自己放在跟本领域的权威平起平坐的地位，才能有效地对他们的想法做出判断和消化。我喜欢对权威显示出藐视的态度，就是这个原因，这是一种“矫枉过正”的方法。因为他们最开头在我心里还占有很重要的地位，为了把他们轰下去，我最开头是很激烈的藐视。到后来自己的认识因此迅速加深之后，才开始慢慢的理解到他们其中一些想法的启发意义。最后那种激烈的情绪逐渐消亡，他们在我心里也就变成了很普通的人。对于计算机领域的人我想强调一点，你们特别需要注意看到 Unix 系统的缺陷。很多人盲目的崇拜 Unix 的创造者，这使得他们看不到它们的设计缺陷，看不到 Unix 的设计者思想的局限性。不错，胜者为王的心理可以让你找到一份好的工作，但我在这里讲的是如何成为天才。Unix 的创造者并不是天才。



    要成为天才，你必须使用直觉（或者图形），而不是符号（或者文字）进行思考。这是很显然的事情，因为人脑根本不是用符号进行思考的。符号只是不同的人脑之间进行信息交互的媒体，就像电脑之间的网线上传输的信号，它并不存在于思维活动中。有些人可能会告诉你，直觉是不可靠的。这些人并不是天才，所以不用听他们说什么。直觉可靠与否，是由你自己的造诣决定的。这些人没有得到可靠的直觉，所以他们就连直觉的价值一起给抹杀了。这里面也许有嫉妒或者故意误导的成分。真正的天才，比如 Nash 和 Feynman，都是用直觉思考的。别人的公式在进入他们头脑里时，首先被翻译成某种“思维模型”，然后他们的头脑对这种模型进行思考。他们通过直觉对这些模型进行变换操作，得出结果。然后他们用符号把这结果表示出来，为的是给其他人看。那些完全用公式进行推导的人，往往是纸上谈兵，只能做出衍生的结果，而不能做出突破性的发现。



    为了得到直觉，你必须去接近自然界，必须出去寻找灵感。这就像作家需要出去“采风”，画家需要出去“写生”一样。蹲在家里看书，思考，会让你的思维局限于文字和符号所能表示的东西，没法达到突破。如果你能看到我的头脑如何思考，你就会发现，当我的眼睛看到代码或者公式的时候，我的头脑看到的并不是代码和公式，而是自动把它们翻译成了一些电路，流体导管一类的东西，它们存在于一个具有多重现实和历史的，像 Matrix 一样的世界里。这些直觉都不是从书里来的，也不是老师教的，而是通过观察身边的事物得到的。这就是为什么你听说有位古人洗了一个澡，然后发现了重大的物理学规律。Nash 在酒吧看到一个绝色美女，然后想出了他最著名的成果。



    另外，你还需要休息。很多人一天学到晚，一天想到晚，以为这样就可以有所成就。可是人脑需要足够的休息和间歇的时间，才能从你想过的，看过的东西里面提取出精华的东西。Feynman 有个方法我觉得很管用。他说，如果你想成为天才，就在你的头脑里随时准备好12个需要解决的问题。每当你的生活中发生一件事，就把这些问题拿出来检查一下，看其中是否有问题会得到进展。当然，你不一定要准备12个之多，也不需要刻意的去回忆它们，否则你就会很累。这个过程应该是由“潜意识”来完成，而不需要你做出努力。如果经过了比较深入的思考还没有得到结果，你可以出去放松一下，然后说不定忽然间你的问题就被解决掉了！这是因为一旦你启动了有意识的思维，当你停下来去做其他事情的时候，你的头脑并不会停止思考，而会把这问题转交给潜意识。潜意识有一种神奇的力量，它会在接受到外界的某种微妙的激发之后，忽然间顿悟。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 休息，休息一会儿

 
 
 
 
    

    
 
     
  

      
   
休息，休息一会儿

    



    本人进入了比较长的，理所应得的休息和娱乐时间。无聊时也看看闲书和电影。这里推荐几个最近看的东西。


《The Design of Everyday Things》


    最近给我最大影响的是这本1988年出版的《The Design of Everyday Things》（简称DOET）。有趣的是，它的作者 Don Norman 曾经是 Apple Fellow，也是《The Unix-Haters Handbook》一书序言的作者。



    DOET 不但包含并且支持了我的博文《黑客文化的精髓》以及《程序语言与……》里的基本观点，而且提出了比《什么是“对用户友好”》更精辟可行的解决方案。



    我觉得这应该是每个程序员必读的书籍。为什么每个程序员必读呢？因为虽然这本书是设计类专业的必读书籍，而计算机及其编程语言和工具，其实才是作者指出的缺乏设计思想的“重灾区”。看了它，你会发现很多所谓的“人为错误”，其实是工具的设计不合理造成的。一个设计良好的工具，应该只需要很少量的文档甚至不需要文档。这本书将提供给你改进一切事物的原则和灵感。你会恢复你的人性。



    值得一提的是，虽然 Don Norman 曾经是 Apple Fellow，但我觉得 Apple 产品设计的人性化程度与 Norman 大叔的思维高度还是有一定的差距的。



    如果你跟我一样不想用眼睛看书，可以到 Audible 买本有声书来听。


《The Conquest of Happiness》


    每个人都想得到快乐，但是他们往往误解了快乐的来源，追求了错误的东西，所以大多数人因此得到的是痛苦，并且给其他人带来痛苦。英国哲学家和数学家罗素写于1930年的《The Conquest of Happiness》就是彻底的分析这些2014现代人的常见问题的。



    在第一部分，罗素透彻的分析了几个常见的不快乐的原因：看破红尘，竞争，过度追求刺激，疲劳，嫉妒，罪恶感，被害妄想症，…… 第二部分，他提出了得到快乐的有效方法。



    如果你认为自己没有这些问题，或者认为自己懂得这些是怎么回事，请再次反思一下，因为每个人都或多或少有这些问题。特别是我发现，竞争和攀比所带来的不快乐，在中国人里面是很普遍的现象。


大独裁者


    谈到人性，我推荐卓别林在电影《大独裁者》里面的最后演讲。他引起了我对技术的价值的思考。有人说，世界不是毁在疯子手里就是毁在工作狂手里，是有一定的道理的。


摩登时代


    其实比《大独裁者》更幽默，更有趣，对现代社会更有意义的，是卓别林的《摩登时代》。这样一部1930年代的黑白无声电影，道出了直到2014年的今天，世界上最大的问题：过度工作。



    现代社会很多人为了所谓的“生存”，把自己变成了一台盲目不停工作的机器。加班加点的干活，并且还试图让别人也变成跟他一样。一切都是为了工作，为了效率，为了“优秀”，为了出人头地。太多的野心，太多的目标，却对身边最简单的乐趣视而不见。试试放慢匆忙的脚步，思考一下自己在干什么吧！



    因为这些原因，我继续睡觉，这是拯救世界的最好办法 zZZZ


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 关系模型的实质

 
 
 
 
    

    
 
     
  

      
   
关系模型的实质

    每当我批评关系式数据库，就会有人说，SQL和关系式数据库的设计，其实偏离了E.F.Codd最初的关系式理论。关系式理论和关系式模型，本身还是很好的，只不过被人实现的时候搞砸了。如果你看透了本质，就会发现这只是一个托词。关系式数据库的问题是根源性的，这个问题其实源自关系式理论本身，而不只是具体的实现。



    人们总是喜欢制造这些概念上的壁垒，用以防止自己的理论受到攻击。把过错推到SQL或者IBM身上，是关系式数据库领域常见的托词，用以掩盖其本质上的空洞和设计上的失误。在下面的讨论里为了方便，我会使用少量SQL来表示关系模型里面对应的概念，但这并不削弱我对关系模型的批评，因为它们表示的是关系式模型里面的核心概念。


关系式模型与数据结构


    很多人把关系式理论和数据库独立开来，认为它们是完全不同的领域。而其实，数据结构的理论，可以很容易的解释所有关系式数据库里面的操作。



    关系模型的每一个“关系”或者“行”（row），表示的不过是一个普通语言里的“结构”，就像C语言的struct。一个表（table），其实不过是某种结构的数组。举个例子，以下SQL语句构造的数据库表：


CREATE TABLE Students ( sid CHAR(20),
   name CHAR(20),
   login CHAR(20),
   age INTEGER,
   gpa REAL )



    其实相当于以下C语言的结构数组：


struct student {
  char* sid;
  char* name;
  char* login;
  int age;
  double gpa;
}



    每一个“foreign key”，其实就是一个指针。每一个join操作，本质上就是对指针的“访问”，找到它所指向的对象。在实现上，join跟指针引用有一定差别，因为 join需要查“索引”（index），所以它比指针引用要慢。



    所谓的查询（query），本质上就是函数式语言里面的filter, map等操作。只不过关系式代数更加笨拙，组合能力很弱。比如，以下的SQL语句


SELECT Book.title
 FROM Book
 WHERE price &gt; 100



    其实相当于以下的Lisp代码：


(map .title
     (filter (lambda (b) (&gt; (.price b) 100)) Book)


关系式模型的局限性


    所以关系模型所能表达的东西，其实不会超过普通程序语言所用的数据结构，然而关系模型，却具有比数据结构更多的局限。由于“行”只能有固定的宽度，所以导致了你没法在里面放进任何“变长”的对象。比如，如果你有一个数组，那你是不能把它放在一个行里的。你需要把数组拿出来，旋转90度，做成另一个表B。从原来的表A，用一个“foreign key”指向B。这样在表B的每一行，这个key都要被重复一次，产生大量冗余。这种做法通常被叫做normalization。



    这种方法虽然可行，其实它只不过是绕过了关系式模型无须有的限制。类似这样的操作，导致了关系式数据库的繁琐。说白了，normalization就是在手动做一些比C语言的手动内存管理还要低级的工作。连C这么低级的语言，都允许你在结构里面嵌套数组，而在关系式模型里面你却不能。很多宝贵的人力，就是在构造，释放，连接这些“中间表格”的工作中消磨掉了。



    另外有一些人（比如这篇文章）通过关系模型与其它数据模型（比如网状模型之类）的对比，以支持关系模型存在的必要性，然而如果你理解了这小节的所有细节就会发现，使用基本的数据结构，其实可以完全的表示关系模型以及被它所“超越”的那些数据模型。这些所谓“数据模型”其实全都是故弄玄虚，无中生有。数据模型可以完全被普通的数据结构所表示，然而它们却不可能表达数据结构带有的所有信息。这些模型之所以流行，是因为它们让人误以为知道了所谓的“一对一”，“一对多”等冠冕堂皇的概念，就可以取代设计数据结构所需要的技能，所以我认为数据模型本身就属于技术上的“减肥药”。


NoSQL


    SQL和关系模型所引起的一系列无须有的问题，终究引发了所谓“NoSQL运动”。很多人认为NoSQL是划时代的革命，然而在我看来，它最多可以被称为“不再愚蠢”。大多数NoSQL数据库的设计者，并没有看到上述的问题，或者他们其实也想故弄玄虚，所以NoSQL数据库的设计，并没有完全摆脱关系模型，以及SQL所带来的思维枷锁。



    最早试图冲破关系模型和SQL限制的一种技术，叫做“列模式数据库”（column-based database），比如Vertica, HBase等。这种数据库其实就是针对了我刚刚提到的，关系模型无法保存变长结构的问题。它们所谓的“列压缩”，其实不过是在“行结构”里面增加了对“数组”的表示和实现。很显然，每一个数组需要一个字段来表示它的长度N，剩下的空间用来依次保存每一个元素，这样你只需要一个key就可以找到数组里所有的元素，而不需要把key重复N遍。



    这种“巧妙”的实现，也就是你在列模式数据库的广告里看到的，只不过那些广告把它说得天花烂坠，貌似与众不同而已。在列模式数据库里，你不需要进行normalization，也不需要重复很多key。这种对数组的表示，是一开始就应该有的，却被关系模型排除在外。然而，很多列模式数据库并没有看到这一实质。它们经常设定一些无端的限制，比如给变长数组的嵌套层数作出限制，等等。所以，列模式数据库，其实没能完全逃脱关系式数据库的思想枷锁。如此明显的事情，数据库专家们最开头恁是看不到。到后来改来改去改得六成对，还美其名曰“优化”和“压缩”。



    最新的一些NoSQL数据库，比如Neo4j, MongoDB等，部分的改善了SQL的表达力问题。Neo4j设计了个古怪的查询语言叫Cypher，不但语法古怪，表达力弱，而且效率出奇的低，以至于几乎任何有用的操作，你都必须使用Java写“扩展”（extension）来完成。MongoDB使用JSON来表示查询，本质就是手写编译器里的语法树（AST），非常奇葩和苦逼。现在看来，数据库的主要问题，其实是语言设计的问题。NoSQL数据库的领域，由于缺乏经过正规教育的程序语言专家，而且由于利益驱使，不尊重事实，所以会在很长一段时间之内处于混沌之中。



    其实数据库的问题哪有那么困难，它其实跟“远过程调用”（RPC）没什么两样。只要你有一个程序语言，你就可以发送这语言的代码，到一个“数据服务器”。服务器接受并执行这代码，对数据进行索引，查询和重构，最后返回结果给客户端。如果你看清了SQL的实质，就会发现这样的“过程式设计”，其实并不会损失SQL的“描述”能力。反而由于过程式语言的简单，直接和普遍，使得开发效率大大提高。NoSQL数据库比起SQL和关系式数据库，存在某种优势，也就是因为它们在朦胧中朝着这个“RPC”的方向发展。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 对 Go 语言的综合评价

 
 
 
 
    

    
 
     
  

      
   
对 Go 语言的综合评价

    以前写过一些对 Go 语言的负面评价。现在看来，虽然那些评价大部分属实，然而却由于言辞激烈，没有点明具体问题，难以让某些人信服。在经过几个月实际使用 Go 来构造网站之后，我觉得现在是时候对它作一些更加“客观”的评价了。


定位和优点


    Go 比起 C 和 C++ 确实有它的优点，这是很显然的事情。它比起 Java 也有少数优点，然而相对而言更多是不足之处。所以我对 Go 的偏好在比 Java 稍低一点的位置。



    Go 语言比起 C，C++ 的强项，当然是它的简单性和垃圾回收。由于 C 和 C++ 的设计有很多历史遗留问题，所以 Go 看起来确实更加优雅和简单。比起那些大量使用设计模式的 Java 代码，Go 语言的代码也似乎更简单一些。另外，Go 的垃圾回收机制比起 C 和 C++ 的全手动内存管理来说，大大降低了程序员的头脑负担。



    但是请注意，这里的所谓“优点”都是相对于 C 之类的语言而言的。如果比起另外的一些语言，Go 的这种优点也许就很微不足道，甚至是历史的倒退了。


语法


    Go 的简单性体现在它的语法和语义的某些方面。Go 的语法比 C 要稍好一些，有少数比 Java 更加方便的设计，然而却也有“倒退”的地方。而且这些倒退还不被很多人认为是倒退，反而认为是进步。我现在举出暂时能想得起来的几个方面：




    进步：Go 有语法支持一种类似 struct literal 的构造，比如你可以写这样的代码来构造一个 S struct：


S { x: 1, y: 2, }



    这比起 Java 只能用构造函数来创建对象是一个不错的方便性上的改进。这些东西可能借鉴于 JavaScript 等语言的设计。


    倒退：类型放在变量后面，却没有分隔符。如果变量和它的类型写成像 Pascal 那样的，比如 x : int，那也许还好。然而 Go 的写法却是 x int，没有那个冒号，而且允许使用 x, y int 这样的写法。这种语法跟 var，函数参数组合在一起之后，就产生了扰乱视线的效果。比如你可以写一个函数是这样开头的：


  func foo(s string, x, y, z int, c bool) {
    ...
  }



    注意 x, y, z 那个位置，其实是很混淆的。因为看见 x 的时候我不能立即从后面那个符号（, y）看到它是什么类型。所以在 Go 里面我推荐的写法是把 x 和 y 完全分开，就像 C 和 Java 那样，不过类型写在后面：


  func foo(s string, x int, y int, z int, c bool) {
    ...
  }



    这样一来就比较清晰了，虽然我愿意再多写一些冒号。每一个参数都是“名字 类型”的格式，所以我一眼就看到 x 是 int。虽然多打几个字，然而节省的是“眼球 parse 代码”的开销。


    倒退：类型语法。Go 使用像 []string 这样的语法来表示类型。很多人说这种语法非常“一致”，但经过一段时间我却没有发现他们所谓的一致性在哪里。其实这样的语法很难读，因为类型的各部分之间没有明确的分隔标识符，如果和其他一些符号，比如 * 搭配在一起，你就需要知道一些优先级规则，然后费比较大的功夫去做“眼球 parse”。比如，在 Go 代码里你经常看到 []*Struct 这样的类型，注意 *Struct 要先结合在一起，再作为 [] 的“类型参数”。这种语法缺乏足够的分隔符作为阅读的“边界信号”，一旦后面的类型变得复杂，就很难阅读了。比如，你可以有 *[]*Struct 或者 *[]*pkg.Struct 这样的类型。所以这其实还不如像 C++ 的 vector&lt;struct*&gt; 这样的写法，也就更不如 Java 或者 Typed Racket 的类型写法来得清晰和简单。


    倒退：过度地“语法重载”，比如 switch, for 等关键字。Go 的 switch 关键字其实包含了两种不同的东西。它可以是 C 里面的普通的 switch（Scheme 的 case），也可以是像 Scheme 的 cond 那样的嵌套分支语句。这两种语句其实是语义完全不同的，然而 Go 的设计者为了显得简单，把它们合二为一，而其实引起了更大的混淆。这是因为，就算你把它们合二为一，它们仍然是两种不同的语义结构。把它们合并的结果是，每次看到 switch 你都需要从它们“头部”的不同点把这两种不同的结构区分开来，增加了人脑的开销。正确的作法是把它们分开，就像 Scheme 那样。其实我设计语言的时候有时候也犯同样的错误，以为两个东西“本质”上是一样的，所以合二为一，结果经过一段时间，发现其实是不一样的。所以不要小看了 Scheme，很多你认为是“新想法”的东西，其实早就被它那非常严谨的委员会给抛弃在了历史的长河中。





    Go 语言里面还有其他一些语法设计问题，比如强制把 { 放在一行之后而且不能换行，if 语句的判断开头可以嵌套赋值操作等等。这些试图让程序显得短小的作法，其实反而降低了程序理解的流畅度。



    所以总而言之，Go 的语法很难被叫做“简单”或者“优雅”，它的简单性其实在 Java 之下。


工具链


    Go 提供了一些比较方便的工具。比如 gofmt，godef 等，使得 Go 代码的编程比起单用 Emacs 或者 VIM 来编辑 C 和 C++ 来说是一个进步。使用 Emacs 编辑 Go 就已经能实现某些 IDE 才有的功能，比如精确的定义跳转等等。



    这些工具虽然好用，但比起像 Eclipse, IntelliJ 和 Visual Studio 这样的 IDE，差距还是相当大的。比起 IDE，Go 的工具链缺乏各种最基本的功能，比如列出引用了某个变量的所有位置，重命名等 refactor 功能，好用的 debugger （GDB 不算好用）等等。



    Go 的各种工具感觉都不大成熟，有时候你发现有好几个不同的 package 用于解决同一个问题，搞不清楚哪一个好些。而且这些东西配置起来不是那么的可靠和简单，都需要折腾。每一个小功能你都得从各处去寻找 package 来配置。有些时候一个工具配置了之后其实没有起作用，要等你摸索好半天才发现问题出现在哪里。这种没有组织，没有计划的工具设计，是很难超过专业 IDE 厂商的连贯性的。



    Go 提供了方便的 package 机制，可以直接 import 某个 GitHub repository 里的 Go 代码。不过我发现很多时候这种 package 机制带来的更多是麻烦事和依赖关系。所以 Go 的推崇者们又设计了一些像 godep 的工具，用来绕过这些问题，结果 godep 自己也引起一些稀奇古怪的问题，导致有时候新的代码其实没有被编译，产生莫名其妙的错误信息（可能是由于 godep 的 bug）。



    我发现很多人看到这些工具之后总是很狂热的认为它们就能让 Go 语言一统天下，其实还差得非常之远。而且如此年轻的语言就已经出现这么多的问题，我觉得所有这些麻烦事累积下来，多年以后恐怕够呛。


内存管理


    比起 C 和 C++ 完全手动的内存管理方式，Go 有垃圾回收（GC）机制。这种机制大大减轻了程序员的头脑负担和程序出错的机会，所以 Go 对于 C/C++ 是一个进步。



    然而进步也是相对的。Go 的垃圾回收器是一个非常原始的 mark-and-sweep，这比起像 Java，OCaml 和 Chez Scheme 之类的语言实现，其实还处于起步阶段。



    当然如果真的遇到 GC 性能问题，通过大量的 tuning，你可以部分的改善内存回收的效率。我也看到有人写过一些文章介绍他们如何做这些事情，然而这种文章的存在说明了 Go 的垃圾回收还非常不成熟。GC 这种事情我觉得大部分时候不应该是让程序员来操心的，否则就失去了 GC 比起手动管理的很多优势。所以 Go 代码想要在实时性比较高的场合，还是有很长的路要走的。



    由于缺乏先进的 GC，却又带有高级的抽象，所以 Go 其实没法取代 C 和 C++ 来构造底层系统。Go 语言的定位对我来说越来越模糊。


没有“generics”


    比起 C++ 和 Java 来说，Go 缺乏 generics。虽然有人讨厌 Java 的 generics，然而它本身却不是个坏东西。Generics 其实就是 Haskell 等函数式语言里面所谓的 parametric polymorphism，是一种非常有用的东西，不过被 Java 抄去之后有时候没有做得全对。因为 generics 可以让你用同一块代码来处理多种不同的数据类型，它为避免重复，方便替换复杂数据结构等提供了方便。



    由于 Go 没有 generics，所以你不得不重复写很多函数，每一个只有类型不同。或者你可以用空 interface {}，然而这个东西其实就相当于 C 的 void* 指针。使用它之后，代码的类型无法被静态的检查，所以其实它并没有 generics 来的严谨。



    比起 Java，Go 的很多数据结构都是“hard code”进了语言里面，甚至创造了特殊的关键字和语法来构造它们（比如哈希表）。一旦遇到用户需要自己定义类似的数据结构，就需要把大量代码重写一遍。而且由于没有类似 Java collections 的东西，无法方便的换掉复杂的数据结构。这对于构造像 PySonar 那样需要大量实验才能选择正确的数据结构，需要实现特殊的哈希表等数据结构的程序来说，Go 语言的这些缺失会是一个非常大的障碍。



    缺少 generics 是一个问题，然而更严重的问题是 Go 的设计者及其社区对于这类语言特性的盲目排斥。当你提到这些，Go 支持者就会以一种蔑视的态度告诉你：“我看不到 generics 有什么用！”这种态度比起语言本身的缺点来说更加有害。在经过了很长一段时间之后 Go 语言的设计者们开始考虑加入 generics，然后由于 Go 的语法设计偷工减料，再加上由于缺乏 generics 而产生的特例（比如 Go 的 map 的语法设计）已经被大量使用，我觉得要加入 generics 的难度已经非常大。



    Go 和 Unix 系统一样，在出现的早期就已经因为不吸取前人的教训，背上了沉重的历史包袱。


多返回值


    很多人都觉得 Go 的多返回值设计是一个进步，然而这里面却有很多蹊跷的东西。且不说这根本不是什么新东西（Scheme 很早就有了多返回值 let-values），Go 的多返回值却被大量的用在了错误的地方—Go 利用多返回值来表示出错信息。比如 Go 代码里最常见的结构就是：


ret, err := foo(x, y, z)
if err != nil {
    return err
}



    如果 foo 的调用产生了错误，那么 err 就不是 nil。Go 要求你在定义了变量之后必须使用它，否则报错。这样它“碰巧”避免了出现错误 err 而不检查的情况。否则如果你想忽略错误，就必须写成


ret, _ := foo(x, y, z)



    这样当 foo 出错的时候，程序就会自动在那个位置当掉。



    不得不说，这种“歪打正着”的做法虽然貌似可行，从类型系统角度看，却是非常不严谨的。因为它根本不是为了这个目的而设计的，所以你可以比较容易的想出各种办法让它失效。而且由于编译器只检查 err 是否被“使用”，却不检查你是否检查了“所有”可能出现的错误类型。比如，如果 foo 可能返回两种错误 Error1 和 Error2，你没法保证调用者完全排除了这两种错误的可能性之后才使用数据。所以这种错误检查机制其实还不如 Java 的 exception 来的严谨。



    另外，ret 和 err 同时被定义，而每次只有其中一个不是 nil，这种“或”的关系并不是靠编译器来保障，而是靠程序员的“约定俗成”。这样当 err 不是 nil 的时候，ret 其实也可以不是 nil。这些组合带来了挺多的混淆，让你每次看到 return 的地方都不确信它到底想返回一个错误还是一个有效值。如果你意识到这种“或”关系其实意味着你只应该用一个返回值来表示它们，你就知道其实 Go 误用了多返回值来表示可能的错误。



    其实如果一个语言有了像 Typed Racket 和 PySonar 所支持的 “union type”类型系统，这种多返回值就没有意义了。因为如果有了 union type，你就可以只用一个返回值来表示有效数据或者错误。比如你可以写一个类型叫做 {String, FileNotFound}，用于表示一个值要么是 String，要么是 FileNotFound 错误。如果一个函数有可能返回错误，编译器就强制程序员检查所有可能出现的错误之后才能使用数据，从而可以完全避免以上的各种混淆情况。对 union type 有兴趣的人可以看看 Typed Racket，它拥有我迄今为止见过最强大的类型系统（超越了 Haskell）。



    所以可以说，Go 的这种多返回值，其实是“歪打”打着了一半，然后换着法子继续歪打，而不是瞄准靶心。


接口


    Go 采用了基于接口（interface）的面向对象设计，你可以使用接口来表达一些想要进行抽象的概念。



    然而这种接口设计却不是没有问题的。首先跟 Java 不同，实现一个 Go 的接口不需要显式的声明（implements），所以你有可能“碰巧”实现了某个接口。这种不确定性对于理解程序来说是有反作用的。有时候你修改了一个函数之后就发现编译不通过，抱怨某个位置传递的不是某个需要的接口，然而出错信息却不能告诉你准确的原因。要经过一番摸索你才发现你的 struct  为什么不再实现之前定义的一个接口。



    另外，有些人使用接口，很多时候不过是为了传递一些函数作为参数。我有时候不明白，这种对于函数式语言再简单不过的事情，在 Go 语言里面为什么要另外定义一个接口来实现。这使得程序不如函数式语言那么清晰明了，而且修改起来也很不方便。有很多冗余的名字要定义，冗余的工作要做。



    举一个相关的例子就是 Go 的 Sort 函数。每一次需要对某种类型 T 的数组排序，比如 []string，你都需要



定义另外一个类型，通常叫做 TSorter，比如 StringSorter
为这个 StringSorter 类型定义三个方法，分别叫做 Len, Swap, Less
把你的类型比如 []string cast 成 StringSorter
调用 sort.Sort 对这个数组排序




    想想 sort 在函数式语言里有多简单吧？比如，Scheme 和 OCaml 都可以直接这样写：


(sort '(3 4 1 2) &lt;)



    这里 Scheme 把函数 &lt; 直接作为参数传给 sort 函数，而没有包装在什么接口里面。你发现了吗，Go 的那个 interface 里面的三个方法，其实本来应该作为三个参数直接传递给 Sort，但由于受到 design pattern 等思想的局限，Go 的设计者把它们“打包”作为接口来传递。而且由于 Go 没有 generics，你无法像函数式语言一样写这三个函数，接受比较的“元素”作为参数，而必须使用它们的“下标”。由于这些方法只接受下标作为参数，所以 Sort 只能对数组进行排序。另外由于 Go 的设计比较“底层”，所以你需要另外两个参数: len 和 swap。



    其实这种基于接口的设计其实比起函数式语言，差距是很大的。比起 Java 的接口设计，也可以说是一个倒退。


goroutine


    Goroutine 可以说是 Go 的最重要的特色。很多人使用 Go 就是听说 goroutine 能支持所谓的“大并发”。



    首先这种大并发并不是什么新鲜东西。每个理解程序语言理论的人都知道 goroutine 其实就是一些用户级的 "continuation"。系统级的 continuation 通常被叫做“进程”或者“线程”。Continuation 是函数式语言专家们再了解不过的东西了，比如我的前导师 Amr Sabry 就是关于 continuation 的顶级专家之一。



    Node.js 那种 "callback hell"，其实就是函数式语言里面常用的一种手法，叫做 continuation passing style (CPS)。而我在 Friedman 课上写的那“40行代码”就是用来实现从普通程序到 CPS 程序的转化的。由于 Scheme 有 call/cc，所以从理论上讲，它可以不通过 CPS 样式的代码而实现大并发。



    所以函数式语言只要支持 continuation，就会很容易的实现大并发，也许还会更高效，更好用一些。比如 Scheme 的一个实现 Gambit-C 就可以被用来实现大并发的东西。Chez Scheme 也许也可以，不过还有待确认。



    当然具体实现上的效率也许有区别，然而我只是说，goroutine 其实并不是像很多人想象的那样全新的，革命性的，独一无二的东西。只要有足够的动力，其它语言都能添加这个东西。


defer


    Go 实现了 defer 函数，用于避免在函数出错后忘了收拾残局（cleanup）。然而我发现这种 defer 函数有被滥用的趋势。比如，有些人把那种不是 cleanup 的动作也做成 defer，到后来累积几个 defer 之后，你就不再能一眼看得清楚到底哪块代码先运行哪块后运行了。位置处于前面的代码居然可以在后来运行，违反了代码的自然位置顺序关系。



    当然这可以怪程序员不明白 defer 的真正用途，然而一旦你有了这种东西就会有人想滥用它。那种急于试图利用一个语言的每种 feature 的人，特别喜欢干这种事情。这种问题恐怕需要很多年的经验之后，才会有人写成书来教育大家。在形成统一的“代码规范”以前，我预测 defer 仍然会被大量的滥用。



    所以我们应该想一下，为了避免可能出现的资源泄漏，defer 带来的到底是利多还是弊多。


库代码


    Go 的标准库的设计里面带有浓郁的 Unix 气息。比起 Java 之类的语言，它的库代码有很多不方便的地方。有时候引入了一些函数式语言的方式，但却由于 Unix 思维的限制，不但没能发挥函数式语言的优点，而且导致了很多理解的复杂性。



    一个例子就是 Go 处理字符串的方式。在 Java 里每个字符串里包含的字符，缺省都是 Unicode 的“code point”。然而在 Go 里面 string 类型里面每个元素都是一个 byte，所以每次你都得把它 cast 成“rune”类型才能正确的遍历每个字符，然后 cast 回去。这种把任何东西都看成 byte 的方式，就是 Unix 的思维方式，它引起过度底层和复杂的代码。


HTML template 库


    我使用过 Go 的 template library 来生成一些网页。这是一种“基本可用”的模板方式，然而比起很多其他成熟的技术，却是相当的不足的。让我比较惊讶的是，Go 的 template 里面夹带的代码，居然不是 Go 语言自己，而是一种表达能力相当弱的语言，有点像一种退化的 Lisp，只不过把括号换成了  { {...} } 这样的东西。



    比如你可以写这样的网页模板：


{ {define "Contents"} }
{ {if .Paragraph.Length} }
&lt;p&gt;{ {.Paragraph.Content} }&lt;/p&gt;
{ {end} }
{ {end} }



    由于每个模板接受一个 struct 作为填充的数据，你可以使用 .Paragraph.Content 这样的代码，然而这不但很丑陋，而且让模板不灵活，不好理解。你需要把需要的数据全都放进同一个结构才能从模板里面访问它们。



    任何超过一行的代码，虽然也许这语言可以表达，一般人为了避免这语言的弱点，还是在 .go 文件里面写一些“帮助函数”。用它们产生数据放进结构，然后传给模板，才能够表达模板需要的一些信息。而这每个帮助函数又需要一定的“注册”信息才能被模板库找到。所以这些复杂性加起来，使得 Go 的 HTML 模板代码相当的麻烦和混乱。



    听说有人在做一个新的 HTML 模板系统，可以支持直接的 Go 代码嵌入。这些工作刚刚起步，而且难说最后会做成什么样子。所以要做网站，恐怕还是最好使用其他语言比较成熟的框架。


总结


    优雅和简单性都是相对而言的。虽然 Go 语言在很多方面超过了 C 和 C++，也在某些方面好于 Java，然而它其实是没法和 Python 的优雅性相比的，而 Python 在很多方面却又不如 Scheme 和 Haskell。所以总而言之，Go 的简单性和优雅程度属于中等偏下。



    由于没有明显的优势，却又有各种其它语言里没有的问题，所以在实际工程中，我目前更倾向于使用 Java 这样的语言。我不觉得 Go 语言和它的工具链能够帮助我迅速的写出 PySonar 那样精密的代码。另外我还听说有人使用 Java 来实现大并发，并没发现比起 Go 有什么明显的不足。



    Alan Perlis 说，语言设计不应该是把功能堆积起来，而应该努力地减少弱点。从这种角度来看，Go 语言引入了一两个新的功能，同时又引入了相当多的弱点。



    Go 也许暂时在某些个别的情况有特殊的强项，可以单独用于优化系统的某些部分，但我不推荐使用 Go 来实现复杂的算法和整个的系统。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 黑客文化的精髓

 
 
 
 
    

    
 
     
  

      
   
黑客文化的精髓

    听说“黑客文化”这个词，就像在昨天。想起它，眼前就出现一些头发蓬乱，穿黑色道袍的人。最早的时候，他们努力地向人们澄清：“黑客”不是贬义词，不是指那些入侵电脑网络的罪犯。当人们明白过来之后，他们开始告诉人们如何成为一个黑客，并且把黑客与画家相提并论。当人们受到鼓舞，决心成为黑客之后，他们开始向这些人灌输黑客的“行为守则”，“提问的艺术”等等。总之就是说，你得显示出一些非常重要的特征以证明你是高手，并且教育那些菜鸟们。否则按照我们的标准，你就不是个黑客！



    于是忽然间，我来到了这个黑客遍地的世界。体验着，忍受着自己向往已久的“黑客文化”。


某大牛说……


    一个中等水平的黑客要说服一个菜鸟水平的黑客，方法很简单：引用一个超级黑客的话。至于为什么嘛，我也不知道，总之你照办就是了。最好记住那超级黑客的名字，以后再遇到不懂事的菜鸟就用同样的方法教育他，免得我亲自来动口舌！


笨蛋才不会用这个工具


    黑客的世界里有很多背着历史包袱，设计拙劣，你却不得不用的工具。黑客文化的其中一个作用就是掩盖这些工具的设计失误。这定律被我叫做“都是用户的错”。



    你的智商和能力被一些肤浅的标准所衡量，你每天都在提心吊胆的接受各种审查。这两个 Git 命令的区别都不知道？还当什么黑客！哪个学校毕业的？老师连这都没教过你们？哎，算我面试时看走眼了。



    于是为了显示自己有能力，接受过良好的教育，你不敢再问这种问题。为了避免再受伤害，为了掩饰自己的“无知”，你变成了一只刺猬。你开始用自己会的那点东西去审查其他人，伤害其它人，以为这样就可以保护自己。这些被伤害的人又转而去伤害更多的人。



    Visitor pattern 都不会写？还当什么黑客！这厮今天终于让我抓住把柄了 :)


只有天才才能理解它的简单


    某超级大牛说过，我的系统是简单的，但只有天才才能理解它的简单。



    你敢说我的系统不简单？哼哼，那你肯定不是像我一样的天才。你知道吗？其实我爷爷的爷爷是给皇帝做衣服的。他的座右铭是：看不见这衣服的人都是白痴或者不称职的人。



    所以你不敢说任何东西太复杂，太难用，太不可视化，对用户不友好。否则就会有人鄙视你：菜鸟，白痴，人笨怪刀钝！


择其难者而从之


    做一件事有两种方法，一种容易一种难，你会选择哪种？



    普通人都会选择更容易的，但是很奇怪的是，受到黑客文化熏陶的人，往往会选择困难的那种。如果这选择只是个人的喜好，如果他们尊重其他人的选择，那还无所谓了。但十有八九，选择了明显更加难用的工具的人，并不会从心底尊重那些选择更加容易的工具的人。这貌似是一种必然的结果。



    这其实是心理上的优越感在作怪。很多人选择困难的工具，并不是因为真的觉得它们好用，而是因为只有用其他人不会的东西，才能显示出自己的特殊性，显示出高人一等的水平。由于其根本的动机就来自于优越感，所以他们是不可能不找机会利用这得来不易的优越感的。



    有些人虽然可能口头上不说，但他们随时都在观察，看其他人选择了哪一种工具。那些选择了（或者倾向于选择）更容易的方法的人，会在他们的印象中产生一种肤浅的感觉，从而不会真正的被尊重。这种不尊重累积起来，就会开始隐约的表现出来，从而导致同事间工作关系的恶化。当然也有人更加露骨一些，直接就问别人选择了什么工具，然后嘲笑那些选择了容易工具的人为菜鸟。



    常见例子：



VIM 与 Emacs，选择 VIM
Emacs 与 IntelliJ（编辑 Java），选择 Emacs
组合键与方向键（移动光标），选择组合键，因为“并不是每个键盘都有方向键的！”
Linux 与 Windows，Mac，选择 Linux
Gentoo 与 Ubuntu，选择 Gentoo
Terminal 与 GUI，选择 Terminal，使用黑底绿字
TeX 与 Word，选择 TeX，拒收 .docx 附件
C++ 与 Java，选择 C++



RTFM!


    RTFM = Read The Fucking Manual!



    




    （图片来源：Abstruse Goose）



    惯用法：有人在#java聊天室问了一个问题，结果大家回答说：“RTFM！”“菜鸟，去读了 API 再来这里混！”


你不会 Google (百度）吗？


    当这种现象普及开来之后，普通的问题你都不能问别人了。比如：“哎，今天会不会下雨呢？”因为在黑客文化里，别人的回答会是：“你不会 Google 吗！”当然，在中国这句话就是：“你不会百度吗！”



    就像 IRC 里面的人一样，我不明白他们为什么在那里面，仿佛他们唯一的乐趣就是告诉别人“你不该问这个问题”，“你浪费了我的时间”。当这种现象普及到更广的社会，你知道会有什么结果吗？任何人都不要再对任何人说话了，因为说话全都是浪费时间。



    “你不该问这个问题”这种说法是非常大的攻击行为，它是人类良好社会关系的杀手。其实对别人“该不该问这个问题”的“考虑”本身就是一个错误。我们甚至不应该说“你可以问这个问题”，因为那应该是不言而喻的，想都不用想。



    任何人都允许问任何问题并不等于会浪费你的时间，因为你并不是必须回答每一个问题。所以我的做法总结下来就是一句话：我誓死捍卫你问问题的权利和尊严，但我不一定要回答你。比如在 IRC 聊天室，如果遇到有很初级的问题我懒得回答或者太忙，我不吭声就是了。我对问问题的人没有任何反感，我只是等其他人去回答他。但是“你不会 Google 吗！”肯定是非常不礼貌的做法。


你问我，所以你懂的没我多


    子贡问曰：“孔文子何以谓之文也？”子曰：“敏而好学，不耻下问，是以谓之文也。”



    可不要被孔老二误导了！在黑客文化里，这种不耻下问的行为是相当危险的。一次可能还好，多几次之后，我看你不被当成傻b菜鸟才怪。


希望你向我们学习


    进了新的黑客公司很兴奋哈？可是发现代码里有不大好的地方怎么办呢？如果吭声，立即讨人嫌。如果不吭声，那就等于承认了我们的代码是“模范”咯。跟着学吧，小弟。要学像哦！


这就是我们的作法


    我们刚从某大公司挖来一个世界级高手。结果他对我们引以为豪的一段代码提出了异议，说那是 premature optimization，思路不清晰。切！



    虽然他是世界级的高手，可我们才是这里的地头蛇，所以我们得告诉他：“这就是我们的作法！”


结束语


    上面的小片段，估计在你自己的生活中已经出现过很多次了吧？它们也在我的生活中出现过很多次。不同的学校或者公司，有可能出现其中的几种或者全部。其实哪里来的什么“黑客文化”？文化就是文化，管你做什么工作。不要忘了黑客不过是一种工作，跟医生，律师，厨师，教师一样的。所谓黑客文化只不过是为一些人的各种无理怪癖找借口，搞特殊化。



    按照以上标准，我不认为自己是个黑客。我是一个计算机科学家，我按照几百年来国际通用的礼节行事。计算机科学家与黑客的区别在于他不只按照工具的手册来完成规定的任务。他经常记不住别人设计的复杂工具如何使用，因为他本人是一个更好的设计师。他审视这些工具的设计合理性，发现蹩脚的地方，然后构思更好的设计方案。他总是嘲笑和自嘲，我们其实仍然生活在计算机的石器时代。



    在自己的公司里，我希望创造一个更加人性化的氛围，而不是宣扬所谓的黑客文化。让所有人无论男女，无论水平如何都身心舒坦，受到尊重，可以谈天说地，不耻下问。



    如果上面有我没有概括到的经典情况，欢迎来信告诉我。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 电视编剧的问题

 
 
 
 
    

    
 
     
  

      
   
电视编剧的问题

    



    听一朋友说“远离韩剧，保护智商”，誓死不看脑残剧《来自星星的你》。觉得好奇，于是乎想看看它为何脑残。开头还觉得挺有创意，风趣幽默，前后呼应，逻辑严密。对它看法大有改观，于是继续看下去。直到第11集的时候开始发现上当，及时悬崖勒马。


公式


    是什么问题呢？问题在于，当坏人都已经打倒在地，证据在手，可以轻易把他绳之以法的时候，却完全无脑地放过了他，反倒让自己被诬陷。这对于一个拥有超能力的外星人来说是不可原谅的错误，于是我能预测到都教授以后还会继续做类似的事情，继续让人着急。而这部电视剧也从此不再依靠创意，而是靠各种扭捏的伎俩来欺骗观众的时间了。这种招数被我称为“坏人不灭定律”。



    就算你要留他活命也不要这么无脑啊。现在我举出几个简单的策划，可以让这剧比较“有脑”地演下去：



坏蛋耍花招使暗器，结果不小心被推下悬崖。结果后来找不到尸体，原来是被另一邪恶的外星人救了。后来这俩成了都教授的死对头……
坏蛋其实自己就是外星人。是几年前杀掉了大哥，附在他的躯壳上面的。都教授没有料到，被整了……



对比


    比起美剧 LOST 在第一季25集完结之后才让我悟出一定的道理，《来自星星的你》功力还是不大足。而这两者比起像《Dark Angel》（James Cameron 编剧 ）之类超级顺畅的美剧又差太远了。有时候看电视电影还真得 follow 你所认可的编剧或者作家，而不是演员。另外我也不推荐 Dark Angel 第二季，尽是这怪物那怪物的出来，却没有很有意思的剧情。我猜本来并没有设计第二季，但是看到第一季收视率高，所以想乘火打劫多赚点钱，于是开始现炒现卖，打怪升级。



    这样的娱乐到后来就不是娱乐，而是受罪了。同样的原理适用于像《生化危机》那样折腾的游戏。那种游戏到后来就不再是在消遣了，而是像完成任务一样跑来跑去的。累不累啊。


相关推荐


    虽然后来有了败笔，《来自星星的你》前10集的剧情和主题其实不错的，所以不能全盘否认它的价值。它与其它一些我看过的东西类似，都有一个外星人主角和比较深刻的爱情主题，所以在这里推荐一下：



电影《星尘》（Star Dust）
小说《小王子》



启发


    韩剧的毛病也许不能怪编剧们。没有很多人真的是想要给世界留下什么宝贵的精神财富。为了混饭活命，这拖泥带水的问题从莎士比亚那时代就开始了 :) 学术界的论文其实与电视编剧也有惊人的相似之处。每个领域最初的经典 paper 一般最有价值，而后来的“续集”就往往是为了领域的“生存”而写。所以不要以为心目中的大师们是什么神，他们也跟我们一样是混饭吃的人类。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 天下第一萌程序

 
 
 
 
    

    
 
     
  

      
   
天下第一萌程序

    很多人都以为我最爱的程序是那“传说中的王垠40行代码”。那段代码固然是天神衣袖般的优雅，然而它却没有地球的气息和灵魂。其实我最爱的程序是下面这段 Racket 代码。有一天，空中出现一道亮光，隐约的听到一些哼哼声，然后我飞速的写下了它。后来发现，这是数学，艺术以及中西方文化的完美结合，绝版的艺术品。



    



    其中猪头照片来源不明，归其版权者所有。“猪头三”原意不明，可以参考 wikipedia，但我对这个词的常用法跟它的愿意有所不同，含有非常可爱的涵义。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 学术腐败是历史的必然

 
 
 
 
    

    
 
     
  

      
   
学术腐败是历史的必然

    今天想分析一下世界范围内的学术腐败。



    我曾经和所有对学术界抱有幻想的人一样，希望有机会发挥自己的才华，过上有智慧的生活。直到最后一个希望破灭之后，我开始分析其中的原因。其结果是非常有趣的，因为我得出的结论是：学术腐败是历史的必然，是人类历史的发展趋势和技术进步的结果。



    为什么这么说呢？



首先想想在资本主义社会里人靠什么过活？钱
一般人怎么得到钱？工作
谁是人最大的工作竞争对手？机器，电脑，互联网，机器人……
自己的工作被机器取代了怎么办？寻找机器干不了的工作！
什么是机器仍然干不了，而且不久的将来也干不了的工作？搞研究！
搞研究是为了什么？制造更高效更智能的机器！




    然后你就明白了，这是一个让人类越来越痛苦的怪圈。越来越多的人涌向大学，涌向研究生院，涌向教职岗位，也就是这个原因。他们试图依靠更高的文凭来提高自己在工作上的竞争力，让自己摆脱由于技术进步带来的失业和无家可归的命运。本来貌似情有可原，然而久而久之，之前的这些“可怜人”爬上高位，致使更多的人卷入其中，就导致了世界性的学术腐败现象。记得吸血鬼的故事吗？每一个吸血鬼最开头都是受害者。我们同情那个受害者，然而他一旦变成了吸血鬼之后，就不再值得同情，因为他原来的灵魂已经不在了。



    并不是每个人都有足够的好奇心，良好的态度和卓越的聪明才智来完成高精尖的研究的。有些人本来就只适合（或者只愿意）做一些简单劳动的，这些人本来应该受到尊重，他们应该过上安稳的生活。而我们的社会用机器代替了他们的工作岗位，却又不给他们耐以生存的资源，所以他们迫于生活压力，只好硬着头皮去“充电”。他们进了大学，甚至进了研究生院攻读 PhD。他们其实对研究根本不感兴趣，他们在那里完全是为了混口饭吃。知之者不如好之者，好之者不如乐之者。硬碰硬的智力较量他们是敌不过真正爱好研究的人的，所以他们就开始耍一些把戏。



    有“志”者事竟成。制度有漏洞，人性有弱点。那么多的人需要高学位，这道防线岂有不破之理？所以呢，你就看到各种勾兑论文，新瓶装老酒，反正以把你搞糊涂混毕业为目标。这就是为什么有些研究课题几句话就可以说清楚，有些人却花了几十年来写各种论文。你要说他们抄袭那又不是抄袭，又没有违法，貌似一切都正大光明，可就是一点用都没有。



    最开头教职岗位还比较好找，所以这批人就跟真正优秀的研究者一起，升到了终身教授的职位。可是他们的本性是不会改的，他们对研究不感兴趣，只是想混口饭吃，所以他们就给同类的，以混饭吃为目的的人大开绿灯。为了提高自己的学术地位，尽管知道是扯淡还是让很多人写点论文混毕业。而这些人也极力的吹捧他们，本来没啥意义的研究课题也要说成是有重大意义的。因为真正优秀的研究者的良心，学术界就展开了许多的政治斗争。然而真正的学者搞政治怎么可能是混混的对手，所以不是败下阵来就是看到别人败得很惨就明哲保身了。



    早期的时候这一招是比较有效的，很多人找到了教职岗位。可是终身教授的铁饭碗岂是那么容易得到的？它们的数目显然是有限的，而“终身教授”意味着这些人直到寿终正寝都不可能被 fire 掉。通过简单的“非抢占线程调度算法”，你会发现这种职位很快就会饱和，产生瓶颈。如果教授职位饱和了，而你博士毕业要找工作怎么办？等吧，等到有人死了你就有机会了。这就是为什么那么多人拼了六七年的 PhD 之后还要去做 postdoc。有些人在好几个学校做好几年 postdoc 才有机会成为助理教授（Assistant Professor）。



    不要高兴得太早。助理教授又是一遭漫长的旅途，一般为期七年左右。这个过程不但是用来考验你是否能胜任终身教授职位的“炼钢炉”，而且是学术界这台机器的上的一个“等待队列”。两三年的 postdoc，加上七年的助理教授，总该有终身教授归西，腾出位置来了吧？可惜的是由于一些肤浅的评价标准，而且里面的渣滓大大的多于优秀的钢材，这个炼钢炉淘掉的经常不是渣滓，而是优秀的钢材。上面讲到的那些混饭吃的人当然是继续耍各种把戏，钻制度的空子，拍正教授的马屁，压榨研究生，甚至压榨跟自己做毕业设计的本科生和硕士生。其唯一的目的是攒够足够的论文，拉拢足够的地位较高者，以支持自己成为终身教授。



    当然，随着终身教授职位越来越饱和，这种现象就愈演愈烈。以至于你几乎每次试图跟助理教授合作搞研究都感觉到两个字：贱！Push！有时候你想人家也没有办法啊，都是出来混的。人家可不会承认这一点。总是要举着贞节牌坊，打着一些“高尚”的目标作为幌子。只有跟他们合作的学生才知道里面的底细，但为了自己的饭碗，学生们当然不会告诉你这里面的潜规则。



    助理教授以及很多正教授都爱玩一招类似计算机里的“广度优先搜索算法”的研究策略，只不过他们用来执行这些搜索的不是机器，而是人。所以我们暂且把这叫做“人肉广度优先搜索算法”。它的工作原理是这样：现在有 A, B, C 三个课题，都是比较扯淡的，但即便如此其中也最多只有一个发得了论文，但我不知道是哪一个。我就找三个 PhD 来分别进行这三个课题。其中两个人是很可能失败的，但我不告诉他们。我把那三个课题都说成是非常有前途的，伟大的课题，鼓舞着学生们努力向前冲。到时候只要有一个人做出好东西，当然我的名字就在那 paper 上面，而且还是作为 PI（Principal Investigator）。另外那两个失败的家伙，就只能怪他们自己不努力，或者悟性不强喽。我尽量避免让他们互通信息或者合作，因为如果他们做同样的题目，就会失去“广度”和发 paper 的总体概率。我只关心总体的 paper 数，因为不管谁发了 paper 都算我一份，没有人会关心我手里 PhD 的毕业率。而且到时候几个人写差不多的题目，争锋斗角，更加麻烦。这就是为什么大部分助理教授对于 PhD 学生都是“求贤若渴”的样子，随时不忘为自己的“宏伟课题”打广告。遇到这种助理教授你需要特别小心，因为你很可能会被作为他的人肉搜索算法的其中一个“处理器”，最后发现自己搜索的是死路一条。



    虽然如此，助理教授仍然是非常辛苦的工作，它往往意味着低廉的工资，昼夜的工作，没有周末可言，工作和生活不分。不但要争取研究经费，还要做研究，指导（操纵）自己的研究生，要教课，还要发论文。学生是最难控制的一种东西，当着他们的面要说空话谎话，他们质疑的时候还要努力“疏导”…… 容易吗我！还有些人结了婚，生了小孩，那就更麻烦了。学校根本不以你的教学质量作为评价标准，所以助理教授上课一般都比较水，管你学得怎么样呢，反正我完成了任务。可是助理教授在七年之后能够拿到正教授的机会有多少呢？呵呵。恐怕比七年之痒之后没有离婚的机会还少吧。



    需要指出的是，学术腐败在计算机科学等专业貌似更加厉害一些。一方面是由于计算机比较热门，机会相对较多，还有工业界作为退路。另一方面是因为物理等“硬科学”经过几百年的发展已经非常成熟，可以造成对地球人有意义的理论突破的机会已经很少了。科学都需要经过实验检验，而且论文把关比较严，所以物理等专业的 PhD 非常不容易混毕业，毕业了也不容易找到工作。计算机科学虽然名字里面有“科学”二字，其实根本不是科学，倒有点像艺术或者数学。不是科学没关系，艺术和数学还是很重要的，但它们的从业者比较容易扯淡也没人看得出来，只要随便给自己的理论起个像“后现代艺术”之类的名字就可以了。现在的计算机科学博士论文里的创新程度，基本相当于有些本科生的“毕业设计”，只不过写的让人更头痛一些。这就是为什么大量的不合格研究者混进了计算机等专业。如果你要混饭吃，我建议你去计算机系。如果你想追求自己的兴趣，那就随你的便了。



    这就是我对于整个世界学术界的发展趋势的分析了。简言之就是，技术和生产力的高度发展，导致了与资本主义资源分配机制的冲突，以至于大量不适合搞学术的人由于生活没有保障，进行滥竽充数，最终导致学术腐败现象在全世界蔓延。资本主义就像是一个内存分配和处理器调度没做好的操作系统，有些进程占用太多内存和 CPU，却没能有效利用，导致其他进程“饿死”。除非社会的资源分配机制得到改善，否则学术腐败不可能好转，只会恶化。



    不要以为所谓的“世界一流大学”里的情况就会好一些，因为没有人可以逃脱社会发展的规律。世界一流大学我见识得多了，本质都一样。而且由于很多人想进去，头破血流的机会还多一些。从那里面出来的人往往都有一种神经症，什么事都跟别人比想看看谁厉害，谁“优秀”，娱乐活动都不例外。以至于你怀疑他们是否知道自己为什么活着。



    中国人太多，而且虽然口头上说是什么“有中国特色的稀里糊涂主义”，其实实行的是比资本主义还要不合理的分配制度，社会的资源越来越集中到极少数人手里或者被浪费掉，导致极度的贫富分化。再加上自古以来的科举制度和“书中自有……”的误导，绝大多数人涌向大学，涌向研究生院。所以学术腐败虽然是世界范围的现象，但在中国就更加厉害一些。



    关于这种“生产力”和“社会生产关系”的冲突，我们从小上政治课就背过了，不是吗？虽然政治课本大部分是扯淡的教条，但极少数几条不是中国人又不是俄国人发明的理论还真是管用的。死记硬背的东西人是永远不会理解的，只有切合实际才会发现，某些德国大胡子说的其实是真话，是科学道理。



    这些都是我们个人没有力量改变的事情。那么这篇文章有什么用呢？



    首先，有些知识是有指导意义的，知道了总比不知道的好。知道了学术界的游戏规则有利于我们玩转它，利用它，却避免它的弊端。比如，我早就知道了学术界的鬼把戏，所以我根本没有为成为它的一员做很多努力。从进入 IU 以后我就不在乎自己的考试成绩和论文发表，因为我知道除了学术界，几乎没有人关心这些。我知道有些领域整个都是扯淡的，所以得个高分不但对我一点用都没有，反而浪费了我的时间。所以除了自己喜欢的课程不拿A+都没办法以外，其它的都是按照能拿到学分的最低标准进行。我利用学校的资源学到了自己需要的东西，却没有为一些扯淡的论文之类花很多时间。每次做教授的 RA 都会发现是在做扯淡空洞的话题，所以我后来选择了做 TA。干这种“体力活”避免了脑力的冲突，自己才有机会去研究自己感兴趣，有价值的东西。由于我知道助理教授们的生存现状，心理以及动机，我就比不知道的人做出更好的决定。当同学们怀着崇尚的心情，跟着一些吹牛皮的助理教授做一些没有希望的研究的时候，我自己的研究早就超过了他们很多年。



    另外，这篇文章对于广大学术界人士也有一定意义。承认了自己在扯淡总是比举着高尚道德的牌子更加以德服人一些。我鼓励广大正在挣扎中的 PhD 和助理教授们发扬自嘲精神，勇于承认自己的现实和弱点，承认自己其实是不得已为了混饭吃，大家都是混饭吃的。有同情心才会有动力，同学们如果知道了你是在混口饭吃，反而会更加理解你的处境，停止质疑你的做法，进而帮助你继续混下去。



    最后，知道事实的人多了，世界自然而然就会改变。很多人进学术界的原因是为了混饭吃，而当社会更多的了解到学术界的这一真相之后，“名校博士”这种东西就会逐渐贬值，失去它原来的光环。人们就会以平常心来看待，最后学术界就不再能吸引那些混饭吃的人，而真正喜欢研究的人也就能自得其所。人们也可以采取甘地的“非暴力不合作”精神，避免成为学术腐败的一部分，就像你知道某个街区经常有吸血鬼出没就不要去一样。这样吸血鬼们找不到食物，邪恶的势力就会逐渐萎缩。知道事实的人们还可以互相鼓舞，发扬正气。腐败的组织慢慢的就会失去人们的支持，走向穷途末路，或者改邪归正。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 一个对 Dijkstra 的采访视频

 
 
 
 
    

    
 
     
  

      
   
一个对 Dijkstra 的采访视频

    



    （也可以访问 YouTube 或者从源地址下载 MPEG1，300M）



    之前在微博上推荐了一个对 Dijkstra 的采访视频，看了两遍之后觉得实在很好，所以再正式推荐一下。大部分人可能都知道他对图论算法和操作系统的贡献，而其实 Dijkstra 在程序语言上的造诣也很深厚。我们常用的程序语言里面司通见惯的“递归函数”，其实当年就是 Dijsktra 和另一个人不顾委员会里众人的反对和怀疑，坚持要放进 Algol 60，所以后来才进入了 Pascal，C，Java 这样的语言的。那个时候 John McCarthy 缺席，不然的话就会有三个人支持了。



    现在看来，任何一个语言里面没有递归函数都是不可思议的事情，然而在1950-60年代的时候，居然很少有人知道它有什么用！所以你就发现，所谓的“主流”和“大多数人”一直都是比较愚蠢的。现在，同样的故事发生在 lambda 身上。多年以后，没有 lambda 的语言将是不可接受的。



    在这里只摘录他提到的几个要点。某些观点也许不是最好的办法，但我确信其中有非常值得学习的地方。



软件的版本号 2.6, 2.7, ... 都是胡扯。本来第1版就应该是最终的产品，可是软件公司总是先弄出来一个不完整的版本，骗大家买了，以后再慢慢“升级”。每次升级都要用户再次付钱。
编程有多种流派，我喜欢把它们归类成“莫扎特 vs 贝多芬”。当莫扎特开始写乐谱时，作品就已经完成了。他的手稿一气呵成，书法也很好。贝多芬不一样，他总是在怀疑和挣扎。他的作品一般是还没有想好就开始写，然后就往上面贴纸条修改。有一次贝多芬改了9遍才把手稿完成，后来有人把这手稿一层层的撕开，发现第一版和最后一版是一摸一样的。这种改来改去的做法是 Anglo-Saxon 民族的传统，它贯穿了英国式的教育。
作曲家的工作不是写乐谱，而是构思音乐。最早的时候人们编程都是用汇编语言的，就跟写乐谱差不多。后来他们发明了高级语言，就以为这些语言把编程的问题解决了。但是你仔细一瞧，发现它们只是把编程最微不足道的问题解决了，但是困难的问题仍然困难。这些高级语言与越来越大的野心加在一起，反而让程序员头脑的负担更重了。
称职的程序员都知道自己头颅的尺寸是有限的，所以他们以谦逊的态度来对待工作，像回避瘟疫一样地回避小聪明。
当我1970年在法国巴黎讲学如何编程的时候很成功，听众都非常积极。回家的路上我又在比利时布鲁塞尔的一个大软件公司进行了同样的演讲，结果非常失败。那恐怕是我一生中最失败的演讲。后来我发现了为什么：他们的管理层不喜欢无懈可击的程序，因为这公司是靠“维护软件”的合同来维持生存的。程序员对此也不感兴趣，因为最让他们兴奋的事情在于不知道自己在干什么。他们觉得如果清楚地知道自己在干什么，那就没有挑战性了，就是无聊的工作。
研究物理的人如果遇到不理解的事情，总是可以责怪上帝，世界这么复杂不是你的错。但是如果你的程序有问题，那就找不到替罪羊了。0就是0，1就是1，就是你把它搞砸了。
1969年，在阿波罗号登月之后不久，我在罗马的北约软件工程会议遇到了 Joel Aron，阿波罗计划的软件负责人。我知道每个阿波罗飞船上面的代码都会比前一个多4万行。我不知道“行”对于代码是个什么单位，但4万行肯定是很多了。我很惊讶他们能把这么多代码做对，所以我问 Joel：你们是怎么做到的？他说：做什么？我说：把那么多代码写正确。Joel 说：“正确？！其实在发射前仅仅五天，我从登月器计算轨道的代码里发现一个错误，这代码把月球的重力方向算反了。本来该吸引的，结果写成了排斥。是一个偶然的机会让我发现了这个错误。”我的脸都白了，说：这些家伙运气真好？Joel 说：“是的。”
软件测试可以确定软件里有 bug，但却不可能用来确定它们没有 bug。
程序的优雅性不是可以或缺的奢侈品，而是决定成功还是失败的一个要素。优雅并不是一个美学的问题，也不是一个时尚品味的问题，优雅能够被翻译成可行的技术。牛津字典对 elegant 的解释是：pleasingly ingenious and simple。如果你的程序真的优雅，那么它就会容易管理。第一是因为它比其它的方案都要短，第二是因为它的组件都可以被换成另外的方案而不会影响其它的部分。很奇怪的是，最优雅的程序往往也是最高效的。
当没有计算机的时候，编程不是问题。当有了比较弱的计算机时，编程成了中等程度的问题。现在我们有了巨大的计算机，编程就成了巨大的问题。
我最开头编程的日子跟现在很不一样，因为我是给一个还没有造出来的计算机写程序。造那台机器的人还没有完工，我在同样的时间给它做程序，所以没有办法测试我的代码。于是我发现自己做的东西必须要能放进自己的脑子里。
我的母亲是一个优秀的数学家。有一次我问她几何难不难，她说一点也不难，只要你用“心”来理解所有的公式。如果你需要超过5行公式，那么你就走错路了。
为什么这么少的人追求优雅？这就是现实。如果说优雅也有缺点的话，那就是你需要艰巨的工作才能得到它，需要良好的教育才能欣赏它。



   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 程序语言与它们的工具

 
 
 
 
    

    
 
     
  

      
   
程序语言与它们的工具

    谈论了这么多程序语言的事情，说得好像语言的好坏就是选择它们的决定性因素。然而我一直没有提到的一个问题是，“程序语言”和“程序语言工具”的设计，其实完全是两码事。一个优秀的程序语言，有可能由于设计者的忽视或者时间短缺，没有提供良好的辅助工具。而一个不怎么好的程序语言，由于用的人多了，往往就会有人花大力气给它设计工具，结果大大的提高了易用性和程序员的生产力。我曾经提到，程序语言其实不是工具，它们是像木头，钉子，胶水一样的材料。如果有公司做出非常好的胶水，粘性极强，但它的包装不好，一打开就到处乱跑，弄得一团糟。你是愿意买这样的胶水还是稍微差一点但粘性足够，包装设计合理，容易涂抹，容易存储的呢？我想大部分人会选择后者，除非后者的粘性实在太弱，那样的话包装再好都白搭。



    这就是为什么虽然我这么欣赏 Scheme，却没有用 Scheme 或者 Racket 来构造 PySonar 和 RubySonar，甚至没有选择 Scala 和 Clojure，而是“臭名昭著”的 Java。这不只是因为 PySonar 最初的代码由于项目原因是用 Java 写的，而且因为 Java 正好有足够的表达能力，可以实现这样的系统，但是最重要的其实是，Java 的工具非常成熟和迅捷。很难想象如果缺少了 Eclipse 我还能在三个月内做出像 PySonar 那样的东西。而现在我只用了一个月就做出了 RubySonar，其中很大的功劳在于 IntelliJ。这些 IDE 的跳转功能，让我可以在代码中自由穿梭。而它们的 refactor 功能，让我不必再为变量的命名而烦恼，因为只要临时起个不重复的名字就行，以后改起来小菜一碟。另外我还经常使用这些 IDE 里面的 debugger，利用它们我可以很方便的找到 bug 的起因。PySonar2 在有一段时间变得很慢，看不出是哪里出了问题。最后我下载了一个 JProfiler 试用版，很快就发现了问题的所在。如果这问题出现在 Scheme 代码里面，恐怕就要费很多功夫才能找到，因为 Scheme 没有像 JProfiler 那样的工具。



    但这并不等于说学习 Scheme 是没有用处的。恰恰相反，Scheme 的知识在任何时候都是非常有用的。一个只学过 Java 的程序员基本上是不可能写出我那样的 Java 代码的。虽然那看起来是 Java，但是其实 Scheme 的灵魂已经融入到其中了。我从 Scheme 学到的知识不但让我知道 Java 可以怎么用，而且让我知道 Java 本身是如何被造出来的。我知道 Java 哪些地方是好的，哪些地方是不好的，从而能够择其善而避其不善。我的代码没有用任何的“Java 设计模式”，也没有转弯抹角的重载。



    其实我有空的时候在设计和实现自己的语言（由于缺乏想象力，暂命名为 Yin），它的实现语言也在最近换成了 Java。Yin 的语法接近于 Scheme，好像理所当然应该用 Scheme 或者 Racket 来实现。有些人可能已经看到了我 GitHub 上面的第一个 prototype 实现（项目已经进入私密状态）用的是 Typed Racket。Racket 在很大程度上是比 Java 好的语言，然而它却有一个让我非常恼火的问题，以至于最后我怀疑自己能否用它顺利实现自己的语言。



    这个问题就是，当运行出现错误的时候，Racket 不告诉我出错代码的具体行号，甚至出错的原因都不说清楚。我经常看到这样一些出错信息：


“函数调用参数个数错误”
“变量 a 没有定义，位于 loop 处”



    只说是函数调用，函数叫什么名字不说。只说是 loop，文件里那么多 loop，到底是哪一个不知道。出错信息里面往往有很多别的垃圾信息，把你指向 Racket 系统里面的某一个文件。有时候把代码拷贝进 DrRacket 才能找到位置，可是很多时候甚至 DrRacket 都不行。每当遇到这些就让我思路被打断很长时间，导致代码质量的下降。



    其它的 Scheme 实现也有类似的问题，像 Petite Chez 这样的就更加严重，只有商业版的 Chez Scheme 会好一些，所以这里不只是小小的批评一下。这种对工具设计的不在意心理，在 Lisp 和 Scheme 等函数式语言的社区里非常普遍。每当有人抱怨它们出错信息混乱，没有 debugger，没有基本的静态检查，铁杆 Schemer 们就会鄙视你说：“Aziz 说得好，我从来不 debug，因为我从来不写 bug。”“函数式语言编程跟普通语言不一样。你要先把小块的代码调试好了，问题都找到了，再组合起来。”“当程序有问题却找不到在哪里的时候，说明我思路混乱，我就把它重写一遍……”我很无语，天才就是这样被传说出来的 :)



    除了由于高傲，Scheme 不提供出错位置的另外一个重要原因，其实是因为它的宏系统。由于 Scheme 的核心非常小，被设计为可以扩展成各种不同的语言，所以绝大部分的代码其实是由宏展开而成的。而由于 Scheme 的宏可以包含非常复杂的代码变换（比 C 语言的宏要强大许多），如果被展开的代码出了问题，是很难回溯找到程序员自己写的那块代码的。即使找到了也很难说清楚那块代码本来是什么东西，因为编译器看到的只是经过宏展开后的代码。如果实现者为了图简单没有把原来的位置信息存起来，那就完全没有办法找到了。这问题有点像有些 C++ 编译器给模板代码的出错信息。



    所以出现这样的问题，不仅仅是语言设计者的心态问题，而且是语言自己的设计问题。我觉得 Lisp 的宏系统其实是一个多余的东西，带来的麻烦多于好处。一个语言应该是拿来用的，而不是拿来扩展的。如果连最基本的报错信息都因此不能准确定位，扩展能力再强又有什么意义呢？所以强调一个语言可以扩展甚至变成另外一种语言，其实是过度抽象。一个设计良好的语言应该基本上不需要宏系统，所以 Yin 语言的语法虽然像 Lisp，但我不会提供任何宏的能力。而且由于以上的经历，Yin 语言从一开头就为方便工具的设计做出了努力。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 RubySonar：一个 Ruby 静态分析器

 
 
 
 
    

    
 
     
  

      
   
RubySonar：一个 Ruby 静态分析器

    在过去一个多月时间里，我大部分时间都在做一个 Ruby 的静态分析叫做 RubySonar。它使用与 PySonar2 类似的技术，不过针对 Ruby 的语义进行了很多调整。现在这个分析器已经能够支持 Sourcegraph 的 Ruby 代码搜索和浏览。这比起之前的效果是一个很大的进步。



    





    在 RubySonar 的帮助下，对于很多 repo，Sourcegraph 可以搜索到比以前多几十倍甚至上百倍的符号，当然代码的使用范例也随之增加了。代码定位的准确性有很大提高，基本不会出现错位的情况了，另外还支持了局部变量的加亮，所以看起来有点像个“静态 IDE”的味道。



    由于 RubySonar 比起 Sourcegraph 之前用的基于 YARD 的分析在速度上有上百倍的提高，我们现在可以处理整个 Ruby 标准库（而不只是以前的一小部分）。Ruby on Rails 的结果也有比较大的改善。另外，以前不支持的像 Homebrew 之类的独立应用，现在也可以分析了。



    RubySonar 的静态分析使用跟 PySonar2 相同的跨过程，数据流+控制流分析，而且采用同样的类型推导系统，所以分析的精度是很高的。我还没有跟 Ruby 的 IDE 比较过，不过因为构架的先进性，它应该已经能处理一些现在最好的 Ruby IDE 也搞不定的事情，当然由于时间短，在细节上比起它们肯定也有不足之处。



    虽然 Ruby 和 Python 看起来是差不多的语言，为了把 PySonar2 改到 Ruby 上，还是做了不少的工作的。最开头我试图让它们“重用”大部分代码，只是在不一样的地方做一些条件分支进行特殊处理。可是后来发现这样越来越复杂，越来越危险。为了照顾一个语言的特性，很容易破坏掉为另一个语言已经调试好的代码。结果最后决定把它们完全分开，其中共享的代码通过手工拷贝修改。事实证明这个决定是正确的，否则到现在我可能还在为一些莫名其妙的错误伤脑筋。这个经验告诉我，所谓的 DRY（Don't Repeat Yourself）原则其实有它的局限性。有时候真的是宁愿拷贝粘贴代码也不要共享。



    目前 RubySonar 还缺少对 native 库代码的支持，但是由于代码始终保持了简单的原则（RubySonar 只有 7000 多行代码），那些东西会比较容易加进去。感兴趣的 Ruby 用户可以看看自己的 repo 是否已经得到处理，如果没有的话可以来信告诉我，也欢迎给我指出其中存在的问题。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 程序语言与……

 
 
 
 
    

    
 
     
  

      
   
程序语言与……

    程序语言的设计类似于其它很多东西的设计。有些微妙的地方只有用过更好的设计的人才能明白。现在我就简要介绍一下我自己的体会。


程序语言与微波炉


    



    有的程序语言就像左边的，现在中国市场上流行的微波炉。布满了花哨的一年都用不到一次的专用菜单，却连最基本的 0-9 数字键都没有。输入个时间都要费脑筋组合一下，按键位置不顺手，不能一次按到位，而且还不能达到需要的精度。



    有的程序语言就像右边的，美国市场上常见的微波炉，几十年不变的设计。虽然按键很少，但十个数字键总是少不了，而且采用标准的“电话键盘”排列。十个数字能够组合产生出任意的时间，所以不管是在自己家里，别人家里，公司或者学校，你总是可以按照自己的经验，食物包装或者菜谱上的说明，迅速而精确的输入想要的时间。



    可惜的是，在中国你已经买不到这么简单实惠的微波炉了。我们中国人学会了美国的很多糟粕，却没有把这么简单，这么好的设计思想学过去。



    中国的微波炉厂商之所以放上这么多的花样，是因为商家抓住了中国人的贪便宜心理。看，一个微波炉可以煮米饭，烤肉串，还可以蒸排骨，那其他的厨具都可以不用买啦！可惜因为所以，科学道理，微波就是微波。加热牛奶剩饭之类的事它做得很好，可是要做美味佳肴它就不行了。煮米饭不如电饭煲，烤肉串不如烧烤架，蒸排骨不如蒸锅，炖东西不如砂锅…… 美国人和稍微有点经验的中国人早就知道这个道理，所以从来不期望微波炉能做超越它所擅长的事情。



    虽然美国人在这些硬件上非常精明，可是在软件上还没发展到那种地步，很多时候对一些不可救药的软件技术寄予太多的希望。左边的微波炉就好像某些程序语言，本来当初设计就是给标准没那么高的人用来处理很简单的网页的。可是后来有人忽然想让它成为一个“万能语言”，用来做复杂的，对性能和可靠性都很高的服务器程序甚至机器人控制程序。然后你就发现类似微波炉的问题，因为一些不可逾越的设计差别决定了它是不可能把那些事情做好的，而且对有些应用还有严重的安全隐患。当然你可以缓慢的“改进”这语言，让它慢慢的提高做这些事的水平。可是这种改进的终点也许只是另一种早已存在的语言。而且由于不想破坏已有的代码和特性，所以每一步的改进都异常艰难。这种方式远远不如直接针对需要选择不同的语言，或者设计新的语言来的迅速和有效。


程序语言与减肥


    



    很多人都想减肥，就像很多人都想学会编程。姑且不说一味的减肥好不好，现在只谈一下什么是有效的减肥方法。



    我自己也有一段时间很胖，也有减肥的经历，而且非常成功。如果有一天我不小心又变胖了，我有非常科学而可靠的办法减回去。我的方法就是一句话：让每天吃进去的热量比消耗的少一些，但是不至于难受，另外适当运动来增加热量的消耗。很显然嘛，根据热力学定律，每天消耗的能量比摄入的多，多出来的部分只能通过分解你身上的物质（脂肪）来产生。我的减肥方法就像某些程序语言教会我的编程理念，是不随潮流而改变的真理。它让我的程序不管用什么语言写都优美而精悍。



    我不是自私的人，我希望大家都健康一点，养眼一点。我已经轻易地告诉了你减肥的终极真理，一分钱都不收，可是你不相信我。你觉得肯定没那么简单，或者你觉得那样太辛苦，自己不可能照办。这就像很多人对编程的希望：要是我不学编程也能编程该多好啊！



    很多程序语言就是针对这群人而产生的，它们大部分的工作花在了研究人的心理和做广告上面。它们就像电视广告里铺天盖地的减肥药：不需运动，不用节食，一个星期瘦 20 斤！它们提出各种新的术语，什么减肥茶，片，胶囊，螺旋，燃脂，纤维，宫廷，祖传，秘方，各种生化术语…… 再加上一些 PS 出来的前后效果对比图，你痛快地花不菲的价钱买了这药，然后每天好几次的像做化学实验一样精确的按时按量服用。这时候任何人跟你说这药不灵的话你都不会相信，你觉得这些人都是想跟你争夺异性的目光故意想让你继续胖下去而其实她（他）们自己背地里也吃这药，所以你对此减肥药必胜的信心有增无减。



    当然你不会成功。在持续服用好多个月，甚至好几年之后，你按照广告里说的“无效退款”条例要求退款。可是减肥药公司说，是你自己没有按说明书服用，或者你吃药之前肯定比现在还胖很多。你拿不出证据，后悔当初没到公证处开你当时体重的证明。可是你仍然相信，世界上一定会有真正有效的减肥药。你觉得国内的公司喜欢骗人，所以你到了美国，寻找传说中那世界一流的减肥药……


程序语言与棋


    



    有人说好的程序语言就像国际象棋（chess），在了解简单的规则之后，你就可以用它们组合出变幻无穷的棋局。而我认为，好的程序语言应该像国际象棋去掉像“王车易位”（castling）一类复杂古怪的规则。实际上，好的程序语言会更加近似于中国象棋，而不是国际象棋。中国象棋只有一条规则比较特殊—“蹩脚马”，可是它其实很直观，容易理解。其它的规则，比如兵卒过河才能横行，几乎都画在棋盘上了。



    可不要小看国际象棋里这少数几个特殊规则，它们需要在好几个非常特殊的条件满足之后才会生效，而且路线诡异。比如，王车易位必须满足：



王和跟他换位的车都没有移动过
王和车之间没有其它棋子
王不能处于被“将军”的状态而且王在换位之后不能处于被攻击的位置但是车可以在换位后处于被攻击位置
王和车处于同一条水平线上




    另外换位的时候王和车不是直接互换位置那么简单，而是这样的路线：



    



    一条这样的特殊规则就够伤脑筋了，据我所知国际象棋还有至少其它两条类似的规则。它们跟其他的规则组合在一起的时候就产生了组合爆炸效应，你发现每走一步，甚至貌似无关的动作都得检查它们是否会出现。你不得不随时把这么复杂的规则放在脑子里。没事找事也不要找这么麻烦的事啊。



    这些规则就像是要你记住 C 语言里的 ++i+i++ 或者 if (x = "foo") {...} 是什么意思。经过多年的痛苦经历之后，你多希望不再需要理解这样的代码。可是一旦这样的规则被加到语言里面，总会有人为了显示自己的水平和记忆力去用它们。不得已，你只好陪他们玩。



    如果你觉得多了这些无厘头的规则会让国际象棋比中国象棋难度大或者更加有趣，那你就低估了中国象棋了。中国象棋的“游戏树复杂度”其实比国际象棋还要高，高达 10150，而国际象棋只有 10123。这跟中国象棋的棋盘要稍微大点有关系，但是总比记忆那些麻烦的规则好多了。所以相对来说中国象棋既简单又耐玩。



    如果国际象棋还凑合算是简单的话，大部分的程序语言就像是魔鬼棋，飞行棋，或者三国杀。它们几乎完全由类似的特殊规则构成。哇，那么多的人物，道具和特殊技，好玩！可是会玩象棋或者国际象棋的人都会觉得它们无聊透顶。



    那么是不是规则越简单越少的棋越好呢？围棋就比中国象棋还简单，那么围棋是不是更好玩呢？我觉得不是的。围棋对我来说太慢，太单调，棋盘太大，耗时太多，而且胜负居然不能一眼就看出来，要数好一会儿！这哪里是在玩，纯粹就是在做组合优化题嘛。我觉得这种任务适合交给电脑去做。所以其实简单也有一个界限，超过了这个界限对于人就没有很大区别了，反而会开始感觉缺少一些东西。



    我觉得中国象棋和围棋一样简单，它的规则虽然比围棋多，但是仍然处于人脑容易记忆的范围，而且每条规则都很直接了当，没有很隐晦的条件。中国象棋的长距离武器（车和炮）让它比围棋多了很多乐趣，而对于象，马和王的走法的限制，让它比起国际象棋多了几分安心和舒适。国际象棋的后，两个车，两个相的攻击距离和范围太大，让人觉得眼睛很辛苦，因为每一个位置都可能被从太多个方向远距离攻击。而那个王，由于可以到处乱跑，以至于你感觉不是在抓一个住在戒备森严的城堡里的人，而是一只在野外乱跑的老鼠。



    什么游戏会让人觉得有趣，真是一个值得研究的问题。我觉得象棋和我以前推荐过的一个游戏 Braid 里面含有同一种吸引人的设计：屈指可数但又有足够变化的简单规则，组合起来制造出许许多多的变化。这种特征其实也是鉴别一个优秀的程序语言的标准。


程序语言与音乐


    



    程序语言就像音乐。当听过很好的音乐之后，你会自然而然的厌倦以前曾经喜欢过，为之疯狂过的那些，觉得它们很无趣，甚至很惊讶自己以前怎么会喜欢它们。当有人问你为什么不喜欢他们推荐给你的音乐，你却说不出来。你只是自然而然觉得太单调，不入耳，不对劲，甚至扰乱你美好的心情。你的判断完全是依靠声波对鼓膜的震动而引起的脑电波的起伏，而不带有任何的成见。完全根据这音乐自己，而不需要知道它的作者是谁。就像玩过像《Braid》之类的游戏之后，你再也不想玩像《生化危机》那种搞不清楚到底是自己在玩游戏还是游戏在玩自己的。你的脑子里有一种对“趣味”的新定义，但是你却说不出来它到底是怎么回事。



    程序语言是同样的感觉，这是一个“流行语言”招摇过市的年代。每当有人问我喜欢什么程序语言我都不好跟他说，因为一旦说出来就有显摆之嫌，而其实真正显摆的是其他人。很多人期望你的回答是他所膜拜的那个最近很热门的语言，你一旦告诉他你喜欢的语言就会被冷嘲热讽，因为你的语言不热门。他们会说你是“学院派”，而他们是“工程派”，而其实这只是给垃圾的存在找借口。他们利用你害怕自己被认为是附庸风雅或者居高临下的心理来变相地压制你，让你不敢直率的袒露自己的兴趣。你不敢显示对有些东西的不屑，而他们却可以任意的显示对真正优秀的技术的不屑。你觉得应该手下留情一些，谦虚一些，结果最后一些垃圾一样的语言就骑到你头上来，让你不得不用它们。



    用过很好的语言，然后自己设计过程序语言之后，我再也不对很多新的语言，或者有些人很崇拜的古老的语言感兴趣了。我完全是凭自己的感觉来判断，一些所谓的“新特性”其实是老酒换新瓶，或者是勾兑的假酒。程序语言本来就只有那么点东西，为什么有人仍然像对那些扮相的流行歌手一样热衷和疯狂。



    我知道这些话说了也白说，因为他们没有用过我用过的语言，他们只看到名字却感觉不到本质，他们靠别人的评价来判断，而不是靠自己的心。所以像音乐一样，只有等有一天他们忽然觉悟，就像很多年前的我一样。


程序语言与武器


    



    前段时间 AK-47 的设计者 Kalashnikov 去世的时候，我从一篇文章了解到他设计 AK-47 的故事，发现 AK 跟我喜欢的程序语言设计有异曲同工之妙。



    AK 简单得就像一把锤子。它身上没有太空时代的材料。大多数汽车修理店都有可以制造出 AK 的工具。



    这篇文章首先提到，AK 的高可靠性最主要来自于它的简单，而其实简单也是程序语言最重要的东西。程序员需要解决的问题一般都挺复杂，如果他们的工具再被设计得复杂，那么他们大量的脑力就被浪费在解决这语言的问题，而不是真正需要解决的问题了。



    Kalashnikov 开始的时候把任何有可能出问题的设计都排除在外了。



    与简单的设计背道而驰，现在很多程序语言为了赶潮流或者吸引眼球，喜欢标新立异，喜欢加入很多“特性”，可是这些特性很有可能不但不解决问题，而且会制造问题。绝大部分程序员都不理解这个道理，所以有些人听说我在设计自己的语言就问我：“它有什么新特性吗？”我没法回答他们，因为我的设计几乎没有新的特性。我现在所做的一切思考和试验都是在去掉不必要的麻烦。一个语言缺少一些好的特性，以后还可以加进去，可是它如果多了一些问题特性，那一旦有人开始用就没法去掉了。



    AK 上面没有袖珍和娇气的部件。这样你就不用费事在草丛里，泥地上或者溪流里找它们了。



    士兵是人，会摔跤犯错误，程序员也是人，所以程序员的武器应该像士兵的武器一样，方便他们找到问题。可是很多程序语言让程序员犯错误之后花很多时间和精力才能找到错误的所在，浪费大量本来可以用来解决问题的时间。我的前同事 TJ 说他刚进入博士学习的时候花了好几个月，就为了找到 C 代码里面一个指针计算错误，导致内存结构破坏和莫名其妙的错误结果，而出现指针计算错误的位置跟错误结果出现的位置毫无关系。我也遇到过类似的问题。C 语言的指针不就像是某些武器上面的袖珍部件吗？一不小心掉在地上就找不到了。



    AK 只有一个复杂一点的部件，那就是它的弹夹。弹夹的设计很大程度上影响到枪的整体性能，所以 Kalashnikov 在上面花了很多设计时间。



    



    这个工程经验其实对于程序语言的设计者有启发意义，因为弹夹与枪主体的接口，和程序语言的函数接口很类似。Tony Hoare 在他的《给程序语言设计的建议》中也提到，函数的调用必须简单而且快速，因为调用的开销会累积起来形成很大的性能问题。可惜的是很多语言没有注意到这个问题，函数调用时总是有一堆的动态检查和重载要做，很大程度的影响了它们的性能。



    AK 的美，在于它身上没有部件具有不必要的精确性。



    这对于程序语言或者编程来说也是有启发意义的。有些人为了所谓的程序“正确性”，损害了它的简单性。他们的代码异常复杂，而且喜欢写很多测试，让自己感觉对程序的“质量”有个底。然而这其实是自欺欺人。这些测试不但不能保证程序的正确，它们阻碍了程序员对程序进行彻底性的修改，防止了他们看到更加简单，甚至一眼就知道是正确的解决方案。



    程序语言的设计也是。有些语言（特别是所谓 dependent type 的语言）想达到程序的完全正确，加入了很多很多的限制条件，要求程序员写很多的辅助声明甚至机器证明。结果很简单一个问题都需要很长的代码才能写出来，这些辅助的逻辑代码严重的影响了程序的阅读和转换。而且由于数理逻辑本身的局限性，它们经常迫使程序员的思路绕弯子。其实起到了相反的结果，让他们看不到更简单的方法。



    Kalashnikov 不是天才，他不是为了发明而发明，他解决不了问题的时候就高兴地从别人那里学过来。



    这是非常值得我们程序语言设计者学习的。很多程序语言专家都有盲目排斥“对手”的心理，“自己人”的东西就不假思索的表扬，对手的东西就一味的批评。最后的结果是没有把敌人的好东西学过来，让自己人吃亏。在操作系统和数据库等领域也有类似的思维方式，这是非常有害的。



    直到被更好的东西取代，AK 会继续和我们在一起。什么才是“更好”，这是由历史和民族来定义的，而不是枪支设计专家。



    在计算机的世界里也是一样，程序语言，操作系统，数据库…… 它们的好坏不应该是由它们的设计者决定的，而是看它们是否经得起时间的考验。很多几十年前以为是好的设计，到现在已经很明显的显示出了它们的缺点。这就是为什么我喜欢批评一些语言，操作系统和数据库的设计，因为我看到了它们在历史的长河中已经快要到达终点。自欺欺人的掩盖这些缺陷只会让我们输掉战争。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 我和权威的故事

 
 
 
 
    

    
 
     
  

      
   
我和权威的故事

    每个人小时候心里都是没有权威的，就像每个人小时候也都不相信广告一样。可是权威就像广告，它埋伏在你的潜意识里。听一遍不信，听两遍不信，……，直到一千遍的时候，它忽然开始起作用了，而且这作用越来越强。



    消灭广告所造成的幻觉，最好的办法就是去尝试，去实地的考察它。有些虚幻的东西只要你第一次尝试就会像肥皂泡一样破灭掉。可是如果你不主动去接触它，它就会一直在你脑海里造成一种美好神圣的假象。越是得不到的越是觉得美好。很神奇的一个现象就是，权威对人思想的作用其实也跟广告一样。



    上大学以前的人因为没有专业，所以还不怎么崇拜权威，大不了追追歌星，影星，球星啥的。而进了大学之后，就会开始对本领域的权威耳濡目染。一遍，两遍，一千遍的听到同学们仰慕某“牛人”或者“大师”的名字，虽然从来没亲身见过，不知不觉就对这人产生了崇拜心理，然后自愧不如。不知不觉的，自己也开始附和这些说法，不自觉地提到这些大师的名字，引用他们说的话作为自己的行动指南。



    Donald Knuth, Dennis Ritchie, Ken Thompson, Rob Pike, ... 就是通过这些途径成为了很多计算机学生的权威。以至于几十年以后，他们的一些历史遗留下来的糟糕设计和错误思想还被很多人奉为神圣。


Donald Knuth


    很多人（包括我）都曾经对 Knuth 和他的 The Art of Computer Programming (TAOCP) 极度崇拜。在我大学和研究生的时候，有些同学花了不少钱买回精装的 TAOCP 全三卷，说是大概不会看，但要供在书架上，镇场子。当时我本着“书非借不能读也”的原则，再加上搬家的时候书是最费力气的东西，所以坚决不买书。我就从图书馆把 TAOCP 借了来。说实话我哪里看的下去啊？那里面的程序都是用一个叫 MIX 的处理器的汇编语言写的。一个字节只有6位，每位里面可以放一个十进制数（不是二进制）！还没开始写程序呢，就开始讲数学，然后就是几十页的公式推导，证明…… 接着我就睡着了。但我总是听说有人真的看完过 TAOCP，然后就成为了大师。比尔盖茨也宣称：“要是谁看完了 TAOCP，请把简历投给我！” 在这一系列的号召和鼓吹之下，我好几次的把 TAOCP 借回来，下定决心这次一定看完这旷世奇书。每次都是雄心勃勃的开始，可从来就没看完过开头那段 MIX 机器语言和数学公式。



    看不懂 TAOCP 总是感觉很失败，因为看不懂 TAOCP 就成不了“大师”，可我仍然认为 Knuth 就是计算机科学的神，总能从他那学点什么吧，所以又开始折腾他的其他作品。这就是为什么我开始用 TeX，并且成为中国 TeX 界的主要“传教士”之一。为了 TeX，我把 Knuth 的 TeXbook 借回来，从头到尾看了两遍，做完所有的习题，包括最难最刁钻的那种“double bend”习题。接着又开始看 MetaFont Book，开始使用 MetaPost 进行绘图。开头还挺有成就感，可是不多久就发现学会的那些 TeX 技巧到了临场的时候就不知道该怎么用，然后就全都忘记了。这就是为什么我把 TeXbook 看了两遍，可是看完第二遍之后不久还是忘记得一干二净。



    师兄师姐看到我用 TeX，说怎么折腾这么过时的玩意儿。我很气愤他们以及国内学术界居然都用 Word 排版论文，就开始针锋相对，写出一系列煽动文章鼓吹 TeX 的种种好处，打击“所见即所得”这种低智商玩意儿。这还不够，又开始折腾 Knuth 设计的 MMIX 处理器，并且认为 MMIX 的寄存器环就是世界上最先进的设计。发现一些无关紧要的小错，就给 Knuth 发 email，居然拿到两张传说中的“Knuth 支票”，并且一度引以为豪。当然像所有拿到 Knuth 支票的人一样，你是不会去兑现它的，甚至有人把它们像奖状一样放在相框里。我还没那么疯狂，那两张支票一直在它们原来的信封里。多年以后我到美国想兑现那支票的时候，发现它们已经过期了。



    



    当你心里有了这样的权威，其他人的话你是不可能听得进去的，就算他们其实比你心目中的权威更具智慧也一样。在清华的时候我有时候去姚期智的小组听客串讲座。有一次请来了美国某大学一个教授讲算法，不知道怎么的我就跟他聊起 TAOCP，大概是想请教他如何学习算法。他跟我说 Knuth 的书已经比较过时了，你可以看看 MIT 的那本《算法导论》。可是这位教授的名气怎能和 Knuth 相比，这话我恁是没有听进去，仍然认为 TAOCP 隐藏了算法界最高的机要，永恒的珍宝。



    在清华的时候我很喜欢一门叫做“计算几何”的课，就经常跟那门课的老师交流思想。有一次我在 email 里面提到 Donald Knuth 是我的偶像，那位老师很委婉的回复道：“有偶像很好啊，Knuth 也曾经是我的偶像。” 我对“曾经”这两个字感到惊讶：难道这意味着 Knuth 现在不是他的偶像了？在我执意的询问之下他才告诉我，其实世界上还有很多更聪明的人，Knuth 并不是计算机科学的一切。你应该多看看其他人的作品，特别是一些数学家的。然后他给了我几个他觉得不错的人的名字。



    现在回想起来，这些话对我是有深远作用的。那位老师虽然在系里的“牛人”们眼里是个研究能力（也就是发 paper 能力）不强的人，但是他却对我的人生转折有着强有力的作用。他引导了我去追寻自己真正的兴趣，而不是去追寻虚无的名气。我发现很多人都在为着名气而进行一些自己其实不感兴趣的事情，去做一些别人觉得“牛气”的事情。我真希望他们遇到跟我一样的好老师。



    在现在看来，Knuth 的 TAOCP 就是所谓的“神圣的白象”（white elephant）。大家都把它供起来，其实很少有人真的看过，却要显得好像看过一样，并且看得津津有味。这就让试图看懂它的人更加自卑和着急，甚至觉得自己智商有问题。别人都看过了，我怎么就看不懂呢？其实 TAOCP 里面的大部分算法都不是 Knuth 自己设计的，而且他对别人算法的解释经常把简单的问题搞得很复杂。再加上他执意要用汇编语言，又让程序的理解难度加倍。



    有一句话说得好：“跟真正的大师学习，而不是跟他们的徒弟。”如果你真的要学一个算法，就应该直接去读那算法的发明者的论文，而不是转述过来的“二手知识”。二手的知识往往把发明者原来的动机和思路都给去掉了，只留下苍白无味，没有什么启发意义的“最后结果”。确实是这样的，多年以后当我看见 Knuth 计划中的几卷新的 TAOCP 的目录时，发现其中大部分的东西我已经通过更容易的方式学到了，因为我找到了这些知识的源头。



    所以之前的那位访问清华的教授说的其实是实话，Knuth 真的落伍了，可是就算在美国也少有人知道或者承认这个情况。有一次看一个对世界上公认最厉害的一些程序员的采访，包括总所周知的一些大牛，以及 ML 的设计者 Robin Milner，Haskell 的设计者之一 Simon Peyton Jones 等人。也不知道采访者是什么心理，在对每个人的采访中他都问，你看过 TAOCP 吗？大部分人都说看过，真是了不起的巨著，很重要啊云云。只有 Robin Milner （如果我没记错的话）比较搞笑，他说我希望我看过，但是可惜实在没时间。我一直把 TAOCP 垫在我的显示器下面，这样我工作时就可以一直看着它们 :)



    Knuth 说“premature optimization is the root of all evil”，然而他自己却是非常喜欢用 premature optimization 的人。他的代码里到处是莫名其妙的小聪明，小技巧。把代码弄得难懂，实际上却并没有得到很多性能的提高。有一次看 MMIX 处理器的模拟程序，发现他用来计算一个寄存器里的“1”的个数的代码非常奇怪。本来写个循环，或者用那种从末位减 1 的做法就可以了，结果他的代码用了 Programming Pearls 里面一个古怪的技巧，费了我半天时间才看懂，后来我发现这个技巧其实还不如最简单的方法。就是这些细小却又蹊跷的做法，使得 Knuth 的代码用细节掩盖了全局，所以到最后我其实也没从大体上搞懂一个处理器的模拟器应该如何工作。直到后来到 Indiana 学习了程序语言的理论之后我才发现，其实处理器模拟器（以至于处理器本身）的工作原理很简单，因为它就是一个机器代码的解释器。使用跟高级语言解释器同样的结构，你可以比较容易的写出像 MMIX 模拟器那样的东西。



    Knuth 最重要的一个贡献恐怕是程序语言的 parsing （语法分析），比如 LR parsing，然而 parsing 其实是一个基本不存在的人造问题。它的存在是因为人们的误解，以为程序语言需要有跟人类语言一样的语法，所以把程序语言搞得无端的复杂和困难。如果你把语法简化一下，其实根本用不着什么 LR，LALR。我最近给我自己设计的语言写了一个 parser ，从头到尾只花了两个小时，500 行 Java 代码，包括了从 lexer 一直到 AST 数据结构的一切。完全手写的代码，根本没用任何复杂的 parsing 技术和 YACC 之类的工具，甚至正则表达式都没有用。之所以可以这样，因为我的语法设计让 parsing 极其容易，比 Lisp 还要容易。Knuth 过度的强调了 parsing。他的误导使得很多人花了几十年时间来研究 parser，到现在还在不时地提出新的技术，用于设计更加复杂的语法。何必呢？这只会让程序员和编译器都更加痛苦。如果这些人把时间都花在真正的问题上，那今天的计算机科学不知道要美好多少。



    几乎每一本编译器教材都花大量篇幅来讲述 DFA, NFA, lexing, LL, LR, LALR…… 几乎每个学校的编译器课程都会花至少 30% 的时间来做 parser，折腾 LEX，YACC 等工具，而对于编译器真正重要的东西却没有得到很多的训练。这就是为什么 Kent Dybvig 的编译器课程如此有效，因为 Scheme 的语法非常简单，我们根本没有花时间来做 parser。我们的时间用在了思考真正的问题：做优化，实现尾递归，高阶函数…… 很多语言梦寐以求却又做不好的东西。这样的课程给了我可以发挥自己潜力的余地，我的课程编译器里面具有大量的独创写法，我的 X64 机器代码生成器生成极其短小的代码，让 Kent Dybvig 都在背地里琢磨是怎么回事。这些东西到现在也许仍然是世界上最先进的技术。



    一个人的思维方式似乎决定了他设计的所有东西。Knuth 的另一个最重要的发明，文学编程（Literate Programming）其实也是多此一举，制造麻烦。文学编程的错误在于认为程序语言应该像人类语言，应该适应所谓的“人类思维”。然而程序语言却是在很多方面高于人类语言的，它不应该受到人类语言里的糟粕的影响。把程序按照 Knuth 的方式分开在不同的文章段落里，造成了代码之间的关系很难搞清楚，而且极其容易出错。这个错误与“Unix 哲学”的错误类似，把程序作为一行一行的文本，而不是一个像电路图一样的数据结构。我不想在这里细说这个问题，对此我专门写了一篇文章，讲述为什么文学编程不是一个好主意。



    TeX 其实也是异常糟糕的设计。它过度的复杂，很少有人搞得懂怎么配置。经常为了一个简单的效果折腾很久，然后不久就忘了当时怎么做的，回头来又得重新折腾。原因就是因为 TeX 的设计缺乏一致性，特殊情况太多，而且组合（compose）能力很差。所以你需要学太多东西，而不是跟象棋一样只需要学习几个非常简单的规则，然后把它们组合起来形成无穷的变化。



    在程序语言设计者看来，TeX 的语言是世界上最恶劣的设计之一，但如果没有这个语言，它也许会更加糟糕。其实 TeX 之所以有一个“扩展语言”，有一个鲜为人知的小故事。在最早的时候 Knuth 的 TeX 设计里并没有一个语言。它之所以有一个语言是因为 Scheme 的发明者 Guy Steele。Knuth 设计 TeX 的那个时候 Steele 碰巧在斯坦福实习。他听说 Knuth 要设计一个排版系统，就建议他设计一个语言，以应付以后的扩展问题。在 Steele 的强烈建议和游说之下，Knuth 采纳了这个建议。可惜的是 Steele 并没能直接参加语言的设计，在短短的一个夏天之后就离开了斯坦福。



    Knuth 的作品里面有他的贡献和价值，TeX 的排版算法（而不是语言）也许仍然是不错的东西。可是如果因为这些好东西爱屋及乌，而把他所推崇的那些乱七八糟的设计当成神圣的话，那你自己的设计就逃脱不出同样的思维模式，让简单的事情变得复杂。仍然对 TeX 顶礼膜拜的人应该看一下 TeXmacs，看看它的作者是如何默默无闻的，彻彻底底的超越了 TeX 和 Knuth。



    在我看来，Knuth 是个典型的精英主义者，他觉得自己做的都是最好，最有“格调”的。他利用自己的权威和特立独行来让用户屈服于自己繁复的设计，而不是想法设计出更加易用的工具。TeX 的版本号每次更新都趋近于圆周率π，意思是完美，没有 bug。他奖励大额的支票给发现 TeX 代码里 bug 的人，用于显示自己对这些代码的自信，然而他却“冰封”了 TeX 的代码，不再填加任何新东西进去，也不再简化它的设计。当然了，如果不改进代码，自然就不会出现新的 bug，然而它的设计也就因此固步自封，停留在了几十年以前。更奇怪的是，“TeX”这个词居然不按照正常的英语发音逻辑读成"teks"。每当有人把它“读错”，就有“高手”打心眼里认为你是菜鸟，然后纠正：“那个词不读 teks，而要读‘特喝’，就像希腊语里的 chi，又像是苏格兰语的 loch，德语的 ach，西班牙语的 j 和俄语的 kh。”也许这就叫做附庸风雅吧，我是纯种的欧洲人！;-) 当一个软件连名字的发音都这么别扭，这么难掌握，那这个软件用起来会怎样？每当你提到 TeX 太不直观，就有人跟你说：“TeX 是所想即所得，比你的所见即所得好多了！”可事实是这样吗？看看 TeXmacs 吧，理解一下什么是“所见即所得+所想即所得”二位一体。



    我跟 Knuth 的最后一次“联系”是在我就要离开清华的时候。我从 email 告诉他我觉得中国的研究环境太浮躁了，不是做学问的好地方，想求点建议。结果他回纸信说：“可我为什么看到中国学者做出那么多杰出的研究？计算机科学不是每个人都可以做的。如果你试了这么久还不行，那说明你注定不是干这行的料。”还好，我从来没有相信他的这段话，我下定了决心要证明这是错的。多年的努力还真没有白费，今天我可以放心的说，Knuth 你错了，因为我已经在你引以为豪的多个方面超过了你。


Unix


    Unix 的创造者们是跟 Knuth 非常类似的权威，他们在我的心目中也曾经占据了重要的位置，以至于十年前我写了一篇文章叫《完全用 Linux 工作》，大力鼓吹 Unix 的“哲学”，甚至指出 Linux 不能做的事情就是不需要做的，并且介绍了一堆难用的 Unix 工具，引得很多人去折腾。可如果你知道我现在对 Unix 的态度，肯定会大吃一惊，因为在经过努力之后，我成功的“忘记”了 Unix 的几乎一切，以至于本科刚毕业的学生都会以为我是脑盲，并且以为可以在我面前炫耀自己知道的 Linux 技巧。他们不会明白，在我心里 Unix/Linux 的设计是计算机软件界目前面临的大部分问题的罪魁祸首，而他们显示给我看的，只不过是 Unix 的思想和精英主义给程序员造成的精神枷锁。其实我并不会忘记 Linux 的设计，但我已经下意识的以熟悉 Linux 的奇技淫巧为耻，所以很多时候我即使知道也要装作不知道。因为我是机器的主宰，而不是它的奴隶，所以我总是想办法让机器去帮我做更多的事，帮我记住那些无聊的细节，而不是去顺从它的设计者所谓的“哲学”。



    评论 Unix 和它的后裔们总是一件尴尬的事情，因为你提到它们的任何一个缺点，都会被很多人认为是优点。GNU 的含义是“GNU is Not Unix”，但很可惜的是 GNU 和 Linux 的设计从来没有摆脱过 Unix 思想的束缚。Unix 的内存管理，进程，线程，shell，进程间通信，文件系统，数据库…… 几乎都是很蹩脚的设计。所谓的“Unix 哲学”，也就是进程间通信主要依靠无结构字符串，造成了一大批过度复杂，毛病众多的工具和语言的产生：AWK，sed，Perl，…… Unix 的内存管理是按“页”而不是按“结构”分配，相当于把内存分配的任务完全推给应用程序。而且允许任意的指针操作，这就像给每个老百姓一把爱走火的枪。可是又想要“安全”，自相矛盾。没办法，不得不强制进程数据空间完全隔离，使得进程间无法直接传递数据结构。进程和线程上下文切换开销过大，造成了使用大规模并发或者分布式计算的瓶颈，导致了 goroutine 和 node.js 等“变通方法”的产生。把数据无结构的存储在文件里，无法有效的查找数据，造成了关系式数据库等过度复杂的数据解决方案的产生。再加上后来 WEB 的设计，现在的网站基本上就是补丁加补丁，一堆堆的 hack。



    “Unix 哲学”貌似也有好的部分，比如“每个程序只做一件事，多个程序互相合作。”然而，这个所谓的哲学其实就是程序语言（比如 Lisp）里面的模块化设计。它当然是好东西，然而这些思想被 Unix 偷来之后，有其名而无其实。很少有 Unix 程序真正只做一件事的，而且由于字符串这种通信机制的不可靠，它们之间其实不能有效地合作。有时候你换了一个版本的 make 或者 sed 之类的工具，你的 build 就莫名其妙的出问题。这就是为什么有的公司请了专门的所谓“build engineer”，因为高级别的程序员不想为这些事情操心。Lisp 程序员早就明白这个道理，所以他们尽一切可能避免使用字符串。他们设计了 S 表达式，用于结构化的传输数据。实际上 S 表达式不是“设计”出来的，它是每个人都应该首先想到的，最简单的可以表示树结构的编码方法。Lisp 的设计原则里面有一条就是：Do not encode。它的意思是，尽量不要把有用的数据编码放进字符串。Unix 的世界折腾来折腾去，XML，CORBA，…… 最后才搞出个 JSON，然而其实 JSON 完全不如 S 表达式简单和强大。Unix 就像一个脑瘤，它让人们放着最好的解决方案几十年不用，不断地设计乌七八糟的东西用来取代乌七八糟的东西。这些垃圾对人有很大的洗脑作用。前段时间我说 S 表达式比 JSON 简单，有人居然跟我说 JSON 好些，因为它结构的 field 是“无顺序”的。这让我相当无语，因为一个编码方式有没有顺序完全取决于你如何解释它。从这个意义来讲，S 表达式可以是有顺序，也可以是没有顺序的。



    Unix 喜欢打着“自由”和“开源”的旗号，可是它的历史却充满了政治，宗教，利益冲突和对“历史教科书”的串改。几乎所有操作系统课本的前言都会提到 Unix 的前身 Multics，而提到 Multics 的目的，都是为了衬托 Unix 的“简单”和伟大，接下去基本上就是按部就班的讲 Unix 的设计，仿佛 Unix 就是世界上唯一的操作系统一样。 课本会告诉你，Multics 由于设计太复杂，试图包罗万象，最后败在了 Unix 手下。可是如果你仔细了解一下 Multics 的历史，就会发现最后一台 Multics 机器直到 2000 年还在运行，拥有 Unix/Linux 到现在还没有的先进而友好的特性，并且被它的用户所爱戴。Multics 的设计并不是没有问题（对比一下 Lisp Machine 和 Oberon），但是相比之下，Unix 的设计一点都不简单。Unix 抄了 Multics 最好的一些思想，有些没有抄得像，然后又引入了很多自以为聪明的糟粕。可是 Unix 靠着自己病毒一样的特征，迅速占领了市场。Unix 最开头是开源和免费的，但是后来 AT&amp;T 发现这里面有利可图，所以就收回了使用权，并且开始跟很多人打官司。AT&amp;T 的邪恶比起微软来，真是有过之而无不及。



    Unix 的很多设计是如此龌龊，很多人却又由于官僚的原因不得不用它。以至于 Unix 出现的早期怨声载道，有人甚至组织了一个 mailing list 叫“Unix 痛恨者”(Unix Haters)。你很有可能把这些人当成菜鸟，可是这些人其实都用过更好的操作系统，有的甚至设计实现过更好的操作系统甚至程序语言。最后他们的叫骂声被整理为一本书，叫做 Unix Hater's Handbook。让人惊讶的是，这本书有一个“反序言” (anti-foreward)，作者正是 Unix 和 C 语言的设计者之一，Dennis Ritchie。这个反序言说，Unix 这座设计缺乏一致性的监狱会继续囚禁你们，聪明的囚犯会从它里面找到破绽，可惜的是自由软件基金会（FSF）会建造跟它完全兼容的监狱，只不过功能多一些。拥有三个 MIT 学位的记者，微软的研究员，Apple 的高级科学家可能还会对这座监狱的“规矩”贡献一些文字。从这些文字里，我看到了一个炫耀武力的暴君，看到了赤裸裸的权威主义和教条主义。



    可惜的是在软件的世界里任何糟糕的设计都可以流行，只要你的广告做得好，只要你的传教士够多。一知半解的人（比如十年前的我）最喜欢到处寻找“新奇”的东西，然后开始吹嘘它们的种种好处，进而成为它们的布道者。再加上大学计算机系的“紧跟市场”的传统，不幸的事情发生了：Unix 和它的后裔们几乎垄断了服务器操作系统的市场。由于 Unix 的垄断，现在的软件世界基本上建立在一堆堆的变通之上，并且固化之后成为了“珍珠”。公司里，学校里，充满了因为知道一些 Unix 的“巧妙用法”而引以为豪的人，殊不知他们知道的只是回避一些蹩脚设计的小计俩。程序员有太多的特例和细节需要记忆，不但不抱怨，还引以为豪。很少有人想过如何从根本上解决问题，历史的教训很少有人吸取，以至于几十年前犯过的设计错误还在重现。Unix 的最大贡献，恐怕就是制造了大量的工作岗位—因为问题太多太麻烦，所以需要大量的人力来维护它的运行。



    现在看来，Unix 当初就是依靠《皇帝的新装》里织布工的办法封住了大家的嘴。皇帝的织布工们说：“愚蠢或者不称职的人都看不见这件衣服。”Dennis Ritchie 说：“Unix 是简单的，但只有天才才能理解这种简单。”看出来了吗？你不敢说 Unix 的设计太乱太复杂，因为这话一出口，立马会有人引用 Dennis 的话说，是你自己不够天才，所以不理解。当然了，这就意味着他比你聪明，因为只有天才才能理解这种简单嘛。哎，这种喜欢显示自己会用某种难用工具的人实在太多了。你不敢批评这些工具对用户不友好，因为你立即会被鄙视为菜鸟。



    Dennis Ritchie 去世了。死者长已矣，可是有些他的崇拜者在那个时候还要煽风点火，拿他的死与 Steve Jobs 的死来做对比，把像这样的照片四处转帖，好像 Steve 死错了时间，抢了 Dennis 的风头似的。然后就有人写一些这样的文章，把世界上的所有系统，所有语言都归功到 Dennis 和 Unix 身上。看到这些我明白了，所谓的“天才”就是这样被造出来的。在我看来这些是很滑稽的谬论，就像是在说有人拿一把很钝的剪刀做出了一件精美的衣服，所以这剪刀立下了汗马功劳。其实这人一边裁布一边在骂这剪刀，心想妈的这么难用，快点做出这衣服，卖了钱买把好点的！



    用了这么久 Apple 的产品，平心而论，虽然它们并不完美，然而它们并不是 Unix 的翻版，它们做出了摆脱 Unix 思想束缚的努力。它们本着机器为人服务的原则，而不是把人作为机器的奴隶。Mac 的很多内部设计跟 Unix 有着本质的不同。然而就是这样的系统，被 Dennis Ritchie 在他的反序言里面蔑称为“以 Sonic the Hedgehog 作为智力主题和交互设计基础的系统”。



    有谁知道，在那同样一段时间里，Lisp 的发明者 John McCarthy，ML 的发明者 Robin Milner，都相继去世了呢？那个时候我只是在 mailing list 看到有人发来简短的消息，然后默默地思念他们给我带来的启迪。我们没有觉得 Steve Jobs 的死抢了他们的风头，因为他们不需要风头。死就是要安安静静的，让知己者默哀已经足矣。出现这种事情恐怕不能怪 Dennis Ritchie 自己，然而这些 Unix 的崇拜者们，真的应该反省一下自己的做法了。



    Unix 的设计者们曾经在我的心里占据了一席之地，可是现在觉得他们其实代表了反动的力量，他们利用自己的影响力让这些糟糕的设计继续流传，利用人们的虚荣心，封住大部分人的嘴，形成教条主义，让你认为 Unix 的设计是必须学习的东西。很多人成为了 Unix 的传教士和跟屁虫，没有什么真实水平，就会跟着瞎起哄，把 Unix 设计者的话当成教条写进书里。可是他们的权威和名气是如此之大，让我在很多人面前只能无语。


Go 语言


    现在，同样这帮 Unix “大牛”们设计了 Go 语言，并且依仗自己的权威和 Google 的名气大力推广。同样的这帮跟屁虫开始使用它，吹捧它，那气势就像以为 Go 可以一统天下的样子。真正的程序语言专家们都知道，Go 的设计者其实连语言设计的门都没摸到。这不是专家们高傲，他们绝不会鄙视和嘲笑一个孩子经过自己的努力做出一个丑陋的小板凳。他们鄙视，他们嘲笑，因为做出这丑陋小板凳的不是一个天真的小孩，而是一些目空一切的人，依仗着一个目空一切的公司。他们高举着广告牌，试图让全人类都坐这样丑陋的板凳。



    跟当年设计 Unix 时一个德行，不虚心向其它语言和系统学习经验教训，就知道瞎猜瞎撞。自己想个什么就是什么，但其实根本就不知道自己在干什么。把很多语言都有的无关紧要的功能（比如自动格式化代码）都吹嘘成是重大的发明，真正重要的东西却被忽略。Go 语言的设计在很多方面都是历史的倒退，甚至犯下几乎所有其他语言都没有的低级错误。在语法上大做花样，却又搞得异常丑陋，连 C 和 Java 都不如。自己不理解或者实现难度大点的东西就说是不需要的，所以连很多语言支持的 parametric type（类似 Java generics）都没有，以至于没法让程序员自定义通用数据结构，只好搞出一堆特例（比如 map，make，range）来让程序员去记。这些做法都跟 Unix 如出一辙。



    Go 语言最鲜明的特征就是 goroutine，然而这个东西其实每个程序语言专家都知道是什么。有些语言比如 Scheme 和 ML 提供了 first-class continuation（call/cc），可以让你很容易实现像 goroutine 这样的东西，甚至实现硬件中断的“超轻量线程”。至于 Go 那种“基于接口”的类型系统设计，我在很多年前就已经试验过，并且寄予了很大的希望。结果最后经过很多的研究和思索后发现有问题，于是放弃了这个想法。很显然，我不是第一个在这个问题上失败的人，很多语言专家在使用 parametric type 以前都试图过做这种基于接口的设计，结果最后发现不是什么好东西，放弃了。然而 Go 的设计者却没有学到这些失败教训，反而把它当成宝贝。一个很显然的问题是，在 Go 里面你经常会需要使用“空接口”（interface{}），用来表示所有类型。这就像使用 C 的 void 指针一样，有着静态类型系统的麻烦，却失去了静态类型系统的好处。



    每当你提到 Go 没有 parametric type，Go 的拥护者们就说“我看不到这有什么用处”，就像一些非洲土著跟你说“我看不到鞋子有什么用处”一样。他们利用人们对 Java 的繁复和设计模式的仇恨，让你抛弃了它里面的少数好东西。其实 Java generics 不是 Java 首先有的。它的主要设计者其实包括 Haskell 的设计者之一 Philip Wadler。这种 parametric type 很早就出现在 ML，Haskell 等语言里面，是非常有用的东西。



    每当受到批评，Go 的拥护者们就托词说，Go 是“系统语言”（systems language）。这里潜在的前提就是，认为 Unix 就是唯一的“系统”，而 C 就是在 Go 以前唯一的“系统语言”，好像其他语言就写不出所谓的“系统”似的。而事实是，在 C 诞生十年以前，人们就已经在用  Algol 60 这样的高级语言来写操作系统了。由于先天不足却又大力推广，所以 Go 的很多缺陷基本已经没法修补了。这样的语言一旦流行起来就会像 Unix 一样，成为一个无休止的补丁堆。如果像 Java 或者 Haskell 这样的语言还值得批评的话，对 Go 语言的设计者我只能说，去补补课吧。


Cornell


    可是权威和名气的威力还是很大的。虽然 Knuth 在我心目中的位置不再处于“垄断地位”，世界上可以占据我心里那个位置的人和事物还很多。在离开清华之后我申请了美国的大学。也许是天意也许是巧合，只有两所大学给了我 offer：Cornell 和 Indiana，而我竟然先后到了这两所大学就读。



    说实话，Indiana 给了我比 Cornell 更好的 offer。Cornell 给我的是一个 TA 的半工读职位，而 Indiana 给我的是一个不需要工作白拿钱的 fellowship。说实话我从来没有搞明白 Cornell 这样的“牛校”怎么会给我这样的人 offer，GPA 一般，paper 很菜，而 Indiana 却是真正在乎我的。Indiana 的 fellowship 来自 GEB 的作者 Doug Hofstadter。他从 email 了解到我的处境和我渴求真知的愿望之后，毅然决定给我，一个素不相识的人写推荐信。后来我才发现那 fellowship 的资金也是他提供的。



    可是 Indiana 和 Hofstadter 的名气哪里能跟 Cornell 的号称 “CS前五” 相比啊？Indiana 的 offer 晚来了几天。当收到 Indiana 的 offer 时，我已经接受了 Cornell。Hofstadter 很惊讶也很失望，因为他以为我一定会做他的学生，可是听说我接受了 Cornell 的 offer，他也不知道该怎么办。我只隐约的记得他告诉我，学校的排名并不是最重要的东西……



    名气和权威的力量是如此之大，它让我不去选择真正欣赏我并且能给我真知的人。有时候回想起来，我当时真的是在寻找真知吗？我明白什么叫做真知吗？



    Cornell 给了我什么呢？到现在想起来，它给我的东西恐怕只有教训，很多的教训。TA 的工作可不是那么好做的，基本就是苦力，你甚至会怀疑他们录取你就是为了利用你的廉价劳动力。我第一次做 TA 就是一个 200 多人在阶梯教室上的大课，教最基本的 Java 编程。虽然有好几个 TA，但任务还是很繁重。讲课的人不是教授，而是专职的讲师。这种讲师一般得靠本科生的好评来谋生，所以虽然在学术上没什么真本事，对学生真可谓是点头哈腰，服务周到。这就苦了各位 TA 了，作业要你设计，还要设计得巧妙，要准备好标准答案，之后还要批作业，批得你头脑麻木，考试要监考，之后还要批试卷。每周还得抽好几个小时来做 office hour，给学生答疑。然后你还有自己要上的课，自己的作业，自己的考试。每当考试的时候都很紧张，因为你得准备自己的考试，还要为学生的考试多做很多工作。



    如果真的学到了东西，这么辛苦也许还值得，可是那些教授真的是想教会你吗？有人打了个比方，说 Cornell 说要教你游泳，就把你推到水池里，任你自己扑腾。当你就要扑腾上岸时，他在你头上用榔头一砸，然后继续等你上岸。当你再次快要扑腾上岸时，他又举起一块大石头扔到你头上，这样你就可以死了，可是 Cornell 仍然等着你游上岸…… 这就是对我在 Cornell 的经历的非常确切的比喻。



    我在一篇老的博文里面提到过，Cornell 的学生，包括博士生，一上课就抄笔记，一天到晚都在赶作业。可其实 Cornell 不只是爱抄笔记的学生的天堂，而且是崇拜权威者的天堂。即使你不是那么的崇拜权威，你不可避免的会被一群像朝圣者一样的人围在中间，在你耳边谈论某某人多么多么的牛。不管你向同学打听哪一个教授，得到的回答总是：“哇，他很牛的！” 然后你就去上了他的几节课，觉得不咋的嘛，可是人家就说那是因为你不理解他的价值。这种气氛我好像在另一个地方感觉到过呢？啊对了，那是在 Google。这样的气氛也许并不是偶然，Cornell 的大部分 PhD 同学当时的最大愿望，就是毕业后能去 Google 工作。当然，后来 Facebook 上升成为了他们的首选。值得一提的是，Indiana 其实是更有个性的地方。我在 Indiana 的同学们一般都把去 Google 工作作为最后的选择之一。有一次一个刚来不久的学生问，如何才能进入 Google 工作？有个老教授说，那个容易，Google 招收任何能做出他们题目的人！



    




    Cornell 的研究可以用“与时俱进”来形容，什么热门搞什么。当时 Facebook 和社交网络正在“崛起”，所以系里最热门的一个教授就是研究社交网络的。我去听过他几堂课，他用最容易的图论算法分析一些社交网络数据，然后得出一些“理论”。其中好些结论实在太显然了，我觉得街上的卖菜大妈都能猜到，还不如研究星际争霸来得有意思点。可是 Facebook 名气之大，跟着这位教授必然有出路啦，再加上有人在耳边煽风点火，所以有好多的学生为做他的 PhD 挤破了头皮，被刷下来的就只好另投门路了。每次新来一个教授都会被吹捧上天，说是多么多么的聪明，甚至称为天才。然后就有一群的人去上他的课，试图做他的学生。结果人家每节课都是背对学生面朝黑板，喃喃自语，写下一堆堆的公式和证明，一堂课总共就没回过几次头。下面的人当然是狂抄笔记，有的人甚至带着录音笔，生怕漏掉一句话。上这样的课还不如干脆把板书打印出来让大家自己回家看。人多了竞争也就难免了。上课的同学们就开始勾心斗角，三国演义的战术都拿出来了。作业做不出来就来找你讨论，等你想讨论了就说自己也没做出来。没听懂偏要故作点头状，显得听懂了，让你觉得有压力。自己越是喜欢的教授就越是说他不咋的，扯淡，然后就自己去跟他。自己不喜欢的教授就告诉你他真是厉害啊，只可惜人家不要我。直到两年后我离开 Cornell 之前，还有好些同学因为没找到教授而焦头烂额。因为两年内没有找到导师的 PhD 学生，基本上等于必须退学。



    当我离开 Cornell 之后，有一位国内的学生给我发 email 套磁（从系里主页上找到我的地址），问我 Cornell 情况如何。我告诉他我都已经走人了，并且告诉了他我的感觉，一天到晚抄笔记赶作业之类的。然后又问我一个刚毕业的 PhD 的情况，我说他水平不咋的，博士论文我看过了，很扯淡，解决一个根本不存在的问题。他对我说的话有点惊讶，但还是将信将疑。为了确保万无一失，他在 visiting day 的时候专程去 Cornell 考察了一下。回去又给我 email，说见到好多牛人啊，大开眼界，哪里像你说的那么不堪。还说跟那位 PhD 的导师谈过话，真是世界级的牛人那，他的博士论文也是世界一流的。我就无话可说了，仁者见仁，智者见智，随他去吧，哎。



    结果两年之后，我又收到这位同学的 email，说他在 Cornell 还没找到导师，走投无路了，问我有没有办法转学。


图灵奖


    说到这里应该有人会问这个问题，我是不是也属于那种没找到导师走投无路的人。答案是，对的，我确实没有在 Cornell 找到可以做我导师的人。然后我就猜到有人会说，就知道王垠水平不行嘛，没搞定导师，被迫退学，哈哈！可是事情其实没他们想象的那么简单。作为一个 PhD 学生，不仅必须精通学术，而且要懂得政治和行情。哦错了，其实不精通学术也行的，但是一定要懂得政治和行情！可是由于学生之间的窝里斗，他们之间的信息互通程度，是没法和教授之间的信息互通程度相比的。这就造成了“学生阶级”在这场信息战上的劣势，总是被动的被教授挑选，而不能有效地挑选适合自己的教授。



    进入 Cornell 之后我上了一门程序语言的课，就开始对这些东西入迷。可是由于“与时俱进”，Cornell 的研究方向并不是那么平衡的发展的，其实是很畸形的发展。程序语言领域的专家们早已因为受到忽视而转移阵地，剩下一群用纸和笔做扯淡理论的。说实话，在历史上程序语言方向曾经是 Cornell 的强项，出现了一些很厉害的成果。可是当我在 Cornell 的时候，只剩下两个名不见经传的教员，一个助理教授，一个副教授。其实 Robert Constable 也在那里，可惜的是他做了 dean 之后已经没空理学生了，以至于我两年之后都不知道这个人的存在。我当时也不知道 Cornell 有过这段历史，看不到它的研究重心的移动趋势。



    我不喜欢那个副教授搞的项目，大部分是在 Java 上面加上一些函数式语言早就有的功能。可是人家做的是热门语言，所以拉得到资金，备受系里亲睐，他的学生们也比较趾高气昂。初次见面的时候，我跟他的一个学生说了我的一个想法，他说：“你那也能叫研究吗？待会儿我给你看看什么是真正的研究！” 其实那只是我的一个微不足道的想法，我也没说那是研究啊。只是随便聊一下而已就这么激动 -_- 何况你们那些 Java 的东西能算是研究？我是不可能跟那样的人合作的，所以我就跟那个助理教授做了一点静态分析的项目。当然我们分析的也不是什么好东西，是用 Fortran 写的 MPI 程序。不过说实话，那个助理教授其实挺有点真知灼见，他有几句话现在仍然在指引我，防止我误入歧途。其中一句话是针对我对 π-calculus 的盲目崇拜 说的：“那些理论其实不管用的。最好是针对自己的问题，自己动脑筋想。” 他也是很谦虚很善良的人，可是好人不一定有好报的。后来他没有拿到 tenure 职位，不得不离开 Cornell 加入了工业界，而我就失去了最后一个有可能在程序语言方向做我的导师的人。



    没办法，我就开始探索其它相关领域的教授，比如做数据库的，做系统的，看他们对相关的语言设计是否感兴趣。可惜他们都不感兴趣，而且告诉我程序语言领域太狭窄了。我当时还将信将疑，甚至附和他们的说法，可是现在我断定他们都是一知半解胡说八道。如果这些人虚心向程序语言专家请教，现在数据库和操作系统的设计也不会那么垃圾，关系式，SQL，NoSQL，…… 一个比一个扯淡。没有办法，我就开始探索其他的方向，开始了解图形学和数值分析等东西，进展很不错。可是终究我还是发现，我不喜欢图形学和数值分析所用的语言。我想制造出更好的程序语言来解决这些问题。可是跟教授们谈这些想法的时候就感觉是在对牛弹琴，他们完全不能理解。后来我发现，教授们貌似不喜欢有自己想法的学生，他们更希望找到愿意“打下手”的学生，帮助实现他们自己的想法。



    这就让我走到了跟那位向我打听 Cornell 情况的同学差不多的局面，真是心里有许多的苦却没有人可以理解。这时候我想到了系里的一些德高望重的教授，比如得过图灵奖的人，也许这些顶级的大牛会给我指出方向。于是我就联系到一位图灵奖得主，说想找他聊聊。我说我感兴趣的东西 Cornell 貌似并不重视和发展。Cornell 的校训是“any person, any study”，而我想 study 的东西却得不到支持。最后我谈了一下我对 Cornell 的总体感受。我说我觉得大家上课死记硬背，不是很 intellectual，我不是很确定学术界是否还保留有它原来的对智慧和真知的向往。



    我很诚恳的告诉了他这些，只是希望得到一些建议。结果他不但没有理解任何一点，而且立马开始用质问的语气问我，你成绩怎么样？考试都通过了没有？哎，说白了就是想搞清楚你是不是成绩不好没人要。怎么就跟高中教导主任一样。于是乎那次谈话就这样不了了之。可是没有想到，这次谈话就造成了我最后的离别。在学生们互相之间勾心斗角，不通信息的同时，系里的教授们其实背后都是“通气”的。他们根本不懂得如何教学，就知道拿作业和考试往学生头上砸，幸存下来的就各自挑去做徒弟，挨不住的就打发掉。这算盘打得真是妙啊。我也不知道他们是什么机制，每个学生对哪些教授感兴趣，表现如何，他们貌似都了如指掌，貌似背后有个什么情报网。然后系里的教授们不知道怎么的，仿佛就都知道有这样一个不知趣的学生，居然敢说学术界的坏话！



    大地震前夕的天空总是异常的美。我竟然在过道里看到那位图灵奖教授对我点头致意并且微笑，以前做 TA 时把我呼来唤去还横竖不满意的教授也对我笑脸相迎。我仿佛觉得那一席话打动了那位德高望重的教授，再加上在图形学和数值计算的扎实进展，也许我的学术生涯有了转机。可是，我那一次真正的领悟了什么叫做所谓的“笑里藏刀”。



    由于那个学期上的图形学还有矩阵计算的课成绩都不错，我心想应该能找这两门课的授课教授的其中一个做导师吧。再加上那些貌似友好的笑容…… 所以没想很多，居然过了一个非常快乐的寒假。没有任何前兆，没有任何直接的通知（email，电话），一封纸信不知道是什么时候默默地进到了我在系里的“信箱”—一个我基本上从来不看的，系里用来塞广告信息的信夹子里，直到下一个学期开始的时候（2月份）我才发现。信是系主任写的，大概就是说，由于你的表现，我们觉得 Cornell 不是适合你的地方……



    说得对，我也觉得 Cornell 不适合我。我本来就有想走的意思，可我一般呆在一个地方就懒得动。如果你们早一点告诉我这个，比如12月以前，我还可以申请转学到其它学校。可是都 2 月份了才收到这样的东西，Cornell 啊 Cornell，你让我现在怎么办？我想我可以说你不仁不义吧？



    在这个万分窘迫的时候，我想起了曾经关心过我却又很失望的 Hofstadter。我告诉他我在 Cornell 很不开心，我很想研究程序语言，可是 Cornell 不理解也不在乎这个领域。他回信说，没有关系，你能找到自己喜欢的东西就应该去追寻它。Indiana 的 Dan Friedman 正好是做程序语言的，你可以联系他，就说是我介绍你去的。



    于是给 Friedman 发了 email，很快得到了回信说：“Yin，两年前我们都看过你的材料，我们觉得你是非常出众的学生，可惜你最后没有选择我们。你要明白，人生最重要的事情不是名利，而是找到你愿意合作的人。你的材料都还在我们这里。现在招生已经快结束了，但是我会把你的材料提交给招生委员会，让他们破例再次考虑你的申请。” 我和 Dan Friedman 的故事就从这里开始了。



    我在 Cornell 的遭遇貌似不可告人的耻辱和秘密，然而我今天却可以把它公之于世，因为 Cornell 不再有任何资格来评价我。依靠自己的努力和 Indiana 的老师们的培养，我的水平已经超越了 Cornell 计算机系的大部分教授。现在我觉得自己就像那个到 Cornell 学“游泳精髓”人，本来就是会游泳的，可是每到岸边 Cornell 就搬起大石头来砸我，还说我不会游。于是我钻到水底下钻了一个洞，把水放干。



    由于曾经与多位图灵奖得主发生不大愉快的遭遇，再加上在自己的研究中多次受到其它图灵奖得主的理论的误导，而且许多位图灵奖得主最主要的贡献仍然在给软件行业带来混乱，图灵奖这个被许多计算机学生膜拜的神物，其实在我心里已经没有任何效力了。很多人可能对此难以想象，可是对图灵奖是这种态度的不只我一个人。我认识的几乎所有程序语言专家几乎都不拿图灵奖当回事，而且其中很多人甚至不拿图灵本人当回事，觉得他设计了一些非常丑陋的东西。虽然我现在觉得图灵的研究成果确实有一定价值，但由于上面的原因，拿图灵奖来开玩笑还是成为了我的家常便饭。我甚至觉得 ACM 应该停发这个奖，因为它是一种非常虚幻和政治的东西。每当人们谈起这些“大奖”煞有介事的时候，就让我看到了他们的愚昧。


常青藤联盟和“世界一流大学”


    我在 Cornell 的经历应该不是偶然，不是因为我比较特殊。跟我同时进入 Cornell 的博士生有好几个没有拿学位就离开了。其中有一个是非常聪明的少年班，18岁就读 PhD 了，我根本听不懂的理论课他还能拿A。可是四年后他退学去了 Facebook，说真是太难毕业了，神马都是扯淡。有些本科生也告诉我类似的经历，说被一个叫做“笑面虎”的教授“整了”。Cornell 的自杀率居美国大学前列。离开以后的有一天，忽然看到新闻报道说一周之内有三个 Cornell 学生从瀑布旁边的那座桥跳下去，结果派了警察在桥上日夜巡逻。我觉得自己在 Cornell 所感受到的压力确实超乎想象，是有可能把人逼上绝路的。现在回想起来真是可笑，因为下意识里在乎权威和名气，我给予了一群根本没有资格来教育我的人莫大的权力，让他们可以向我施加无端的压力。



    应该指出，这种现象应该不是 Cornell 所特有的。我对清华，还有 Princeton，Harvard，MIT，Stanford，Berkeley，CMU 等学校的学生都有了解。这些所谓的“世界一流大学”或者“世界一流大学 wannabee”差不多都是类似的气氛。你冲着它们的名气和“关系网”挤破了头皮进去，然后就每天有人在你耳边对其它人感叹：哇，他好牛啊！发了好多 paper，还得了XX奖。跟参加传销大会似的，让你怀疑这些人还有没有自尊。然后就是填鸭式的教育，无止境的作业和考试，让你感觉他们不是在“教育”你，而是在“筛选”你。这种筛选总是筛掉最差的，但也筛掉最好的。因为最好的学生能意识到你在干什么，他们不给你筛选他们的机会。一旦发现其实没学到东西，中途就辍学出去创业了。所以剩下来的就是最一般的，循规蹈矩听话的。在这样的环境里，你感觉不到真正的智慧和真知的存在。GRE 考试所鼓吹的什么“批判性思维”（critical thinking ）在美国大学里其实是相当缺乏的。学生们只不过是在被培训成为某些其他人的工具，他们具有固定的思维定势，像是一个模子倒出来的。他们不是真正的创造者和开拓者。



    人们在这些大学里的时候都是差不多感受的，可是一旦他们出来了，就会对此绝口不提。自己身上挂着这些学校的镀金牌子，怎么能砸了自己的品牌，长别人的威风？所以每当我批判 Cornell 就有些以前的同学一脸的着急相，好像自己没有吃过那苦头一样。


程序语言专家


    虽然我在 Indiana 得到了思想的自由，但这种自由其实是以孤独为代价的。我并不是一个自高自大不合群的人，但是我不喜欢跟一群像追星族一样的人在一起。应该说在 Indiana 的日子里，权威主义的影子也是经常出现的。Indiana 学生们的权威比较特殊一点，不然就是 Dan Friedman，不然就是 Kent Dybvig。Friedman 的身边总是围绕着一群自认为是天才的本科生，喜欢拍他的马屁，喜欢在人面前炫耀。博士生们开始时貌似还比较酷，可是后来发现其实也有很多类似现象，急于表现自己，越是研究能力弱的人越是爱表现。所以你就发现有人开头为了混进这个圈子拍你的马屁，过了两年就开始自高自大，而且经常想这样来压倒你：“Kent 说过……”我很尊敬 Dan 和 Kent，但我其实在很多方面已经超越了他们。我看到他们的一些思维方式并不是那么的正确，我也从来不引用他们的话作为理论依据。对权威的崇拜其实显示了一个人心理的弱小。如果你对自己有信心，有自己的想法和判断力，又何必抬出个名人来压制别人呢？



    在我自己心里毫无疑问的是，我是 Indiana 最厉害的程序语言（PL）学生。由于我不断地动手尝试新的想法，所以几乎没有任何其他人的研究逃脱过我的探索。我从来不记录自己的半成品和失败（因为太多了），而且我对自己的标准异常的高，所以我经常看到有人做演讲或者写论文，里面其实是我很久以前尝试过又抛弃了的想法。有时候我去听别人的演讲，就会立即看出破绽，问一些演讲者答不出来的问题。其实很多时候我只是怀疑自己，我试图给那些想法再一次的机会来证明它们的价值，而且问得相当委婉，但那样的问题仍然是不受欢迎的，所以同学们甚至一些助理教授看到我在场都是心惊胆战的。吃饭的时候我也不喜欢旁边的人讨论问题，因为他们经常显示出对理论提出者的膜拜心理，而且煞有介事，可惜那些经常是我早就知道不管用的理论。他们有时候其实也知道那些是扯淡的，但却又怕我捅破这窗户纸，所以就像鸵鸟一样把头埋在沙子下面。



    我也想合群一点，但是屡试不爽，所以后来我就基本是孤立的做自己的研究了。最开头是不得已，但后来就越来越喜欢独自一人。这是不可避免的，因为创造力和孤独几乎是双胞胎。因为免去了跟人讨论的时间，我有了大把的时间来做自己的探索。然后我才发现当年期望的那种 common room 其实没什么用，因为那里根本不会有人理解你在说什么。现在即使有这样的地方我也不会去了。



    我从一开始进入 Indiana 就没想过要拿博士学位，我只是在玩弄这个系统以达到我求知的目的。所以除非危及到我的存在，我把学校对学位的各种要求都抛到了九霄云外。给教授做 RA 几乎总是被要求研究各种毫无前途的东西，与我自己的思考相冲突，所以我后来干脆都做 TA 了。虽然累点，但不怎么费脑力。其结果是，在短短的一两年时间之内，我利用自己抠出来的时间，独自摸索出了这个领域大部分的理论。我经常不看书不看论文，在一个星期之内解决别人十多年才完成的研究。让人惊讶的应该不是我有多么聪明，而是这些研究者们十年来到底在干什么。我从来不认为自己比别人聪明，我只是觉得很多人的脑子被禁锢了而已。我有非常简单的头脑，我看不懂复杂的公式，听不懂高深的术语。可正是因为这一点，让我脱离了已有理论的困扰。



    可以说，这个领域在过去一个多世纪的研究，很少有逃脱过我的洞察力和直觉的。这些研究最早可以追溯到 1870 年代。我一般很少看论文，因为自己想清楚一个问题其实花不了那么多时间的。看别人的论文一般都枯燥乏味，所以与其花那么多时间读论文还不如自己思考。当我看论文的时候，一般是想搞清楚自己琢磨出来的问题有没有人已经研究过了，所以很多论文只需要扫一下就够了。我看到一个东西一般很快就会知道它到底会不会管用。我经常发现一些被认为很艰深的理论其实是在解决根本不存在的问题，甚至是在制造问题，而真正的问题却没有得到有效的解决。很多问题其实是权威的阴影造成的，它让人们不敢否认这些大牛思想的价值，不敢揭穿它们，抛弃它们，甚至想让自己寄生在它们上面，所以很多的时间花在了解决一些历史遗留问题，而不是真正的问题。这就是为什么我的英文 blog 标题叫做“Surely I Am Joking”，因为它记录了一些我认为根本不存在，或者是人为造成的问题。


逻辑学家


    批评 PL 领域的问题并不意味着其它领域就好一些。恰恰相反，我认为做系统和数据库的领域有更大的权威崇拜和扯淡的成分。有时候程序语言专家看起来很明显的问题，做数据库和操作系统的人却看不到，扯来扯去扯不清楚，还自以为是的认为 PL 的东西他们都懂。



    程序语言的理论是计算机科学的精髓所在，可是程序语言专家有他们自己的问题：他们膜拜逻辑学家。几乎每一篇 PL 领域的论文，至少有一页纸里面排列着天罡北斗阵一样的稀奇古怪的逻辑符号，而它们表示的其实不过是一些可以用程序语言轻松做出来的解释器和数据结构。有人（比如 Kent Dybivg）早就发现了这个规律，所以写了一些工具，可以把程序语言自动转换成 LaTeX 格式的逻辑公式，用以对付论文的写作。



    有人觉得那些公式有“数学的美感”，可是它们其实是挺有毛病的设计。如果你看看现代逻辑学鼻祖 Gottlob Frege 的原著，就会发现其实最早的时候逻辑学不是用公式表示的。Frege 那篇开创性的论文 Begriffsschrift 里面全都是像电路图一样的图片，只有 20 多页，而且非常容易读懂。不知道是哪一个后辈把电路图改成了一些稀奇古怪的符号。其实他的目的是用符号来表示那些电路图，结果到后来徒孙们以为那些符号就是祖传秘籍的精髓，忘记了那些符号背后的电路图，所以导致了今天的混乱局面。看完了 Frege 的论文，我再一次领悟到了之前那句话：跟真正的大师学习，而不是跟他们的徒弟。



    ACM SIGPLAN 的主席 Philip Wadler 有一次写了一篇论文介绍 Curry-Howard corresponce，里面提到，好的点子逻辑学家总是比我们先想到。可是他却没有发现，其实程序语言的能力已经大大超越了数理逻辑，数理逻辑那些公式里面的 bug 其实不少。因为逻辑学家们不用机器帮助进行推理，有些问题搞了一百多年都搞不清楚是怎么回事，然后就弄出一些特殊情况和补丁来。有了一堆逻辑“定理”，却又不能确信它们是正确的，而且存在悖论一类无厘头的东西，所以又掰出一些 model theory 之类的东西来验证它们的正确性。逻辑学家们折腾了一百多年都是在折腾类似的事情，却没怀疑过老祖宗的设计。我之前提到的 Hindley-Milner 系统的问题，很大部分原因就在于它所使用的逻辑里面其实有一个根本性的误解。简言之，就是把全称量词 ∀ 随意乱放，导致输入与输出关系混乱。这也就是我为什么不喜欢 Haskell 和 OCaml 的最主要原因。



    现在最热门的逻辑学家莫过于 Per Martin-Löf。他的类型理论 Martin-Löf Type Theory 被很多 PL 人奉为神圣。我一直没有搞清楚这个类型理论有什么特别，直到有一天我把 Martin-Löf 1980 年的那篇论文（其实是演讲稿）拿出来看了一遍。然后我发现他通篇本质上就是在讲一个 partial evaluator 要怎么写，而我早就自己写过 partial evaluator。其实并不是特别神奇的东西，只需要在普通解释器里面改一两行代码就行，可是有人（比如 Neil Jones）却为此写出了 400 多页的书和大量的论文。



    之前提到的 Curry-Howard corresponce 也被很多人奉为神圣，它来自数学家 Haskell Curry 和逻辑学家 W.A. Howard 的一些早期发现。他们发现有些程序和定理的证明之间有对应的关系。然后就有 PL 专家开始走火入魔，说“程序就是证明，程序的类型就是定理”。可是他们却没有发现这个说法没法解释操作系统这种程序，因为它被设计为永远不停地运行，所以不能满足一个证明所具有的基本特征。而且很多程序被设计出来根本就不是要证明什么定理，它们是被设计来帮人做事情的。所以我觉得“程序就是证明”是很牵强附会的说法，你不能因为有的程序可以用来证明数学定理，就认为所有的程序都是某个定理的证明啊！把那句话反过来，说成“证明就是程序”还差不多。



    但从以上的发现，我很高兴的看到了自己作为一个程序员的价值。很多人瞧不起程序员，把他们蔑称为“码农”，可是程序如果写好了，其实比起那些高深的逻辑学家和哲学家还要强，因为程序语言其实比数理逻辑还要强。有一位数学家说得好：为了真正深入的理解一个东西，你应该把它写成程序。还有人说，编程只是一门失传的艺术的别名，这门艺术叫做“思考”。我觉得很在理。


再见了，权威们


    几经颠簸的求学生涯，让我获得了异常强大的力量。我的力量不仅来自于老师们的教诲，而且在于我自己不懈的追求，因为机会只亲睐有准备的头脑。



    曾经 Knuth 是我心中唯一的权威，后来我又屈服于 Cornell 和常青藤联盟的权威和名气。在一而再再而三的上当受骗之后，我终于把所有的权威们从我的脑子里轰了下去。也许有时候轰得太猛烈了一些，但总的说来是有好处的。不再是我心目中的权威并不等于我鄙视他们或者不尊敬他们。我只是获得了不用膜拜他们，不用跟一群人瞎起哄的自由。我不尊敬的人都是一些自视过高的人或者他们的跟屁虫。一般来说，权威们在我的脑子里失去的只是他们在很多其他人脑子里的那种被膜拜的地位，那种你可以用“XX人说过……”来压倒理性分析的地位。现在他们在我心目中是一群普通的，由蛋白质形成的生物，有好心肠或者坏心眼的，高傲，谦虚或者虚伪的人。我不会自讨苦吃，他们的想法如果真的好，我当然要拿来用，但是没有任何人的东西我是不加批判全盘接受的。我深深地知道接受错误想法的危害性，所以我也希望大家都具有批判的思维，不要盲目的接受我说的话。我不喜欢“大神”或者“牛人”这种称呼，我也反感那种自称膜拜我的人，因为正是这种人让权威主义现在横行于世。



    美国的权威主义胜于欧洲，但也不是每个人都那么的崇拜权威，而中国才是权威主义的重灾区。像“图灵奖得主XX”这样的称呼，恐怕只有在中国才见得到。所以我希望国内的同学们，不要盲目的崇拜国外的所谓“大师”，“牛校”或者“牛公司”。祝你们早日消灭掉心里的各种权威以及对他们的畏惧心理，认识到自己的价值和力量。


后记（关于 IU）


    有些人看了我的文章介绍在 IU 的经历，告诉我他们申请了 IU。我觉得有必要免责声明一下：我没想到，也不希望有人因为我的文章而去 IU，YMMV (your mileage may vary)。由于我有所准备，所以对于 Friedman 的教学如鱼得水。很多同学也说学到很多，可是有一些其他人告诉我他们觉得 Friedman 的课他们听起来很吃力，只能说是勉强过关。而且我只介绍了 IU 好的方面，却把不大好的地方一笔带过了。我在 IU 也有很艰难的时候。现在的情况是 Kent Dybvig 已经离开了 IU，加入了 Cisco。他的公司 Cadence Research Systems 和 Chez Scheme 也并入了 Cisco。Dan Friedman 由于年纪原因说不准还带不带学生。最近引进了一些貌似不错的助理教授，但是我跟他们都不熟。我的经验是助理教授一般都会为了研究资金，为了升为正教授而做一些身不由己的事情。其他的 CS 方向我都说不准 IU 是什么水平，所以还请同学们自己斟酌。我可以毫无疑问的一点是，IU 有非常美丽的校园，大大的超过清华，北大，Cornell，Stanford，MIT。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 PySonar2 开源了

 
 
 
 
    

    
 
     
  

      
   
PySonar2 开源了

    经过 Google 的许可，我现在将 PySonar 第二版本开源，就叫 PySonar2 吧。代码可以在我的 GitHub 下载：



    https://github.com/yinwang0/pysonar2



    经过一阵子考察之后，我发现 PySonar2 仍然是当今最先进的 Python 静态分析器。其分析的深度和准确程度其实超过了所有的 Python IDE （包括 PyCharm 3.0 在内）。PySonar2 做的是跨过程，具有精确控制流的分析，而现在最好的 Python IDE 仍然是局部过程分析。



    PySonar2 的工作原理却极其简单，说白了就是：写一个 Python 解释器，然后想办法让它“停机”。实际上这个简单的方法超过了一些程序语言研究者花几十年做出来的“艰深理论”。比如 Olin Shivers 及其学生们的 control-flow analysis 系列 20 多年来的成果，当我看他们的论文的时候，发现他们其实在解决一个自己（不小心）造出来的问题。我一开头什么都不知道，全凭自己感觉出发，所以就没有走上那条不归路 ;-)



    另外，其实给 Google 的代码里有一个很“严重”的 bug，导致算法成为指数时间复杂度，所以他们其实仍然在用第一版的代码 ;-) Sourcegraph.com  使用的也是第一版的代码。在 Coverity 的时候，我从他们的代码里面也发现同样的问题，对某些 benchmark 运行时间太长。最后被我两行代码修好了（虽然找到这两行代码花了好几天）。



    最近重新燃起了对 PySonar 代码的兴趣。经过修改两行代码之后，这个性质与 Coverity 完全一样的 bug 被消灭掉了。然后又发现一些逻辑细节和数据结构性能上的问题，也逐渐修补了。现在它能够处理整个 Python 2.5, 2.6, 2.7 的标准库和类似 Django 的项目，只需要3分钟的样子。我惊喜的发现能够检索到的名字比第一版多很多。界面还算比较友好吧，但是有待提高。欢迎喜欢美工的人士参与合作。



    因为 Python 语言的复杂性，而且由于我其实不是 Python 程序员，我相信 PySonar2 里面肯定还有一些细节没有照顾到（虽然最主要的部分是没问题的）。如果发现问题，请开启 GitHub 的 issue。



    另外，同样的原理其实可以应用到所有的语言分析里面。在将来我希望开发出通用的代码分析器，能够处理多种语言。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 丘奇和图灵

 
 
 
 
    

    
 
     
  

      
   
丘奇和图灵

		&emsp;	




    丘奇（Alonzo Church）和图灵（Alan Turing）是两位对计算机科学具有最大影响力的人物，然而他们却具有非常对立的观点和相差很多的名气。在我长达16年的计算机科学生涯中，总是感觉到自己的思想反反复复的徘徊于这两个“阵营”之间。丘奇代表了“逻辑”和“语言”，而图灵代表着“物理”和“机器”。在前面的8年中，我对丘奇一无所知，而在后面的8年中，我却很少再听到图灵的名字。他们的观点谁对谁错，是一个无法回答的问题。完全投靠丘奇，或者完全投靠图灵，貌似都是错误的做法。这是一种非常难说清楚的，矛盾的感觉，但是今天我试图把自己的感悟简要的介绍一下。


丘奇与图灵之争


    想必世界上所有的计算机学生都知道图灵的大名和事迹，因为美国计算机器学会（ACM）每年都会颁发“图灵奖”，它被誉为计算机科学的最高荣誉。大部分的计算机学生都会在某门课程（比如“计算理论”）学习“图灵机”的原理。然而，有多少人知道丘奇是什么人，他做出了什么贡献，他与图灵是什么样的关系呢？我想恐怕不到一半的人吧。



    如果你查一下数学家谱图，就会发现丘奇其实是图灵的博士导师。然而从 Andrew Hodges 所著的《图灵传》，你却可以看到图灵的心目中仿佛并没有这个导师，仿佛自己的“全新发明”应得的名气，被丘奇抢走了一样（注意作者的用词：robbed）。事实到底是怎样的，恐怕谁也说不清楚。我只能说，貌似计算机科学从诞生之日开始就充满了各种“宗教斗争”。



    虽然现在图灵更加有名，然而在现实的程序设计中，却是丘奇的理论在起着绝大部分的作用。据我的经验，丘奇的理论让很多事情变得简单，而图灵的机器却过度的复杂。丘奇所发明的 lambda calculus 以及后续的工作，是几乎一切程序语言的理论基础。而根据老一辈的计算机工程师们的描述，最早的计算机构架也没有受到图灵的启发，那是一些电机工程师完全独立的工作。然而有趣的是，继承了丘奇衣钵的计算机科学家们拿到的那个大奖，仍然被叫做“图灵奖”。我粗略的算了一下，在迄今所有的图灵奖之中，程序语言的研究者占了近三分之一。


从图灵机到 lambda calculus


    图灵机永远的停留在了理论的领域，绝大多数被用在“计算理论”（Theory of Computation）中。计算理论其实包括两个主要概念：“可计算性理论”（computability）和“复杂度理论”(complexity）。这两个概念在通常的计算理论书籍（比如 Sipser 的经典教材）里，都是用图灵机来叙述的。在学习计算理论的时候，绝大多数的计算机学生恐怕都会为图灵机头痛好一阵子。



    然而在做了研究生“计算理论”课程一个学期的 TA 之后我却发现，其实几乎所有计算理论的原理，都可以用 lambda calculus，或者程序语言和解释器的原理来描述。所谓“通用图灵机”（Universal Turing Machine），其实就是一个可以解释自己的解释器，叫做“元解释器”（meta-circular interpreter）。在 Dan Friedman 的 B621 程序语言理论课程中，我最后的项目就是一个 meta-circular interpreter。这个解释器能够完全的解释它自己，而且可以任意的嵌套（也就是说用它自己来解释它自己，再来解释它自己……）。然而我的“元解释器”却是基于 lambda calculus 的，所以我后来发现了一种方法，可以完全的用 lambda calculus 来解释计算理论里面几乎所有的定理。



    我为这个发现写了两篇博文：《A Reformulation of Reducibility》和《Undecidability Proof of Halting Problem without Diagonalization》。我把 Sipser 的计算理论课本里面的几乎整个一章的证明都用我自己的这种方式改写了一遍，然后讲给上课的学生。因为这种表示方法比起通常的“图灵机+自然语言”的方式简单和精确，所以收到了相当好的效果，好些学生对我说有一种恍然大悟的感觉。



    我把这一发现告诉了我当时的导师 Amr Sabry。他笑了，说这个他早就知道了。他推荐我去看一本书，叫做《Computability and Complexity from a Programming Perspective》，作者是大名鼎鼎的 Neil Jones (他也是“Partial Evaluation”这一重要概念的提出者）。这本书不是用图灵机，而是一种近似于 Pascal，却又带有 lambda calculus  的一些特征的语言（叫做 “WHILE 语言”）来描述计算理论。用这种语言，Jones 不但轻松的证明了所有经典的计算理论定理，而且能够证明一些使用图灵机不能证明的定理。



    我曾经一直不明白，为什么可以如此简单的解释清楚的事情，计算理论需要使用图灵机，而且叙述也非常的繁复和含糊。由于这些证明都出于资深的计算理论家们之手，让我不得不怀疑自己的想法里面是不是缺了点什么。可是在看到了 Jones 教授的这本书之后，我倍感欣慰。原来一切本来就是这么的简单！



    后来从 CMU 的教授 Robert Harper 的一篇博文《Languages and Machines》中，我也发现 Harper 跟我具有类似的观点，甚至更加极端一些。他强烈的支持使用 lambda calculus，反对图灵机和其他一切机器作为计算理论的基础。


从 lambda calculus 到电子线路


    当我在 2012 年的 POPL 第一次见到 Neil Jones 的时候，他跟我解释了许多的问题。当我问到他这本书的时候，他对我说：“我不推荐我的书给你，因为大部分的人都觉得 lambda calculus 难以理解。”Lambda calculus 难以理解？我怎么不觉得呢？我觉得图灵机麻烦多了。然后我才发现，由于经过了这么多年的研究之后，自己对 lambda calculus 的理解程度已经到了深入骨髓的地步，所以我已经全然不知新手对它是什么样的感觉。原来“简单”这个词，在具有不同经历的人头脑里，有着完全不同的含义。



    所以其实 Jones 教授说的没错，lambda calculus 也许对于大部分人来说不合适，因为对于它没有一个好的入门指南。Lambda calculus 出自逻辑学家之手，而逻辑学家们最在行的，就是把很简单的“程序”用天书一样的公式表示出来。这难怪老一辈的逻辑学家们，因为他们创造那些概念的时候，计算机还不存在。但是如果现在还用那一堆符号，恐怕就有点落伍了。大部分人在看到 beta-reduction, alpha-conversion, eta-conversion, ... 这大堆的公式的时候，就已经头痛难忍了，怎么还有可能利用它来理解计算理论呢？



    其实那一堆符号所表示的东西，终究超越不了现实里的物体和变化，最多不过再幻想一下“多种未来”或者“时间机器”。有了计算机之后，这些符号公式，其实都可以用数据结构和程序语言来表示。所以 lambda calculus 在我的头脑里真的很简单。每一个 lambda 其实就像是一个电路模块。它从电线端子得到输入，然后输出一个结果。你把那些电线叫什么名字根本不重要，重要的是同一根电线的名字必须“一致”，这就是所谓的“alpha-conversion”的原理…… 不在这里多说了，如果你想深入的了解我心目中的 lambda calculus，也许可以看看我的另一篇博文《怎样写一个解释器》，看看这个关于类型推导的幻灯片的开头，或者进一步，看看如何推导出 Y combinator，或者看看《What is a program?》。你也可以看看 Matthias Felleisen 和 Matthew Flatt 的《Programming Languages and Lambda Calculi》。



    所以，也许你看到了在我的头脑里面并存着丘奇和图灵的影子。我觉得丘奇的 lambda calculus 是比图灵机简单而强大的描述工具，然而我却又感染到了图灵对于“物理”和“机器”的执着。我觉得逻辑学家们对 lambda calculus 的解释过于复杂，而通过把它理解为物理的“电路元件”，让我对 lambda calculus 做出了更加简单的解释，把它与“现实世界”联系在了一起。



    



    所以到最后，丘奇和图灵这两种看似矛盾的思想，在我的脑海里得到了和谐的统一。这些精髓的思想帮助我解决了许多的问题。感谢你们，计算机科学的两位鼻祖。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    










PyDiff - Python 结构化程序比较工具

　　


PyDiff - Python 结构化程序比较工具


    在之前的一篇博文里，我介绍了 ydiff，一个通用的结构化程序比较工具。其实在设计 ydiff 之前，这个工具是用 Python 实现的，并且只处理 Python 程序。在设计了 ydiff 之后，我发现其实我不想费很多精力来写 Python 的 parser，所以对 Python 的支持就日渐疏忽了。后来我把那块代码放在了 ydiff 的 repo 里面（叫做 pydiff.py），然而几乎没有人注意到它。


    现在我发现 Python 其实是一个挺重要而且有趣的语言。说它重要是因为它简单而且在某种程度上是优雅的，所以有很多人用它。说它有趣是因为它的一些设计其实比起很多更加“严谨”的语言要来得合理。语言的设计不只要有逻辑的严谨和效率，而且需要有“易用性”（usability）。Python 在易用性上面是做的比较好的。最近仔细看了一下 PEP 8 (Python 的 "Style Guide"），发现它有很多地方比起 Java, Scheme, Haskell 都有让程序更加“易读”的特点。


    所以，现在我为这个 Python 的结构化比较程序重新建立了它自己的 GitHub 项目。你可以在这里得到它的代码：

https://github.com/yinwang0/pydiff


    对比大型文件的时候可能速度会成一定的问题。不过我打算以后对算法做一个比较大的改进。如果发现 bug 请在 GitHub 中向我报告。谢谢。


Demo


    你可以在下面的窗口中看到 PyDiff 的输出结果，是 PyDiff 对比它自己的代码（我最近两天对它的修改）。


    


(单独浏览)


    上面的界面有如下特点：


红色表示“删除”，绿色表示“插入”，白色表示“移动”或者没有变化，蓝色表示有小幅度“修改”。
左右窗口同步滚动。
点击白色方框，就可以依据框里的变量进行对齐。
点击之后，左右窗口根据对齐的变量重新“耦合”，同步滚动。




    

 
 
 
 

 我离开了Coverity

 
 
 
 
    

    
 
     
  

      
   
我离开了Coverity

    在写这篇博文的时候，我已经不再是 Coverity 的员工了，我已经在今天下午向公司正式辞职。



    走出公司的大门，我觉得一身的轻松。这是我几个月以来第一次感受到加州美丽的阳光，AT&amp;T Park 到处是欢笑的人群，他们是来看巨人队的棒球赛的。我第一次发现他们的面庞是那么的美，那么的友善。湾里的海水也格外的蓝，水面上船帆招展，一幅恬静自然，其乐融融的景象。我就像是一个刚从 Alcatraz（恶魔岛）释放出来的囚犯。我已经很久没有欣赏过这样的风景了，虽然我每天都从这风景中走过。



    进入 Coverity 之前，我就在 glassdoor（一个让员工评价自己公司的网站）上面看过给它的评价，只有 3.2 颗星，只有 44% 的员工愿意推荐朋友去那里工作。评价者们写到：“管理队伍非常不成熟”，“不重视自己的员工”，“高层总是互相打架”，“每个星期都有人莫名其妙的被炒鱿鱼”，“过劳工作，工资太低”，“工程师非常聪明，可是不受尊重”，“你不再是一个人，你是一个数字”，“对新人不友好”……



    可是就在六个月以前，我认定了 Coverity 拥有我想要探索的技术，而且想当然地对自己说，也许给差评的都是销售人员，或者他们自己有问题？而且往加州飞一趟面试也不容易啊，单程就是 7 个小时。所以尽管如此的恶评如潮，还是加入了这个公司。现在我如愿以偿了，Coverity 的产品里确实有一些不错的地方，我很快的把它们都“偷学”过来了（虽然他们压根没教过我）。Coverity 实现了几个我设想中的点子，从而让我眼光的正确性得到了免费的证明。



    然而我也逐渐地看到，glassdoor 的评价者们对公司的每一条批评，都一一的兑现了。管理层的高压，以及对自己的身心健康的考虑，是我离开 Coverity 的真正原因。就在离职之前，我因为头痛请了两天假。回到公司的时候领导很不高兴，把我叫去办公室，说：“你请假两天。我想起这两天还付给你工资，那个心痛哟……” 我的 PTO 之前一天都没有用过，从早忙到晚紧紧张张的，给你们创造了多少价值。现在我身体不适请了两天假，你居然说心痛那几百块钱！



    这是一个既有高技术含量，却又极其吝啬而压榨的公司。Coverity 的软件技术难度非常之高，工程师的水平必须得高于普通程序员才能胜任这里的工作。有多少人会做这样高级的静态分析软件呢？极其稀少！好些员工都有博士学位。可是这些极其聪明的人，却并没有得到他们应该得到的待遇和尊敬，他们过着非常不轻松的生活。他们的工资并不比其它公司打酱油的普通程序员高。而且每个人的头顶上，都仿佛有一双眼睛在随时盯着，督促着你干活。



    你一天工作了多少个小时，每个任务的“估计时间”，你花在任务上的“实际时间”，全都使用一种叫做 Jira 的软件进行记录。正如评价上说的，你确实只是一个数字。你的工作效率按照（实际花费时间 / 任务估计时间）这个比例来简单的判断。这个数字越大，那么你的效率就越低。看你工作效率的时候，领导才不会管你到底做的是什么事情，也根本不看你的代码，所以就算你水平很高，他们也完全不知道你代码的质量。开会时 manager 会不断地提醒你，这个用来衡量你工作效率的黄金公式，提醒你要做“top performer”，因为他们只愿意留下 top performer……



    这句话潜在的含义就是在警告你，如果超出时间过多，你随时会有被解雇的危险！我发现每个任务的“估计时间”都被故意设置得非常短，它是由完全不写代码的 manager 和 architect 设定的。有些问题本来需要好多天的，也被设成4个小时，8个小时的样子，所以几乎每个任务都无法在估计时间之内完成。那怎么办呢？为了不显得笨，你就只有加班加点。每个人都工作到很晚，然而为了显得自己是称职的员工，几乎没有人敢把实际花费的时间记录在 Jira 里面，因为这样按照公式，你的 performance 就下去了。所以就算你熬夜完成任务花了14个小时，你也只敢记录8个小时作为“实际时间”，跟估算时间扯平。甚至记录比8个小时还少的时间，这样显得自己很聪明…… 殊不知，这正好中了管理层让大家拼命干活，尽可能免费压榨劳动时间的诡计。



    曾经有一个人就是精确地记录了时间，最后他被解雇了。Mark 是一个波兰来的同事，是个 senior engineer，人非常友善而且聪明，同事们都喜欢他。可是这个人太敬业了一点，他桌上摆着一个国际象棋对弈用的那种计时器，上面有两个钟，用两个按钮来切换计时。Mark 用它把每个任务的时间都兢兢业业地记下来。在交替处理两个问题的时候，甚至还利用这个计时器的切换功能，分别记录时间…… 然后忽然有一天，他从公司人间蒸发了。我们收到一封来自 manager 的 email：“今天是 Mark 的最后一天。如果你们对此有什么问题，来问我好了！” 看这口气，我们哪里敢问问题。后来同事们议论说，显然他被炒了鱿鱼，连跟我们说再见的机会都没有。我想跟 Mark 保持联系，也许还可以打听一下到底发生了什么事情，发了一封 email 询问他的个人联系方式，结果无法投递，因为他的内部 email 立即就被停掉了。



    这个公司一星期一大会，一天一小会，要你报告前一天完成了什么，今天准备做什么。仿佛生怕你就偷懒了。这就是他们所谓的“Agile”管理模式，其原理就像是操作系统一样，把人作为可以任意调用和替换的“进程”，并发执行。很可惜，这种管理模式，加上过劳赶工，无法清晰地思考，造成了软件质量的低下，bug 多得不计其数，而且难以修复。



    最令我惊奇的其实是 manager 的言语里随时透露出来的威胁口气，仿佛随时都在质疑员工的工作态度和积极性，随时都在检查员工是否工作够了时间，随时都在琢磨要炒谁的鱿鱼。这是极度的不自信，仿佛他们不相信有人真的愿意为他们工作，随时都在对员工察言观色，生怕一下子走人了没人来给他们修补 bug。所以公司里总是感觉一种人人自危的气氛。感觉这怎么不像是一个高科技公司，而是麦当劳呢？比麦当劳还小气。



    我经常发现好几个工程师晚上工作到八，九点。一个同事因为住的远，6点就冲去坐 Caltrain，可是过不久我就发现他屏幕上的 VNC 在动，我能清晰地看到他在继续工作，直到很晚…… 呵呵，我为什么知道这些呢？因为我也工作到很晚！



    整个公司处于一种压抑的气氛之中，很少见到人们的笑脸。有少数的人总是嘻嘻哈哈，可是那些都是 HR，Sales，…… 我不觉得他们的笑声中存在真诚的喜悦。



    当我辞职的时候，HR 对我说：“随便你到湾区哪一家公司，都是差不多的情况。” 但我不相信这就是整个软件行业的情况，否则软件行业就是新的奴隶社会。我相信，世界上还存在有良心的公司。


2015年更新


    有人看了这篇写于 2013 年的文章，质疑我的说法，说自己用过 Coverity 的产品，质量其实不错，哪有那么多 bug。确实 Coverity 有相当不错的 C 和 C++ 分析产品，然而那些都是很多年以前慢慢的，静心积累起来的技术。在 2012-2013 年为了拓宽市场，我们工作的重心是 Java 分析产品。这个产品是在我加入之前，由其它工程师在近一年时间之内，在 manager 的高压，威逼甚至咆哮之下赶制出来的，所以留下许许多多的 tech debt 和 bug。我工作的那几个月，完全就是在修补前人留下来的各种让人头痛的 bug。



    另外，Coverity 的创始人 Andy Chou 这个人对我其实不错，可惜即使作为创始人，他当时似乎并没有掌握公司的实权。据公司早期员工口述，Coverity 本来是个不错的公司，自负盈亏。可是在一次经济危机的时候遇到了困难，所以第一次引入了 VC 投资，随后就被 VC 控制了。VC 进入之后，公司的 VP Engineering 被忽然的，非常不人道的解职。在新上任的 VP 领导下，公司完全变了样，最后成了我所描述的样子。



    现在 Coverity 已经被 Synopsys 收购，然而据我调查，工程团队的领导班子并没有变，还是原来那两个 manager。不过我还是祝愿在 Synopsys 的领导下，这个公司的管理会有所改善。创始人 Andy Chou 赚了点钱，已经不再管理这个公司，开始做天使投资人。在被 VC 控制的日子里，他应该也没少忧虑，我希望他在将来的日子里快乐自在的生活。在 Coverity 我遇到了实行高压的 manager，非常讨厌的自大狂，但也遇到了一些友好的同事：Aaron，Dzin，Eric，…… 我希望他们一切都好。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 原因与证明

 
 
 
 
    

    
 
     
  

      
   
原因与证明
证明


    我在 Cornell 的时候经常遇到这样的问题，那就是教授们一上课就在黑板上写长篇的“定理证明”，全体同学认认真真在下面抄笔记，就连只有十来个人的小课也是那样。有些写字速度慢的人就不得不带上小型录音机，把教授的课全都录下来，要不就是之后去借别人的笔记来抄。



    有一次某知名教授照着讲义，背对着学生，在黑板上写了大半节课，写下好几板的证明，证明的是 simply typed lambda calculus （STLC）的 strong normalization 特性（SN）。刚写完就到下课时间了，他回过头来喘了一口气，说：“Any questions？”没有人啃声，于是他说：“很好！下课！”



    几天后我问他，你证明了 STLC 有这个特性，然而你却没有告诉我它“为什么”有这个特性。他神气的看了我一眼：“你不懂吗？”我说：“你的证明我看懂了大部分，可是一个东西具有如此的性质，并不是因为你证明了它。这性质是它天生就有的，不管你是否能证明它。我想知道的是什么让 STLC 具有这个性质，而不只是证明它。”他说：“你问这样的问题有什么意义吗？你需要非常聪明，并且需要经过大量的努力才能想出这样的证明。”


原因


    两年之后，我在 Indiana 上了另外一堂程序语言理论课。教授是我之前的导师 Amr Sabry。他上课从来不带讲义，貌似也没有准备，漫不经心的，却每次都能讲清楚问题的关键。于是有一天他也开始讲 STLC 的 SN 特性。他说，我不想写下这个证明让你们抄，我只告诉你们大概怎么去想。SN 的意思就是程序肯定会“终止”。所有会终止的程序，都会有一个“特征值”会随着程序的运行而减小。你需要做的就是找到 STLC 的“特征值”是什么。接着他就开始在黑板上画一个图……



    过了一段时间，我不仅学会了这个“证明”，而且知道了 STLC 具有如此特性的“原因”。


证明与原因的区别


    从以上的故事，以及你的亲身经历中，你也许注意到了大部分的教育过分的重视了“证明”，却忽略了比证明更重要的东西——“原因”。



    原因往往比证明来得更加简单，更加深刻，但却更难发现。对于一个事实往往有多种多样的证明，然而导致这个事实的原因却往往只有一个。如果你只知道证明却不知道原因，那你往往就被囚禁于别人制造的理论里面，无法自拔。你能证明一个事物具有某种特性，然而你却没有能力改变它。你无法对它加入新的，好的特性，也无法去掉一个不好的特性。你也无法发明新的理论。有能力发明新的事物和理论的人，他们往往不仅知道“证明”，而且知道“原因”。



    打个比方。证明与原因的区别，就像是犯罪的证据与它的原因的区别。证据并不是导致犯罪的原因。有了证据可以帮助你把罪犯绳之以法，可是如果你找不到他犯罪的原因，你就没法防止同样的犯罪现象再次发生。



    古人说的“知其然”与“知其所以然”的区别，也就是同样的道理吧。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    










ydiff - 结构化的程序比较


　　


ydiff - 结构化的程序比较


    ydiff 是我的一个开源项目，用以探索一种全新的程序比较以及版本控制系统。


    也许我根本不应该给它起名叫“ydiff”，让人感觉它只不过是对 diff 的微小改进。然而，ydiff 跟 diff 是有本质区别的。它们的区别在于，diff 只是对程序进行基于“文本”的对比，它根本不对程序进行 parse。而 ydiff 含有完整的针对程序语言的 parser，在得到了 AST 之后，才对 AST 进行“结构化的比较”。


    这种结构化的程序比较，不但可以避免文件里的“空白字符”引起的肤浅区别，而且可以根据程序的结构，进行更加有意义的对比。比如，ydiff 不会认为字符串 "1000" 和数字 1000 的区别只是多了一对引号。ydiff 在比较函数的时候，首先寻找名字相同的函数，而不只是对相同位置的函数进行无谓的对比。


    ydiff 含有 C++, JavaScript 和 Lisp 的 parser。这些 parser，包括用于支持这些 parser 的库代码，都是我自己完成的。ydiff 不含有任何第三方代码。ydiff 的 parser 技术不依赖于任何第三方工具（比如 ANTLR 或者 YACC）。


界面

跟普通 diff 程序的输出不一样，ydiff 生成美观的含有 JavaScript 的 HTML 文件，可以直接使用浏览器浏览，并且可以嵌入其它网页，比如像下面这样：


    


(单独浏览)


    上面的界面有如下特点：


红色表示“删除”，绿色表示“插入”，白色表示“移动”或者没有变化
左右窗口同步滚动
点击白色方框，就可以依据框里的变量进行对齐
点击之后，左右窗口根据对齐的变量重新“耦合”，同步滚动


技术

ydiff 里面含有一些比较独特的技术。

强大而简单的 parser combinator library


    一般编译器的 parser 都使用像 YACC 和 ANTLR 一样的 parser generator。这种方法虽然可行，但是它有一个很大的问题，就是你需要使用另外一种语言和另外一个工具，这样就多了一层“语义”。当你的 parser 出了问题的时候，你不能使用已有的编程工具进行调试，而只能依靠这种 parser 工具所提供的信息。这就是为什么人们都觉得 parser 很难写。有一家叫 EDG 的公司，专门销售 C++ 的 parser 代码。你可以由此看出 parser 的技术是多么的复杂和混乱。


    由于这个原因，很多人的 parser 都是自己手写的。可是手写 parser 相当的费事，而且不模块化。所以函数式语言的社区就出现了 Parsec 这样的“parser combinator library”。它的原理是，每一个 parser 都是一个函数，它接受一个字符串，输出一种特定的 AST 结构。比如你可以写出一个很简单的 parser，它只能从字符串里提取一个变量，或者一个数字。由于函数式语言可以把函数作为数据，这种小的 parser 可以被一些叫做 parser combinator 的“高阶函数”作为输入，然后把它们“组合”在一起，形成更大的 parser。当所有这些 parser 组合在一起，它们就可以拥有分析整个程序文本的威力，就像“组合金刚大力神”一样。




    我的 parser 库就是受到了 Parsec 的启发。然而我的库在某种程度上比 parsec 还好用。它不但更加简单灵活，而且能够检测并且报告“左递归”的位置。这是 Parsec 没有的功能。另外，我的 parser 库里面含有很方便的宏，使得写 parser 就像写 BNF 范式一样简单，但却又不需要使用像 YACC 一样的麻烦的工具。


    比如，C++ 函数的 parser 是这样定义的：


(::= $function-definition 'function
     (@or (@... (@? $modifiers) $type
  (@= 'name $identifier ) $formal-parameter-list)

   (@... (@= 'name $identifier ) $formal-parameter-list))
     (@? $initializer)
     $function-body)




    在创造了这个库之后，我在一天之内写出了一个 JavaScript 的 parser。两天之后，在这个 JS parser 基础上，又写出了一个 C++ 的 parser。两天之内写出 C++ 的 parser 对于很多人来说都是不可思议的事情，但我没有感觉这有什么难度。大部分的人只不过高估了问题的难度，不然就是把问题复杂化了。


    最后的 C++ parser 只有 600 行代码（不包括空行），而 JS 的 parser 只有 470 行代码。最令人惊奇的事情是，Lisp (S-expression) 的 parser 只有 11 行代码，以至于我可以把它完整的贴在这里：


(:: $open
     (@or (@~ "(") (@~ "[")))
(:: $close
     (@or (@~ ")") (@~ "]")))
(:: $non-parens
     (@and (@! $open) (@! $close)))
(::= $parens 'sexp
     (@seq $open (@* $sexp) $close))
(:: $sexp
    (@+ (@or $parens $non-parens)))
(:: $program $sexp)



精确的探测“代码移动”


    不管你在任何位置剪切了一段代码到另外一个地方，ydiff 都能准确的探测到这个动作。比如在上面的代码里面，你也许发现了函数 unify 的主体被移动到了另一个叫做 unify-good 的函数里面。ydiff 能够精确地显示出这个事实：





    这种对于代码移动的检测，可以让人找到很长时间段内对代码的一切修改。为此我做了一个实验，我用 ydiff 对比了 V8 编译器的一个文件相距两年的变化，得到了直观可读的结果。如果你用普通的 diff 来对比它们，恐怕不会看出很多有用的信息，因为这个文件里的有些函数被切分成了好几个小的“帮助函数”。ydiff 能够准确的找到这些被切分的代码所在的位置。

比如我轻而易举的看到，Shell::Initialize 这个函数被切分成了如下一些函数：


Shell::Initialize
Shell::CreateGlobalTemplate
Shell::RenewEvaluationContext
Shell::InstallUtilityScript




    你可以在以下的 ydiff 输出中直观的看到这个事实（搜索 Shell::Initialize 然后就可以点击每一行，看它们到什么地方去了）：


    

(单独浏览)




    这里有一个可能的改进之处，就是让这种代码移动的现象被更加直接的显示出来，而不需要用户挨个的点击这些代码。

未来

    ydiff 只是一个开端，我希望由它的启发，形成出一种全新的“版本控制系统”。这种系统将从本质上超越现有的基于文本的版本控制系统。关于这系统的细节，我已经在一篇英文博文中有基本的描述。


源代码

ydiff 是完全开源的项目，它可以从我的 GitHub 免费获得。


    https://github.com/yinwang0/ydiff



    

 
 
 
 

 程序语言不是工具

 
 
 
 
    

    
 
     
  

      
   
程序语言不是工具

    在谈论到程序语言的好坏的时候，总是有人说：“程序语言只是一种工具。只要你的算法好，不管用什么语言都能写出一样好的程序。”在本科第一堂编程课上，我的教授就这么对我们说。可是现在我却发现，这是一个根本错误的说法。



    我不知道这种说法确切的来源，然而昨天在浏览网页的时候，偶然发现了 C++ 的设计者 Bjarne Stroustrup 的一些类似的说法。这些说法来自于 2007 年 MIT Technology Review 对 Stroustrup 的采访。




    问：一个好的语言是什么样的？

Stroustrup：所有能帮助人们表达他们的想法的东西都会让语言更好。一个语言在一个好的工匠手里应该能胜任每天的任务。语言是否优美是次要的问题。被认为是丑陋的语言开发出来的有用的系统，比优美的语言开发出来的系统要多得多。


    问：优雅难道不重要吗？

Stroustrup：优雅很重要，可是你如何衡量“优雅”？可以表达问题答案的最少字数？我觉得我们应该看构造出来的应用程序的优雅程度，而不是语言自身的优雅程度。就像你不能把木工的一套复杂的工具（很多是危险的工具）叫做“优雅”一样。但是我的餐桌和椅子却真的很优雅，很美。当然，如果一个语言本身也很美，那当然最好。




一些基本的错误


    对这两个回答，我都不满意，我觉得这只是他对于 C++ 的恶劣设计的借口而已。下面我对其中几个说法进行质疑：



    所有能帮助人们表达他们的想法的东西都会让语言更好。



    作为一个程序语言，并不是好心想“帮助人”就可以说是好的。如果是这样的话，那么我就可以把所有国家的脏话都加到你的语言里面，因为它们可以帮助我们骂人。



    被认为是丑陋的语言开发出来的有用的系统，比优美的语言开发出来的系统要多得多。



    系统的数量再多也不能说明这个语言好。正好相反，众多的系统由于语言的一些设计失误，把人们的生命置于危险之中，这说明了这个语言的危害性之大。一种像炸药一样的语言，用的人越多越是危险。


语言不是工具，而是材料


    我这篇文章想说的最关键的部分，其实是他所支持的“语言工具论”的错误。



    Stroustrup 说：



    我觉得我们应该看构造出来的应用程序的优雅程度，而不是语言自身的优雅程度。就像你不能把木工的一套复杂的工具（很多是危险的工具）叫做“优雅”一样。但是我的餐桌和椅子却很优雅，很美。



    他的言下之意就是把程序语言比作木工的工具，而餐桌也椅子就是这些工具做出来的产品。比方的威力是很大的，很多人一见到大牛给出这么形象的比方，想都不用想就接受了。如果你不仔细分析的话，这貌似一个恰当的比方，然而经过仔细推敲，这却是错误的比方。这是因为程序语言其实不是一种“工具”，而是一种“材料”。



    木工不会把自己的锯子，墨线等东西放进餐桌和椅子里面，而程序员却需要把语言的代码放到应用程序里面。虽然这些程序经过了编译器的转化，但是程序本身却仍然带有语言的特征。这就像一种木材经过墨线和锯子的加工，仍然是同样的木材。一个 C++ 的程序在编译之后有可能产生内存泄漏和下标越界等低级错误，而更加安全的语言却不会出现这个问题。



    所以在这个比方里面，程序语言所对应的应该是木工所用的木料，钉子和粘胶等“材料”，而不是锯子和墨线等“工具”。这些材料其实随着应用程序一起，到了用户的手里。那么对应木工工具的是什么呢？是 Emacs, vi, Eclipse，Visual Studio 等编程环境，以及各种编译器，调试器，make，界面设计工具，等等。这些真正的“工具”丑一点，真的暂时无所谓。



    现在你还觉得程序语言的优雅程度是次要的问题吗？一个复杂而不安全的语言就像劣质的木料和粘胶。它不但会让餐桌和椅子的美观程度大打折扣，而且会造成它们结构的不牢靠，以至于威胁到用户的生命安全。同时它还可能会造成木工的工作效率低下以及工伤的产生。



    这也许就是为什么我的一个同事说，他看 C++ 代码的时候都会带上 OSHA（美国职业安全与健康管理局）批准的护目镜。



    


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 编辑器与IDE

 
 
 
 
    

    
 
     
  

      
   
编辑器与IDE
无谓的编辑器战争


    很多人都喜欢争论哪个编辑器是最好的。其中最大的争论莫过于 Emacs 与 vi 之争。vi 的支持者喜欢说：“看 vi 打起字来多快，手指完全不离键盘，连方向键都可以不用。”Emacs 的支持者往往对此不屑一顾，说：“打字再快又有什么用。我在 Emacs 里面按一个键，等于你在 vi 里面按几十个键。”



    其实还有另外一帮人，这些人喜欢说：“对于 Emacs 与 vi 之争，我的答案是 {jEdit， Geany, TextMate, Sublime...}”这些人厌倦了 Emacs 的无休止的配置和 bug，也厌倦了 vi 的盲目求快和麻烦的模式切换，所以他们选择了另外的更加简单的解决方案。


临时解决方案 - IDE


    那么我对此的答案是什么呢？在目前的情况下，我对程序编辑的临时答案是：IDE。



    写程序的时候，我通常根据语言来选择最能“理解”那种语言的“IDE”（比如 Visual Studio, Eclipse, IntelliJ IDEA 等），而不是一种通用的“文本编辑器”（比如 Emacs, vi, jEdit, ...）。这是因为“文本编辑器”这种东西一般都不真正的理解程序语言。很多 Emacs 和 vi 的用户以为用 etags 和 ctags 这样的工具就能让他们“跳转到定义”，然而这些 tags 工具其实只是对程序的“文本”做一些愚蠢的正则表达式匹配。它们根本没有对程序进行 parse，所以其实只是在进行一些“瞎猜”。简单的函数定义它们也许能猜对位置，但是对于有重名的定义，或者局部变量的时候，它们就力不从心了。



    很多人对 IDE 有偏见，因为他们认为这些工具让编程变得“傻瓜化”了，他们觉得写程序就是应该“困难”，所以他们眼看着免费的 IDE 也不试一下。有些人写 Java 都用 Emacs 或者 vi，而不是 Eclipse 或者 IntelliJ。可是这些人错了。他们没有意识到 IDE 里面其实蕴含了比普通文本编辑器高级很多的技术。这些 IDE 会对程序文本进行真正的 parse，之后才开始分析里面的结构。它们的“跳转到定义”一般都是很精确的跳转，而不是像文本编辑器那样瞎猜。



    这种针对程序语言的操作可以大大提高人们的思维效率，它让程序员的头脑从琐碎的细节里面解脱出来，所以他们能够更加专注于程序本身的语义和算法，这样他们能写出更加优美和可靠的程序。这就是我用 Eclipse 写 Java 程序的时候相对于 Emacs 的感觉。我感觉到自己的“心灵之眼”能够“看见”程序背后所表现的“模型”，而不只是看到程序的文本和细节。所以，我经常发现自己的头脑里面能够同时看到整个程序，而不只是它的一部分。我的代码比很多人的都要短很多也很有很大部分是这个原因，因为我使用的工具可以让我在相同的时间之内，对代码进行比别人多很多次的结构转换，所以我往往能够把程序变成其他人想象不到的样子。



    对于 Lisp 和 Scheme，Emacs 可以算是一个 IDE。Emacs 对于 elisp 当然是最友好的了，它的 Slime 模式用来编辑 Common Lisp 也相当不错。然而对于任何其它语言，Emacs 基本上都是门外汉。我大部分时间在 Emacs 里面是在写一些超级短小的 Scheme 代码，我有自己的一个简单的配置方案。虽然谈不上是 IDE，Emacs 编辑 Scheme 确实比其它编辑器方便。R. Kent Dybvig 写 Chez Scheme 居然用的是 vi，但是我并不觉得他的编程效率比我高。我的代码很多时候比他的还要干净利落，一部分原因就是因为我使用的 ParEdit mode 能让我非常高效的转换代码的“形状”。



    当要写 Java 的时候，我一般都用 Eclipse。最近写 C++ 比较多，C++ 的最好的 IDE 当然是 Visual Studio。可惜的是 VS 没有 Linux 的版本，所以就拿 Eclipse 凑合用着，感觉还比较顺手。个别情况 Eclipse “跳转定义”到一些完全不相关的地方，对于 C++ 的 refactor 实现也很差，除了最简单的一些情况（比如局部变量重命名），其它时候几乎完全不可用。当然 Eclipse 遇到的这些困难，其实都来自于 C++ 语言本身的糟糕设计。


终极解决方案 - 结构化编辑器


    想要设计一个 IDE，可以支持所有的程序语言，这貌似一个不大可能的事情，但是其实没有那么难。有一种叫做“结构化编辑器”的东西，我觉得它可能就是未来编程的终极解决方案。



    跟普通的 IDE 不同，这种编辑器可以让你直接编辑程序的 AST 结构，而不是停留于文本。每一个界面上的“操作”，对应的是一个对 AST 结构的转换，而不是对文本字符的“编辑”。这种 AST 的变化，随之引起屏幕上显示的变化，就像是变化后的 AST 被“pretty print”出来一样。这些编辑器能够直接把程序语言保存为结构化的数据（比如 S表达式，XML 或者 JSON），到时候直接通过对 S表达式，XML 或者 JSON 的简单的“解码”，而不需要针对不同的程序语言进行不同的 parse。这样的编辑器，可以很容易的扩展到任何语言，并且提供很多人都想象不到的强大功能。这对于编程工具来说将是一个革命性的变化。




    已经有人设计了这样一种编辑器的模型，并且设计的相当不错。你可以参考一下这个结构化编辑器，它包含一些 Visual Studio 和 Eclipse 都没有的强大功能，却比它们两者都要更加容易实现。你可以在这个网页上下载这个编辑器模型来试用一下。


    我之前推荐过的 TeXmacs 其实在本质上就是一个“超豪华”的结构化编辑器。你可能不知道，TeXmacs 不但能排版出 TeX 的效果，而且能够运行 Scheme 代码。


    IntelliJ IDEA 的制造者 JetBrains 做了一个结构化编辑系统，叫做 MPS。它是开源软件，并且可以免费下载。


    另外，Microsoft Word 的创造者 Charles Simonyi 开了一家叫做 Intentional Software 的公司，也做类似的软件。




   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 程序语言的常见设计错误(2) - 试图容纳世界

 
 
 
 
    

    
 
     
  

      
   
程序语言的常见设计错误(2) - 试图容纳世界

    之前的一篇文章里，我谈到了程序语言设计的一个常见错误倾向：片面追求短小，它导致了一系列的历史性的设计错误。今天我来谈一下另外一种错误的倾向，这种倾向也导致了很多错误，并且继续在导致错误的产生。



    今天我要说的错误倾向叫做“试图容纳世界”。这个错误导致了 Python，Ruby 和 JavaScript 等“动态语言”里面的一系列问题。我给 Python 写过一个静态分析器，所以我基本上实现了整个 Python 的语义，可以说是对 Python 了解的相当清楚了。在设计这个静态分析的时候，我发现 Python 的设计让静态分析异常的困难，Python 的程序出了问题很难找到错误的所在，Python 程序的执行速度比大部分程序语言都要慢，这其实是源自 Python 本身的设计问题。这些设计问题，其实大部分出自同一个设计倾向，也就是“试图容纳世界”。



    在 Python 里面，每个“对象”都有一个“字典”（dictionary）。这个 dict 里面含有这个对象的 field 到它们的值之间的映射关系，其实就是一个哈希表。一般的语言都要求你事先定义这些名字，并且指定它们的类型。而 Python 不是这样，在 Python 里面你可以定义一个人，这个人的 field 包括“名字”，“头”，“手”，“脚”，……



    但是 Python 觉得，程序应该可以随时创建或者删除这些 field。所以，你可以给一个特定的人增加一个 field，比如叫做“第三只手”。你也可以删除它的某个 field，比如“头”。Python 认为这更加符合这个世界的工作原理，有些人就是可以没有头，有些人又多长了一只手。



    好吧，这真是太方便了。然后你就遇到这样的问题，你要给这世界上的每个人戴一顶帽子。当你写这段代码的时候，你意识中每个人都有头，所以你写了一个函数叫做 putOnHat，它的输入参数是任意一个人，然后它会给他（她）的头上戴上帽子。然后你想把这个函数 map 到一个国家的所有人的集合。



    然而你没有想到的是，由于 Python 提供的这种“描述世界的能力”，其它写代码的人制造出各种你想都没想到的怪人。比如，无头人，或者有三只手，六只眼的人，…… 然后你就发现，无论你的 putOnHat 怎么写，总是会出意外。你惊讶的发现居然有人没有头！最悲惨的事情是，当你费了几个月时间和相当多的能源，给好几亿人戴上了帽子之后，才忽然遇到一个无头人，所以程序当掉了。然而即使你知道程序有 bug，你却很难找出这些无头人是从哪里来的，因为他们来到这个国家的道路相当曲折，绕了好多道弯。为了重现这个 bug，你得等好几个月，它还不一定会出现…… 这就是所谓 Higgs-Bugson 吧。



    怎么办呢？所以你想出了一个办法，把“正常人”单独放在一个列表里，其它的怪人另外处理。于是你就希望有一个办法，让别人无法把那些怪人放进这个列表里。你想要的其实就是 Java 里的“类型”，像这样：


List&lt;有一个头和两只手的正常人&gt; normalPeople;



    很可惜，Python 不提供给你这种机制，因为这种机制按照 Python 的“哲学”，不足以容纳这个世界的博大精深的万千变化。让程序员手工给参数和变量写上类型，被认为是“过多的劳动”。



    这个问题也存在于 JavaScript 和 Ruby。



    语言的设计者们都应该明白，程序语言不是用来“构造世界”的，而只是对它进行简单的模拟。试图容纳世界的倾向，没带来很多好处，没有节省程序员很多精力，却使得代码完全没有规则可言。这就像生活在一个没有规则，没有制度，没有法律的世界，经常发生无法预料的事情，到处跑着没有头，三只手，六只眼的怪人。这是无穷无尽的烦恼和时间精力的浪费。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 关于语言的思考

 
 
 
 
    

    
 
     
  

      
   
关于语言的思考

    之前写了那么多 Haskell 的不好的地方，却没有提到它好的地方，其实我必须承认我从 Haskell 身上学到了非常重要的东西，那就是对于“类型”的思考。虽然 Haskell 的类型系统有过于强烈的约束性，从一种“哲学”的角度（不是数学的角度）来看非常“不自然”，但如果一个程序员从来没学过 Haskell，那么他的脑子里就会缺少一种重要的东西。这种东西很难从除 Haskell，ML，Clean，Coq，Agda 以外的其它语言身上学到。


Haskell 给我的启发


    一个没有学过 Haskell 的 Scheme 程序员最容易犯的一个错误就是，把除 #f（Scheme 的逻辑“假”） 以外的任何值都作为 #t（Scheme 的逻辑“真”）。很多人认为这是 Scheme 的一个“特性”，可是殊不知这其实是 Scheme 的极少数缺点之一。如果你了解 Lisp 的历史，就会发现在最早的时候，Lisp 把 nil（空链表）这个值作为“假”来使用，而把 nil 以外的其它值都当成“真”。这带来了逻辑思维的混乱。



    Scheme 对 Lisp 的这种混乱做法采取了一定的改进，所以在 Scheme 里面，空链表 '() 和逻辑“假”值 #f 被划分开来。这是很显然的事情，一个是链表，一个是 bool，怎么能混为一谈。Lisp 的这个错误影响到了很多其它的语言，比如 C 语言。C 语言把 0 作为“假”，而把不是 0 的值全都作为“真”。所以你就看到有些自作聪明的 C 程序员写出这样的代码：


int i = 0;
...
...
if (i++) { ...}



    Scheme 停止把 nil 作为“假”，却仍然把不是 #f 的值全都作为“真”。Scheme 的崇拜者一般都告诉你，这样做的好处是，你可以使用


(or x y z)



    这样的表达式，如果其中有一个不是 #f，那么这个表达式会直接返回它实际的值，而不只是 #t。然后你就可以写这样的代码：


(cond
 [(or x y z)
  =&gt; (lambda (found)
(do-something-with found))])



    而不是：


(let ([found (first-non-false x y z)])
  (cond
   [(not (eq? found #f))
    (do-something-with found)]))



    第一段代码使用了 Scheme 的一个特殊“语法”，=&gt; 后面的 (lambda (found) ...) 会把 (or x y z) 返回的值作为它的参数 found，然后返回函数计算出的结果。第二段代码没有假设任何不是 #f 的值都是“真”，所以它不把 (or x y z) 放进 cond 的条件里，而是首先把它返回的值绑定到 found，然后再把这个值放进 cond 的条件。



    这第二段代码比第一段代码多了一个 let，增加了一层缩进，貌似更加复杂了，所以很多人觉得把不是 #f 的值全都作为“真”这一做法是合理的。其实 Scheme 为了达到这个目的，恰好犯了“片面追求短小”的语言设计的小聪明（参考这篇博文）。为了让这种情况变得短小而损失类型的准确，这种代价是非常不值得的。



    Haskell 的类型系统就是帮助你严密的思考类似关于类型的问题的。如果你从来没学过 Haskell，你就不会发现这里面其实有个类型错误。可是 Haskell 做得过分了一点，由于对类型推导，一阶逻辑和 category theory 等理论的盲目崇拜，Haskell 里面引入了很多不必要的复杂性。



    各种各样的类型推导我设计过不下十个，其中有一些比 Haskell 强大很多。category theory 其实也不是什么特别有用的东西。很多数学家把它叫做“abstract nonsense”，就是说它太“通用”了，以至于相当于什么都没说。我曾经在一个晚上看完了整本的 category theory 教材，发现里面的内容我其实通过自己的动手操作（实现编译器，设计类型系统和静态分析等等），早就明白了。这里面的理论并不能带来对程序语言的简化。恰恰相反，它让程序语言变得复杂。



    我对 Haskell 程序员的“天才态度”也感到厌倦，所以我不想再使用 Haskell，然而我的脑子里却留下了它“启发”我的东西。对 Haskell 的理解，让我成为了一个更好的 Scheme 程序员，更好的 Java 程序员，更好的 C++ 程序员，甚至更好的 shell 脚本程序员。我能够在任何语言里再现 Haskell 的编程方式的精髓。然而让我继续用 Haskell ，却就像是让我坐牢一样。本来很简单的事情，到 Haskell 里面就变成一些莫名其妙的新术语。Haskell 的设计者们的论文我大部分都看过，几分钟之内我就知道他们那一套东西怎么变出来的，其实里面很少有新的东西。大部分是因为 Haskell 引入的那些“新概念”（比如 monad）而产生的无须有的问题。世界上有比他们更聪明的人，更简单却更强大的理论。所以不要以为 Haskell 就是世界之巅。



    怎么说呢，我觉得每个程序员的生命中都至少应该有几个月在静心学习 Haskell。学会 Haskell 就像吃几天素食一样。每天吃素食显然会缺乏全面的营养，但是每天都吃荤的话，你恐怕就永远意识不到身体里的毒素有多严重。


专攻一门语言的害处


    我曾经对人说 C++ 里面其实有一些好东西，但是我没有说的是，C++ 里面的坏东西实在太多了。C++是一门“毒素”很多的语言，就像猪肉一样。



    有些人从小写 C++，一辈子都在写 C++，就像每天每顿吃猪肉一样。结果是他们对 C++ 里面的“珍珠”掌握的非常牢靠，以至于出现了一种“脑残”的现象——他们没法再写出逻辑清晰的程序。（这里“珍珠”是一个特殊的术语，它并不含有赞美的意思。请参考这篇博文。）



    比如，很多 C++ 程序员很精通 functor 的写法，可是其实 functor 只是由于 C++ 没有 first-class function 而造成的“变通”。C++ 的 functor 永远也不可能像 Scheme 的 lambda 函数一样好用。因为每次需要一个 functor 你都得定义一个新的 class，然后制造这个 class 的对象。如果函数里面有自由变量，那么这些自由变量必须通过构造函数放进 functor 的 field 里面，这样当 functor 内部的“主方法”被调用的时候，它才能知道自由变量的值。所以为此，你又得定义一些 field。麻烦了这么久，你得到的其实不过是 Scheme 程序员用起来就像呼吸空气一样的 lambda。



    很多精通 functor 的 C++ 程序员认为会用 functor 就说明自己水平高。殊不知 functor 这东西不但是一个“变通”，而且是从函数式语言里面“学”过来的。在最早的时候，C++ 程序员其实是不知道 functor 这东西的。如果你考一下古就会发现，C++ 诞生于 1983 年，而 Scheme 诞生于 1975 年，Lisp 诞生于 1958 年。C++ 的诞生比 Scheme 整整晚了8年，然而 Scheme 一开始就有 lexical scoping 的 lambda。functor 只不过是对 lambda 的一种绕着弯的模仿。实际上 C++ 后来加进去的一些东西（包括 boost 库），基本上都是东施效颦。



    记得2011年11月11日的良辰吉日，C++ 的创造者 Bjarne Stroustrup 在 Indiana 大学做了一个演讲，主题是关于 C++11 的新特性。当时我也在场，主持人 Andrew 是 boost 库的首席设计师之一（他后来有段时间当过我的导师）。他连夸 Stroustrup 会选日子，只遗憾演讲时间没有定在11点。



    虽然我对 Stroustrup 的幽默感和谦虚的态度感到敬佩，但我也看出来 C++11 相对于像 Scheme 这样的语言，其实没有什么真正的“新东西”。大部分时候它是在改掉自己的一些坏毛病，然后向其它语言学习一些东西，然后把这些学习的痕迹掩盖起来。可是到最后，它仍然不可能达到其他语言那么原汁原味的效果。然而，由于 C++ 的普及程度高，现成的代码又多，它的地位和重要性还是一时难以动摇的。所以这些“先辈的罪”，我们恐怕要用好几代人的工作才能弥补。



    那么 C++ 有什么其他语言没有的好东西呢？其实非常少。我还是有空再讲吧。


多学几种语言


    我今天想说其实就是，没有任何一种语言值得你用毕生的精力去“精通”它。“精通”其实代表着“脑残”——你成为了一个高效的机器，而不是一个有自己头脑的人。你必须对每种语言都带有一定的怀疑态度，而不是完全的拥抱它。每个人都应该学习多种语言，这样才不至于让自己的思想受到单一语言的约束，而没法接受新的，更加先进的思想。这就像每个人都应该学会至少一门外语一样，否则你就深陷于自己民族的思维方式。有时候这种民族传统的思想会让你深陷无须有的痛苦却无法自拔。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 Yoda 表示法错在哪里

 
 
 
 
    

    
 
     
  

      
   
Yoda 表示法错在哪里

    在上一篇博文里，我提到了 Yoda 表示法。


Yoda Notation（Yoda 表示法）


    



    它的含义是，在 C/C++ 里面使用这样的表达式顺序：


if ("blue" == theSky) ...



    这是为了避免意外的写成：


if (theSky = "blue") ...



    “Yoda 表示法”的名字来源于《星球大战》的 Yoda 大师。他说话的单词顺序相当奇特，比如：“Backwards it is, yes!”


一般认为


    使用这个表示法是为了“变通”（workaround） C/C++ 的一个设计抉择：使用 = 来表示赋值，而使用 == 来表示比较。这个设计充分的展现了“先辈的罪”（Sins of our Forefathers）这一词汇的精髓。


我认为


    使用 = 来表示赋值其实并不是真正的错误所在。真正的错误在于 C/C++ 的赋值语句不应该返回一个值。



    也就是说，theSky = "blue" 的所有功能应该只是“赋值”这种“副作用”，副作用不应该具有“值”。即使你牵强附会说它有一个值，它的“值”也应该是 void（随之这个 void 会被类型检查所拒绝，因为它不是 if 所期望的 bool）。所以，一个良好的语言不应该允许你把 theSky = "blue" 放进 if (...) 的“条件”里面。如果你真的要赋值又要判断，它会迫使你把这拆开成两行：


theSky = "blue";
if (theSky) ...



    更近一步。if (theSky) 这个写法其实也是一个先辈的罪。theSky 的类型是 string，它不应该可以直接被作为 bool 使用。if (...) 的条件应该必须是一个 bool。 所以这里其实应该写成：


theSky = "blue";
if (theSky != NULL) ...



    因为赋值语句永远不可能出现在条件的位置，所以之前的那种错误，即使我们使用 = 作为赋值操作符，也完全不可能出现。这样我们也就完全没必要用 Yoda 表示法了。



    相反，如果我们只是把 = 换成像 Pascal 的 := 这样的赋值操作符，而保留其它的“特性”（赋值操作会返回值）的话，我们其实还是会遇到同样的问题：


if (theSky := "blue") ...



    这里假设你想打 =，却不小心打成了 :=。机会虽然小，但是仍然有可能。而我推荐的解决方案，会让你故意想犯错误都不可能，编译器会拒绝接受你的程序。



    所以你看到了，问题的根源其实不在于赋值操作的名字，而是有更深的原因。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 几个超炫的专业词汇

 
 
 
 
    

    
 
     
  

      
   
几个超炫的专业词汇

    从同事的博客上学会了几个超炫的专业词汇，激动不已。觉得这些词汇可以言简意赅的概括我的好几篇博文，自己的文章水准真是自愧不如。现在来见识一下真正大师级的英语词汇：




    Yoda Notation（Yoda 表示法）



    



    在 C/C++ 里面使用这样的表达式顺序：


if ("blue" == theSky) ...



    这是为了避免意外的写成：


if (theSky = "blue") ...



    “Yoda 表示法”的名字来源于《星球大战》的 Yoda 大师。他说话的单词顺序相当奇特，比如：“Backwards it is, yes!”



    同事认为：使用这个表示法是为了“变通”（wordaround） C/C++ 的一个设计抉择：使用 = 来表示赋值，而使用 == 来表示比较。这个设计充分的展现了“先辈的罪”（Sins of our Forefathers）这一词汇的精髓。



    关于 Yoda 表示法我有不同的见解，请参考《Yoda 表示法错在哪里》。


    Mental Speedbump（头脑减速杠）



    



    由于设计的不协调性造成的用户的注意力分散。比如，很多软件喜欢弹出一个窗口问你“是否继续？”


    Pearl Effect （珍珠效应）



    



    珍珠是怎么形成的？是由于异物掉进了蛤蚌的外套膜和贝壳之间的夹层里面，没法排出来。异物不断的刺激该处的外套膜，又痒又痛，于是外套膜分泌珍珠质把异物包围起来，包了一层又一层。久而久之，就形成了珍珠。



    在软件里面也有很多这样的“珍珠”。由于早期的挠人的设计错误，用户不得不采用一些“变通方案”（workaround）或者“附加过程”，这些就像珍珠质一样。久而久之，这些变通方案凝结起来，变成了“软件珍珠”，不了解它们来源的人都视之为宝贝。虽然产生于同样的原理，“软件珍珠”远远没有真正的珍珠那么好看。



    （请比较：Sins of our Forefathers）


    Sins of our Forefathers（先辈的罪）



    



    当时看起来合乎逻辑并且合情合理最后回顾起来却很傻b的历史遗留设计。



    与“珍珠”相比，这些是有意识的加进去的，而不是不小心造成的，虽然这两者都会造成“变通”（workaround）。


    Katrina Effect（卡特里娜飓风效应）



    



    这个词描述的是一种飓风过后完全重头来过的悲惨景象。这种现象现在经常出现在重装或者升级软件之后，或者 Windows 安装完软件之后要你重启机器（关掉所有窗口）。


    Workaround（变通）



      



    因为开发过程的失败而让用户必须进行的一些操作。这些通常是设计失误。


    Jenga Code



    



    当你加上一小块代码之后，就整个垮掉的那种代码。



    Jenga 是一种非常流行的 party 玩具，如图。它的工作原理是，先把那些小木条堆成一个规则的塔。然后，参加游戏的人轮流从下面抽出一块（只能用一只手）来放在最上面。谁放上之后木塔垮掉了，谁就“胜利”了。之后这个人就要做其他人想出来的一些“惩罚”，跟真心话大冒险那些事情差不多。


    Higgs-Bugson



    



    一种假想中的 bug。它一般是跟据运行日志的少数记录和零星含糊的用户报告推测出来，但是在开发员的机器上很难重现。


    Heisenbug



    



    当你试图观察它的时候就突然消失或者改变行为特征的 bug。




   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 一种新的操作系统设计

 
 
 
 
    

    
 
     
  

      
   
一种新的操作系统设计

    我一直在试图利用程序语言的设计原理，设计一种超越“Unix 哲学”的操作系统。这里是我的设想：




    这种系统里面的程序间通信不使用无结构的字符串，而是使用带有类型和结构的数据。在这样的系统里面，Unix 和其它类似操作系统（比如 Windows）里的所谓“应用程序”的概念基本上完全消失。系统由一个个很小的“函数”组成，每个函数都可以调用另外一个函数，通过参数传递数据。每个函数都可以手动或者自动并发执行。用现在的系统术语打个比方，这就像是所有代码都是“库”代码，而不存在独立的“可执行文件”。


    由于参数是数据结构而不是字符串，这避免了程序间通信繁琐的编码和解码过程。使得“进程间通信”变得轻而易举。任何函数都可以调用另一个函数来处理特定类型的数据，这使得像 “OLE 嵌入”这样的机制变得极其简单。


    所有函数由同一种先进的高级程序语言写成，所以函数间的调用完全不需要“翻译”。不存在 SQL injection 之类由于把程序当成字符串而产生的错误。


    由于这种语言不允许应用程序使用“指针运算”，应用程序不可能产生 segfault 一类的错误。为了防止不良用户手动在机器码里面加入指针运算，系统的执行的代码不是完全的机器代码，而必须通过进一步的验证和转换之后才会被硬件执行。这有点像 JVM，但它直接运行在硬件之上，所以必须有一些 JVM 没有的功能，比如把内存里的数据结构自动换出到硬盘上，需要的时候再换进内存。


    由于没有指针运算，系统可以直接使用“实地址”模式进行内存管理，从而不再需要现代处理器提供的内存映射机制以及 TLB。内存的管理粒度是数据结构，而不是页面。这使得内存访问和管理效率大幅提高，而且简化了处理器的设计。据 Kent Dybvig 的经验，这样的系统的内存使用效率要比 Unix 类的系统高一个数量级。


    系统使用与应用程序相同的高级语言写成，至于“系统调用”，不过是调用另外一个函数。由于只有这些“系统驱动函数”才有对设备的“引用”，又因为系统没有指针运算，所以用户函数不可能绕过系统函数而非法访问硬件。


    系统没有 Unix 式的“命令行”，它的“shell”其实就是这种高级语言的 REPL。用户可以在终端用可视化的结构编辑方式输入各种函数调用，从而启动进程的运行。所以你不需要像 Unix 一样另外设计一种毛病语言来“粘接”应用程序。


    所有的数据都作为“结构”，保存在一个分布式的数据共享空间。同样的那个系统语言可以被轻松地发送到远程机器，调用远程机器上的库代码，执行任意复杂的查询索引等动作，取回结果。这种方式可以高效的完成数据库的功能，然而却比数据库简单很多。所谓的“查询语言”（比如 SQL，Datalog，Gremlin，Cypher）其实是多此一举，它们远远不如普通的程序语言强大。说是可以让用户“不需要编程，只提出问题”，然而它们所谓的“优化”是非常局限甚至不可能实现的，带来的麻烦远比直接编程还要多。逻辑式编程语言（比如 Prolog）其实跟 SQL 是一样的问题，一旦遇到复杂点的查询就效率低下。所以系统不使用关系式数据库，不需要 SQL，不需要 NoSQL，不需要 Datalog。


    由于数据全都是结构化的，所以没有普通操作系统的无结构“文件系统”。数据结构可能通过路径来访问，然而路径不是一个字符串或者字符串模式。系统不使用正则表达式，而是一种类似 NFA 的数据结构，对它们的拆分和组合操作不会出现像字符串那样的问题，比如把 /a/b/ 和 /c/d 串接在一起就变成错误的 /a/b//c/d。


    所有的数据在合适的时候被自动同步到磁盘，并且进行容错处理，所以即使在机器掉电的情况，绝大部分的数据和进程能够在电源恢复后继续运行。


    程序员和用户几乎完全不需要知道“数据库”或者“文件系统”的存在。程序假设自己拥有无穷大的空间，可以任意的构造数据。根据硬件的能力，一些手动的存盘操作也可能是有必要的。


    为了减少数据的移动，系统或者用户可以根据数据的位置，选择： 1）迁移数据，或者 2）迁移处理数据的“进程”。程序员不需要使用 MapReduce，Hadoop 等就能进行大规模并行计算，然而表达能力却比它们强大很多，因为它们全都使用同一种程序语言写成。





    我曾经以为我是第一个想到这个做法的人。可是调查之后发现，很多人早就已经做出了类似的系统。Lisp Machine 似乎是其中最接近的一个。Oberon 是另外一个。IBM System/38 是类似系统里面最老的一个。最近一些年出现的还有微软的 Singularity，另外还有人试图把 JVM 和 Erlang VM 直接放到硬件上执行。



    所以这篇文章的标题其实是错的，这不是一种“新的操作系统设计”。它看起来是新的，只不过因为我们现在用的操作系统忘记了它们本该是什么样子。我也不该说它“超越了 Unix 哲学”，而应该说，所谓的 Unix 哲学其实是历史的倒退。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 Markdown 的一些问题

 
 
 
 
    

    
 
     
  

      
   
Markdown 的一些问题

    把我之前的博文基本上转换成了 markdown 格式。我发现 markdown 虽然在编辑器里看起来比 HTML 清晰一些，但也有一些不足。



    这些 markup 语言的格式都有点像我本科的时候给我爸做的一种“标准化试卷标记语言”（因为他是中学英语老师）。当时我写了一个1000来行的 Perl 脚本，可以把这种简单的标记语言转换成美观的 LaTeX 格式文档，并且带有友好的 Tk 图形界面。现在回想起来，我那时候的设计就已经相当先进了。跟我的语言相比，这些 blog 用的 markup 语言真是小巫见大巫了，而且问题多多。有点跑题了，还是回头来看看 markdown 的问题吧。




    Markdown 实际上采用的是类似 Python 和 Haskell 的 layout 语法。



    我已经在一篇英文博文里提到了 layout 语法的多种问题。因为空格的数量决定了文档的结构，这种文档格式相当的“脆弱”。稍微少打一两个空格，就会出现不可预测的结果。这种现象在“itemize”内部的代码块最容易出现。因为每个 item 带来了缩进，所以内部的代码必须比 item 的缩进多4个空格，才能被排到正确的位置。比如我转换博文的时候多次出现以下的情况：



    



    这里的问题是，代码里的第一行 helloworld z = let x = 1 因为缩进不够，被放到了代码块外面。但是为了准确的缩进所耗费的精力，其实比直接打 &lt;pre&gt; 这样的 tag 还要多。


    特殊字符的选择不合理



    markdown 对特殊字符的使用不大合理。我多次发现文档段落整段的变成斜体，就是因为原来的文档里出现了 x*y 这样的表达式。在程序员的世界里，“乘法”显然比“强调”更加频繁。把 * 用于标记“强调”，实际上把一个非常有用的字符用在了很不频繁的用途。


    表达力相当有限



    在很多细节上，markdown 并不能表达我想要的格式。比如它不能正确的插入断行 &lt;br&gt;。如果你有两块紧接在一起的代码，但你不想把它们连在一起，markdown 非要给你连在一起…… 于是我就发现自己加入了越来越多的 HTML。



    这在图片的语法上就更加明显，markdown 引入了 ![alt](image url) 这样的格式，其实比起 HTML 还要难看和不一致。比如现在它仍然无法表达图片的大小，这是相当重要的信息。所以我觉得 markdown 的语法已经显示出了它的弱点，如果它要表达更复杂的信息，就会变得比 HTML 还要难记，难看。所以对于图片，我觉得还不如直接用 HTML 的 &lt;img&gt; 。





    所以总的感觉是 markdown 引入了太多的“语法”，以至于稍微复杂一点的信息表达起来还不如 HTML 来的直接。现在就这样先凑合着吧。也许过段时间自己设计一个格式。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 谈程序的“通用性”

 
 
 
 
    

    
 
     
  

      
   
谈程序的“通用性”

    在现实的软件工程中，我经常发现这样的一种现象。本来用很简单的代码就可以解决的问题，却因为设计者过分的关注了“通用性”，“可维护性”和“可扩展性”，被搞得绕了几道弯，让人琢磨不透。



    这些人的思维方式是这样的：“将来这段代码可能会被用到更多的场合，所以我现在就考虑到扩展问题。”于是乎，他们在代码中加入了各种各样的“框架结构”，目的是为了在将来有新的需要的时候，代码能够“不加修改”就被用到新的地方。



    我并不否认“通用性”的价值，实际上我的某些程序通用性非常之强。可是很多人所谓的“通用性”，其实达到的是适得其反的效果。这种现象通常被称为“过度工程” (over-engineer)。关于过度工程，有一个有趣的故事：



    http://www.snopes.com/business/genius/spacepen.asp



    传说 1960 年代美俄“太空竞赛”的时候，NASA 遇到一个严重的技术问题：宇航员需要一支可以在外太空的真空中写字的钢笔。最后 NASA 耗资150万美元研制出了这样的钢笔。可惜这种钢笔在市场上并不行销。



    俄国人也遇到同样的问题。他们使用了铅笔。



    这个故事虽然是假的，但是却具有伊索寓言的威力。现在再来看我们的软件行业，你也许会发现：




    代码需要被“重用”的场合，实际上比你想象的要少



    我发现很多人写程序的时候连“眼前特例”都没做好，就在开始“展望将来”。他们总是设想别人会重用这段代码。而实际上，由于他们的设计过于复杂，理解这设计所需的脑力开销已经高于从头开始的代价，所以大部分人其实根本不会去用他们的代码，自己重新写一个就是了。也有人到后来发现，之前写的那段代码，连自己都看不下去了，恨不得删了重来，就不要谈什么重用了。


    修改代码所需要的工作实际上比你想象的要少



    还有一种情况是，这些被设计来“共享”的代码，其实根本没有被用在很多的地方，所以即使你完全手动的修改它们也花不了很多时间。现在再加上 IDE 技术的发展和各种先进的 refactor 工具，批量的修改代码已经不是特别麻烦的事情。曾经需要在逻辑层面上进行的可维护性设计，现在有可能只需要在 IDE 里面点几下鼠标就轻松完成。所以在考虑设计一个框架之前，你应该同时考虑到这些因素。


    “考虑”到了通用性，并不等于你就准确地“把握”住了通用性



    很多人考虑到了通用性，却没有准确的看到，到底是哪一个部分将来可能需要修改，所以他们的设计经常抓不住关键。当有新的需要出现的时候，才发现原来设想的可能变化的部分，其实根本没有变，而原来以为不会变的地方却变了。



    能够准确的预测将来的需要，能够从代码中抽象出真正通用的框架，是一件非常困难的事情。它不止需要有编程的能力，而且需要对真实世界里的事物有强大的观察能力。很多人设计出来的框架，其实只是照搬别人的经验，却不能适应实际的需要。在 Java 世界里的很多 design pattern，就是这些一知半解的人设计出来的。


    初期设计的复杂性



    如果在第一次的设计中就过早的考虑到将来，由此带来的多余的复杂性，有可能让初期的设计就出现问题。所以这种对于将来的变化的考虑，实际上帮了倒忙。本来如果专注于解决现在的问题，能够得到非常好的结果。但是由于“通用性”带来的复杂度，设计者的头脑每次都要多转几道弯，所以它无法设计出优雅的程序。


    理解和维护框架性代码的开销



    如果你设计了框架性的代码，每个程序员为了在这个框架下编写代码，都需要理解这种框架的构造，这带来了学习的开销。一旦发现这框架有设计问题，依赖于它的代码很有可能需要修改，这又带来了修改的开销。所以加入“通用性”之后，其实带来了更多的工作。这种开销能不能得到回报，依赖于以上的多种因素。





    所以在设计程序的时候，我们最好是先把手上的问题解决好。如果发现这段代码还可以被用在很多别的地方，到时候再把框架从中抽象出来也不迟。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 什么是启发

 
 
 
 
    

    
 
     
  

      
   
什么是启发

    我喜欢用“启发”这个词。比如我经常会对人说：“你启发了我。”然而听到这话的人有时候不明白我的意思，自以为高我一筹，于是顿显傲气。其实我用“启发”这个词，是有深刻含义的。“启发”的意思并不等于“我没有你懂得多”或者“你比我聪明”，而是一个很含糊的词。



    如果 A 受到了 B 启发，有几种可能性：



B 做了一件很聪明的事情，所以从正面启发了 A
B 做了一件很笨的事情，所以从反面启发了 A
B 做了一件不好也不坏的事情，但是这个事情正好触发了 A 事先想的一个问题的答案




    这就是为什么“美丽心灵”里的 John Nash 在酒吧看到一个美女之后，解决了一个重要的问题，然后对她说“谢谢”，让人家都莫名其妙。



    Richard Feynman 也提到：“在你的头脑里随时准备好12个问题。每当发生一件有趣的事情，就检查一下其中是否有问题可以由此获得线索。久而久之，人们就会称你为天才。”



    孔夫子所谓的“三人行必有我师”，也就是这个意思吧。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 Scheme 编程环境的设置

 
 
 
 
    

    
 
     
  

      
   
Scheme 编程环境的设置

    



    介绍了这么久的 Scheme，却没有讲过如何配置一个高效的 Scheme 的编程环境。有些人开始学习 Scheme 的时候感觉无从下手，所以今天讲一下它的配置。



    Scheme 的配置有很多种方式，我不想介绍太多东西，免得有人看花了眼，所以这里只介绍一下我自己的配置。我不大喜欢像 Quack 一类的复杂的环境，因为它们经常有很多多余的功能，却缺少我想要的功能。一旦我想修改它们，又到处出问题。我的配置很简约，我用它写了几千行的超高难度的代码，翻来覆去的改，感觉效率非常高，也没有觉得缺少什么特别重要的东西。



    现在我就一步一步的介绍我的配置。


安装 Scheme

Chez Scheme


    世界上最快，最成熟可靠的 Scheme 实现是 R. Kent Dybvig 所作的 Chez Scheme。它可以把 Scheme 编译成机器代码，运行速度非常高。Chez Scheme 曾经是商业软件，价格昂贵，然而现在却开源了，并且可以免费使用。你可以在这里下载 Chez Scheme 的源代码：



    https://github.com/cisco/ChezScheme



    编译安装很快很方便，在 Linux 和 Mac 系统基本就是这样：


./configure
make
sudo make install



    整个编译安装过程只需要30秒。这是世界上最快编译自己全套系统的编译器。


Racket


    如果你对性能没有特别高的需求，主要用于学习，也可以用 Racket。它可以在这里下载：



    http://racket-lang.org



    安装应该很容易。Ubuntu 也自带了 Racket，所以可以直接让系统安装它。


设置 ParEdit mode


    我编辑 Scheme 的时候都用 Emacs。我使用一个叫做 ParEdit mode 的插件。它可以让你“半结构化”式的编辑 Scheme 和其它的 Lisp 文件。开头你可能会有点不习惯，可是一旦习惯了，你就再也离不开它。



    ParEdit mode 可以在这里下载：



    http://mumble.net/~campbell/emacs/paredit.el



    下载之后，把它放到一个目录里，比如 ~/.emacs.d，然后打开 ~/.emacs 配置文件，加入如下设置：


(add-to-list 'load-path "~/.emacs.d")
(autoload 'paredit-mode "paredit"
  "Minor mode for pseudo-structurally editing Lisp code."
  t)



    这样，只要你使用 M-x paredit-mode 就可以自动载入这个模式。具体的操作方式可以看它的说明（按 C-h m 查看“模式帮助”），我下面也会简单说一下。


设置 scheme mode


    我一般就用系统自带的 Scheme 模式，叫 cmuscheme。但是为了方便，我自己写了几个函数，用于在执行 Scheme 代码的时候自动启动解释器，并且打开解释器窗口。你基本只需要把下面的代码拷贝到你的 .emacs 文件里就行：


;;;;;;;;;;;;
;; Scheme 
;;;;;;;;;;;;

(require 'cmuscheme)
(setq scheme-program-name "racket")  ;; 如果用 Petite 就改成 "petite"


;; bypass the interactive question and start the default interpreter
(defun scheme-proc ()
  "Return the current Scheme process, starting one if necessary."
  (unless (and scheme-buffer
 (get-buffer scheme-buffer)
 (comint-check-proc scheme-buffer))
    (save-window-excursion
      (run-scheme scheme-program-name)))
  (or (scheme-get-process)
      (error "No current process. See variable `scheme-buffer'")))


(defun scheme-split-window ()
  (cond
   ((= 1 (count-windows))
    (delete-other-windows)
    (split-window-vertically (floor (* 0.68 (window-height))))
    (other-window 1)
    (switch-to-buffer "*scheme*")
    (other-window 1))
   ((not (find "*scheme*"
 (mapcar (lambda (w) (buffer-name (window-buffer w)))
  (window-list))
 :test 'equal))
    (other-window 1)
    (switch-to-buffer "*scheme*")
    (other-window -1))))


(defun scheme-send-last-sexp-split-window ()
  (interactive)
  (scheme-split-window)
  (scheme-send-last-sexp))


(defun scheme-send-definition-split-window ()
  (interactive)
  (scheme-split-window)
  (scheme-send-definition))

(add-hook 'scheme-mode-hook
  (lambda ()
    (paredit-mode 1)
    (define-key scheme-mode-map (kbd "&lt;f5&gt;") 'scheme-send-last-sexp-split-window)
    (define-key scheme-mode-map (kbd "&lt;f6&gt;") 'scheme-send-definition-split-window)))



    我的配置会在加载 Scheme 文件的时候自动载入 ParEdit mode，并且把 F5 键绑定到“执行前面的S表达式”。这样设置的目的是，我只要把光标移动到一个S表达式之后，然后用一根手指头按 F5，就可以执行程序。够懒吧。


ParEdit mode 的简单使用方法


    ParEdit mode 是一个很特殊的模式。它起作用的时候，你不能直接修改括号。这样所有的括号都保持完整的匹配，不可能出现语法错误。但是这样有一个问题，如果你要把一块代码放进另一块代码，或者从里面拿出来，就不是很方便了。



    为此，ParEdit mode 提供了几个非常高效的编辑方式。我平时只使用两个：




    C-right: 也就是按住 Ctrl 再按右箭头。它的作用是让光标右边的括号，“吞掉”下一个S表达式。


比如，`(a b c) (d e)`。你把光标放在 `(a b c)` 里面，然后按 `C-right`。结果就是 `(a b c (d e))`。也就是把 `(d e)` 被整个“吞进”了 `(a b c)` 里面。 


    M-r: 去掉外层代码。



    这在你需要去掉外层的 let 等结构的时候非常有用。比如，如果你的代码看起来是这样：


(let ([x 10])
  (* x 2))



    当你把光标放在 (* x 2) 的最左边，然后按  M-r，结果就变成了


(* x 2)



    也就是把外面的 (let ([x 10]) ...) 给“掀掉”了。



    其它的一些按键虽然也有用，不过我觉得这两个是最有用的，甚至不可缺少的。有些其他的自动匹配括号的模式，没有提供这种按键，所以用起来很别扭。




设置括号颜色


    很多人看见 Lisp 就怕了，就是因为它看起来括号太多。可是这样的语法，却是有很大的好处的（参考这篇博文《谈语法》）。如果你真的觉得括号碍眼，你可以稍微调整一下括号的颜色，比如淡灰色。这样括号看起来就没有那么显眼了。



    你只需要下载这个 el，放到你的 .emacs.d:



    https://www.dropbox.com/s/v0ejctd1agrt95x/parenface.el



    然后在 .emacs 里面加入两行：


(require 'parenface)
(set-face-foreground 'paren-face "DimGray")



    然后再打开 Scheme 代码的时候，你就会看到是这个样子：



    



    好了，这就是我写 Scheme 的所有配置了。希望这些有所帮助。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 我为什么离开 Cornell

 
 
 
 
    

    
 
     
  

      
   
我为什么离开 Cornell

    很多人都知道，我曾经在 Cornell 博士就读，两年之后转学到了 Indiana 大学。几乎所有人，包括 Indiana 大学的人都感觉奇怪，为什么会有人从 Cornell 这样的“牛校”转学到 Indiana。我曾经在之前的博文里提到 Cornell 的情况，比如学生一上课就忙着抄笔记，作业压得喘不过气，等等。那些都是实际的情况，所以我没什么必要为我的“母校”说好话。



    离开 Cornell 之后，看到有人在 facebook 上成立了一个“Cornell 痛恨者协会”。其中一个人写到：



    “Cornell 说要教你游泳，就把你推进池塘里，任凭你扑腾挣扎。等你快扑腾到岸边的时候，它忽然拿起一块大石头砸在你头上，然后继续等着你上岸。当你再次接近岸边的时候，它又拿起一个榔头敲在你头上，这样你就可以死了，可是 Cornell 仍然继续等着你游上岸边……”



    这就是一个非常形象的，对我在 Cornell 的两年的总结。现在看看我在 Indiana 学到了什么，而 Cornell 教会了我什么，感觉简直一个天上一个地下。Dan Friedman 和 R. Kent Dybvig，他们的教育真的像是爱因斯坦所说的，像是珍贵的礼物，而不是沉重的负担。他们教会我的东西，让我不再在乎任何“牛校”的博士学位甚至教授职位，不管是 Cornell, Stanford, Berkeley, MIT 还是 Harvard, ……



    所谓的“牛校”，恐怕都是这样吧。学生对于它们只是一种成为“牛校”的工具。你拼着命要进来，好我让你进来。但是我不教你，我让你拼死的做作业。如果你做出来了，我就拿最偏最扯淡的试卷来考你。如果你通过了所有这些，那我就给你一个学位。你得到了这样的“荣誉”，自然就会说“我的学校很牛”。你不敢说它不牛，因为那样就是说你也不牛了。所以这样的学校其实什么也不用干，你能学会东西能毕业，全都是靠你自己，到时候你却要把功劳都归到学校头上。天底下就是有这样好的生意。



    曾经有一个 Cornell 的校友跟我是朋友。当我提到 Cornell 的一些事，他总是像个老师一样，上气不接下气地“教育”我，也就是说类似家丑不可外扬的意思吧。“牛校”就是一种传染病，在你还没进去之前就已经埋下病种，当你进去之后它就开始蔓延，等你毕业很多年，它仍然与你同在。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 谈“测试驱动的开发”

 
 
 
 
    

    
 
     
  

      
   
谈“测试驱动的开发”

    现在的很多公司，包括 Google 和我现在的公司 Coverity，都喜欢一种“测试驱动的开发”（test-driven development）。它的原理是，在写程序的时候同时写上自动化的“单元测试”（unit test）。在代码修改之后，这些测试可以批量的被运行，这样就可以避免不应该出现的错误。



    这不是一个坏主意。我在 Kent 的编译器课程上也使用了很多测试。它们在编译器的开发中是不可缺少的。编译器是一种极其精密的程序，微小的改动都可能带来重大的错误。所以编译器的项目一般都含有大量的测试。



    然而测试的构建，应该是在程序主体已经成形的情况下才能进行。如果程序属于创造性的设计，主体并未成形，过早的加入测试反而会大幅度的降低开发效率。所以当我给 Google 开发 Python 静态分析的时候，我几乎没有使用任何测试。虽然组里的成员催我写测试，但是我却知道那只会降低我的开发效率，因为这个程序在几个星期的过程中，被我推翻重来了好几次。要是我一开头就写上测试，这些测试就会碍手碍脚，阻碍我大幅度的修改代码。



    测试的另一个副作用是，它让很多人对测试有一种盲目的依赖心理。改了程序之后，把测试跑一遍没出错，就以为自己的代码是正确的。可是测试其实并不能保证代码的正确，即使完全“覆盖”了也是一样。覆盖只是说你的代码被测试碰到过了，可是它在什么条件下碰到的却没法判断。如果实际的条件跟测试时的条件不同，那么实际运行中仍然会出问题。测试的条件往往是“组合爆炸”的数量级，所以你不可能测试所有的情况。唯一能可靠的方法是使用严密的“逻辑推理”，证明它的正确。



    当然我并不是让你用 ACL2 或者 Coq 这样的定理证明软件。虽然它们的逻辑非常严密，但是用它们来证明复杂的软件系统，需要顶尖的程序员和大量的时间。即使如此，由于理论的限制，程序的正确性有可能根本无法证明。所以我这里说的“逻辑推理”，只是局部的，人力的，基本的逻辑推理。



    很多人写程序只是凭现象来判断，而不能精密的分析程序的逻辑，所以他们修改程序经常“治标不治本”。如果程序出问题了，他们的办法是看看哪里错了，也不怎么理解，就改一下让它不再出错，最多再把所有测试跑一遍。或者再加上一些新的测试，以保证这个地方下次不再出问题。



    这种做法的结果是，程序里出现大量的“特殊情况”和“创可贴”。把一个“虫子”按下去，另一个虫子又冒出来。忙活来忙活去，最后仍然不能让程序满足“所有情况”。其实能够“满足所有情况”的程序，往往比能够“满足特殊情况”的程序简单很多。这是一个很奇怪的事情：能做的事越多，代码量却越少。也许这就叫做程序的“美”，它跟数学的“美”其实是一回事。



    美的程序不可能从修修补补中来。它必须完美的把握住事物的本质，否则就会有许许多多无法修补的特例。其实程序员跟画家差不多，画家如果一天到头蹲在家里，肯定什么好东西也画不出来。程序员也一样，蹲在家里面对电脑，其实很难写出什么好的代码。你必须出去观察事物，寻找“灵感”，而不只是写代码。在修改代码的时候，你必须用“心灵之眼”看见代码背后所表达的事物。这也是为什么很多高明的程序员不怎么用调试器（debugger）的原因。他们只是用眼睛看着代码，然后闭上眼，脑海里浮现出其中信息的流动，所以他们经常一动手就能改到正确的地方。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 爱因斯坦谈教育

 
 
 
 
    

    
 
     
  

      
   
爱因斯坦谈教育

    继续看爱因斯坦的 Ideas and Opinions，发现挺多有趣的东西。现在把他关于教育的话题摘录在下面。自己关于教育的一些想法，等整理好了再写。





    我在我的老师手里遭受了同样的待遇。因为我的独立，他们不喜欢我。当他们需要助教的时候，他们没有选择我。



    世界上已经有太多的教育，特别是在美国的学校里面。



    教育的唯一理性的方式是自己做一个榜样——如果实在不行，你可以做一个反例。



    教一个人专业知识是不够的。通过专业知识，他可以变成一个有用的机器，但却不具有和谐的人格。



    过分强调竞争，过早的功利化和专业化，可以杀灭所有文化生活所赖以生存的精神。



    独立的，批判性的思维，必须从小培养。过度的，过于多样化的科目（分数制度）会破坏这种思维的发展。



    教育应该是这样：被传授的知识应该被当成宝贵的礼物，而不是沉重的任务。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 谈谈 Currying

 
 
 
 
    

    
 
     
  

      
   
谈谈 Currying

    很多基于 lambda calculus 的程序语言，比如 ML 和 Haskell，都习惯用一种叫做 currying 的手法来表示函数。比如，如果你在 Haskell 里面这样写一个函数：


f x y = x + y



    然后你就可以这样把链表里的每个元素加上 2：


map (f 2) [1, 2, 3]



    它会输出 [3, 4, 5]。



    注意本来 f 需要两个参数才能算出结果，可是这里的 (f 2) 只给了 f 一个参数。这是因为 Haskell 的函数定义的缺省方式是“currying”。Currying 其实就是用“单参数”的函数，来模拟多参数的函数。比如，上面的 f 的定义在 Scheme 里面相当于：


(define f
  (lambda (x)
    (lambda (y)
      (+ x y))))



    它是说，函数 f，接受一个参数 x，返回另一个函数（没有名字）。这个匿名函数，如果再接受一个参数 y，就会返回 x + y。所以上面的例子里面，(f 2) 返回的是一个匿名函数，它会把 2 加到自己的参数上面返回。所以把它 map 到 [1, 2, 3]，我们就得到了 [3, 4, 5]。



    在这个例子里面，currying 貌似一个挺有用的东西，它让程序变得“简短”。如果不用 currying，你就需要制造另一个函数，写成这个样子：


map (\y-&gt;f 2 y) [1, 2, 3]



    这就是为什么 Haskell 和 ML 的程序员那么喜欢 currying。这个做法其实来源于最早的 lambda calculus 的设计。因为 lambda calculus 的函数都只有一个参数，所以为了能够表示多参数的函数，有一个叫 Haskell Curry 的数学家和逻辑学家，发明了这个方法。



    当然，Haskell Curry 是我很尊敬的人。不过我今天想指出的是，currying 在程序设计的实践中，其实并不是想象中的那么好。大量使用 currying，其实会带来程序难以理解，复杂性增加，并且还可能因此引起意想不到的错误。



    不用 currying 的写法(\y-&gt;f 2 y)虽然比起 currying 的写法(f 2)长了那么一点，但是它有一点好。那就是你作为一个人（而不是机器），可以很清楚的从“\y->f 2 y”这个表达式，看到它的“用意”是什么。你会很清楚的看到：



    “f 本来是一个需要两个参数的函数。我们只给了它第一个参数 2。我们想要把 [1, 2, 3] 这个链表里的每一个元素，放进 f 的第二个参数 y，然后把 f 返回的结果一个一个的放进返回值的链表里。”



    仔细看看上面这段话说了什么吧，再来看看 (f 2) 是否表达了同样的意思？注意，我们现在的“重点”在于你，一个人，而不在于计算机。你仔细想，不要让思维的定势来影响你的判断。



    你发现了吗？(f 2) 并不完全的含有 \y-&gt;f 2 y 所表达的内容。因为单从 (f 2) 这个表达式（不看它的定义），你看不到“f 总共需要几个参数”这一信息，你也看不到 (f 2) 会返回什么东西。f 有可能需要2个参数，也有可能需要3个，4个，5个…… 比如，如果它需要3个参数的话，map (f 2) [1, 2, 3] 就不会返回一个整数的链表，而会返回一个函数的链表，它看起来是这样：[(\z-&gt;f 2 1 z), (\z-&gt;f 2 2 z), (\z-&gt;f 2 3 z)]。这三个函数分别还需要一个参数，才会输出结果。



    这样一来，表达式 (f 2) 含有的对“人”有用的信息，就比较少了。你不能很可靠地知道这个函数接受了一个参数之后会变成什么样子。当然，你可以去看 f 的定义，然后再回来，但是这里有一种“直觉”上的开销。如果你不能同时看见这些信息，你的脑子就需要多转一道弯，你就会缺少一些重要的直觉。这种直觉能帮助你写出更好的程序。



    然而，currying 的问题不止在于这种“认知”的方面，有时候使用 curry 会直接带来代码复杂性的增加。比如，如果你的 f 定义不是加法，而是除法：


f x y = x / y



    然后，我们现在需要把链表 [1, 2, 3] 里的每一个数都除以 2。你会怎么做呢？



    map (f 2) [1, 2, 3] 肯定不行，因为 2 是除数，而不是被除数。熟悉 Haskell 的人都知道，可以这样做：


map (flip f 2) [1, 2, 3]



    flip 的作用是“交换”两个参数的位置。它可以被定义为：


flip f x y = f y x



    但是，如果 f 有 3 个参数，而我们需要把它的第 2 个参数 map 到一个链表，怎么办呢？比如，如果 f 被定义为：


f x y z = (x - y) / z



    稍微动一下脑筋，你可能会想出这样的代码：


map (flip (f 1) 2) [1, 2, 3]



    能想出这段代码说明你挺聪明，可是如果你这样写代码，那就是缺乏一些“智慧”。有时候，好的程序其实不在于显示你有多“聪明”，而在于显示你有多“笨”。现在我们就来看看笨一点的代码：


map (\y -&gt; f 1 y 2) [1, 2, 3]



    现在比较一下，你仍然觉得之前那段代码很聪明吗？如果你注意观察，就会发现 (flip (f 1) 2) 这个表达式，是多么的晦涩，多么的复杂。



    从 (flip (f 1) 2) 里面，你几乎看不到自己想要干什么。而 \y-&gt; f 1 y 2 却很明确的显示出，你想用 1 和 2 填充掉 f 的第一，三号参数，把第二个参数留下来，然后把得到的函数 map 到链表 [1, 2, 3]。仔细看看，是不是这样的？



    所以你花费了挺多的脑力才把那使用 currying 的代码写出来，然后你每次看到它，还需要耗费同样多的脑力，才能明白你当时写它来干嘛。你是不是吃饱了没事干呢？



    练习题：如果你还不相信，就请你用 currying 的方法（加上 flip）表达下面这个语句，也就是把 f 的第一个参数 map 到链表 [1, 2, 3]：


map (\y -&gt; f y 1 2) [1, 2, 3]



    得到结果之后再跟上面这个语句对比，看谁更加简单？



    到现在你也许注意到了，以上的“笨办法”对于我们想要 map 的每一个参数，都是差不多的形式；而使用 currying 的代码，对于每个参数，形式有很大的差别。所以我们的“笨办法”其实才是以不变应万变的良策。



    才三个参数，currying 就显示出了它的弱点，如果超过三个参数，那就更麻烦了。所以很多人为了写 currying 的函数，特意把参数调整到方便 currying 的顺序。可是程序的设计总是有意想不到的变化。有时候你需要增加一个参数，有时候你又想减少一个参数，有时候你又会有别的用法，导致你需要调整参数的顺序…… 事先安排好的那些参数顺序，很有可能不能满足你后来的需要。即使它能满足你后来的需要，你的函数也会因为 currying 而难以看懂。



    这就是为什么我从来不在我的 ML 和 Haskell 程序里使用 currying 的原因。古老而美丽的理论，也许能够给我带来思想的启迪，可是未必就能带来工程中理想的效果。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 谈惰性求值

 
 
 
 
    

    
 
     
  

      
   
谈惰性求值

    从之前的几篇博文里面你也许已经看到了，Haskell 其实是问题相当严重的语言，然而这些问题却没有引起足够的重视。我能看到的 Haskell 的问题在于：




    复杂的基于缩进的语法，使得任何编辑器都不能高效的编辑 Haskell 程序，并且使得语法分析难度加倍。对这个观点，请参考我的博文《谈语法》以及我的英文博文《Layout Syntax Considered Harmful》。


    “纯函数式”的语义以及 monad 其实不是好东西。对此请参考博文《对函数式语言的误解》。


    Haskell 所用的 Hindley-Milner 类型系统，其实含有一个根本性的错误。对此请参考《Hindley-Milner 类型系统的根本性错误》。


    Haskell 所用的 type class，其实跟一般语言（比如 Java）里面的重载（overloading）并没有本质区别。你看到的区别都是因为 Hindley-Milner 系统和重载混合在一起产生的效果。type class 并不能比其它语言里的重载做更多的事。





    这样一来，好像 Haskell 的“特征”，要么是错误的，要么就不是自己的。可是现在我再给它加上一棵稻草：Haskell 的惰性求值（lazy evaluation）方式，其实大大的限制了它的运行效率，并且使得它跟并行计算的目标相矛盾。



    这是一个对我已经非常明显的问题，所以我只简要的说明一下。惰性求值的方式，使得我们在“需要”一个变量的值的时候，总是有两种可能性：1）这个变量在这之前已经被求值，所以可以直接取值 2）这个变量还没有被求值，也就是说它还是一个 thunk，我们必须启动对它的求值。



    可能你已经发现了，这其实带来了类型系统的混乱。任何类型，不管是 Int, Bool, List, ... 或者自定义数据类型，都多出了这么一个东西：thunk。它表示的是“还没有求值的计算”。Haskell 程序员一般把它叫做“bottom”，写作 |。它的意思是：死循环。因为任何 thunk 都有可能 1）返回一个预定的类型的值，或者 2）导致死循环。



    这有点像 C++ 和 Java 里的 null 指针，因为 null 可以被作为任何其他类型使用，却又不具有那种类型的特征，所以会产生意想不到的问题。| 给 Haskell 带来的问题没那么严重，但却一样的不可预料，难以分析和调试。对于 Haskell 来说，有可能出现这样的事情：明明写了一个很小的函数，觉得应该不会花很多时间。结果呢，因为它对某个变量取值，间接的触发了一段很耗时间的代码，所以等了老半天还没返回。想知道是哪里出了问题，却难以发现线索，因为这函数并没有直接或者间接的调用那段耗时间的代码，而是这个变量的 thunk 启动了那段代码。这就导致了程序的效率难以分析：被“惰性”搁在那里的计算，有可能在出乎你意料的地方爆发。这就是所谓“平时不烧香，临时抱佛脚。”



    这种不确定性，并没有带来总体计算开销的增加。然而“惰性”却在另外一方面带来了巨大的开销，这就是“问问题”的开销。每当看到一个变量，Haskell 都会问它一个问题：“你被求值了没有？”即使这变量已经被求值，而且已经被取值一百万次，Haskell 仍然会问这个问题：“你被求值了没有？”问一个变量这问题可能不要紧，可是 Haskell 会问几乎所有的变量这个问题，反复的问这个问题。这就累积成了巨大的开销。跟我在另一篇博文里谈到的“解释开销”差不多，这种问题是“运行时”的，所以没法被编译器“优化”掉。



    具有讽刺意味的是，Haskell 这种“纯函数式语言”的惰性求值所需要的 thunk，全都需要“副作用”才可以更新，所以它们必须被放在内存里面，而不是寄存器里面。如果你理解了我写的《对函数式语言的误解》，你就会发现连 C 程序里面的“副作用”也没有 Haskell 这么多。这样一来，处理器的寄存器其实得不到有效的利用，从而大大增加了内存的访问。我为什么可以很确信的告诉你这个呢？因为我曾经设计了一个寄存器分配算法，于是开会的时候我问 GHC 的实现者们，你们会不会对一个新的寄存器分配算法感兴趣，我可以帮你们加到 GHC 里面。结果他们说，我们不需要，因为 Haskell 到处都是 thunk，根本就没什么机会用寄存器。



    所以，问太多问题，没法充分利用寄存器，这使得 Haskell 在效率上大打折扣。



    然后我们来看看，为什么惰性求值会跟并行计算的目标相冲突。这其实很明显，它的原因就在于“惰性求值”的定义。惰性求值说：“到需要我的时候再来计算我。”而并行计算说：“到需要你的时候，你最好已经被某个处理器算出来了。”所以你看到了，并行计算要求你“勤奋”，要求你事先做好准备。而惰性求值本来就是很“懒”，怎么可能没事找事，先把自己算出来呢？由于这个问题来自于“惰性求值”的定义，所以这是不可调和的矛盾。



    所以，惰性求值不管是在串行处理还是在并行处理的时候，都会带来效率上的大打折扣。它是一个很鸡肋的语言特征。



    虽然惰性求值不能给我们带来直接的益处，但它背后的理论思想却可以启发另外的设计。如果你想真的了解惰性求值的原理，可以先看一下我写的一个惰性求值的解释器。看看如何在不到 40 行代码之内，实现 Haskell 语义的精髓：



    https://github.com/yinwang0/lightsabers/blob/master/interp-lazy.rkt



    这段代码的工作原理，我以后再专门写文章讲解。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 对函数式语言的误解

 
 
 
 
    

    
 
     
  

      
   
对函数式语言的误解

    很早的时候，“函数式语言”对于我来说就是 Lisp，因为 Lisp 可以在程序的几乎任何位置定义函数，并且把它们作为值来传递（这叫做 first-class function）。后来有人告诉我，Lisp 其实不算是“函数式语言”，因为 Lisp 的函数并不“纯”（pure）。所谓“纯函数”的意思，就是像数学的函数一样，如果你给它同样的输入，它就给你同样的输出。然后你就发现在这种定义下，几乎所有程序语言里面常见的随机数函数（random），其实都不是“纯函数”。因为每一次调用 random()，你都会得到不同的随机数。



    在这种害怕自己所用的语言“不纯”的恐慌之下，我开始接触 Haskell，一种号称“纯函数式”的语言。Haskell 的社区喜欢在他们的概念里省掉“纯”这个字，把 Haskell 叫做“函数式语言”。他们喜欢“纠正”别人的概念。他们告诉人们，“不纯”的函数式语言，其实都不配叫做“函数式语言”。在他们的这种定义下，Lisp 这么老牌的函数式语言，居然都不能叫“函数式语言”了。但是看完这篇文章你就会发现，其实他们的这种定义是狭隘和错误的。



    在 Haskell 里面，你不能使用通常语言里面都有的赋值语句，比如 Pascal 里的 x:=1，C 和 Java 里的 x=1，或者 Scheme 里的 (set! x 1)，Common Lisp 里的 (setq x 1)。这样一来，你就不可能保留“状态”（state）。所谓“状态”，就是指“随机数种子”那样的东西，其实本质上就是“全局变量”。比如，在 C 语言里定义 random() 函数，你可以这么做：


int random()
{
  static int seed = 0;
  seed = next_random(seed);
  return seed;
}    



    这里的 seed 是一个“static 变量”，其本质就是一个全局变量，只不过这个全局变量只能被 random 这一个函数访问。每次调用 random()，它都会使用 next_random(seed) 生成下一个随机数，并且把 seed 的值更新为这个新的随机数。在 random() 的执行结束之后，seed 会一直保存这个值。下一次调用 random()，它就会根据 seed 保存的值，算出下一个随机数，然后再次更新 seed，如此继续。这就是为什么每一次调用 random()，你都会得到不同的随机数。



    可是在 Haskell 里面情况就很不一样了。由于 Haskell 不能保留状态，所以同一个“变量”在它作用域的任何位置都具有相同的值。每一个函数只要输入相同，就会输出同样的结果。所以在 Haskell 里面，你不能轻松的表达 random 这样的“不纯函数”。为了让 random 在每次调用得到不同的输出，你必须给它“不同的输入”。那怎么才能给它不同的输入呢？Haskell 采用的办法，就是把“种子”作为输入，然后返回两个值：新的随机数和新的种子，然后想办法把这个新的种子传递给下一次的 random 调用。所以 Haskell 的 random 的“线路”看起来像这个样子：


（旧种子）---&gt; （新随机数，新种子）



    现在问题来了。得到的这个新种子，必须被准确无误的传递到下一个使用 random 的地方，否则你就没法生成下一个随机数。因为没有地方可以让你“暂存”这个种子，所以为了把种子传递到下一个使用它的地方，你经常需要让种子“穿过”一系列的函数，才能到达目的地。种子经过的“路径”上的所有函数，必须增加一个参数（旧种子），并且增加一个返回值（新种子）。这就像是用一根吸管扎穿这个函数，两头通风，这样种子就可以不受干扰的通过。



    所以你看到了，为了达到“纯函数”的目标，我们需要做很多“管道工”的工作，这增加了程序的复杂性和工作量。如果我们可以把种子存放在一个全局变量里，到需要的时候才去取，那就根本不需要把它传来传去的。除 random() 之外的代码，都不需要知道种子的存在。



    为了减轻视觉负担和维护这些进进出出的“状态”，Haskell 引入了一种叫 monad 的概念。它的本质是使用类型系统的“重载”（overloading），把这些多出来的参数和返回值，掩盖在类型里面。这就像把乱七八糟的电线塞进了接线盒似的，虽然表面上看起来清爽了一些，底下的复杂性却是不可能消除的。有时候我很纳闷，在其它语言里易如反掌的事情，为什么到 Haskell 里面就变成了“研究性问题”，很多时候就是 monad 这东西在捣鬼。特别是当你有多个“状态”的时候，你就需要使用像 monad transformer 这样的东西。而 monad transformer 在本质上其实是一个丑陋的 hack，它并不能从根本上解决问题，却可以让你伤透脑筋也写不出来。有些人以为会用 monad 和 monad transformer 就说明他水平高，其实这根本就是自己跟自己过不去而已。



    当谈到 monad 的时候，我喜欢打这样一个比方：



    使用含有 monad 的“纯函数式语言”，就像生活在一个没有电磁波的世界。



    在这个世界里面没有收音机，没有手机，没有卫星电视，没有无线网，甚至没有光！这个世界里的所有东西都是“有线”的。你需要绞尽脑汁，把这些电线准确无误的通过特殊的“接线器”（monad）连接起来，才能让你的各种信息处理设备能够正常工作，才能让你自己能够看见东西。如果你想生活在这样的世界里的话，那就请继续使用 Haskell。



    其实要达到纯函数式语言的这种“纯”的效果，你根本不需要使用像 Haskell 这样完全排斥“赋值语句”的语言。你甚至不需要使用 Lisp 这样的“非纯”函数式语言。你完全可以用 C 语言，甚至汇编语言，达到同样的效果。



    我只举一个非常简单的例子，在 C 语言里面定义如下的函数。虽然函数体里面含有赋值语句，它却是一个真正意义上的“纯函数”：


int f(int x) {
    int y = 0;
    int z = 0;
    y = 2 * x;
    z = y + 1;
    return z / 3;
}    



    这是为什么呢？因为它计算的是数学函数 f(x) = (2x+1)/3 。你给它同样的输入，肯定会得到同样的输出。函数里虽然对 y 和 z 进行了赋值，但这种赋值都是“局部”的，它们不会留下“状态”。所以这个函数虽然使用了被“纯函数程序员”们唾弃的赋值语句，却仍然完全的符合“纯函数”的定义。



    如果你研究过编译器，就会理解其中的道理。因为这个函数里的 y 和 z，不过是函数的“数据流”里的一些“中间节点”，它们的用途是用来暂存一些“中间结果”。这些局部的赋值操作，跟函数调用时的“参数传递”没有本质的区别，它们不过都是把信息传送到指定的节点而已。如果你不相信的话，我现在就可以把这些赋值语句全都改写成函数调用：


int f(int x) {
    return g(2 * x);
}

int g(int y) {
    return h(y + 1);
}

int h(int z) {
    return z/3;
}    



    很显然，这两个 f 的定义是完全等价的，然而第二个定义却没有任何赋值语句。第一个函数里对 y 和 z 的“赋值语句”，被转换成了等价的“参数传递”。这两个程序如果经过我写的编译器，会生成一模一样的机器代码。所以如果你说赋值语句是错误的话，那么函数调用也应该是错误的了。那我们还要不要写程序了？



    盲目的排斥赋值语句，来自于对“纯函数”这个概念的片面理解。很多研究像 Haskell，ML 一类语言的专家，其实并不明白我上面讲的道理。他们仿佛觉得如果使用了赋值，函数就肯定不“纯”了似的。CMU 的教授 Robert Harper 就是这样一个极端。他在一篇博文里指出，人们不应该把程序里的“变量”叫做“变量”，因为它跟数学和逻辑学里所谓的“变量”不是一回事，它可以被赋值。然而，其果真如他所说的那样吗？如果你理解了我对上面的例子的分析，你就会发现其实程序里的“变量”，跟数学和逻辑学里面的“变量”相比，其实并没有本质的不同。



    程序里的变量甚至更加严格一些。如果你把数学看作一种程序语言的话，恐怕没有一本数学书可以编译通过。因为它们里面充满了变量名冲突，未定义变量，类型错误等程序设计的低级错误。你只需要注意概率论里表示随机数的大写变量（比如 X），就会发现数学所谓的“变量”其实是多么的不严谨。这变量 X 根本不需要被赋值，它自己身上就带“副作用”！实际上，90%以上的数学家都写不出像样的程序来。所以拿数学的“变量”来衡量程序语言的“变量”，其实是颠倒了。我们应该用程序的“变量”来衡量数学的“变量”，这样数学的语言才会有所改善。



    逻辑学家虽然有他们的价值，但他们并不是先知，并不总是对的。由于沉迷于对符号的热爱，他们经常看不到事物的本质。虽然他们理解很多符号公式和推理规则，但他们却经常不明白这些符号和推理规则，到底代表着自然界中的什么物体，所以有时候他们连最基本的问题都会搞错（比如他们有时候会混淆“全称量词”∀的作用域）。逻辑学家们的教条主义和崇古作风，也许就是图灵当年在 Church 手下做学生那么孤立，那么痛苦的原因。也就是这个图灵，在某种程度上超越了 Church，把一部分人从逻辑学的死板思维模式下解放了出来，变成了“计算机科学家”。当然其中某些计算机科学家堕入了另外一种极端，他们对逻辑学已有的精华一无所知，所以搞出一些完全没有原则的设计，然而这不是这篇文章的主题。



    所以综上所述，我们完全没有必要追求什么“纯函数式语言”，因为我们可以在不引起混淆的前提下使用赋值语句，而写出真正的“纯函数”来。可以自由的对变量进行赋值的语言，其实超越了通常的数理逻辑的表达能力。如果你不相信这一点，就请想一想，数理逻辑的公式有没有能力推断出明天的天气？为什么天气预报都是用程序算出来的，而不是用逻辑公式推出来的？所以我认为，程序其实在某种程度上已经成为比数理逻辑更加强大的逻辑。完全用数理逻辑的思维方式来对程序语言做出评价，其实是很片面的。



    说了这么多，对于“函数式语言”这一概念的误解，应该消除得差不多了。其实“函数式语言”唯一的要求，应该是能够在任意位置定义函数，并且能够把函数作为值传递，不管这函数是“纯”的还是“不纯”的。所以像 Lisp 和 ML 这样的语言，其实完全符合“函数式语言”这一称号。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 什么是“脚本语言”

 
 
 
 
    

    
 
     
  

      
   
什么是“脚本语言”

    很多人都会用一些“脚本语言”（scripting language），却很少有人真正的知道到底什么是脚本语言。很多人用 shell 写一些“脚本”来完成日常的任务，用 Perl 或者 sed 来处理一些文本文件，很多公司用“脚本”来跑它们的“build”（叫做 build script）。那么，到底什么是“脚本语言”与“非脚本语言”的区别呢？



    其实“脚本语言”与“非脚本语言”并没有语义上，或者执行方式上的区别。它们的区别只在于它们设计的初衷：脚本语言的设计，往往是作为一种临时的“补丁”。它的设计者并没有考虑把它作为一种“通用程序语言”，没有考虑用它构建大型的软件。这些设计者往往没有经过系统的训练，有些甚至连最基本的程序语言概念都没搞清楚。相反，“非脚本”的通用程序语言，往往由经过严格训练的专家甚至一个小组的专家设计，它们从一开头就考虑到了“通用性”，以及在大型工程中的可靠性和可扩展性。



    首先我们来看看“脚本”这个概念是如何产生的。使用 Unix 系统的人都会敲入一些命令，而命令貌似都是“一次性”或者“可抛弃”的。然而不久，人们就发现这些命令其实并不是那么的“一次性”，自己其实一直在重复的敲入类似的命令，所以有人就发明了“脚本”这东西。它的设计初衷是“批量式”的执行命令，你在一个文件里把命令都写进去，然后执行这个文件。可是不久人们就发现，这些命令行其实可以用更加聪明的方法构造，比如定义一些变量，或者根据系统类型的不同执行不同的命令。于是，人们为这脚本语言加入了变量，条件语句，数组，等等构造。“脚本语言”就这样产生了。



    然而人们却没有发现，其实他们根本就不需要脚本语言。因为脚本语言里面的这些结构，在任何一种“严肃”的程序语言（比如 Java，Scheme）里面，早就已经存在了，而且设计得更加完善。所以脚本语言往往是在重新发明轮子，甚至连轮子都设计不好。早期脚本语言的“优势”，也许只在于它不需要事先“编译”，它“调用程序”的时候，貌似可以少打几个字。脚本语言对于 C 这样的语言，也许有一定的价值。然而，如果跟 Scheme 或者 Java 这样的语言来比，这个优势就非常不明显了。比如，你完全可以想一个自动的办法，写了 Java 代码之后，先调用 Java 编译器，然后调用 JVM，最后删掉 class 文件。或者你可以选择一种有解释执行方式的“严肃语言”，比如 Scheme。



    很多人把 Scheme 误称为“脚本语言”，就是因为它像脚本语言一样可以解释执行，然而 Scheme 其实是比 C 和 Java 还要“严肃”的语言。Scheme 从一开头就被设计为一种“通用程序语言”，而不是用来进行某种单一简单的任务。Scheme 的设计者比Java 的设计者造诣更加深厚，所以他们对 Java 的一些设计错误看得非常清楚。像 Chez Scheme 这样的编译器，其实早就可以把 Scheme 编译成高效的机器代码。实际上，很多 Scheme 解释器也会进行一定程度的“编译”，有些编译为字节码，有些编译为机器代码，然后再执行。所以在这种情况下，通常人们所谓的“编译性语言”与“解释性语言”，几乎没有本质上的区别，因为你看到的“解释器”，不过是自动的先编译再执行。



    跟 Java 或者 Scheme 这样的语言截然不同，“脚本语言”往往意味着异常拙劣的设计，它的设计初衷往往是目光短浅的。这些语言里面充满了历史遗留下来的各种临时的 hack，几乎没有“原则”可言。Unix 的 shell（比如 bash，csh，……），一般都是这样的语言。Java 的设计也有很多问题，但也跟“脚本语言”有天壤之别。然而，在当今现实的工程项目中，脚本语言却占据了它们不该占有的地位。例如很多公司使用 shell 脚本来处理整个软件的“build”过程或者测试过程，其实是相当错误的决定。因为一旦这种 shell 脚本日益扩展，就变得非常难以控制。经常出现一些莫名其妙的问题，却很难找到问题的所在。Linux 使用 shell 脚本来管理很多启动项目，系统配置等等，其实也是一个历史遗留错误。所以，不要因为看到 Linux 用那么多 shell 脚本就认为 shell 语言是什么好东西。



    如果你在 shell 脚本里使用通常的程序设计技巧，比如函数等，那么写几百行的脚本还不至于到达不可收拾的地步。可是我发现，很多人头脑里清晰的程序设计原则，一遇到“写脚本”这样的任务就完全崩溃了似的，他们仿佛认为写脚本就是应该“松散”一些。很多平时写非常聪明的程序的人，到了需要处理“系统管理”任务的时候，就开始写一些 shell 脚本，或者 Perl 脚本。他们写这些脚本的时候，往往完全的忘记了程序设计的基本原则，例如“模块化”，“抽象”等等。他们大量的使用“环境变量”一类的东西来传递信息，他们忘记了使用函数，他们到处打一些临时性的补丁，只求当时不出问题就好。到后来，他们开始耗费大量的时间来处理脚本带来的麻烦，却始终没有发现问题的罪魁祸首，其实是他们错误的认为自己需要“脚本语言”，然后认为写脚本的时候就是应该随便一点。



    所以我认为脚本语言是一个祸害，它几乎永远是错误的决定。我们应该尽一切可能避免使用脚本语言。在没有办法的情况下（比如老板要求），也应该在脚本里面尽可能的使用通常的程序设计原则。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 Chez Scheme 的传说

 
 
 
 
    

    
 
     
  

      
   
Chez Scheme 的传说

    在上一篇博文的最后，我提到了 Lisp 编译器的问题。由于早期的 Lisp 编译器生成的代码效率普遍低下，成为了 Lisp 失败的主要原因之一。而现在的高性能 Lisp 编译器（比如 Chez Scheme），其实已经可以生成非常高效的代码，甚至可以匹敌 C 程序的速度。如果你看得到我脑子里的东西，就会明白这完全不是吹牛，而是科学的结论。我在这里介绍一下我写 Scheme 编译器的经历，也许你就会从根本上明白为什么我会对此这么自信。这里的介绍其实不止针对函数式语言，而且针对所有语言的编译器。



    编译器是一种神秘，有趣，又无聊的的程序。说它神秘，是因为只有非常少的人知道如何写出优秀的编译器。这些会写编译器的人，就像身怀绝技的武林高手一样神出鬼没。说它有趣，是因为编译器的技术里面含有大量的“哲学问题”和深刻的理论（比如 partial evaluation）。但为什么又说它无聊呢？因为你一旦掌握了编译器技术里面最精华的原理，就会发现其实说来说去就那么点东西。编译器代码里面的“创造性含量”其实非常低。里面有些固定的“模式”，几十年都不变。这是因为编译器只是一种“工具”，而不是最终的“目的”。它就像做菜的锅一样，只有屈指可数的那几种形状。设计应用程序才是程序员的最终目的。只有应用程序才能有无穷无尽的创造性。这就像厨师用同样的锅，却能做出无穷变化的菜肴来。然而，我并不是说普通程序员不应该学习写编译器。相反，编译器的原理是非常重要的知识。不理解编译原理的应用程序设计者，就像不理解菜锅组成原理的厨师。



    先来说一说为什么早期的 Lisp 编译器生成的代码效率低下吧。在函数式语言的早期，由于它比普通的语言多了一些表达力强大的构造（比如函数作为值传递），人们其实都不知道如何实现它的编译器。很多 Scheme 的编译器其实只是把 Scheme 编译成 C，然后再调用 C 语言的编译器。Haskell 的编译器 GHC 在早期也是这样的。而且由于 C 编译器生成的汇编代码不完全符合 Haskell 的需求，GHC 里面含有一个 Perl 脚本，专门用于调整这汇编代码的结构。这个 Perl 脚本，由于它的工作方式毫无原则，被叫做 evil mangler。现在这个东西已经被去掉了，但从它曾经的存在你可以看出，其实函数式编译器的技术在早期是相当混沌的。



    在我看来，早期 Lisp 编译器出现的主要问题，其实在于对编译的本质的理解，以及编译器与解释器的根本区别。解释器之所以大部分时候比编译器慢，是因为解释器“问太多的问题”。每当看到一个构造，解释器就会问：“这是一个整数吗？”“这是一个字符串吗？”“这是一个函数吗？”…… 然后根据问题的结果进行不同的处理。这些问题，在编译器的理论里面叫做“解释开销”（interpretive overhead）。编译的本质，其实就是在程序运行之前进行“静态分析”，试图一劳永逸的回答这些问题。于是编译后的代码根本不问这种问题，它直接就知道那个位置肯定会出现什么构造，应该做什么事，于是它就直接去做了。早期的 Lisp 编译器，以及现在的很多 Scheme 编译器出现的问题其实在于，它们并没有干净的消除这些问题，甚至根本没有消除这些问题。



    当我最早学习 Scheme 语言的时候，我发现 Scheme 有太多的“实现”：PLT Scheme（现在叫 Racket）, MIT Scheme, Scheme 48, Bigloo, Chicken, Gambit, Guile, ... 让人搞不清楚哪一个更好。有些 Scheme 实现显得高级一些，但实际用起来总是感觉不放心，因为你心里总想着，这代码编译出来到底能不能跟 C 语言代码比？这也是我后来开始使用 Common Lisp 的原因，因为 Common Lisp 似乎有挺多高效的编译器（CMUCL，Lispworks，Allegro 等等）。



    直到有一天，我发现了 Chez Scheme，它改变了我对 Scheme 编译器，以至于整个编译器概念的理解。当时我只下载了 Chez Scheme 的免费版本，叫做 Petite。Petite 与正式版 Chez Scheme 的区别是，它不输出二进制代码，所以你不能把编译后的代码拿去销售。另外出于商业目的，Petite 的出错信息非常的“简约”，以至于有时候你不得不用其它的 Scheme 实现，才能找到 bug 的位置。但是一运行就见分晓，Petite 被作为一个“解释器”直接运行 Scheme 代码，比其他的 Scheme 实现编译后的代码还要快很多倍。



    Chez Scheme 导致了我命运的改变，我怎么也没有想到，自己最终会见到它的作者 R. Kent Dybvig，并且成为他的学生。我只能说也许一切都是天意吧。第一次见到 Kent 的时候，他安静的对我说，你应该拥有自己的代码，将来有一天，你会发现它的价值。



    也就是这个 Kent，单枪匹马的创造了 Chez Scheme，世界上唯一的商业 Scheme 编译器，并且为此成立了自己的公司（Cadence Research Systems）。Chez Scheme 价格不菲，而且不明码实价，它的价格跟项目的大小和公司的规模成正比。有些大公司花重金购买 Chez Scheme 用于一些核心的项目。其中有些公司为了保证这编译器的安全，又花了好几倍的价钱买下了它的源代码。Kent 的公司只有他一个人，不用操心管理，也不用操心销售。所以他过的非常舒服，基本是一个不愁吃穿，不问世事的人。



    Kent 是我一生中见过的最神秘，最酷的人。他几乎从来不表扬任何人，但也不贬低任何人。从冷漠的言语之中，你仿佛感觉他并不是这个世界上的人。任何人的喜怒与哀乐，傲慢与偏见，蔑视与奉承，全都不能引起他情绪的变化。他的心里有许许多多的秘密，你需要一些技巧才能套出他的真言。他很少发表论文，却把别人的论文全都看得很透。没有人知道他的核心技术，他也从来不在乎别人是否了解他的水平。最让人惊奇的是，没有人知道他叫什么名字！他的全名叫 R. Kent Dybvig，那么 R. 就应该是他的 first name。然而，却从来没有人知道那个 R. 是哪一个名字的简写，所以大家只好叫他的 middle name，Kent。他的照片从来不放在网上，如果你真想知道他长得什么样，我在网上找到一个跟他长得非常相似的人的照片：



    



    Chez Scheme 生成的“目标代码”效率之高，我还没有见到任何其它 Scheme 编译器可以与之匹敌。而它的“编译速度”之快，没有任何语言的任何编译器可以相提并论（注意我去掉了“Scheme”这个限定词）。Chez Scheme 可以在 5 秒钟之内完成从头到尾的自我编译。想想编译 GCC 或者 GHC 需要多少时间，你就明白差距了。



    另外值得一提的是，Chez Scheme 从头到尾都是 Kent 一个人的作品。它的工作原理是从 Scheme 源程序一直编译到机器代码，而不依赖任何其他语言的编译器。它甚至不依赖第三方的汇编器，所有三种体系构架（Intel, ARM, SPARC）的汇编器，都是 Kent 自己写的。为什么这样做呢？因为几乎没有其它人的编译器代码能够达到他的标准。连 Intel 自己给自己的处理器写的汇编器，都不能满足他的要求。



    如果你上了 Kent 的课，再来看看普通的编译器书籍（比如有名的 Dragon Book），或者 LLVM 的代码，你就会发现 Kent 的水平其实远在这些知名的大牛之上。我为什么可以这么说呢？因为如果你的水平不如这些人的话，你自己都会对这种判断产生怀疑。而如果你超过了别人，他们的一言一行，他们的每一个错误，都像是处于你的显微镜底下，看得一清二楚。这就是为什么有一天我拿起 Dragon Book，感觉它变得那么的幼稚。而其实并不是它变幼稚了，而是我变成熟了。实话实说吧，在编译器这个领域，我觉得 Kent 很有可能就是世界的 No.1。



    如果你不了解 Scheme 的编译器里面有什么东西，也许就会轻视它的难度。Scheme 是比 C 语言高级很多的语言，所以它的编译器需要做比 C 语言的编译器多很多的事情。在 Kent 的编译器课程的前半段，我们其实本质上是在实现一个 C 语言的编译器，把一种基于“S表达式”的中间语言，编译为 X64 汇编代码。在后半学期的课程中，我们才加入了各种 Scheme 的先进功能，比如函数作为值（需要进行 closure conversion 以及 closure 优化），尾递归优化（tail-call optimization），等等。另外，我还自己为它加入了一种非常漂亮的技术，叫做 online partial evaluation。这种技术可以在一个 pass 就完成普通编译器需要好几个 pass 才能完成的优化。



    在这些先进的优化技术之下，几乎所有的冗余代码都会被编译器消除掉。这些优化的智能程度，在很多方面拥有人类思维没法达到的准确性和深度。如果你的程序没有使用到 Scheme 特有的功能，那么生成的目标代码就会跟 C 语言编译后的代码没有什么两样。比如，如果你的代码没有把函数作为值传递，或者你的函数里面没有“自由变量”，或者你的函数里虽然有自由变量，但是你却没法在函数外部改变它的值，那么生成的代码里面就不会含有“闭包”，也就不会产生多余的内存数据交换。你有时甚至会得到比 C 程序编译之后更好的代码，因为我们的“后端”编译器其实比 GCC，LLVM 之类的 C 编译器先进。



    Kent 的课程编译器有很好的结构，它被叫做“nanopass 编译器构架”。它的每一个 pass 只做很小的一件事情，然后这些 pass 被串联起来，形成一个完整的编译器。编译的过程，就是将输入程序经过一系列的变换之后，转化为机器代码。你也许发现了，这在本质上跟 LLVM 的构架是一样的。但是我可以告诉你，我们的课程编译器比 LLVM 干净利落许多，处于远远领先的地位。每一节课，我们都学会一个 pass。每一个讲义，都非常精确的告诉你需要干什么。每一次的作业，提交的时候都会经过上百个测试（当然 Kent 不可能把 Chez Scheme 的测试都给我们），如果没有通过就会被拒绝接受。这些测试也可以下载，用于自己的调试。有趣的是，每一次作业我们都需要提交一些自己写的新测试，目的是用于“破坏”别人的编译器。所以我们每次都会想出很刁钻的输入代码，让同学的日子不好过。当然是开玩笑的，这种做法其实大大的提高了我们对编译器测试的理解和兴趣，以及同学之间的友谊。这比起我曾经在 Cornell 选过（然后 drop 掉）的编译器课程，真是天壤之别。



    在课程的最后，我们做出了一个完整的编译器，它可以把 Scheme 最关键的子集编译到 X64 汇编代码，然后通过 GNU 的汇编器转化成机器代码。在最后的一节课，Kent 对我们的学期做了一个令人难忘的总结。他说：“你们现在写出的这个编译器里面含有很多先进的技术。也许过一段时间再回头看这段代码，你们才会发现它的价值。如果你们觉得自己已经成为了编译器的专家，那我就告诉你们，你们提交的最快的编译器，编译速度比 Chez Scheme 慢了 700 倍。但是不要灰心，我告诉你们哪些地方可以改进……”



    只有极少数的人见到过 Chez Scheme 的源代码，我也没有看见过。但是见到过它的人告诉我，Chez Scheme 里面其实只有很少几个 pass，而不是像我们的课程编译器有 50 个左右的 pass，这节省了很多用于“遍历”代码树所需要的时间。Chez Scheme 只使用了一些非常简单的算法，没有使用论文里很炫很复杂的方法，这也是它速度快的原因之一。比如它的寄存器分配，没有使用通常的“图着色”（graph coloring）方法，而是使用非常简单的一种类似 linear scan 的算法，生成的代码效率却更高。另外，Scheme 使用“S表达式”作为它的语法，使得“语法分析”的速度非常之快。其它语言由于使用了复杂的语法，挺大一部分编译时间其实花在了语法分析上面。



    所以实际上 Chez Scheme 早就有了超越世人的技术，Kent 却很少为它们发表论文。这是因为他自私吗？应该不是。他已经通过他的课程给予了我们那么宝贵的礼物，我们又怎能要求更多？所以对于更深入的内容，我都是自己摸索出解决方案，再去套他的口气，看他有没有更好的想法。于是有时候我会很惊讶的发现他的一些非常透彻的见解。比如有一天我问他，为什么编译器需要进行寄存器分配？为什么需要寄存器？我觉得 Knuth 设计的 MMIX 处理器里的“寄存器环”，也许能够从根本上避免“寄存器分配”这问题。他听了之后不动声色的说，MMIX 的寄存器环（以及 SPARC 的寄存器窗口）其实是有问题的，当函数递归调用达到一定的深度之后，寄存器环里有再多寄存器都会被用光，到时候就会出现大量的寄存器与内存之间的数据交换，而被“压栈”之后的寄存器，并不会得到有效地“再利用”。于是我才发现，他不但早已了解 MMIX 的设计，而且看透了它的本质。



    有趣的是在课程进行之中的时候，我发现自己有些突发灵感的做法，其实已经超越了 Chez Scheme，以至于在某些 pass 会生成比它还要高效的代码，然而我的编译器代码却比它的还要短小（当然绝大部分时间我的代码不如 Chez Scheme）。于是我就隐约的发现，Kent 有时候会悄悄的花时间看我的作业，想搞明白我是怎么做的，但却不想让我知道。有一天开会的时候 Kent 没有来，他的编译器课程助教 Andy 对我说：“Kent 还在对你写的代码进行一些侦探工作……” 从任何人那里得到启发，吸收并且融入到自己的能力里面，也许就是 Kent 练就如此盖世神功的秘诀吧。



    我想，这篇文章就该到此结束了。写这些东西的目的，其实只是树立人们对于函数式语言编译器的信心。它们有些其实比 C 和 C++ 之类语言的编译器高明很多。我没有时间也没有精力去讲述这编译器里面的细节，因为它实在是非常困难，却又非常优雅的程序。如果你有兴趣的话，可以看看我最后的代码。由于版权原因，有些辅助部件我不能放在网上，所以你并不能运行它，只能看一个大概的形状。如果你需要一个 Scheme 版本用于学习的话，Chez Scheme 有一个免费的版本叫做 Petite Chez Scheme，可以免费下载。因为 Petite 的出错信息非常不友好，所以我也推荐 Racket 作为替补。不过你需要注意的是，Racket 的速度比起 Chez Scheme 是天壤之别。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 Lisp 已死，Lisp 万岁！

 
 
 
 
    

    
 
     
  

      
   
Lisp 已死，Lisp 万岁！

    有一句古话，叫做“国王已死，国王万岁！”它的意思是，老国王已经死去，国王的儿子现在继位。这句话的幽默，就在于这两个“国王”其实指的不是同一个人，而你咋一看还以为它自相矛盾。今天我的话题仿效了这句话，叫做“Lisp 已死，Lisp 万岁！”希望到最后你会明白这是什么意思。



    首先，我想总结一下 Lisp 的优点。你也许已经知道，Lisp 身上最重要的一些优点，其实已经“遗传”到了几乎每种流行的语言身上（Java，C#，JavaScript，Python, Ruby，Haskell，……）。由于我已经在其他博文里详细的叙述过其中一些，所以现在只把这些 Lisp 的优点简单列出来（关键部分加了链接）：




    Lisp 的语法是世界上最精炼，最美观，也是语法分析起来最高效的语法。这是 Lisp 独一无二的，其他语言都没有的优点。有些人喜欢设计看起来很炫的语法，其实都是自找麻烦。为什么这么说呢，请参考这篇《谈语法》。


    Lisp 是第一个可以在程序的任何位置定义函数，并且可以把函数作为值传递的语言。这样的设计使得它的表达能力非常强大。这种理念被 Python，JavaScript，Ruby 等语言所借鉴。


    Lisp 有世界上最强大的宏系统（macro system）。这种宏系统的表达力几乎达到了理论所允许的极限。如果你只见过 C 语言的“宏”，那我可以告诉你它是完全没法跟 Lisp 的宏系统相提并论的。


    Lisp 是世界上第一个使用垃圾回收（garbage collection）的语言。这种超前的理念，后来被 Java，C# 等语言借鉴。





    想不到吧，现代语言的很多优点，其实都是来自于 Lisp — 世界上第二古老的程序语言。所以有人才会说，每一种现代语言都在朝着 Lisp 的方向“进化”。如果你相信了这话，也许就会疑惑，为什么 Lisp 今天没有成为主流，为什么 Lisp Machine 会被 Unix 打败。其实除了商业原因之外，还有技术上的问题。



    早期的 Lisp 其实普遍存在一个非常严重的问题：它使用 dynamic scoping。所谓 dynamic scoping 就是说，如果你的函数定义里面有“自由变量”，那么这个自由变量的值，会随着函数的“调用位置”的不同而发生变化。



    比如下面我定义一个函数 f，它接受一个参数 y，然后返回 x 和 y 的积。


(setq f 
      (let ((x 1)) 
 (lambda (y) (* x y))))



    这里 x 对于函数 (lambda (y) (* x y)) 来说是个“自由变量”（free variable），因为它不是它的参数。



    看着这段代码，你会很自然的认为，因为 x 的值是 1，那么 f 被调用的时候，结果应该等于 (* 1 y)，也就是说应该等于 y 的值。可是这在 dynamic scoping 的语言里结果如何呢？我们来看看吧。



    （你可以在 emacs 里面试验以下的结果，因为 Emacs Lisp 使用的就是 dynamic scoping。）



    如果我们在函数调用的外层定义一个 x，值为 2：


(let ((x 2))
  (funcall f 2))



    因为这个 x 跟 f 定义处的 x 的作用域不同，所以它们不应该互相干扰。所以我们应该得到 2。可是，这段代码返回的结果却为 4。



    再来。我们另外定义一个 x，值为 3：


(let ((x 3))
  (funcall f 2))



    我们的期望值还是 2，可是结果却是 6。



    再来。如果我们直接调用：


(funcall f 2)



    你想这次总该得到 2 了吧？结果，出错了：


Debugger entered--Lisp error: (void-variable x)
  (* x y)
  (lambda (y) (* x y))(2)
  funcall((lambda (y) (* x y)) 2)
  eval_r((funcall f 2) nil)
  eval-last-sexp-1(nil)
  eval-last-sexp(nil)
  call-interactively(eval-last-sexp nil nil)



    看到问题了吗？f 的行为，随着调用位置的一个“名叫 x”的变量的值而发生变化。而这个 x，跟 f 定义处的 x 其实根本就不是同一个变量，它们只不过名字相同而已。这会导致非常难以发现的错误，也就是早期的 Lisp 最令人头痛的地方。我的老师 Dan Friedman 当年就为此痛苦了很多年，直到 Scheme 的出现，他才欢呼道：“终于有人把它给做对了！”



    （附带说一句，Scheme 不是 Dan Friedman 发明的，而是 Guy Steele 和 Gerald Sussman。然而，Friedman 对程序语言的本质理解，其实超越了 Lisp 的范畴，并且对 Scheme 的后期设计做出了重要的贡献。以至于 Sussman 在 Friedman 的 60 大寿时发表演说，戏称自己比起 Friedman 来，“只是 Scheme 的用户”。）



    好在现在的大部分语言其实已经吸取了这个教训，所以你不再会遇到这种让人发疯的痛苦。不管是 Scheme, Common Lisp, Haskell, OCaml, Python, JavaScript…… 都不使用 dynamic scoping。



    那现在也许你了解了，什么是让人深恶痛绝的 dynamic scoping。如果我告诉你，Lisp Machine 所使用的语言 Lisp Machine Lisp 使用的也是 dynamic scoping，你也许就明白了为什么 Lisp Machine 会失败。因为它跟现在的 Common Lisp 和 Scheme，真的是天壤之别。我宁愿写 C++，Java 或者 Python，也不愿意写 Lisp Machine Lisp 或者 Emacs Lisp。



    话说回来，为什么早期的 Lisp 会使用 dynamic scoping 呢？其实这根本就不是一个有意的“设计”，而是一个无意的“巧合”。你几乎什么都不用做，它就成那个样子了。这不是开玩笑，如果你在 emacs 里面显示 f 的值，它会打印出：


'(lambda (y) (* x y))



    这说明 f 的值其实是一个 S 表达式，而不是像 Scheme 一样的“闭包”（closure）。原来，Emacs Lisp 直接把函数定义处的 S 表达式 ‘(lambda (y) (* x y)) 作为了函数的“值”，这是一种很幼稚的做法。如果你是第一次实现函数式语言的新手，很有可能就会这样做。Lisp 的设计者当年也是这样的情况。



    简单倒是简单，麻烦事接着就来了。调用 f 的时候，比如 (funcall f 2)，y 的值当然来自参数 2，可是 x 的值是多少呢？答案是：不知道！不知道怎么办？到“外层环境”去找呗，看到哪个就用哪个，看不到就报错。所以你就看到了之前出现的现象，函数的行为随着一个完全无关的变量而变化。如果你单独调用 (funcall f 2) 就会因为找不到 x 的值而出错。



    那么正确的实现函数的做法是什么呢？是制造“闭包”(closure)。这也就是 Scheme，Common Lisp 以及 Python，C# 的做法。在函数定义被解释或者编译的时候，当时的自由变量（比如 x）的值，会跟函数的代码绑在一起，被放进一种叫做“闭包”的结构里。比如上面的函数，就可以表示成这个样子：(Closure '(lambda (y) (* x y)) '((x . 1)))。



    在这里我用 (Closure ...) 表示一个“结构”（就像 C 语言的 struct）。它的第一个部分，是这个函数的定义。第二个部分是 '((x . 1))，它是一个“环境”，其实就是一个从变量到值的映射（map）。利用这个映射，我们记住函数定义处的那个 x 的值，而不是在调用的时候才去瞎找。



    我不想在这里深入细节。如果你对实现语言感兴趣的话，可以参考我的另一篇博文《怎样写一个解释器》。它教你如何实现一个正确的，没有以上毛病的解释器。



    与 dynamic scoping 相对的就是“lexical scoping”。我刚才告诉你的闭包，就是 lexical scoping 的实现方法。第一个实现 lexical scoping 的语言，其实不是 Lisp 家族的，而是 Algol 60。“Algol”之所以叫这名字，是因为它的设计初衷是用来实现算法（algorithm）。其实 Algol 比起 Lisp 有很多不足，但在 lexical scoping 这一点上它却做对了。Scheme 从 Algol 60 身上学到了 lexical scoping，成为了第一个使用 lexical scoping 的“Lisp 方言”。9 年之后，Lisp 家族的“集大成者” Common Lisp 诞生了，它也采用了 lexical scoping。看来英雄所见略同。



    你也许发现了，Lisp 其实不是一种语言，而是很多种语言。这些被人叫做“Lisp 家族”的语言，其实共同点只是它们的“语法”：它们都是基于 S 表达式。如果你因此对它们同样赞美的话，那么你赞美的其实只是 S 表达式，而不是这些语言本身。因为一个语言的本质应该是由它的语义决定的，而跟语法没有很大关系。你甚至可以给同一种语言设计多种不同的语法，而不改变这语言的本质。比如，我曾经给 TeX 设计了 Lisp 的语法，我把它叫做 SchTeX（Scheme + TeX）。SchTeX 的文件看起来是这个样子：


(documentclass article (11pt))
(document
  (abstract (...))
  (section (First Section)
      ... )
  (section (Second Section)
      ... )
)



    很明显，虽然这看起来像是 Scheme，本质却仍然是 TeX。



    所以，因为 Scheme 的语法使用 S 表达式，就把 Scheme 叫做 Lisp 的“方言”，其实是不大准确的做法。Scheme 和 Emacs Lisp，Common Lisp 其实是三种不同的语言。Racket 曾经叫做 PLT Scheme，但是它跟 Scheme 的区别日益增加，以至于现在 PLT 把它改名叫 Racket。这是有他们的道理的。



    所以，你也许明白了为什么这篇文章的标题叫做“Lisp 已死，Lisp 万岁！” 因为这句话里面的两个 “Lisp”其实是完全不同的语言。“Lisp 已死”，其实是说 Lisp Machine Lisp 这样的 Lisp，由于严重的设计问题，已经死去。而“Lisp 万岁”，是说像 Scheme，Common Lisp 这样的 Lisp，还会继续存在。它们先进于其它语言的地方，也会更多的被借鉴，被发扬广大。



    （其实老 Lisp 的死去还有另外一个重要的原因，那就是因为早期的 Lisp 编译器生成的代码效率非常低下。这个问题我留到下一篇博文再讲。）


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 论对东西的崇拜

 
 
 
 
    

    
 
     
  

      
   
论对东西的崇拜

    在之前的几篇博文里面，我多次提到了 Lisp，它相对于其它语言的优势，以及 Lisp Machine 相对于 Unix 的优点。于是有人来信请教我如何学习 Lisp，也有人问我为什么 Lisp Machine 没有“流行”起来。我感觉到了他们言语中对 Lisp 的敬畏和好奇心，但也感觉到了一些隐含的怀疑。



    这是一种复杂的感觉，仿佛我在原始人的部落兜售一些原子能小玩具，却被人当成了来自天外的传教士。敬畏和奉承，并不能引起我的好感。怀疑和嘲讽，也不能引起我的不平。当我看到有人说“别听他误导群众，学那些语言是找不到工作的”的时候，我心里完全没有愤怒，也没有鄙视，我也没必要说服他。我只是微笑着摇摇头，对自己说：可怜而可笑的人。



    不明白为什么，当我提到某个东西相对于另一个东西的优点的时候，我总是被人认为是在“推崇”某个东西，或者被人称为是它的“狂热分子”。现在显然已经有人认为我在推崇 Lisp 了，甚至在某个地方看到有人称我为“国内三大 Lisp 狂人之一”。他们仿佛觉得我推荐一个东西，就是想让他们完全的拥抱这个东西，而丢弃自己已经有的东西。而“支持”这另一个东西的人，也往往会产生敌视情绪。



    很多人都不明白，每个东西都有它好的方面，也有它不好的方面。我推荐的只是 Lisp 好的方面，不好的方面我心里清楚，但是还没有机会讲。这些人显然已经在下意识里把“东西”当成了人。有人说“爱一个人就要爱她（他）的全部”，这是一种很无奈的说法，因为你没有能力把一个人分解成你喜欢的和不喜欢的两部分，然后重新组装成你的梦中情人。可是东西却不一样。因为东西是人造出来的，所以你可以把它们大卸八块，然后挑出你喜欢的部分。



    所以我可以很清楚的告诉你，我并不推崇 Lisp，我也不是 Lisp 狂人，它只是我的小玩意儿之一。这个非常精巧的小玩意儿，包含了很多其它东西身上没有的优点。人们都说忘记历史就等于毁灭未来。如果 Java 没有从 Lisp 身上学会“垃圾回收”，C# 没有从 Lisp 身上学会 lambda，那么我们今天也许还在为 segfault 而烦恼，也许会继续使用没必要的 design patterns。如果你了解一点历史就会发现，今天非常流行的 JavaScript，其实不过是一个“没能正确实现的 Scheme”。所以 Lisp 的精髓，其实正在越来越多的渗透到常用的语言里面。



    很多人没有设计程序语言的能力，所以他们把程序语言，操作系统一类的东西当成是不可改变的，凌驾于自己之上的。相比之下，我受到的训练却给了我设计和实现几乎任何语言的能力。我知道它们的优点和弱点，我有能力把它们大卸八十块，再组装还原。我有能力改变其中我不喜欢的地方，或者增加我觉得有必要的功能。当我谈论某个东西比另一个好的地方，总有人以为我在“抱怨”，说：“既然如此，那为什么你说的这个好东西被打败了？”他不明白，其实我只是在“分析”。我希望从各个东西里面提取出好的部分，然后想办法把它们都注入到一个新的东西里面。我也希望吸取前人教训，免得重犯这些东西里面的设计错误。



    如果在见识短浅的人们心目中，Paul Graham 和 Peter Norvig 算是“Lisp 牛人”的话，那么 Dan Friedman 和 R. Kent Dybvig 就应该被称为 “Lisp 天外来客”了。我不敢大言不惭的说我超过了恩师们，但我除了学到他们的真功夫之外，还偷学了一些他们不屑一顾的“旁门左道”。所以我经常能看到他们看不到的东西，我知道他们的弱点。他们对于 Lisp 的热爱，防止了他们看到它的一些缺点，但这些对于我却非常的清晰明了。然而也是因为他们对其它语言的不屑，才让我逐步的理解了，我曾经认为是优点的某些语言特征（比如 Hindley-Milner 类型系统），其实是缺点。



    所以，我其实并不是那么热心的希望有更多的人用 Lisp，Haskell 或者其它什么语言。我不会，也没那工夫去分享自己的秘诀。我没有责任，也没有能力去拯救世界。这是一种找到巨大宝藏的感觉，我蹲在一堆堆的财宝上休养生息。我知道世界上即使没有了我，太阳明天照样会升起。我为什么要那么热心的让别人也知道如何进入这个宝藏？我不是一个特别自私的人，但我也不需要推销什么。这就像我介绍了我的“减肥成功经验”，你觉得太辛苦，偏要去买那些吹得神乎其神的减肥药。我有什么动机来说服你呢？又不是我身上的肥肉。



    推崇一个东西，为一个东西狂热，这些感情都在我身上存在过。也许它们确实给我带来了一些益处，让我很快的学会了一些东西。但是这些感情的存在，其实也显示了一个人的弱小。当一个人没有办法控制一个东西的时候，他就会对它产生“崇拜”的心理，这就像所有的宗教和迷信一样。当人们处于自然灾害的凌威之下，没有能力掌握自己命运的时候，他们就对神和超自然的力量产生了崇拜。这是一种心灵的慰藉，至少有上帝或者观音菩萨，可以聆听他们的心声，可以给予他们度过灾难的勇气，但它同时也显示出人的无助和自卑。这种无助和自卑，也引发了偏激的宗教心理，因为他们害怕自己的“保护神”被别人的“保护神”所压倒，以至于让自己受制于他人。这是一种愚昧和卑劣的感情。



    可是当你拥有了强大的力量，可以不再畏惧的时候，这种崇拜，以及由于崇拜所带来的偏激心理，就渐渐的消亡了。这就像是一个身怀绝世武功的人，他完全没必要让别人都相信他是高手。因为他知道，自己在谈笑之间，就可以让樯橹灰飞烟灭。于是，他自得其乐，对别人表现出的任何感情，都变得淡漠和无动于衷。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 “解决问题”与“消灭问题”

 
 
 
 
    

    
 
     
  

      
   
“解决问题”与“消灭问题”

    一直以来，人们都重视“解决问题”的能力，却忽视了另一种重要的能力：“消灭问题”的能力。各种各样的竞赛，分数和排名，让很多人从小就片面的认为，能“解决问题”的人，就是最厉害的人。拿到一个问题就埋头求解，很少考虑这问题到底有什么意义。这种呆板的思维方式，不仅存在于低级的“应试”和“解题”过程，而且蔓延到了很多艰深的研究领域。



    如果你仔细观察就会发现，很多“难题”，其实是“人造”出来的，而不是“必然”的。它们的存在，往往是由于一些早期的“设计错误”。人造的东西里面往往有设计上的错误，如果你把这些东西看成是不可改变的东西，那你就会遇到很多不必要的问题。打个比方，如果当初轮子被设计成方形的，而没有人质疑这样做的“必要性”，那么也许人类早就因为“能源问题”而灭绝了。有点夸张，但它却形象的说明了，为什么错误的设计会导致不必要的难题。



    其实如果我们转换一下思路，或者改变一下“设计”，很多问题就可以不解自消。这就是我所谓的“消灭问题”的能力。这种“消灭问题”的能力，表面上容易其实难，有点像脑经急转弯，所以经常受到人们的忽视。看到一个问题轻而易举的消失了，总有人满不在乎的说：“这个容易。我也能做到。” 可问题就在于，你怎么没想到？说这种话的人，完全没有意识到，他们的思维里面其实缺少了非常重要的东西。由于喜欢炫耀自己的“头脑暴力”，他们经常解决（甚至制造）错误的问题。



    所以，在解决问题之前，我们应该先问自己三个问题：




    这问题是否真的“存在”？



    也许你已经看出来了，很多问题，即使众人都认为它存在，其实也可能是不存在的。在这一点上不能相信任何人或者机构，不管他有多么的“权威”。就像小马过河的道理，只有靠自己的实践。


    如果解决了这个问题，会给我和他人带来什么实际的好处？



    世界上不存在“永远”，也不存在“无穷”。如果一个“科学算命家”花100年才能算出我的未来，那我还不如坐等“未来”的到来。所有的人，都不过是来这世界上做短暂的旅行。所以，问题的答案，应该能在合理的时间之内给人带来实际的好处。


    这问题是否可以在简单的改变某些“设计”或者“思路”之后，不复存在？



    很多问题的“存在”，其实是因为人们的“思维定势”。他们看不到问题的“根源”和因果关系，而是经常在下意识里假定某种“先决条件”（A）的存在，然后坚定不移的相信由此“导致”的问题（B）的存在，如下图：


     A -----&gt; B





    然后，他们开始呆头呆脑的解决 B，完全忘记了质疑 A 存在的必要性。他们从来没有想过，如何消除 A，或者切断 A 与 B 之间的关系。他们没有发现，一旦这前提 A 不复存在，问题 B 就可以不解自消。



    对这一点，我想起一个有趣的故事。有人在饭桌上给大家出了一道“难题”，要他们把自己盘子里的鸡蛋立起来，最后只有一个人做到了。这个人把蛋壳打破了。所有其他人都没有想到这个做法，却说他“犯规”。可是应该检讨的其实应该是他们自己，因为出题的人根本没有说不能打破蛋壳，他们却对此做出了错误的假设。



    我经常发现计算机科学界存在这样的问题。研究了几十年，结果到最后才发现，辛辛苦苦解决的问题，其实包含了错误的假设。如果换一个角度来看，或者稍微改一改设计，这问题就基本不存在了。其中一个例子，就是编译器里面的“语法分析”（parsing）问题。



    语法分析成为一个问题的原因，就在于很多人错误的以为程序语言应该有复杂的语法。正是这些复杂的语法，造成了这个问题研究了很多年，仍然没有一个很好的解决方案。可是一旦语法设计被简化（比如像 Lisp 那样），语法分析就变成一个非常容易的问题。实际上计算机系统（比如 Unix）里的很多问题都是由此引发的，想要利用字符串来进行数据交换，却又设计了一些非常不方便的“数据格式”。简单的语法设计，会让这些问题一并消失掉。关于这个问题，我不想重复发文，细节请见另一篇博文《谈语法)》。



    爱因斯坦说“想象力比知识更重要”，也许就是这个道理。没有想象力的人经常钻牛角尖，走死胡同，忘记了自己其实还有另外的路可走。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 程序语言的常见设计错误(1) - 片面追求短小

 
 
 
 
    

    
 
     
  

      
   
程序语言的常见设计错误(1) - 片面追求短小

    我经常以自己写“非常短小”的代码为豪。有一些人听了之后很赞赏，然后说他也很喜欢写短小的代码，接着就开始说 C 语言其实有很多巧妙的设计，可以让代码变得非常短小。然后我才发现，这些人所谓的“短小”跟我所说的“短小”完全不是一回事。



    我的程序的“短小”是建立在语义明确，概念清晰的基础上的。在此基础上，我力求去掉冗余的，绕弯子的，混淆的代码，让程序更加直接，更加高效的表达我心中设想的“模型”。这是一种在概念级别的优化，而程序的短小精悍只是它的一种“表象”。就像是整理一团电线，并不是把它们揉成一团然后塞进一个盒子里就好。这样的做法只会给你以后的工作带来更大的麻烦，而且还有安全隐患。



    所以我的这种短小往往是在语义和逻辑 层面的，而不是在语法上死抠几行代码。我绝不会为了程序显得短小而让它变得难以理解或者容易出错。相反，很多其它人所追求的短小，却是盲目的而没有原则的。在很多时候这些小伎俩都只是在语法层面，比如想办法把两行代码“搓”成一行。可以说，这种“片面追求短小”的错误倾向，造就了一批语言设计上的错误，以及一批“擅长于”使用这些错误的程序员。



    现在我举几个简单的“片面追求短小”的语言设计。


自增减操作


    很多语言里都有 i++ 和 ++i 这两个“自增”操作和 i-- 和 --i 这两个“自减”操作（下文合称“自增减操作”。很多人喜欢在代码里使用自增减操作，因为这样可以“节省一行代码”。殊不知，节省掉的那区区几行代码比起由此带来的混淆和错误，其实是九牛之一毛。



    从理论上讲，自增减操作本身就是错误的设计。因为它们把对变量的“读”和“写”两种根本不同的操作，毫无原则的合并在一起。这种对读写操作的混淆不清，带来了非常难以发现的错误。相反，一种等价的，“笨”一点的写法，i = i + 1，不但更易理解，而且在逻辑上更加清晰。



    有些人很在乎 i++ 与 ++i 的区别，去追究 (i++) + (++i) 这类表达式的含义，追究 i++ 与 ++i 谁的效率更高。这些其实都是徒劳的。比如，i++ 与 ++i 的效率差别，其实来自于早期 C 编译器的愚蠢。因为 i++ 需要在增加之后返回 i 原来的值，所以它其实被编译为：


(tmp = i, i = i + 1, tmp)



    但是在


for (int i = 0; i &lt; max; i++)



    这样的语句中，其实你并不需要在 i++ 之后得到它自增前的值。所以有人说，在这里应该用 ++i 而不是 i++，否则你就会浪费一次对中间变量 tmp 的赋值。而其实呢，一个良好设计的编译器应该在两种情况下都生成相同的代码。这是因为在 i++ 的情况，代码其实先被转化为：


for (int i = 0; i &lt; max; (tmp = i, i = i + 1, tmp))



    由于 tmp 这个临时变量从来没被用过，所以它会被编译器的“dead code elimination”消去。所以编译器最后实际上得到了：


for (int i = 0; i &lt; max; i = i + 1)



    所以，“精通”这些细微的问题，并不能让你成为一个好的程序员。很多人所认为的高明的技巧，经常都是因为早期系统设计的缺陷所致。一旦这些系统被改进，这些技巧就没什么用处了。



    真正正确的做法其实是：完全不使用自增减操作，因为它们本来就是错误的设计。



    好了，一个小小的例子，也许已经让你意识到了片面追求短小程序所带来的认知上，时间上的代价。很可惜的是，程序语言的设计者们仍然在继续为此犯下类似的错误。一些新的语言加入了很多类似的旨在“缩短代码”，“减少打字量”的雕虫小技。也许有一天你会发现，这些雕虫小技所带来的，除了短暂的兴奋，其实都是在浪费你的时间。


赋值语句返回值


    在几乎所有像 C，C++，Java 的语言里，赋值语句都可以被作为值。之所以设计成这样，是因为你就可以写这样的代码：


if (y = 0) { ... }



    而不是


y = 0;
if (y) { ... }



    程序好像缩短了一行，然而，这种写法经常引起一种常见的错误，那就是为了写 if (y == 0) { ... } 而把 == 比较操作少打了一个 =，变成了 if (y = 0) { ... }。很多人犯这个错误，是因为数学里的 = 就是比较两个值是否相等的意思。



    不小心打错一个字，就让程序出现一个 bug。不管 y 原来的值是多少，经过这个“条件”之后，y 的值都会变成 0。所以这个判断语句会一直都为“假”，而且一声不吭的改变了 y 的值。这种 bug 相当难以发现。这就是另一个例子，说明片面追求短小带来的不应有的问题。



    正确的做法是什么呢？在一个类型完备的语言里面，像 y=0 这样的赋值语句，其实是不应该可以返回一个值的，所以它不允许你写：


x = y = 0



    或者


if (y = 0) { ... }



    这样的代码。



    x = y = 0 的工作原理其实是这样：经过 parser 它其实变成了 x = (y = 0)（因为 = 操作符是“右结合”的）。x = (y = 0) 这个表达式也就是说 x 被赋值为 (y = 0) 的值。注意，我说的是 (y = 0) 这整个表达式的值，而不是 y 的值。所以这里的 (y = 0) 既有副作用又是值，它返回 y 的“新值”。



    正确的做法其实是：y = 0 不应该具有一个值。它的作用应该是“赋值”这种“动作”，而不应该具有任何“值”。即使牵强一点硬说它有值，它的值也应该是 void。这样一来 x = y = 0 和 if (y = 0) 就会因为“类型不匹配”而被编译器拒绝接受，从而避免了可能出现的错误。



    仔细想一想，其实 x = y = 0 和 if (y = 0) 带来了非常少的好处，但它们带来的问题却耗费了不知道多少人多少时间。这就是我为什么把它们叫做“小聪明”。


思考题：



    Google 公司的代码规范里面规定，在任何情况下 for 语句和 if 语句之后必须写花括号，即使 C 和 Java 允许你在其只包含一行代码的时候省略它们。比如，你不能这样写


for (int i=0; i &lt; n; i++)
   some_function(i);



    而必须写成


 for (int i=0; i &lt; n; i++) {
   some_function(i);
 }



    请分析：这样多写两个花括号，是好还是不好？



    （提示，Google 的代码规范在这一点上是正确的。为什么？）


    当我第二次到 Google 实习的时候，发现我一年前给他们写的代码，很多被调整了结构。几乎所有如下结构的代码：


 if (condition) {
   return x;
 } else {
   return y;
 }



    都被人改成了：


 if (condition) {
   return x;
 }
 return y;



    请问这里省略了一个 else 和两个花括号，会带来什么好处或者坏处？



    （提示，改过之后的代码不如原来的好。为什么？）


    根据本文对于自增减操作的看法，再参考传统的图灵机的设计，你是否发现图灵机的设计存在类似的问题？你如何改造图灵机，使得它不再存在这种问题？



    （提示，注意图灵机的“读写头”。）


    参考这个《Go 语言入门指南》，看看你是否能从中发现由于“片面追求短小”而产生的，别的语言里都没有的设计错误？




   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 谈语法

 
 
 
 
    

    
 
     
  

      
   
谈语法

    



    使用和研究过这么多程序语言之后，我觉得几乎不包含多余功能的语言，只有一个：Scheme。所以我觉得它是学习程序设计最好的入手点和进阶工具。当然 Scheme 也有少数的问题，而且缺少一些我想要的功能，但这些都瑕不掩瑜。在用了很多其它的语言之后，我觉得 Scheme 真的是非常优美的语言。



    要想指出 Scheme 所有的优点，并且跟其它语言比较，恐怕要写一本书才讲的清楚。所以在这篇文章里，我只提其中一个最简单，却又几乎被所有人忽视的方面：语法。



    其它的 Lisp “方言”也有跟 Scheme 类似的语法（都是基于“S表达式”），所以在这篇（仅限这篇）文章里我所指出的“Scheme 的优点”，其实也可以作用于其它的 Lisp 方言。从现在开始，“Scheme”和“Lisp”这两个词基本上含义相同。



    我觉得 Scheme （Lisp） 的基于“S表达式”（S-expression）的语法，是世界上最完美的设计。其实我希望它能更简单一点，但是在现存的语言中，我没有找到第二种能与它比美。也许在读过这篇文章之后，你会发现这种语法设计的合理性，已经接近理论允许的最大值。



    为什么我喜欢这样一个“全是括号，前缀表达式”的语言呢？这是出于对语言结构本质的考虑。其实，我觉得语法是完全不应该存在的东西。即使存在，也应该非常的简单。因为语法其实只是对语言的本质结构，“抽象语法树”（abstract syntax tree，AST），的一种编码。一个良好的编码，应该极度简单，不引起歧义，而且应该容易解码。在程序语言里，这个“解码”的过程叫做“语法分析”（parse）。



    为什么我们却又需要语法呢？因为受到现有工具（操作系统，文本编辑器）的限制，到目前为止，几乎所有语言的程序都是用字符串的形式存放在文件里的。为了让字符串能够表示“树”这种结构，人们才给程序语言设计了“语法”这种东西。但是人们喜欢耍小聪明，在有了基本的语法之后，他们开始在这上面大做文章，使得简单的问题变得复杂。



    Lisp （Scheme 的前身）是世界上第二老的程序语言。最老的是 Fortran。Fortran 的程序，最早的时候都是用打孔机打在卡片上的，所以它其实是几乎没有语法可言的。



    



    显然，这样写程序很痛苦。但是它却比现代的很多语言有一个优点：它没有歧义，没有复杂的 parse 过程。



    在 Lisp 诞生的时候，它的设计者们一下子没能想出一种好的语法，所以他们决定干脆先用括号把这语法树的结构全都括起来，一个不漏。等想到更好的语法再换。



    自己想一下，如果要表达一颗“树”，最简单的编码方式是什么？就是用括号把每个节点的“数据”和“子节点”都括起来放在一起。Lisp 的设计者们就是这样想的。他们把这种完全用括号括起来的表达式，叫做“S表达式”（S 代表 "symbolic"）。这貌似很“粗糙”的设计，甚至根本谈不上“设计”。奇怪的是，在用过一段时间之后，他们发现自己已经爱上了这个东西，再也不想设计更加复杂的语法。于是S表达式就沿用至今。



    在使用过 Scheme，Haskell，ML，和常见的 Java，C，C++，Python，Perl，…… 之后，我也惊讶的发现， Scheme 的语法，不但是最简单，而且是最好看的一个。这不是我情人眼里出西施，而是有一定理论依据的。



    首先，把所有的结构都用括号括起来，轻松地避免了别的语言里面可能发生的“歧义”。程序员不再需要记忆任何“运算符优先级”。



    其次，把“操作符”全都放在表达式的最前面，使得基本算术操作和函数调用，在语法上发生完美的统一，而且使得程序员可以使用几乎任何符号作为函数名。



    在其他的语言里，函数调用看起来像这个样子：f(1)，而算术操作看起来是这样：1+2。在 Lisp 里面，函数调用看起来是这样(f 1)，而算术操作看起来也是这样(+ 1 2)。你发现有什么共同点吗？那就是 f 和 + 在位置上的对应。实际上，加法在本质也是一个函数。这样做的好处，不但是突出了加法的这一本质，而且它让人可以用跟定义函数一模一样的方式，来定义“运算符”！这比起 C++ 的“运算符重载”强大很多，却又极其简单。



    关于“前缀表达式”与“中缀表达式”，我有一个很独到的见解：我觉得“中缀表达式”其实是一种过时的，来源于传统数学的历史遗留产物。几百年以来，人们都在用 x+y 这样的符号来表示加法。之所以这样写，而不是 (+ x y)，是因为在没有计算机以前，数学公式都得写在纸上，写 x+y 显然比 (+ x y) 方便简洁。但是，中缀表达式却是容易出现歧义的。如果你有多个操作符，比如 1+2*3。那么它表示的是 (+ 1 (* 2 3)) 呢，还是 (* (+ 1 2) 3)？所以才出现了“运算符优先级”这种东西。看见没有，S表达式已经在这里显示出它没有歧义的优点。你不需要知道 + 和 * 的优先级，就能明白 (+ 1 (* 2 3)) 和 (* (+ 1 2) 3) 的区别。第一个先乘后加，而第二个先加后乘。



    对于四则运算，这些优先级还算简单。可是一旦有了更多的操作，就容易出现混淆。这就是为什么数学（以及逻辑学）的书籍难以看懂。 实际上，那些看似复杂的公式，符号，不过是在表示一些程序里的“数据结构”，“对象”以及“函数”。大部分读数学书的时间，其实是浪费在琢磨这些公式：它们到底要表达的什么样一个“数据结构”或者“操作”！这个“琢磨”的过程，其实就是程序语言里所谓的“语法分析”（parse）。



    这种问题在微积分里面就更加明显。微积分难学，很大部分原因，就是因为微积分的那些传统的运算符，其实不是很好的设计。如果你想了解更好的设计，可以参考一下 Mathematica 的公式设计。试试在 Mathematica 里面输入“单行”的微积分运算（而不使用它传统的“2D语法”）。



    其实 Lisp 已经可以轻松地表示这种公式，比如对 x^2 进行微分，可以表示成


      (D ‘(^ x 2) ‘x)



    看到了吗？微分不过是一个用于处理符号的函数 D，输入一个表达式和另一个符号，输出一个新的表达式。



    同样的公式，传统的数学符号是这个样子：



    



    这是什么玩意啊？d 除以 dx，然后乘以 x 的平方？



    在 Lisp 里，你其实可以比较轻松地实现符号微分的计算。SICP里貌似有一节就是教你写个符号微分程序。做微积分这种无聊的事情，就是应该交给电脑去做。总之，这从一方面显示了，Lisp 的语法其实超越了传统的数学。



    其实我一直都在想，如果把数学看成是一种程序语言，它也许就是世界上语法最糟糕的语言。数学里的“变量”，几乎总是没有明确定义的作用域（scope）。也就是说他们只有“全局变量”。上一段话的 x，跟下一段话的 x，经常指的不是同一个东西。所以训练有素的数学家，总是避免使用同一个符号来表示两种不同的东西。很快他们就发现所有的拉丁字母都用光了，于是乎开始用希腊字母。大写的，小写的，粗体的，斜体的，花体的，…… 而其实，他们只不过是想实现 C++ 里的 “namespace”。



    可惜的是，很多程序语言的设计者没能摆脱数学的思想束缚，对数学和逻辑有盲目崇拜的倾向。所以他们继续在新的语言里使用中缀表达法。Haskell，ML，Coq，Agda，这些“超高级”的语言设计，其实都中了这个圈套。在 Coq 和 Agda 里面，你不但可以使用中缀表达式，还可以定义所谓的 "mixfix" 表达式。这样其实是把简单的问题复杂化。想让自己看起来像“数学”，很神秘的样子，其实是学会了数学的糟粕，自讨苦吃。



    另外，由于 Lisp 的表达能力和灵活性比其他语言要大很多，所以类似 C 或者 Pascal 那样的语法其实不能满足 Lisp 的需要。在 Lisp 里，你可以写 (+ 10 (if test 1 2)) 这样的代码，然而如果你使用 C 那样的无括号语法，就会发现没法很有效的嵌入里面的那个条件语句而不出现歧义。这就是为什么 C 必须使用 test? 1 : 2 这样的语法来表示 Lisp 的 if 能表示的东西。然而即使如此，你仍然会经常被迫加上一对括号，结果让程序非常难看，最后的效果其实还不如用 Lisp 的语法。在 C 这样的语言里，由于结构上有很多限制，所以才觉得那样的语法还可以。可是一旦加入 Lisp 的那些表达能力强的结构，就发现越来越难看。JavaScript（node.js）就是对此最好的一个证据。



    最后，从美学的角度上讲，S表达式是很美观的设计。所有的符号都用括号括起来，这形成一种“流线型”的轮廓。而且由于可以自由的换行排版，你可以轻松地对齐相关的部分。在 Haskell 里，你经常会发现一些很蹩脚，很难看的地方。这是因为中缀表达式的“操作符”，经常不能对在一起。比如，如果你有像这样一个 case 表达式：


case x
  Short _ -&gt; 1
  VeryLooooooooooooooooooooooooog _ -&gt; 2



    为了美观，很多 Haskell 程序员喜欢把那两个箭头对齐。结果就成了这样：


case x
  Short _      -&gt; 1
  VeryLooooooooooooooooooooooooog _ -&gt; 2



    作为一个菜鸟级摄影师，你不觉得第一行中间太“空”了一点吗？



    再来看看S表达式如何表达这东西：


(case x
  (-&gt; (Short _) 1)
  (-&gt; (VeryLooooooooooooooooooooooooog _) 2))



    发现“操作符总在最前”的好处了吗？不但容易看清楚，而且容易对齐，而且没有多余的间隙。



    其实我们还可以更进一步。因为箭头的两边全都用括号括起来了，所以其实我们并不需要那两个箭头就能区分“左”和“右”。所以我们可以把它简化为：


(case x
  ((Short _) 1)
  ((VeryLooooooooooooooooooooooooog _) 2))



    最后我们发现，这个表达式“进化”成了 Lisp 的 case 表达式。



    Lisp 的很多其它的设计，比如“垃圾回收”，后来被很多现代语言（比如 Java）所借鉴。可是人们遗漏了一个很重要的东西：Lisp 的语法，其实才是世界上最好的语法。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 Oberon 操作系统：被忽略的珍宝

 
 
 
 
    

    
 
     
  

      
   
Oberon 操作系统：被忽略的珍宝

    推荐一篇很久以前看的文章：Oberon - The Overlooked Jewel



    它介绍的是 Niklaus Wirth 设计的一种操作系统，叫做 Oberon。Niklaus Wirth 就是大家熟知的 Pascal 语言的设计者。绝大部分人都没听说过有 Oberon 这个东西存在，更难以把它跟 Niklaus Wirth 的大名挂上钩。所以作者说：“Wirth 因为 Pascal 而闻名于世，可是接下来几年，他成为了 Pascal 的受害者。” 确实是这样。Wirth 一直都不觉得 Pascal 是他的杰作。我想他应该会更喜欢以 Oberon 闻名于世。



    Oberon 比起 Unix，有很大的不同，在于它的数据都是结构化的。进程间不通过字符串交换数据，而是直接使用数据结构。很奇特的一点是，Oberon 操作系统是用一种同名的程序语言（Oberon 语言）写成。令人惊讶的是，在那个年代，ETH 计算机系的所有教职员工，学生，包括办公室的大妈，都是用的这种操作系统。



    操作系统的设计，真是天外有天。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 谈 Linux，Windows 和 Mac

 
 
 
 
    

    
 
     
  

      
   
谈 Linux，Windows 和 Mac

    这段时间受到很多人的来信。他们看了我很早以前写的推崇 Linux 的文章，想知道如何“抛弃 Windows，学习 Linux”。天知道他们在哪里找到那么老的文章，真是好事不出门…… 我觉得我有责任消除我以前的文章对人的误导，洗清我这个“Linux 狂热分子”的恶名。我觉得我已经写过一些澄清的文章了，可是怎么还是有人来信问 Linux 的问题。也许因为感觉到“舆论压力”，我把文章都删了。



    简言之，我想对那些觉得 Linux 永远也学不会的“菜鸟”们说：




    Linux 和 Unix 里面包含了一些非常糟糕的设计。不要被 Unix 的教条主义者吓倒。学不会有些东西很多时候不是你的错，而是 Linux 的错，是“Unix 思想” 的错。不要浪费时间去学习太多工具的用法，钻研稀奇古怪的命令行。那些貌似难的，复杂的东西，特别要小心分析。


    Windows 避免了 Unix，Linux 和 Mac OS X 的很多问题。微软是值得尊敬的公司，是真正在乎程序开发工具的公司。我收回曾经对微软的鄙视态度。请菜鸟们吸收 Windows 设计里面好的东西。另外 Visual Studio 是非常好的工具，会带来编程效率的大幅度提升。请不要歧视 IDE。要正视 Emacs，VIM 等文本编辑器的局限性。当然，这些正面评价不等于说你应该为微软工作。就像我喜欢 iPhone，但是却不一定想给 Apple 工作一样。


    学习操作系统最好的办法是学会（真正的）程序设计思想，而不是去“学习”各种古怪的工具。所有操作系统，数据库，Internet，以至于 WEB 的设计思想（和缺陷），几乎都能用程序语言的思想简单的解释。





    先说说我现在对 Linux 和相关工具（比如 TeX）的看法吧。我每天上班都用 Linux，可是回家才不想用它呢。上班的时候，我基本上只是尽我所能的改善它，让它不要给我惹麻烦。Unix 有许许多多的设计错误，却被当成了教条，传给了一代又一代的程序员，恶性循环。Unix 的 shell，命令，配置方式，图形界面，都是相当糟糕的。每一个新版本的 Ubuntu 都会在图形界面的设计上出现新的错误，让你感觉历史怎么会倒退。其实这只是表面现象。Linux 所用的图形界面（X Window）在本质上几乎是没救的。我不想在这里细说 Unix 的缺点，在它出现的早期，已经有人写了一本书，名叫 Unix Hater's Handbook，里面专门有一章叫做 The X-Windows Disaster。它分析后指出，X Window 貌似高明的 client-server 设计，其实并不像说的那么好。



    这本书汇集了 Unix 出现的年代，很多人对它的咒骂。有趣的是，这本书有一个“反序言”，是 Unix 的创造者之一 Dennis Ritchie 写的。我曾经以为这些骂 Unix 的人都是一些菜鸟。他们肯定是智商太低，或者被 Windows 洗脑了，不能理解 Unix 的高明设计才在那里骂街。现在理解了程序语言的设计原理之后，才发现他们说的那些话里面居然大部分是实话！其实他们里面有些人在当年就是世界顶尖的编程高手，自己写过操作系统和编译器，功底不亚于 Unix 的创造者。在当年他们就已经使用过设计更加合理的系统，比如 Multics，Lisp Machine 等。



    可惜的是，在现在的操作系统书籍里面，Multics 往往只是被用来衬托 Unix 的“简单”和伟大。Unix 的书籍喜欢在第一章讲述这样的历史：“Multics 由于设计过于复杂，试图包罗万象，而且价格昂贵，最后失败了。” 可是 Multics 失败了吗？Multics，Oberon，IBM System/38， Lisp Machine，…… 在几十年前就拥有了 Linux 现在都还没有的好东西。Unix 里面的东西，什么虚拟内存，文件系统，…… 基本上都是从 Multics 学来的。Multics 的机器，一直到 2000 年都还在运行。Unix 不但“窜改”了历史教科书，而且似乎永远不吸取教训，到现在还没有实现那些早期系统早就有的好东西。Unix 的设计几乎完全没有一致性和原则。各种工具程序功能重复，冗余，没法有效地交换数据。可是最后 Unix 靠着自己的“廉价”，“宗教”和“哲学”，战胜了别的系统在设计上的先进，统治了程序员的世界。



    如果你想知道这些“失败的”操作系统里面有哪些我们现在都还没有的先进技术，可以参考这篇文章：Oberon - The Overlooked Jewel。它介绍的是 Niklaus Wirth（也就是 Pascal 语言的设计者）的 Oberon 操作系统。



    胜者为王，可是 Unix 其实是一个暴君，它不允许你批评它的错误。它利用其它程序员的舆论压力，让每一个系统设计上的错误，都被说成是用户自己的失误。你不敢说一个工具设计有毛病，因为如果别人听到了，就会以为你自己不够聪明，说你“人笨怪刀钝”。这就像是“皇帝的新装”里的人们，明明知道皇帝没穿衣服，还要说“这衣服这漂亮”！总而言之，“对用户友好”这个概念，在 Unix 的世界里是被歧视，被曲解的。Unix 的狂热分子很多都带有一种变态的“精英主义”。他们以用难用的工具为豪，鄙视那些使用“对用户友好”的工具的人。



    我曾经强烈的推崇 FVWM，TeX 等工具，可是现在擦亮眼睛看来，它们给用户的界面，其实也是非常糟糕的设计，跟 Unix 一脉相承。他们把程序设计的许多没必要的细节和自己的设计失误，无情的暴露给用户。让用户感觉有那么多东西要记，仿佛永远也没法掌握它。实话说吧，当年我把 TeXbook 看了两遍，做完了所有的习题（包括最难的“double bend”习题）。几个月之后，几乎全部忘记干净。为什么呢？因为 TeX 的语言是非常糟糕的设计，它没有遵循程序语言设计的基本原则。



    这里有一个鲜为人知的小故事。TeX 之所以有一个“扩展语言”，是 Scheme 的发明者 Guy Steele 的建议。那年夏天，Steele 在 Stanford 实习。他听说 Knuth 在设计一个排版系统，就强烈建议他使用一种扩展语言。后来 Knuth 采纳了他的建议。不幸的是 Steele 几个月后就离开了，没能帮助 Knuth 完成语言的设计。Knuth 老爹显然有我所说的那种“精英主义”，他咋总是设计一些难用的东西，写一些难懂的书？



    一个好的工具，应该只有少数几条需要记忆的规则，就像象棋一样。而这些源于 Unix 的工具却像是“魔鬼棋”或者“三国杀”，有太多的，无聊的，人造的规则。有些人鄙视图形界面，鄙视 IDE，鄙视含有垃圾回收的语言（比如 Java），鄙视一切“容易”的东西。他们却不知道，把自己沉浸在别人设计的繁复的规则中，是始终无法成为大师的。就像一个人，他有能力学会各种“魔鬼棋”的规则，却始终无法达到象棋大师的高度。所以，容易的东西不一定是坏的，而困难的东西也不一定是好的。学习计算机（或者任何其它工具），应该“只选对的，不选难的”。记忆一堆的命令，乌七八糟的工具用法，最后脑子里什么也不会留下。学习“原理性”的东西，才是永远不会过时的。



    Windows 技术设计上的很多细节，也许在早期是同样糟糕的。但是它却向着更加结构化，更加简单的方向发展。Windows 的技术从 OLE，COM，发展到 .NET，再加上 Visual Studio 这样高效的编程工具，这些带来了程序员和用户效率的大幅度提高，避免了 Unix 和 C 语言的很多不必存在的问题。Windows 程序从很早的时候就能比较方便的交换数据。比如，OLE 让你可以把 Excel 表格嵌入到 Word 文档里面。不得不指出，这些是非常好的想法，是超越“Unix 哲学”的。相反，由于受到“Unix 哲学”的误导，Unix 的程序间交换数据一直以来都是用字符串，而且格式得不到统一，以至于很多程序连拷贝粘贴都没法正确进行。Windows 的“配置”，全都记录在一个中央数据库（注册表）里面，这样程序的配置得到大大的简化。虽然在 Win95 的年代，注册表貌似老是惹麻烦，但现在基本上没有什么问题了。相反，Unix 的配置，全都记录在各种稀奇古怪的配置文件里面，分布在系统的各个地方。你搞不清楚哪个配置文件记录了你想要的信息。每个配置文件连语法都不一样！这就是为什么用 Unix 的公司总是需要一个“系统管理员”，因为软件工程师们才懒得记这些麻烦的东西。



    再来比较一下 Windows 和 Mac 吧。我认识一个 Adobe 的高级设计师。他告诉我说，当年他们把 Photoshop 移植到 Intel 构架的 Mac，花了两年时间。只不过换了个处理器，移植个应用程序就花了两年时间，为什么呢？因为 Xcode 比起 Visual Studio 真是差太多了。而 Mac OS X 的一些设计原因，让他们的移植很痛苦。不过他很自豪的说，当年很多人等了两年也没有买 Intel 构架的 Mac，就是因为他们在等待 Photoshop。最后他直言不讳的说，微软其实才是真正在乎程序员工具的公司。相比之下，Apple 虽然对用户显得友好，但是对程序员的界面却差很多。Apple 尚且如此，Linux 对程序员就更差了。可是有啥办法呢，有些人就是受虐狂。自己痛过之后，还想让别人也痛苦。就像当年的我。



    我当然不是人云亦云。微软在程序语言上的造诣和投入，我看得很清楚。我只是通过别人的经历，来验证我已经早已存在的看法。所以一再宣扬别的系统都是向自己学习的 Apple 受到这样的评价，我也一点不惊讶。Mac OS X 毕竟是从 Unix 改造而来的，还没有到脱胎换骨的地步。我有一个 Macbook Air，一个 iPhone 5，和一个退役的，装着 Windows 7 的 T60。我不得不承认，虽然我很喜欢 Macbook 和 iPhone 的硬件，但我发现 Windows 在软件上的很多设计其实更加合理。



    我为什么当年会鄙视微软？这很简单。我就是跟着一群人瞎起哄而已！他们说 Linux 能拯救我们，给我们自由。他们说微软是邪恶的公司…… 到现在我身边还有人无缘无故的鄙视微软，却不知道理由。可是 Unix 是谁制造的呢？是 AT&amp;T。微软和 AT&amp;T 哪个更邪恶呢？我不知道。但是你应该了解一下 Unix 的历史。AT&amp;T 当年发现 Unix 有利可图，找多少人打了多少年官司？说微软搞垄断，其实 AT&amp;T 早就搞过垄断了，还被拆散成了好几个公司。想想世界上还有哪一家公司，独立自主的设计出这从底至上全套家什：程序语言，编译器，IDE，操作系统，数据库，办公软件，游戏机，手机…… 我不得不承认，微软是值得尊敬的公司。



    公司还不都一样，都是以利益为本的。我们程序员就不要被他们利用，作为利益斗争的炮灰啦。见到什么好就用什么，就学什么。自己学到的东西，又不属于那些垄断企业。我们都有自由的头脑。



    当然我不是在这里打击 Linux 和 Mac 而鼓吹 Windows。这些系统的纷争基本上已经不关我什么事。我只是想告诉新人们，去除头脑里的宗教，偏激，仇恨和鄙视。每次仇恨一个东西，你就失去了向它学习的机会。



    后记：“对用户友好”是一个值得研究，却又研究得非常不够的东西。很多 UI 的设计者，把东西设计的很漂亮，但是却不方便，不顺手。如果你想了解我认为怎样的设计才是“对用户友好的”，可以参考这篇博客《什么是“对用户友好”》


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 解密“设计模式”

 
 
 
 
    

    
 
     
  

      
   
解密“设计模式”

    有些人问我，你说学习操作系统的最好办法是学习程序设计。那我们是不是应该学习一些“设计模式”（design patterns）。这是一个我很早就有定论，而且经过实践检验的问题，所以想在这里做一个总结。



    总的来说，如果光从字面上讲，程序里确实是有一些“模式”可以发掘的。因为你总是可以借鉴以前的经验，用来构造新的程序。你可以把这种经验叫做“模式”。可是自从《设计模式》（通常叫做 GoF，“Gang of Four”，“四人帮”）这本书在 1994 年发表以来，“设计模式”这个词有了新的，扭曲的含义。它变成了一种教条，带来了公司里程序的严重复杂化以及效率低下。



    



    GoF 借鉴的是一个叫 Christopher Alexander 的建筑师的做法。Alexander 给一些建筑学里的“设计模式”起了名字，试图让建筑师们有一些“共同语言”。可惜的是，Alexander 后来自己都承认，他的实验失败了。因为这些固定的模式，并没能有效地传递精髓的知识，没能让新手成长为出色的建筑师。



    照搬模式东拼西凑，而不能抓住事物的本质，没有“灵感”，其实是设计不出好东西的。这就像照搬“模版”把作文写得再好，也成不了作家一样。



    我孤陋寡闻，当听说这本书的时候，我已经学会了函数式编程，正在 Cornell 读 PhD，专攻程序语言设计。有一天由于好奇这书为什么名气这么大，我从图书馆借了一本回来看。我很快的发现，其实这本书的作者只是给早已经存在的编程方法起了一些新的名字而已。当时我就拿起一张纸，把所有的20来个设计模式跟我常用的编程概念做了一个映射。这个映射居然是“多对一”（many-to-one）的。也就是说，多个 GoF 设计模式，居然只对应同一个我每天都用的概念。有些概念是如此的不值一提，以至于我根本不需要一个名字来描述它，更不要说多个名字！



    其中极少数值得一提的“模式”，也许是 visitor 和 interpreter。很可惜的是，只有很少的人明白如何使用它们。所谓的 visitor，本质上就是函数式语言里的含有“模式匹配”（pattern matching）的递归函数。在函数式语言里，这是多么轻松的事情。可是因为 Java 没有模式匹配，所以很多需要类似功能的人就得使用 visitor pattern。为了所谓的“通用性”，他们往往把 visitor pattern 搞出多层继承关系，让你转几道弯也搞不清楚到底哪个 visitor 才是干实事的。



    其实，函数式语言的研究者们早就知道 visitor pattern 是怎么得来的。如果你想知道如何从无到有，一步一步“发明”出 Java 的 visitor pattern，可以参考 Dan Friedman 跟他的学生 Matthias Felleisen 合写的的另一本“小人书”《A Little Java, A Few Patterns》（发表于 1997 年）。



    



    而 interpreter （解释器）模式呢？看了作者们写的例子程序之后，我发现他们其实并不会写解释器，或者说他们不知道如何写出优雅的，正确的解释器。如果你想知道如何写出好的解释器，可以参考我的博文《怎样写一个解释器》。



    你说我在贬低这本书的真正价值，因为 GoF 说了：“我们的贡献，就是给这些编程方式起名字。这样让广大程序员有共同的语言。” 如果这也叫贡献的话，我就可以写本书，给“空气”，“水”，“猪肉”这些东西全都起个新名字，让大家有“共同的语言”。这不是搞笑吗。



    这不是我的一家之言，Peter Norvig 在 1998 年就做了一个演讲，指出在“动态语言”里面，GoF 的20几个模式，其中绝大部分都“透明”了。也就是说，你根本感觉不到它们的存在。这就像我刚才告诉你的。



    



    在这里 Norvig 的观点是正确的，不过需要小心一个概念错误。Norvig 对“静态语言”的概念是有局限性的。有的静态语言其实也能传递函数作为参数，而且不像 Java 那样什么都得放进 class 里。这样的静态语言，其实也可以避免大部分 GoF 设计模式。而“动态语言”这个概念，在程序语言的理论里面，其实是没有明确的定义的。“动态语言”其实也能进行某些“静态类型检查”。不过在 1998 年，我还是个啥都不懂的屁孩，所以这里就不跟 Norvig 大叔计较了。



    既然老人们都有历史局限性，那么为啥我还跟 GoF 找茬？本来这本书很老了，如果没有人再被它误导的话，这篇博文也就不必存在了。可是当我在 Google 实习的时候，我发现几乎每个程序员的书架上都有一本 GoF！我在 Google 实习了两次，第一次的时候代码全都是我一个人写的，所以没有使用任何 GoF 设计模式。代码直接，精巧而简单。当我第二次回到 Google，发现我的代码里已经被加入了各种 factory，visitor，…… 其实啥好事也没做，只不过让我的代码弯了几道弯，让人难以理解。



    可见一本坏书，毁掉的不只是一代程序员。鉴于如此，特发此文。各位新手，希望你们敲响警钟，不要再走上这条老路，写出代码来让大家痛苦。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 Braid - 一个发人深思的游戏

 
 
 
 
    

    
 
     
  

      
   
Braid - 一个发人深思的游戏

    



    我已经很久很久没有打游戏了（如果不算 Angry Birds 之类用来打发时间的游戏的话）。我的最后一个真正意义上的游戏机，是 PlayStation 1。在那上面，我真正欣赏的最后一个游戏，是 [Metal Gear Solid (1)]。



    我曾经是一个游戏迷，可是进入了计算机专业的学习之后，我就开始失去对游戏的兴趣，基本上每玩一个都让我失望一次，不管别人把它吹的多么“经典”。不知道为什么，别人玩得津津有味的游戏，我玩一会儿就把它里面的“公式”都看透了。我清楚地知道这游戏的设计者是怎么在“耍我”，在如何想方设法浪费我的时间。同样的，别人看得津津有味的小说和电影，我经常一看开头就能猜到它要怎么发展，以至于一路猜到结局，索然无味。所以我基本上不去影院看最新的电影。我宁愿在网上看一些几十年前的老电影。我貌似只喜欢那些能让我“猜不透”的东西。



    Braid，就是这样一个让我没猜得透的游戏。



    这是一个同事推荐的。本来已经对电玩完全失望的我，破例的从 App Store 买了来。玩过之后觉得真的很不错，有一种所谓的“mind blowing”的感觉。以至于我花了两整天时间，废寝忘食，把它给打通关了。



    Braid 的主体结构，和最古老的“超级玛丽”没什么两样。一个小人，可以跑，可以跳。一些小怪物，跑来跑去的。你可以跳起来踩它们。



    最终的目标，是收集到所有的拼图，然后把它们组合成图片。组合图片是很容易的事情。游戏的难度其实在于如何拿到这些拼图。它们有可能被挂在很高的地方，或者被门挡住。



    可是这有什么值得一提的呢？这游戏很不一样的地方是，它给你提供了几种绝无仅有的“超能力”，而且把它们与谜题结合得几乎天衣无缝。



    你有三种超能力：



逆转时间的能力




    在任何时候按下 Shift 键，游戏的时间就会逆转，“undo”之前的所有动作。即使你死了，都是可以复活的。死去的小怪物们也会复活。可是就算这样，有些拼图还是很难拿到。



    值得一提的是，时间逆转的时候，画面是流畅无缺损的，连爆炸场面都会“收缩”。更令人赞叹的是，游戏的背景音乐也会同步逆转。如果在时间逆转的时候按“上”，“下”键，就可以调整时间“快退”和“快进”的速度。当然，此时的场景就像录像机在快退或者快进。



产生“多重现实”的能力




    



    在某些章节，你可以实现“多重现实”。做一个动作，然后按 Shift 键让时间逆转，当你停止逆转的时候，你的影子就会开始“redo”刚才的那段“历史”。而这个时候你可以做一些不同于以前的事情。这就好像有两个世界，一新一旧，从“历史的分叉点”开始，同步交汇。



    你必须掌握好时间才能跟影子合作，因为影子的行动速度是不受你的“现场控制”的，它只是按部就班的重演你 undo 掉的历史。



扭曲时间的指环




    



    在某些章节，你会有机会使用一个魔法指环。把这个指环放在地上之后，它会在附近的球状空间中形成时间的“扭曲”。这有点像黑洞的原理。越是靠近指环的位置，时间流动越慢。而当你远离指环，时间就逐渐恢复正常。指环的巧妙使用，是解决这些章节谜题的关键。



    同样的，音乐与指环的特异功能是完美配合的。当你靠近指环的时候，背景音乐就会出现相应程度的扭曲。有点像录音机卡带的感觉  :)



    在解决了所有的谜题之后，我回味了一下，自己为什么欣赏 Braid。这也许是因为它符合一个优秀的，非低级趣味的游戏设计：屈指可数的简单规则，却可以组合起来，制造出许许多多的变化。



    你只有3种超能力，但是如何利用和“组合”这些超能力，却形成了解决谜题的关键。有些题目很有点难度，以至于你会希望有第4种超能力出现，或者希望捡到别的什么“法宝”。可是它们是不存在的。你必须使用那仅有的3种能力，加上巧妙的思索，细心的观察，才能达到目的。在解决了一个很难的谜题之后，你往往会一拍脑袋：哇，我怎么一开头没想到！


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 TeXmacs：一个真正“所见即所得”的排版系统

 
 
 
 
    

    
 
     
  

      
   
TeXmacs：一个真正“所见即所得”的排版系统

    



    好久没有推荐过自己喜欢的软件了，现在推荐一款我在美国做数学作业的私家法宝：TeXmacs。我恐怕不可能跟以前那么有闲心写个长篇的 TeXmacs 说明文档了，不过这东西如此的简单好用，所以基本上不用我写什么文档了。鉴于知道的人很少，不理解它的人很多，这里只是帮它打个广告，吊一下胃口。



    TeXmacs 的主要特点是：




    跟 Lyx 等不同，它不是一个 TeX 的“前端”，而是一个完全独立的，超越 TeX 的系统。TeXmacs 拥有跟 TeX 相同，甚至更好的排版美观程度。这是因为它采用跟 TeX 一样的排版算法，并且用 C++ 重新实现。据说分页的算法比 TeX 的还要好些。


    拥有超越 Word （或者任何一款字处理软件）的，真正的“所见即所得” (WYSIWYG)。Word 所谓的“所见即所得”其实是假的。所见即所得的含义应该是，屏幕上显示的内容，跟打印下来的完全一样。可是 Word 能做到吗？打印一个文档出来你就发现跟屏幕上显示的有很大区别，一般来说屏幕上显示的要粗糙一些。一些 TeX 的前端，比如 Lyx, Scientific Workspace 等也是类似的，它们都不能达到真正的所见即所得。


    直接可在屏幕文档里绘图。完全可视化的表格，公式编辑环境。这些都是比 TeX 方便高效很多的方式。需要当心的是，用过 TeXmacs 一段时间之后，你会发现回到 TeX 的公式编辑方式简直就像回到原始社会。


    非常人性化的按键设计。比如，在数学公式环境下，你按任意一个字符，然后就可以用多次 TAB 键相继选择“拓扑相同”的字符。举个例子，如果你按 @，然后再按几下 TAB，就会发现这个字符变成各种各样的圆圈形的字符。如果你按 >，再按 =，就会出现大于等于号，之后再按 TAB，就会相继出现大于等于号的各种变体。


    在直观的同时不失去对底层结构的控制。比如，（见下图）窗口右下角的状态栏，显示出当前光标位置的“上下文”是“proof eqnarry* (1,1) start”，这表示的是这是在一个 proof 环境里的 eqnarry 的坐标 (1,1) 的开始处。当你使用 Ctrl-Backspace，最靠近光标的那层“环境”会被删除。比如，如果你现在的字体是斜体，那么在 Ctrl-Backspace 之后，字体就立即还原成正体。



    


    结构化的浏览功能。比如，按 Ctrl-PgUp, Ctrl-PgDn 就可以在“相同类型”的结构里上下跳转。比如，如果你在小节标题里按这个键，就可以迅速的浏览所有的小节标题。如果你在数学公式里按这个键，就可以迅速浏览所有的数学公式。


    与交互式程序接口。支持很多种计算机代数系统，和交互式软件，比如 MAXIMA，Octave，…… 这些系统返回的数学公式会直接被 TeXmacs 显示为“TeX 效果”。使用 Scheme 作为嵌入式语言，并且可以使用它来扩展系统。这比起 TeX 的语言是非常大的进步。





    目前由于 TeX 的垄断地位，以及由于 TeXmacs 是法国人做的，这个系统在美国还不是很流行，很多人都没听说过有这种东西存在。学术圈的很多人由于受到某种错误思想的“洗脑”，都不理解这种图形化编辑软件的价值。希望中国人民和法国人民一样后来居上，超越美国。



    想要迅速的掌握 TeXmacs 的基本用法，可以参考我绘制的 TeXmacs 思维导图：



    


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 怎样写一个解释器

 
 
 
 
    

    
 
     
  

      
   
怎样写一个解释器

    写一个解释器，通常是设计和实现程序语言的第一步。解释器是简单却又深奥的东西，以至于好多人都不会写，所以我决定写一篇这方面的入门读物。



    虽然我试图从最基本的原理讲起，尽量不依赖于其它知识，但这并不是一本编程入门教材。我假设你已经理解 Scheme 语言，以及基本的编程技巧（比如递归）。如果你完全不了解这些，那我建议你读一下 SICP 的第一，二章，或者 HtDP 的前几章，习题可以不做。注意不要读太多书，否则你就回不来了 ;-) 当然你也可以直接读这篇文章，有不懂的地方再去查资料。



    实现语言容易犯的一个错误，就是一开头就试图去实现很复杂的语言（比如 JavaScript 或者 Python）。这样你很快就会因为这些语言的复杂性，以及各种历史遗留的设计问题而受到挫折，最后不了了之。学习实现语言，最好是从最简单，最干净的语言开始，迅速写出一个可用的解释器。之后再逐步往里面添加特性，同时保持正确。这样你才能有条不紊地构造出复杂的解释器。



    因为这个原因，这篇文章只针对一个很简单的语言，名叫“R2”。它可以作为一个简单的计算器用，还具有变量定义，函数定义和调用等功能。


我们的工具：Racket


    本文的解释器是用 Scheme 语言实现的。Scheme 有很多的“实现”，这里我用的实现叫做 Racket，它可以在这里免费下载。为了让程序简洁，我用了一点点 Racket 的模式匹配（pattern matching）功能。我对 Scheme 的实现没有特别的偏好，但 Racket 方便易用，适合教学。如果你用其它的 Scheme 实现，可能得自己做一些调整。



    Racket 具有宏（macro），所以它其实可以变成很多种语言。如果你之前用过 DrRacket，那它的“语言设置”可能被你改成了 R5RS 之类的。所以如果下面的程序不能运行，你可能需要检查一下 DrRacket 的“语言设置”，把 Language 设置成 “Racket”。



    



    



    Racket 允许使用方括号而不只是圆括号，所以你可以写这样的代码：


(let ([x 1]
      [y 2])
  (+ x y))



    方括号跟圆括号可以互换，唯一的要求是方括号必须和方括号匹配。通常我喜欢用方括号来表示“无动作”的数据（比如上面的 [x 1], [y 2]），这样可以跟函数调用和其它具有“动作”的代码，产生“视觉差”。这对于代码的可读性是一个改善，因为到处都是圆括号的话，确实有点太单调。



    另外，Racket 程序的最上面都需要加上像 #lang racket 这样的语言选择标记，这样 Racket 才可以知道你想用哪个语言变种。


解释器是什么


    准备工作就到这里。现在我来谈一下，解释器到底是什么。说白了，解释器跟计算器差不多。解释器是一个函数，你输入一个“表达式”，它就输出一个 “值”，像这样：



    



    比如，你输入表达式 '(+ 1 2) ，它就输出值，整数3。表达式是一种“表象”或者“符号”，而值却更加接近“本质”或者“意义”。解释器从符号出发，得到它的意义，这也许就是它为什么叫做“解释器”。



    需要注意的是，表达式是一个数据结构，而不是一个字符串。我们用一种叫“S表达式”（S-expression）的结构来存储表达式。比如表达式 '(+ 1 2) 其实是一个链表（list），它里面的内容是三个符号（symbol）：+, 1 和 2，而不是字符串"(+ 1 2)"。



    从S表达式这样的“结构化数据”里提取信息，方便又可靠，而从字符串里提取信息，麻烦而且容易出错。Scheme（Lisp）语言里面大量使用结构化数据，少用字符串，这就是 Lisp 系统比 Unix 系统先进的地方之一。



    从计算理论的角度讲，每个程序都是一台机器的“描述”，而解释器就是在“模拟”这台机器的运转，也就是在进行“计算”。所以从某种意义上讲，解释器就是计算的本质。当然，不同的解释器就会带来不同的计算。你可能没有想到，CPU 也是一个解释器，它专门解释执行机器语言。


抽象语法树（Abstract Syntax Tree）


    我们用S表达式所表示的代码，本质上是一种叫做“树”（tree）的数据结构。更具体一点，这叫做“抽象语法树”（Abstract Syntax Tree，简称 AST）。下文为了简洁，我们省略掉“抽象”两个字，就叫它“语法树”。



    跟普通的树结构一样，语法树里的节点，要么是一个“叶节点”，要么是一颗“子树”。叶节点是不能再细分的“原子”，比如数字，字符串，操作符，变量名。而子树是可以再细分的“结构”，比如算术表达式，函数定义，函数调用，等等。



    举个简单的例子，表达式 '(* (+ 1 2) (+ 3 4))，就对应如下的语法树结构：



    



    其中，*，两个+，1，2，3，4 都是叶节点，而那三个红色节点，都表示子树结构：'(+ 1 2)，'(+ 3 4)，'(* (+ 1 2) (+ 3 4))。


树遍历算法


    在基础的数据结构课程里，我们都学过二叉树的遍历操作，也就是所谓先序遍历，中序遍历和后序遍历。语法树跟二叉树，其实没有很大区别，所以你也可以在它上面进行遍历。解释器的算法，就是在语法树上的一种遍历操作。由于这个渊源关系，我们先来做一个遍历二叉树的练习。做好了之后，我们就可以把这段代码扩展成一个解释器。



    这个练习是这样：写出一个函数，名叫tree-sum，它对二叉树进行“求和”，把所有节点里的数加在一起，返回它们的和。举个例子，(tree-sum '((1 2) (3 4)))，执行后应该返回 10。注意：这是一颗二叉树，所以不会含有长度超过2的子树，你不需要考虑像 ((1 2) (3 4 5)) 这类情况。需要考虑的例子是像这样：(1 2)，(1 (2 3)), ((1 2) 3) ((1 2) (3 4))，……



    （为了达到最好的学习效果，你最好试一下写出这个函数再继续往下看。）



    好了，希望你得到了跟我差不多的结果。我的代码是这个样子：


#lang racket

(define tree-sum
  (lambda (exp)
    (match exp    ; 对输入exp进行模式匹配
      [(? number? x) x]  ; exp是一个数x吗？如果是，那么返回这个数x
      [`(,e1 ,e2) ; exp是一个含有两棵子树的中间节点吗？
(let ([v1 (tree-sum e1)] ; 递归调用tree-sum自己，对左子树e1求值
      [v2 (tree-sum e2)]); 递归调用tree-sum自己，对右子树e2求值
  (+ v1 v2))])))  ; 返回左右子树结果v1和v2的和



    你可以通过以下的例子来测试它的正确性：


(tree-sum '(1 2))
;; =&gt; 3
(tree-sum '(1 (2 3)))
;; =&gt; 6
(tree-sum '((1 2) 3))
;; =&gt; 6
(tree-sum '((1 2) (3 4)))
;; =&gt; 10



    （完整的代码和示例，可以在这里下载。）



    这个算法很简单，我们可以把它用文字描述如下：



如果输入 exp 是一个数，那就返回这个数。
否则如果 exp 是像 (,e1 ,e2) 这样的子树，那么分别对 e1 和 e2 递归调用 tree-sum，进行求和，得到 v1 和 v2，然后返回 v1 + v2 的和。




    你自己写出来的代码，也许用了 if 或者 cond 语句来进行分支，而我的代码里面使用的是 Racket 的模式匹配（match）。这个例子用 if 或者 cond 其实也可以，但我之后要把这代码扩展成一个解释器，所以提前使用了 match。这样跟后面的代码对比的时候，就更容易看出规律来。接下来，我就简单讲一下这个 match 表达式的工作原理。


模式匹配


    现在不得不插入一点 Racket 的技术细节，如果你已经学会使用 Racket 的模式匹配，可以跳过这一节。你也可以通过阅读 Racket 模式匹配的文档来代替这一节。但我建议你不要读太多文档，因为我接下去只用到很少的模式匹配功能，我把它们都解释如下。



    模式匹配的形式一般是这样：


(match x
  [模式 结果]
  [模式 结果]
   ...   ...
)    



    它先对 x 求值，然后根据值的结构来进行分支。每个分支由两部分组成，左边是一个模式，右边是一个结果。整个 match 语句的语义是这样：从上到下依次考虑，找到第一个可以匹配 x 的值的模式，返回它右边的结果。左边的模式在匹配之后，可能会绑定一些变量，这些变量可以在右边的表达式里使用。



    模式匹配是一种分支语句，它在逻辑上就是 Scheme（Lisp） 的 cond 表达式，或者 Java 的嵌套条件语句 if ... else if ... else ...。然而跟条件语句里的“条件”不同，每条 match 语句左边的模式，可以准确而形象地描述数据结构的形状，而且可以在匹配的同时，对结构里的成员进行“绑定”。这样我们可以在右边方便的访问结构成员，而不需要使用访问函数（accessor）或者 foo.x 这样的属性语法（attribute）。而且模式可以有嵌套的子结构，所以它能够一次性的表示复杂的数据结构。



    举个实在点的例子。我的代码里用了这样一个 match 表达式：


(match exp
  [(? number? x) x]
  [`(,e1 ,e2)
   (let ([v1 (tree-sum e1)]
  [v2 (tree-sum e2)])
     (+ v1 v2))])



    第二行里面的 '(,e1 ,e2) 是一个模式（pattern），它被用来匹配 exp 的值。如果 exp 是 '(1 2)，那么它与'(,e1 ,e2)匹配的时候，就会把 e1 绑定到 '1，把 e2 绑定到 '2。这是因为它们结构相同：


`(,e1 ,e2)
'(  1   2)



    说白了，模式就是一个可以含有“名字”（像 e1 和 e2）的结构，像 '(,e1 ,e2)。我们拿这个带有名字的结构，去匹配实际数据，像 '(1 2)。当它们一一对应之后，这些名字就被绑定到数据里对应位置的值。



    第一行的“模式”比较特殊，(? number? x) 表示的，其实是一个普通的条件判断，相当于 (number? exp)，如果这个条件成立，那么它把 exp 的值绑定到 x，这样右边就可以用 x 来指代 exp。对于无法细分的结构（比如数字，布尔值），你只能用这种方式来“匹配”。看起来有点奇怪，不过习惯了就好了。



    模式匹配对解释器和编译器的书写相当有用，因为程序的语法树往往具有嵌套的结构。不用模式匹配的话，往往要写冗长，复杂，不直观的代码，才能描述出期望的结构。而且由于结构的嵌套比较深，很容易漏掉边界情况，造成错误。模式匹配可以直观的描述期望的结构，避免漏掉边界情况，而且可以方便的访问结构成员。



    由于这个原因，很多源于 ML 的语言（比如 OCaml，Haskell）都有模式匹配的功能。因为 ML（Meta-Language）原来设计的用途，就是用来实现程序语言的。Racket 的模式匹配也是部分受了 ML 的启发，实际上它们的原理是一模一样的。



    好了，树遍历的练习就做到这里。然而这跟解释器有什么关系呢？下面我们只把它改一下，就可以得到一个简单的解释器。


一个计算器


    计算器也是一种解释器，只不过它只能处理算术表达式。我们的下一个目标，就是写出一个计算器。如果你给它 '(* (+ 1 2) (+ 3 4))，它就输出 21。可不要小看这个计算器，稍后我们把它稍加改造，就可以得到一个更多功能的解释器。



    上面的代码里，我们利用递归遍历，对树里的数字求和。那段代码里，其实已经隐藏了一个解释器的框架。你观察一下，一个算术表达式  '(* (+ 1 2) (+ 3 4))，跟二叉树 '((1 2) (3 4)) 有什么不同？发现没有，这个算术表达式比起二叉树，只不过在每个子树结构里多出了一个操作符：一个 * 和两个 + 。它不再是一棵二叉树，而是一种更通用的树结构。



    这点区别，也就带来了二叉树求和与解释器算法的区别。对二叉树进行求和的时候，在每个子树节点，我们都做加法。而对表达式进行解释的时候，在每一个子树节点，我们不一定进行加法。根据子树的“操作符”不同，我们可能会选择加，减，乘，除四种操作。



    好了，下面就是这个计算器的代码。它接受一个表达式，输出一个数字作为结果。


#lang racket      ; 声明用 Racket 语言

(define calc
  (lambda (exp)
    (match exp    ; 分支匹配：表达式的两种情况
      [(? number? x) x]  ; 是数字，直接返回
      [`(,op ,e1 ,e2)    ; 匹配提取操作符op和两个操作数e1,e2
(let ([v1 (calc e1)]     ; 递归调用 calc 自己，得到 e1 的值
      [v2 (calc e2)])    ; 递归调用 calc 自己，得到 e2 的值
  (match op; 分支匹配：操作符 op 的 4 种情况
    ['+ (+ v1 v2)]; 如果是加号，输出结果为 (+ v1 v2)
    ['- (- v1 v2)]; 如果是减号，乘号，除号，相似的处理
    ['* (* v1 v2)]
    ['/ (/ v1 v2)]))])))



    你可以得到如下的结果：


(calc '(+ 1 2))
;; =&gt; 3
(calc '(* 2 3))
;; =&gt; 6
(calc '(* (+ 1 2) (+ 3 4)))
;; =&gt; 21



    （完整的代码和示例，可以在这里下载。）



    跟之前的二叉树求和代码比较一下，你会发现它们惊人的相似，因为解释器本来就是一个树遍历算法。不过你发现它们有什么不同吗？它们的不同点在于：




    算术表达式的模式里面，多出了一个“操作符”（op）叶节点：(,op ,e1 ,e2)


    对子树 e1 和 e2 分别求值之后，我们不是返回 (+ v1 v2)，而是根据 op 的不同，返回不同的结果：


(match op
  ['+ (+ v1 v2)]
  ['- (- v1 v2)]
  ['* (* v1 v2)]
  ['/ (/ v1 v2)])





    最后你发现，一个算术表达式的解释器，不过是一个稍加扩展的树遍历算法。


R2：一个很小的程序语言


    实现了一个计算器，现在让我们过渡到一种更强大的语言。为了方便称呼，我给它起了一个萌萌哒名字，叫 R2。R2 比起之前的计算器，只多出四个元素，它们分别是：变量，函数，绑定，调用。再加上之前介绍的算术操作，我们就得到一个很简单的程序语言，它只有5种不同的构造。用 Scheme 的语法，这5种构造看起来就像这样：



变量：x
函数：(lambda (x) e)
绑定：(let ([x e1]) e2)
调用：(e1 e2)
算术：(• e2 e2)




    （其中，• 是一个算术操作符，可以选择 +, -, *, / 其中之一）



    一般程序语言还有很多其它构造，可是一开头就试图去实现所有那些，只会让人糊涂。最好是把这少数几个东西搞清楚，确保它们正确之后，才慢慢加入其它元素。



    这些构造的语义，跟 Scheme 里面的同名构造几乎一模一样。如果你不清楚什么是”绑定“，那你可以把它看成是普通语言里的”变量声明“。



    需要注意的是，跟一般语言不同，我们的函数只接受一个参数。这不是一个严重的限制，因为在我们的语言里，函数可以被作为值传递，也就是所谓“first-class function”。所以你可以用嵌套的函数定义来表示有两个以上参数的函数。



    举个例子， (lambda (x) (lambda (y) (+ x y))) 是个嵌套的函数定义，它也可以被看成是有两个参数（x 和 y）的函数，这个函数返回 x 和 y 的和。当这样的函数被调用的时候，需要两层调用，就像这样：


(((lambda (x) (lambda (y) (+ x y))) 1) 2)
;; =&gt; 3



    这种做法在PL术语里面，叫做咖喱（currying）。看起来啰嗦，但这样我们的解释器可以很简单。等我们理解了基本的解释器，再实现真正的多参数函数也不迟。



    另外，我们的绑定语法 (let ([x e1]) e2)，比起 Scheme 的绑定也有一些局限。我们的 let 只能绑定一个变量，而 Scheme 可以绑定多个，像这样 (let ([x 1] [y 2]) (+ x y))。这也不是一个严重的限制，因为我们可以啰嗦一点，用嵌套的 let 绑定：


(let ([x 1])
  (let ([y 2])
    (+ x y)))


R2 的解释器


    下面是我们今天要完成的解释器，它可以运行一个 R2 程序。你可以先留意一下各部分的注释。


#lang racket

;;; 以下三个定义 env0, ext-env, lookup 是对环境（environment）的基本操作：

;; 空环境
(define env0 '())

;; 扩展。对环境 env 进行扩展，把 x 映射到 v，得到一个新的环境
(define ext-env
  (lambda (x v env)
    (cons `(,x . ,v) env)))

;; 查找。在环境中 env 中查找 x 的值。如果没找到就返回 #f
(define lookup
  (lambda (x env)
    (let ([p (assq x env)])
      (cond
[(not p) #f]
[else (cdr p)]))))

;; 闭包的数据结构定义，包含一个函数定义 f 和它定义时所在的环境
(struct Closure (f env))

;; 解释器的递归定义（接受两个参数，表达式 exp 和环境 env）
;; 共 5 种情况（变量，函数，绑定，调用，数字，算术表达式）
(define interp
  (lambda (exp env)
    (match exp; 对exp进行模式匹配
      [(? symbol? x) ; 变量
(let ([v (lookup x env)])
  (cond
   [(not v)
    (error "undefined variable" x)]
   [else v]))]      
      [(? number? x) x]     ; 数字
      [`(lambda (,x) ,e)    ; 函数
(Closure exp env)]
      [`(let ([,x ,e1]) ,e2); 绑定
(let ([v1 (interp e1 env)])
  (interp e2 (ext-env x v1 env)))]
      [`(,e1 ,e2)    ; 调用
(let ([v1 (interp e1 env)]
      [v2 (interp e2 env)])
  (match v1
    [(Closure `(lambda (,x) ,e) env-save)
     (interp e (ext-env x v2 env-save))]))]
      [`(,op ,e1 ,e2); 算术表达式
(let ([v1 (interp e1 env)]
      [v2 (interp e2 env)])
  (match op
    ['+ (+ v1 v2)]
    ['- (- v1 v2)]
    ['* (* v1 v2)]
    ['/ (/ v1 v2)]))])))

;; 解释器的“用户界面”函数。它把 interp 包装起来，掩盖第二个参数，初始值为 env0
(define r2
  (lambda (exp)
    (interp exp env0)))



    这里有一些测试例子：


(r2 '(+ 1 2))
;; =&gt; 3

(r2 '(* 2 3))
;; =&gt; 6

(r2 '(* 2 (+ 3 4)))
;; =&gt; 14

(r2 '(* (+ 1 2) (+ 3 4)))
;; =&gt; 21

(r2 '((lambda (x) (* 2 x)) 3))
;; =&gt; 6

(r2
'(let ([x 2])
   (let ([f (lambda (y) (* x y))])
     (f 3))))
;; =&gt; 6

(r2
'(let ([x 2])
   (let ([f (lambda (y) (* x y))])
     (let ([x 4])
(f 3)))))
;; =&gt; 6



    （完整的代码和示例，可以在这里下载。)



    在接下来的几节，我们来仔细看看这个解释器的各个部分。


对基本算术操作的解释


    算术操作一般都是程序里最基本的构造，它们不能再被细分为多个步骤，所以我们先来看看对算术操作的处理。以下就是 R2 解释器处理算术的部分，它是 interp 的最后一个分支。


(match exp
  ... ...
  [`(,op ,e1 ,e2)
   (let ([v1 (interp e1 env)]      ; 递归调用 interp 自己，得到 e1 的值
  [v2 (interp e2 env)])     ; 递归调用 interp 自己，得到 e2 的值
     (match op; 分支：处理操作符 op 的 4 种情况
['+ (+ v1 v2)]; 如果是加号，输出结果为 (+ v1 v2)
['- (- v1 v2)]; 如果是减号，乘号，除号，相似的处理
['* (* v1 v2)]
['/ (/ v1 v2)]))])



    你可以看到它几乎跟刚才写的计算器一模一样，不过现在 interp 的调用多了一个参数 env 而已。这个 env 是所谓“环境”，我们下面很快就讲。


对数字的解释


    对数字的解释很简单，把它们原封不动返回就可以了。



    [(? number? x) x]


变量和函数


    变量和函数是解释器里最麻烦的部分，所以我们来仔细看看。



    变量（variable）的产生，是数学史上的最大突破之一。因为变量可以被绑定到不同的值，从而使函数的实现成为可能。比如数学函数 f(x) = x * 2，其中 x 是一个变量，它把输入的值传递到函数体 x * 2 里面。如果没有变量，函数就不可能实现。



    对变量最基本的操作，是对它的“绑定”（binding）和“取值”（evaluate）。什么是绑定呢？拿上面的函数 f(x) 作为例子。当我们调用 f(1) 时，函数体里面的 x 等于 1，所以 x * 2 的值是 2，而当我们调用 f(2) 时，函数体里面的 x 等于 2，所以 x * 2 的值是 4。这里，两次对 f 的调用，分别对 x 进行了两次绑定。第一次 x 被绑定到了 1，第二次被绑定到了 2。



    你可以把“绑定”理解成这样一个动作，就像当你把插头插进电源插座的那一瞬间。插头的插脚就是 f(x) 里面的那个 x，而 x * 2 里面的 x，则是电线的另外一端。所以当你把插头插进插座，电流就通过这根电线到达另外一端。如果电线导电性能良好，两头的电压应该相等。


环境


    我们的解释器只能一步一步的做事情。比如，当它需要求 f(1) 的值的时候，它分成两步操作：



把 x 绑定到 1，这样函数体内才能看见这个绑定。
进入 f 的函数体，对 x * 2 进行求值。




    这就像一个人做出这两个动作：



把插头插进插座 。
到电线的另外一头，测量它的电压，并且把结果乘以 2。




    在第一步和第二步之间，我们如何记住 x 的值呢？通过所谓“环境”！我们用环境记录变量的值，并且把它们传递到变量的“可见区域”。变量的可见区域，用术语说叫做“作用域”（scope）。



    在我们的解释器里，用于处理环境的代码如下：


;; 空环境
(define env0 '())

;; 对环境 env 进行扩展，把 x 映射到 v
(define ext-env
  (lambda (x v env)
    (cons `(,x . ,v) env)))

;; 取值。在环境中 env 中查找 x 的值
(define lookup
  (lambda (x env)
    (let ([p (assq x env)])
      (cond
[(not p) #f]
[else (cdr p)]))))



    这里我们用一种最简单的数据结构，Scheme 的 association list，来表示环境。Association list 看起来像这个样子：((x . 1) (y . 2) (z . 5))。它是一个两元组（pair）的链表，左边的元素是 key，右边的元素是 value。写得直观一点就是：


((x . 1)
 (y . 2)
 (z . 5))



    查表操作就是从头到尾搜索，如果左边的 key 是要找的变量，就返回整个 pair。简单吧？效率很低，但是足够完成我们现在的任务。



    ext-env 函数扩展一个环境。比如，如果原来的环境 env1 是 ((y . 2) (x . 1)) 那么 (ext-env x 3 env1)，就会返回 ((x . 3) (y . 2) (x . 1))。也就是把 (x . 3) 加到 env1 的最前面去。



    那我们什么时候需要扩展环境呢？当我们进行绑定的时候。绑定可能出现在函数调用时，也可能出现在 let 绑定时。我们选择的数据结构，使得环境自然而然的具有了作用域（scope）的特性。



    环境其实是一个堆栈（stack）。内层的绑定，会出现在环境的最上面，这就是在“压栈”。这样我们查找变量的时候，会优先找到最内层定义的变量。



    举个例子：


(let ([x 1])  ; env='()。绑定x到1。
  (let ([y 2]); env='((x . 1))。绑定y到2。
    (let ([x 3])     ; env='((y . 2) (x . 1))。绑定x到3。
      (+ x y))))     ; env='((x . 3) (y . 2) (x . 1))。查找x，得到3；查找y，得到2。
;; =&gt; 5



    这段代码会返回5。这是因为最内层的绑定，把 (x . 3) 放到了环境的最前面，这样查找 x 的时候，我们首先看到 (x . 3)，然后就返回值3。之前放进去的 (x . 1) 仍然存在，但是我们先看到了最上面的那个(x . 3)，所以它被忽略了。



    这并不等于说 (x . 1) 就可以被改写或者丢弃，因为它仍然是有用的。你只需要看一个稍微不同的例子，就知道这是怎么回事：


(let ([x 1])   ; env='()。绑定x到1。
  (+ (let ([x 2])     ; env='((x . 1))。绑定x到2。
x)      ; env='((x . 2) (x . 1))。查找x，得到2。
   x))  ; env='((x . 1))。查找x，得到1。
;; =&gt; 3 ; 两个不同的x的和，1+2等于3。



    这个例子会返回3。它是第3行和第4行里面两个 x 的和。由于第3行的 x 处于内层 let 里面，那里的环境是 ((x . 2) (x . 1))，所以查找 x 的值得到2。第4行的 x 在内层 let 外面，但是在外层 let 里面，那里的环境是 ((x . 1))，所以查找 x 的值得到1。这很符合直觉，因为 x 总是找到最内层的定义。



    值得注意的是，环境被扩展以后，形成了一个新的环境，而原来的环境并没有被改变。比如，上面的 ((y . 2) (x . 1)) 并没有删除或者修改，只不过是被“引用”到一个更大的列表里去了。



    这样不对已有数据进行修改（mutation）的数据结构，叫做“函数式数据结构”。函数式数据结构只生成新的数据，而不改变或者删除老的。它可能引用老的结构，然而却不改变老的结构。这种“不修改”（immutable）的性质，在我们的解释器里是很重要的，因为当我们扩展一个环境，进入递归，返回之后，外层的代码必须仍然可以访问原来外层的环境。



    当然，我们也可以用另外的，更高效的数据结构（比如平衡树，串接起来的哈希表）来表示环境。如果你学究一点，甚至可以用函数来表示环境。这里为了代码简单，我们选择了最笨，然而正确，容易理解的数据结构。


对变量的解释


    了解了变量，函数和环境，我们来看看解释器对变量的“取值”操作，也就是 match 的第一种情况。



    [(? symbol? x) (lookup x env)]



    这就是在环境中，沿着从内向外的“作用域顺序”，查找变量的值。



    这里的 (? symbol? x) 是一种特殊的模式，它使用 Scheme 函数 symbol? 来判断输入是否是一个符号，如果是，就把它绑定到 x，然后你就可以在右边用 x 来指称这个输入。


对绑定的解释


    现在我们来看看对 let 绑定的解释：


[`(let ([,x ,e1]) ,e2)      
 (let ([v1 (interp e1 env)]); 解释右边表达式e1，得到值v1
   (interp e2 (ext-env x v1 env)))]; 把(x . v1)扩充到环境顶部，对e2求值



    通过代码里的注释，你也许已经可以理解它在做什么。我们先对表达式 e1 求值，得到 v1。然后我们把 (x . v1) 扩充到环境里，这样 (let ([x e1]) ...) 内部都可以看到 x 的值。然后我们使用这个扩充后的环境，递归调用解释器本身，对 let 的主体 e2 求值。它的返回值就是这个 let 绑定的值。


Lexical Scoping 和 Dynamic Scoping


    下面我们准备谈谈函数定义和调用。对函数的解释是一个微妙的问题，很容易弄错，这是由于函数体内也许会含有外层的变量，叫做“自由变量”。所以在分析函数的代码之前，我们来了解一下不同的“作用域”（scoping）规则。



    我们举个例子来解释这个问题。下面这段代码，它的值应该是多少呢？


(let ([x 2])
  (let ([f (lambda (y) (* x y))])
    (let ([x 4])
      (f 3))))



    在这里，f 函数体 (lambda (y) (* x y)) 里的那个 x，就是一个“自由变量”。x 并不是这个函数的参数，也不是在这个函数里面定义的，所以我们必须到函数外面去找 x 的值。



    我们的代码里面，有两个地方对 x 进行了绑定，一个等于2，一个等于4，那么 x 到底应该是指向哪一个绑定呢？这似乎无关痛痒，然而当我们调用 (f 3) 的时候，严重的问题来了。f 的函数体是 (* x y)，我们知道 y 的值来自参数 3，可是 x 的值是多少呢？它应该是2，还是4呢？



    在历史上，这段代码可能有两种不同的结果，这种区别一直延续到今天。如果你在 Scheme （Racket）里面写以上的代码，它的结果是6。


;; Scheme
(let ([x 2])
  (let ([f (lambda (y) (* x y))])
    (let ([x 4])
      (f 3))))

;; =&gt; 6



    现在我们来看看，在 Emacs Lisp 里面输入等价的代码，得到什么结果。如果你不熟悉 Emacs Lisp 的用法，那你可以跟我做：把代码输入 Emacs 的那个叫 *scratch* 的 buffer。把光标放在代码最后，然后按 C-x C-e，这样 Emacs 会执行这段代码，然后在 minibuffer 里显示结果：



    



    结果是12！如果你把代码最内层的 x 绑定修成其它的值，输出会随之改变。



    奇怪吧？Scheme 和 Emacs Lisp，到底有什么不一样呢？实际上，这两种看似差不多的 “Lisp 方言”，采用了两种完全不同的作用域方式。Scheme 的方式叫做 lexical scoping （或者 static scoping），而 Emacs 的方式叫做 dynamic scoping。



    那么哪一种方式更好呢？或者用哪一种都无所谓？答案是，dynamic scoping 是非常错误的做法。历史的教训告诉我们，它会带来许许多多莫名其妙的 bug，导致 dynamic scoping 的语言几乎完全没法用。这是为什么呢？



    原因在于，像 (let ((x 4)) …) 这样的变量绑定，只应该影响它内部“看得见”的 x 的值。当我们看见  (let ((x 4)) (f 3)) 的时候，并没有在 let 的内部看见任何叫“x” 的变量，所以我们“直觉”的认为，(let ((x 4)) …) 对 x 的绑定，不应该引起 (f 3) 的结果变化。



    然而对于 dynamic scoping，我们的直觉却是错误的。因为 f 的函数体里面有一个 x，虽然我们没有在 (f 3) 这个调用里面看见它，然而它却存在于 f 定义的地方。要知道，f 定义的地方也许隔着几百行代码，甚至在另外一个文件里面。而且调用函数的人凭什么应该知道， f 的定义里面有一个自由变量，它的名字叫做 x？所以 dynamic scoping 在设计学的角度来看，是一个反人类的设计 :)



    相反，lexical scoping 却是符合人们直觉的。虽然在 (let ((x 4)) (f 3)) 里面，我们把 x 绑定到了 4，然而 f 的函数体并不是在那里定义的，我们也没在那里看见任何 x，所以 f 的函数体里面的 x，仍然指向我们定义它的时候看得见的那个 x，也就是最上面的那个 (let ([x 2]) ...)，它的值是 2。所以 (f 3) 的值应该等于 6，而不是12。


对函数的解释


    为了实现 lexical scoping，我们必须把函数做成“闭包”（closure）。闭包是一种特殊的数据结构，它由两个元素组成：函数的定义和当前的环境。我们把闭包定义为一个 Racket 的 struct 结构：


(struct Closure (f env))



    有了这个数据结构，我们对 (lambda (x) e) 的解释就可以写成这样：


[`(lambda (,x) ,e)
 (Closure exp env)]



    注意这里的 exp 就是 `(lambda (,x) ,e) 自己。



    有意思的是，我们的解释器遇到  (lambda (x) e)，几乎没有做任何计算。它只是把这个函数包装了一下，把它与当前的环境一起，打包放到一个数据结构（Closure）里面。这个闭包结构，记录了我们在函数定义的位置“看得见”的那个环境。稍候在调用的时候，我们就能从这个闭包的环境里面，得到函数体内的自由变量的值。


对调用的解释


    好了，我们终于到了最后的关头，函数调用。为了直观，我们把函数调用的代码拷贝如下：


[`(,e1 ,e2)  
 (let ([v1 (interp e1 env)]      ; 计算函数 e1 的值
[v2 (interp e2 env)])     ; 计算参数 e2 的值
   (match v1
     [(Closure `(lambda (,x) ,e) env-save)      ; 用模式匹配的方式取出闭包里的各个子结构
      (interp e (ext-env x v2 env-save))]))]    ; 在闭包的环境env-save中把x绑定到v2，解释函数体     



    函数调用都是 (e1 e2) 这样的形式，e1 表示函数，e2 是它的参数。我们需要先分别求出函数 e1 和参数 e2 的值。



    函数调用就像把一个电器的插头插进插座，使它开始运转。比如，当 (lambda (x) (* x 2)) 被作用于 1 时，我们把 x 绑定到 1，然后解释它的函数体 (* x 2)。但是这里有一个问题，函数体内的自由变量应该取什么值呢？从上面闭包的讨论，你已经知道了，自由变量的值，应该从闭包的环境查询。



    操作数 e1 的值 v1 是一个闭包，它里面包含一个函数定义时保存的环境 env-save。我们把这个环境 env-save 取出来，那我们就可以查询它，得到函数体内自由变量的值。然而函数体内不仅有自由变量，还有对函数参数的使用，所以我们必须扩展这个 env-save 环境，把参数的值加进去。这就是为什么我们使用 (ext-env x v2 env-save)，而不只是 env-save。



    你可能会奇怪，那么解释器的环境 env 难道这里就不用了吗？是的。我们通过 env 来计算 e1 和 e2 的值，是因为 e1 和 e2 里面的变量，在“当前环境”（env）里面看得见。可是函数体的定义，在当前环境下是看不见的。它的代码在别的地方，而那个地方看得见的环境，被我们存在闭包里了，它就是 env-save。所以我们把 v1 里面的闭包环境 env-save 取出来，用于计算函数体的值。



    有意思的是，如果我们用 env，而不是env-save 来解释函数体，那我们的语言就变成了 dynamic scoping。现在来实验一下：你可以把 (interp e (ext-env x v2 env-save)) 里面的 env-save 改成 env，再试试我们之前讨论过的代码，它的输出就会变成 12。那就是我们之前讲过的，dynamic scoping 的结果。


(r2
'(let ([x 2])
   (let ([f (lambda (y) (* x y))])
     (let ([x 4])
(f 3)))))

;; =&gt; 12



    你也许发现了，如果我们的语言是 dynamic scoping，那就没必要使用闭包了，因为我们根本不需要闭包里面保存的环境。这样一来，dynamic scoping 的解释器就可以写成这样：


(define interp
  (lambda (exp env)
    (match exp
      ... ...
      [`(lambda (,x) ,e)     ; 函数：直接返回自己的表达式
exp]
      ... ...
      [`(,e1 ,e2)    
(let ([v1 (interp e1 env)]
      [v2 (interp e2 env)])
  (match v1
    [`(lambda (,x) ,e); 调用：直接使用函数的表达式本身
     (interp e (ext-env x v2 env))]))]
      ... ...
)))



    注意到这个解释器的函数有多容易实现吗？它就是这个函数的表达式自己，原封不动。用函数的表达式本身来表示它的值，是很直接很简单的做法，也是大部分人一开头就会想到的。然而这样实现出来的语言，就不知不觉地采用了 dynamic scoping。



    这就是为什么很多早期的 Lisp 语言，比如 Emacs Lisp，都使用 dynamic scoping。这并不是因为它们的设计者在 dynamic scoping 和 lexical scoping 两者之中做出了选择，而是因为使用函数的表达式本身来作为它的值，是最直接，一般人都会首先想到的做法。



    另外，在这里我们也看到环境用“函数式数据结构”表示的好处。闭包被调用时它的环境被扩展，但是这并不会影响原来的那个环境，我们得到的是一个新的环境。所以当函数调用返回之后，函数的参数绑定就自动“注销”了。



    如果你用一个非函数式的数据结构，在绑定参数时不生成新的环境，而是对已有环境进行赋值，那么这个赋值操作就会永久性的改变原来环境的内容。所以你在函数返回之后必须删除参数的绑定。这样不但麻烦，而且在复杂的情况下很容易出错。



    思考题：可能有些人看过 lambda calculus，这些人可能知道 (let ([x e1]) e2) 其实等价于一个函数调用：((lambda (x) e2) e1)。现在问题来了，我们在讨论函数和调用的时候，很深入的讨论了关于 lexical scoping 和 dynamic scoping 的差别。既然 let 绑定等价于一个函数定义和调用，为什么之前我们讨论对绑定的时候，没有讨论过 lexical scoping 和 dynamic scoping 的问题，也没有制造过闭包呢？


不足之处


    现在你已经学会了如何写出一个简单的解释器，它可以处理一个相当强的，具有“first-class 函数”的语言。出于教学的考虑，这个解释器并没有考虑实用的需求，所以它并不能作为“工业应用”。在这里，我指出它的一些不足之处。




    缺少必要的语言构造。我们的语言里缺少好些实用语言必须的构造：递归，数组，赋值操作，字符串，自定义数据结构，…… 作为一篇基础性的读物，我不能把这些都加进来。如果你对这些有兴趣，可以看看其它书籍，或者等待我的后续作品。


    不合法代码的检测和报告。你也许发现了，这个解释器的 match 表达式，全都假定了输入都是合法的程序，它并没有检查不合法的情况。如果你给它一个不合法的程序，它的行为会变得诡异。一个实用的解释器，必须加入对代码格式进行全面检测，报告不合法的代码结构。


    低效率的数据结构。在 association list 里面查找变量，是线性的复杂度。当程序有很多变量的时候就有性能问题。一个实用的解释器，需要更高效的数据结构。这种数据结构不一定非得是函数式的。你也可以用非函数式的数据结构（比如哈希表），经过一定的改造，达到同样的性质，却具有更高的效率。
​
另外，你还可以把环境转化成一个数组。给环境里的每个变量分配一个下标（index），在这个数组里就可以找到它的值。如果你用数组表示环境，那么这个解释器就向编译器迈进了一步。


    S表达式的歧义问题。为了教学需要，我们的解释器直接使用S表达式来表达语法树，用模式匹配来进行分支遍历。在实际的语言里，这种方式会带来比较大的问题。因为S表达式是一种通用的数据结构，用它表示的东西，看起来都差不多的样子。一旦程序的语法构造多起来，直接对S表达式进行模式匹配，会造成歧义。
​



    比如 (,op ,e1 ,e2) ，你以为它只匹配二元算术操作，比如 (+ 1 2)。但它其实也可以匹配一个 let 绑定： (let ([x 1]) (* x 2))。这是因为它们顶层元素的数目是一样的。为了消除歧义，你得小心的安排模式的顺序，比如你必须把 (let ([,x ,e1]) ,e2) 的模式放在 (,op ,e1, e2) 前面。所以最好的办法，是不要直接在S表达式上写解释器，而是先写一个“parser”，这个parser把S表达式转换成 Racket 的 struct 结构。然后解释器再在 struct 上面进行分支匹配。这样解释器不用担心歧义问题，而且会带来效率的提升。




付费方式


    如果你喜欢这篇文章，愿意鼓励我继续出品这类精品，欢迎向我的支付宝账号进行捐款。



    



    在美国的朋友，也可以通过paypal捐款：【PayPal付款链接】


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 什么是语义学

 
 
 
 
    

    
 
     
  

      
   
什么是语义学

    



    很多人问我如何在掌握基本的程序语言技能之后进入“语义学”的学习。现在我就简单介绍一下什么是“语义”，然后推荐一本入门的书。这里我说的“语义”主要是针对程序语言，不过自然语言里的语义，其实本质上也是一样的。



    一个程序的“语义”通常是由另一个程序决定的，这另一个程序叫做“解释器”(interpreter)。程序只是一个数据结构，通常表示为语法树(abstract syntax tree)或者指令序列。这个数据结构本身其实没有意义，是解释器让它产生了意义。对同一个程序可以有不同的解释，就像上面这幅图，对画面元素的不同解释，可以看到不同的内容（少女或者老妇）。



    解释器接受一个“程序”(program)，输出一个“值”(value)。用图形的方法表示，解释器看起来就像一个箭头：程序 ===> 值。这个所谓的“值”可以具有非常广泛的含义。它可能是一个整数，一个字符串，也有可能是更加奇妙的东西。



    其实解释器不止存在于计算机中，它是一个很广泛的概念。其中好些你可能还没有意识到。写 Python 程序，需要 Python 解释器，它的输入是 Python 代码，输出是一个 Python 里面的数据，比如 42 或者“foo”。CPU 其实也是一个解释器，它的输入是以二进制表示的机器指令，输出是一些电信号。人脑也是一个解释器，它的输入是图像或者声音，输出是神经元之间产生的“概念”。如果你了解类型推导系统 (type inference)，就会发现类型推导的过程也是一个解释器，它的输入是一个程序，输出是一个“类型”。类型也是一种值，不过它是一种抽象的值。比如，42 对应的类型是 int，我们说 42 被抽象为 int。



    所以“语义学”，基本上就是研究各种解释器。解释器的原理其实很简单，但是结构非常精巧微妙，如果你从复杂的语言入手，恐怕永远也学不会。最好的起步方式是写一个基本的 lambda calculus 的解释器。lambda calculus 只有三种元素，却可以表达所有程序语言的复杂结构。



    专门讲语义的书很少，现在推荐一本我觉得深入浅出的：《Programming Languages and Lambda Calculi》。只需要看完前半部分（Part I 和 II，100来页）就可以了。这书好在什么地方呢？它是从非常简单的布尔表达式（而不是 lambda calculus）开始讲解什么是递归定义，什么是解释，什么是 Church-Rosser，什么是上下文 (evaluation context)。在让你理解了这种简单语言的语义，有了足够的信心之后，才告诉你更多的东西。比如 lambda calculus 和 CEK，SECD 等抽象机 (abstract machine)。理解了这些概念之后，你就会发现所有的程序语言都可以比较容易的理解了。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 GTF - Great Teacher Friedman

 
 
 
 
    

    
 
     
  

      
   
GTF - Great Teacher Friedman
写小人书的老顽童


    Dan Friedman 是 Indiana 大学的教授，程序语言领域的创始人之一。他主要的著作《The Little Schemer》（前身叫《The Little Lisper》) 是程序语言界最具影响力的书籍之一。现在很多程序语言界的元老级人物，当年都是看这本“小人书”学会了 Lisp/Scheme，才决心进入这一领域。



    




    Friedman 对程序语言的理解可以说是世界的最高标准，很可惜的是，由于他个人的低调，他受到很多人的误解。很多人以为他只懂得 Scheme 这种“类型系统落后的语言”。有些人觉得他只顾自己玩，不求“上进”，觉得他的研究闭门造车，不“前沿”。我也误解过他，甚至在见面之前，根据这些书的封面，我断定他肯定是个年轻小伙。结果呢，第一次见到他的时候，他已经过了60岁大寿。



    程序语言的研究者们往往追逐一些“新概念”，却未能想到很多这些新概念早在几十年前就被 Friedman 想到了。举个例子，Haskell 所用的 lazy evaluation 模型，最早就是他在 1976 年在与 David Wise 合写的论文“CONS should not Evaluate its Arguments”中提出来的。



    虽然写了 The Little Schemer， 但 Friedman 的学识并不限于 Scheme。他不断地实验各种其它的语言设计，包括像 ML 一类的含有静态类型系统的函数式语言，逻辑式语言，面向对象语言，用于定理证明的语言等等。在每次的试验之后，他几乎都会写一本书，揭示这些语言最精要的部分。



    觉得 ML 比 Scheme 先进很多的人们应该看看 Friedman 这本书：The Little MLer：



    



    想要真正理解 Java 设计模式的人可以看看这本：A Little Java, A Few Patterns:



    



    这些东西的优点和弱点仿佛在他心里都有数，他几乎总是指向正确的前进方向。


你知道些什么？


    可惜的是，由于个人原因，Friedman 始终没有成为我正式的导师（他 “超然物外”，几乎完全不关心自己的学生什么时候能毕业），但他确实是这一生中教会我最多东西的人。所以我想写一些关于他的小故事。也许你能从中看出一个世界级的教育者是什么样子的。我来 IU 之前一位师兄告诉我，Dan Friedman 就像指环王里的甘道夫 (Gandalf)，来了之后发现确实很像。



    第一次在办公室见到 Friedman 的时候，他对我说：“来，给我讲讲你知道些什么？”我自豪地说：“我在 Cornell 上过研究生的程序语言课，会用 ML 和 Haskell，看过 Paul Graham 的 On Lisp，Peter Norvig 的 Paradigms of Artificial Intelligence Programming, Richard Gabriel 的一些文章……” 他看着我平静地笑了：“不错，你已经有一定基础……”



    这么几年以后，我才发现他善良的微笑里面其实隐藏着难以启齿的秘密：当时的我是多么的幼稚。在他的这种循循善诱之下，我才逐渐的明白了，知识的深度是无止境的。他的水平其实远在以上这些人之上，可是出于谦虚，他不能自己把这话说出来。


反向运行


    Dan Friedman 已经远远超过了退休年龄，却仍然坚持教学。他的本科生程序语言课程 C311 是 IU 的“星级课程”。我最敬佩的，其实是他那孩子般的好奇心和探索精神。几乎每一年的 C311，他都会发明不同的东西来充实课程内容。有时候是一种新的逻辑编程语言 (叫 miniKanren)，有时候是些小技巧 （比如把 Scheme 编译成 C 却不会堆栈溢出），等等。



    Friedman 研究一个东西的时候总是全身心的投入，执着的热爱。自从开始设计一个叫 miniKanren 的逻辑编程语言，Friedman 多了一句口头禅：“Does it run backwards?”（能反向运行吗？）因为逻辑式的语言（像Prolog）的程序都是能“反向运行”的。普通程序语言写的程序，如果你给它一个输入，它会给你一个输出。但是逻辑式语言很特别，如果你给它一个输出，它可以反过来运行，给你所有可能的输入。但是 Friedman 真的走火入魔了。不管别人在讲什么，经常最后都会被他问一句：“Does it run backwards?”让你哭笑不得。



    Friedman 有一个本领域的人都知道的“弱点”——他不喜欢静态类型系统 (static type system)。其实 Scheme 专家们大部分都不喜欢静态类型系统。为此，他深受“类型专家”们的误解甚至鄙视，可是他都从容对待之。



    有一次在他的进阶课程 B621 上，他给我们出了一道题：用 Scheme 实现 ML 和 Haskell 所用的 Hindley-Milner 类型系统。这种类型系统的工作原理一般是，输入一个程序，它经过对程序进行类型推导（type inference），输出一个类型。如果程序里有类型错误，它就会报错。由于之前在 Cornell 用 ML 实现过这东西，再加上来到 IU 之后对抽象解释 (abstract interpretation) 的进一步理解，我很快做出了这个东西，而且比在 Cornell 的时候做的还要优雅。



    他知道我做出来了，很高兴的样子，让我给全班同学（也就8，9个人）讲我的做法。当我自豪的讲完，他问：“Does it run backwards? 如果我给它一个类型，它能自动生成出符合这个类型的程序来吗？”我愣了，欲哭无泪啊，“不能……”他往沙发靠背上一躺，得意的笑了：“我的系统可以！哈哈！我当年写的那个类型系统比你这个还要短呢。我早就知道这些类型系统怎么做，可我就是不喜欢。哈哈哈哈……”



    我后来对类型系统的进一步研究显示，Hindley-Milner 类型系统确实有很多不必要的问题，才导致了他不喜欢。他就是这样一个老顽童。他喜欢先把你捧上天，再把你打下来，让你知道天外有天 :-)


miniCoq


    你永远想象不到 Dan Friedman 的思维的极限在哪里。当你认为他是一个函数式语言专家的时候，他设计了 miniKanren，一种逻辑式编程语言 (logic programming language)，并且写出 《The Reasoned Schemer》这样的书，用于教授逻辑编程。当你认为他不懂类型系统的时候，他开始捣鼓最尖端的 Martin-Löf 类型理论，并且开始设计机器证明系统。而他做这些，完全是出于自己的兴趣。他从来不在乎别人在这个方向已经做到了什么程度，却经常能出乎意料的简化别人的设计。



    有一次系里举办教授们的“闪电式演讲”(lightening talk)，每位教授只有5分钟时间上去介绍自己的研究。轮到 Friedman 的时候，他慢条斯理的走上去，说：“我不着急。我只有几句话要说。我不知道我能不能拖够5分钟……”大家都笑了。他接着说：“我现在最喜欢的东西是 Curry-Howard correspondence 和定理证明。我觉得现在的机器证明系统太复杂了，比如 Coq 有 nnnnn 行代码。我想在 x 年之内，简化 Coq，得到一个 miniCoq……”



    miniCoq... 听到这个词全场都笑翻了。为什么呢？自己去联想吧。从此，“Dan Friedman 的 miniCoq” 成为了 IU 的程序语言学生茶余饭后的笑话。



    但是 Firedman 没有吹牛。他总是说到做到。他已经写出一个简单的定理证明工具叫 JBob（迫于社会舆论压力，不能叫 miniCoq），而且正在写一本书叫 《The Little Prover》，用来教授最重要的定理证明思想。他开始在 C311 上给本科生教授这些内容。我看了那本书的初稿，获益至深，那是很多 Coq 的教材都不涉及的最精华的道理。它不仅教会我如何使用定理证明系统，而且教会了我如何设计一个定理证明系统。我对他说：“你总是有新的东西教给我们。每隔两年，我们就得重新上一次你的课！”


C311


    当我刚从 Cornell 转学到 IU 的时候，Dan Friedman 叫我去上他的研究生程序语言课 B521。我当时以自己在 Cornell 上过程序语言课程为由，想不去上他的课。Friedman 把我叫到他的办公室，和蔼的对我说：“王垠，我知道你在 Cornell 上过这种课。我也知道 Cornell 是比 IU 好很多的学校。可是每个老师的教学方法都是不一样的，你应该来上我的课。我和我的朋友们在这里做教授，不是因为喜欢这个学校，而是因为我们的家人和朋友都在这里。”后来由于跟 Amr Sabry（我现在的导师）的课程 B522 时间重合，他特别安排我坐在本科生的 C311 的课堂上，却拿研究生课程的学分。后来发现，这两门课的内容基本没有区别，只不过研究生的作业要多一些。



    在第一堂课上，他说了一句让我记忆至今的话：“《The Little Schemer》和《Essentials of Programming Languages》是这门课的参考教材，但是我上课从来不讲我的书里的内容。”刚一开始，我就发现这门课跟我在 Cornell 学到的东西很不一样。虽然有些概念，比如 closure，CPS，我在 Cornell 都学过，在他的课堂上，我却看到这些概念完全不同的一面，以至于我觉得其实我之前完全不懂这些概念！这是因为在 Cornell 学到这些东西的时候只是用来应付作业，而在 Friedman 的课上，我利用它们来完成有实际意义的目标，所以才真正的体会到这些概念的内涵和价值。



    一个例子就是课程进入到没几个星期的时候，我们开始写解释器来执行简单的 Scheme 程序。然后我们把这个解释器进行 CPS 变换，引入全局变量作为"寄存器" (register)，把 CPS 产生的 continuation 转换成数据结构（也就是堆栈）。最后我们得到的是一个抽象机 (abstract machine)，而这在本质上相当于一个真实机器里的中央处理器（CPU）或者虚拟机（比如 JVM）。所以我们其实从无到有，“发明”了 CPU！从这里，我才真正的理解到寄存器，堆栈等的本质，以及我们为什么需要它们。我才真正的明白了，冯诺依曼体系构架为什么要设计成这个样子。后来他让我们去看一篇他的好朋友 Olivier Danvy 的论文，讲述如何从各种不同的解释器经过 CPS 变换得出不同种类的抽象机模型。这是我第一次感觉到程序语言的理论对于现实世界的巨大威力，也让我理解到，机器并不是计算的本质。机器可以用任何可行的技术实现，比如集成电路，激光，分子，DNA…… 但是无论用什么作为机器的材料，我们所要表达的语义，也就是计算的本质，却是不变的。



    而这些还不是我那届 C311 全部的内容。后半学期，我们开始学习 miniKanren，一种他自己设计的用于教学的逻辑式语言 (logic programming language)。这个语言类似 Prolog，但是它把 Prolog 的很多缺点给去掉了，而且变得更加容易理解。教材是免费送给我们的《The Reasoned Schemer》。在书的最后，两页纸的篇幅，就是整个 miniKanren 语言的实现！我学得比较快，后来就开始捣鼓这个实现，把有些部分重新设计了一下，然后加入了一些我想要的功能。这样的教学，给了我设计逻辑式语言的能力，而不只是停留于一个使用者。这是学习 Prolog 不可能做到的事情，因为 Prolog 的复杂性会让初学者无从下手，只能停留在使用者的阶段。



    我很幸运当初听了他的话去上了这门课，否则我就不会是今天的我。


独立思维


    Dan Friedman 是一个不随波逐流，有独立思想的人。他的眼里容不下过于复杂的东西，他喜欢把一个东西简化到容得进几行程序，把相关的问 题理解得非常清楚。他的书是一种独特的“问答式”的结构，很像孔夫子或者苏格拉底的讲学方式。他的教学方式也非常独特。这在本科生课程 C311 里已经有一些表现，但是在研究生的课程 B621 里，才全部的显示出来。



    我写过的最满意的一个程序，自动 CPS 变换，就是在 C311 产生的。在 C311 的作业里，Friedman 经常加入一些“智力题”（brain teaser），做出来了可以加分。因为我已经有一定基础，所以我有精力来做那些智力题。开头那些题还不是很难，直到开始学 CPS 的时候，出现了这么一道：“请写出一个叫 CPSer 的程序，它的作用是自动的把 Scheme 程序转换成 CPS 形式。”那次作业的其它题目都是要求“手动”把程序变成 CPS 形式，这道智力题却要求一个“自动”的——用一个程序来转换另一个程序。



    我觉得很有意思。如果能写出一个自动的 CPS 转换程序，那我岂不是可以用它完成所有其它的题目了！所以我就开始捣鼓这个东西，最初的想法其实就是“模拟”一个手动转换的过程。然后我发现这真是个怪物，就那么几十行程序，不是这里不对劲，就是那里不对劲。这里按下去一个 bug，那里又冒出来一个，从来没见过这么麻烦的东西。我就跟它死磕了，废寝忘食几乎一星期。经常走进死胡同，就只有重新开始，不知道推翻重来了多少次。到快要交作业的时候，我把它给弄出来了。最后我用它生成了所有其它的答案，产生的 CPS 代码跟手工转换出来的看不出任何区别。当然我这次我又得了满分（因为每次都做智力题，我的分数总是在100以上）。



    作业发下来那天下课后，我跟 Friedman 一起走回 Lindley Hall（IU 计算机系的楼）。半路上他问我：“这次的 brain teaser 做了没有。”我说：“做了。这是个好东西啊，帮我把其它作业都做出来了。”他有点吃惊，又有点将信将疑的样子：“你确信你做对了？”我说：“不确信它是完全正确，但是转换后的作业程序全都跟手工做的一样。”走回办公室之后，他给了我一篇30多页的论文 “Representing control: a study of the CPS transformation”，作者是他的好朋友 Olivier Danvy 和 Andrzej Filinski。然后我才了解到，这是这个方向最厉害的两个人。正是这篇论文，解决了这个悬而不决十多年的难题。其实自动的 CPS 转换，可以被用于实现高效的函数式语言编译器。Princeton 大学的著名教授 Andrew Appel 写了一本书叫《Compiling with Continuations》，就是专门讲这个问题的。Amr Sabry（我现在的导师）当年的博士论文就是一个比 CPS 还要简单的变换（叫做 ANF）。凭这个东西，他几乎灭掉了这整个 CPS 领域，并且拿到了终身教授职位。在他的论文发表10年之内也没有 CPS 的论文出现。



    Friedman 啊，把这样一个问题作为“智力题”，真有你的！我开玩笑地对他说：“我保证，我不会把这个程序开源，不然以后你的 C311 学生们就可以拿来作弊了。”回到家，我开始看那篇 Danvy 和 Filinski 的论文。这篇 1991 年的论文的想法，是从 1975 年一篇 Gordon Plotkin 的论文的基础上经过一系列繁琐的推导得出来的，而它最后的结果几乎跟我的程序一模一样，只不过我的程序可以处理更加复杂的 Scheme，而不只是 lambda calculus。我之前完全不知道 Plotkin 的做法，从而完全没有收到他的思想的影响，直接就得到了最好的结果。这是我第一次认识到自己头脑的威力。



    第二个学期，当我去上 Friedman 的进阶课程 B621 的时候，他给我们出了同样的题目。两个星期下来，没有其它人真正的做对了。最后他对全班同学说：“现在请王垠给大家讲一下他的做法。你们要听仔细了哦。这个程序价值100美元！”



    下面就是我的程序对于 lambda calculus 的缩减版本。我怎么也没想到，这短短 30 行代码耗费了很多人 10 年的时间才琢磨出来。


(define cps
  (lambda (exp)
    (letrec
 ([trivs '(zero? add1 sub1)]
  [id (lambda (v) v)]
  [C~ (lambda (v) `(k ,v))]
  [fv (let ((n -1))
 (lambda ()
   (set! n (+ 1 n))
   (string-&gt;symbol (string-append "v" (number-&gt;string n)))))]
  [cps1
   (lambda (exp C)
     (pmatch exp
[,x (guard (not (pair? x))) (C x)]
[(lambda (,x) ,body)
 (C `(lambda (,x k) ,(cps1 body C~)))]
[(,rator ,rand)
 (cps1 rator
(lambda (r)
  (cps1 rand
 (lambda (d)
   (cond
    [(memq r trivs)
     (C `(,r ,d))]
    [(eq? C C~)  ; tail call
     `(,r ,d k)]
    [else
     (let ([v* (fv)])
`(,r ,d (lambda (,v*) ,(C v*))))])))))]))])
      (cps1 exp id))))



    而这还不是 B621 的全部，每一个星期 Friedman 会在黑板上写下一道很难的题目。他不让你看书或者看论文。他有时甚至不告诉你题目里相关概念的名字，或者故意给它们起个新名字，让你想查都查不到。他要求你完全靠自己把这些难题解出来，下一个星期的时候在黑板上给其它同学讲解。他没有明确的评分标准，让你感觉完全没有成绩的压力。



    这些题目包括一些很难的问题， 比如 church numeral 的前驱 (predecessor)。这个问题，当年是 Stephen Kleene （图灵的学长） 花了三个月冥思苦想才做出来的。不幸的是我在 Cornell 就学到了 Kleene 的做法，造成了思维的定势，所以这个训练当时对我来说失去了意义。而我们班上却有一个数学系的同学，出人意料的在一个星期之内做出了一个比 Kleene 还要简单的方法。他的完整的代码（用传统的 lambda calculus 语法表示）如下：


λn w z. ((n λl h. h (l w)) (λd.z)) (λx.x)



    其它的问题包括从 lambda calculus 到 SKI combinator 的编译器，逻辑式（可逆）CPS 变换，实现 Hindley-Milner 类型系统，等等。我发现，就算自认为明白了的东西，经过一番思索，认识居然还可以更进一步。



    当然，重新发明东西并不会给我带来论文发表，但是它却给我带来了更重要的东西，这就是独立的思考能力。一旦一个东西被你“想”出来，而不是从别人那里 “学”过来，那么你就知道这个想法是如何产生的。这比起直接学会这个想法要有用很多，因为你知道这里面所有的细节和犯过的错误。而最重要的，其实是由此得到的直觉。如果直接去看别人的书或者论文，你就很难得到这种直觉，因为一般人写论文都会把直觉埋藏在一堆符号公式之下，让你看不到背后的真实想法。如果得到了直觉，下一次遇到类似的问题，你就有可能很快的利用已有的直觉来解决新的问题。



    而这一切都已经发生在我身上。比如在听说 ANF 之后，我没有看 Amr Sabry 的论文，只把我原来的 CPSer 程序改了一点点，就得到了 ANF 变换，整个过程只花了十几分钟。而在 R. Kent Dybvig 的编译器课程上，我利用 CPS 变换里面的直觉，改造和合并了 Dybvig 提供的编译器框架的好几个 pass，使得它们变得比原来短小好几倍，却生成更好的代码。



    现在我仍然是这样，喜欢故意重新发明一些东西，探索不止一个领域。这让我获得了直觉，不再受别人思想的限制，节省了看论文的时间，而且多了一些乐趣。一个问题，当我相信自己能想得出来，一般都能解决。虽然我经常不把我埋头做出来的东西放在心上，把它们叫做“重新发明”(reinvention)，但是出乎意料的是，最近我发现这里面其实隐藏了一些真正的发明。我准备慢慢把其中一些想法发掘整理出来，发表成论文或者做成产品。



    俗话说“授人以鱼，不如授人以渔。”就是这个道理吧。Dan Friedman，谢谢你教会我钓鱼。


   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    



    

 
 
 
 

 什么是“对用户友好”

 
 
 
 
    

    
 
     
  

      
   
什么是“对用户友好”

    



    当我提到一个工具“对用户不友好”(user-unfriendly)的时候，我总是被人“鄙视”。难道这就叫“以其人之道还治其人之身”？想当年有人对我抱怨 Linux 或者 TeX 对用户不友好的时候，我貌似也差不多的态度吧。现在当我指出 TeX 的各种缺点，提出新的解决方案的时候，往往会有美国同学眼角一抬，说：“菜鸟们抱怨工具不好用，那是因为他们不会用。LaTeX 是‘所想即所得’，所以不像 Word 之类的上手。”



    殊不知他面前这个“菜鸟”，其实早已把 TeX 的配置搞得滚瓜烂熟，把 TeXbook 翻来覆去看了两遍，"double bend" 的习题都全部完成，可以用 TeX 的语言来写宏包。而他被叫做“菜鸟”，这是一个非常有趣的问题。所以现在抛开个人感情不谈，我们来探讨一下这种“鄙视”现象产生的原因，以及什么叫做“对用户友好”。



    首先我们从心理的角度来分析一下为什么有人对这种“对用户不友好”的事实视而不见，而称抱怨的用户为“菜鸟”。这个似乎很明显，答案是“优越感”。如果每个人都会做一件事情，如何能体现出我的超群智力？所以我就是要专门选择那种最难用，最晦涩，最显得高深的东西，把它折腾会。这样我就可以被称为“高手”，就可以傲视群雄。我不得不承认，我以前也有类似的思想。从上本科以来我就一直在想，同样都会写程序，是什么让计算机系的学生与非计算机系的学生有所不同？经过多年之后的今天，我终于得到了答案（以后再告诉你）。可是在多年以前，我犯了跟很多人一样的错误：把“难度”与“智力”或者“专业程度”相等同。但是其实，一个人会用难用的工具，并不等于他智力超群或者更加专业。



    可惜的是，我发现世界上有非常少的人明白这个道理。在大学里，公司里，彰显自己对难用的工具的掌握程度的人比比皆是。这不只是对于计算机系统，这也针对数学以及逻辑等抽象的学科。经常听人很自豪的说：“我准备用XX逻辑设计一个公理化的系统……”可是这些人其实只知道这个逻辑的皮毛，他们会用这个逻辑，却不知道它里面所有含混晦涩的规则都可以用更简单更直观的方法推导出来。



    爱因斯坦说：“Any intelligent fool can make things bigger and more complex... It takes a touch of genius - and a lot of courage to move in the opposite direction.”我现在深深的体会到这句话的道理。想要简化一个东西，让它更“好用”，你确实需要很大的勇气。而且你必须故意的忽略这个东西的一些细节。但是由于你的身边都是不理解这个道理的人，他们会把你当成菜鸟或者白痴。即使你成功了，可能也很难说服他们去尝试这个简化后的东西。



    那么现在我们来谈一下什么是“对用户友好”。如何定义“对用户友好”？如何精确的判断一个东西是否对用户友好？我觉得这是一个现在仍然非常模糊的概念，但是程序语言的设计思想，特别是其中的类型理论(type theory)可以比较好的解释它。我们可以把机器和人看作同一个系统：



这个系统有多个模块，包括机器模块和人类模块。
机器模块之间的界面使用通常的程序接口。
人机交互的界面就是机器模块和人类模块之间的接口。
每个界面必须提供一定的抽象，用于防止使用者得到它不该知道的细节。这个使用者可能是机器模块，也可能是人类模块。
抽象使得系统具有可扩展性。因为只要界面不变，模块改动之后，它的使用者完全不用修改。




    在机器的各个模块间，抽象表现为函数或者方法的类型(type)，程序的模块(module)定义，操作系统的系统调用(system call)，等等。但是它们的本质都是一样的：他们告诉使用者“你能用我来干什么”。很多程序员都会注意到这些机器界面的抽象，让使用者尽量少的接触到实现细节。可是他们却往往忽视了人和机器之间的界面。也许他们没有忽视它，但是他们却用非常不一样的设计思想来考虑这个问题。他们没有真正把人当成这个系统的一部分，没有像对待其它机器模块一样，提供具有良好抽象的界面给人。他们貌似觉得人应该可以多做一些事情，所以把纷繁复杂的程序内部结构暴露给人（包括他们自己）。所以人对“我能用这个程序干什么”这个问题总是很糊涂。当程序被修改之后，还经常需要让人的操作发生改变，所以这个系统对于人的可扩展性就差。通常程序员都考虑到机器各界面之间的扩展性，却没有考虑到机器与人之间界面的可扩展性。



    举个例子。很多 Unix 程序都有配置文件，它们也设置环境变量，它们还有命令行参数。这样每个用户都得知道配置文件的名字，位置和格式，环境变量的名字以及意义，命令行参数的意义。一个程序还好，如果有很多程序，每个程序都在不同的位置放置不同名字的配置文件，每个配置文件的格式都不一样，这些配置会把人给搞糊涂。经常出现程序说找不到配置文件，看手册吧，手册说配置文件的位置是某某环境变量 FOO 决定的。改了环境变量却发现没有解决问题。没办法，只好上论坛问，终于发现配置文件起作用当且仅当在同一个目录里没有一个叫 ".bar" 的文件。好不容易记住了这条规则，这个程序升级之后，又把规则给改了，所以这个用户又继续琢磨，继续上论坛，如此反复。也许这就叫做“折腾”？他何时才能干自己的事情？



    TeX 系统的配置就更为麻烦。成千上万个小文件，很少有人理解 kpathsea 的结构和用法，折腾好久才会明白。但是其实它只是解决一个非常微不足道的问题。TeX 的语言也有很大问题，使得扩展起来非常困难。这个以后再讲。



    一个良好的界面不应该是这样的。它给予用户的界面，应该只有一些简单的设定。用户应该用同样的方法来设置所有程序的所有参数，因为它们只不过是一个从变量到值的映射（map）。至于系统要在什么地方存储这些设定，如何找到它们，具体的格式，用户根本不应该知道。这跟高级语言的运行时系统(runtime system)的内存管理是一个道理。程序请求建立一个对象，系统收到指令后分配一块内存，进行初始化，然后把对象的引用(reference)返回给程序。程序并不知道对象存在于内存的哪个位置，而且不应该知道。程序不应该使用对象的地址来进行运算。



    所以我们看到，“对用户不友好”的背后，其实是程序设计的不合理使得它们缺少抽象，而不是用户的问题。这种对用户不友好的现象在 Windows，Mac，iPhone, Android 里也普遍存在。比如几乎所有 iPhone 用户都被洗脑的一个错误是“iPhone 只需要一个按钮”。一个按钮其实是不够的。还有就是像 Photoshop, Illustrator, Flash 之类的软件的菜单界面，其实把用户需要的功能和设置给掩藏了起来，分类也经常出现不合理现象，让他们很难找到这些功能。



    如何对用户更加友好，是一两句话说不清楚的事情。所以这里只粗略说一下我想到过的要点：




    统一：随时注意，人是一个统一的系统的一部分，而不是什么古怪的神物。基本上可以把人想象成一个程序模块。


    抽象：最大限度的掩盖程序内部的实现，尽量不让人知道他不必要知道的东西。不愿意暴露给其它程序模块的细节，也不要暴露给人。“机所不欲，勿施于人”。


    充要：提供给人充分而必要（不多于）的机制来完成人想完成的任务。


    正交：机制之间应该尽量减少冗余和重叠，保持正交(orthogonal)。


    组合：机制之间应该可以组合(compose)，尽量使得干同一件事情只有一种组合。


    理性：并不是所有人想要的功能都是应该有的，他们经常欺骗自己，要搞清楚那些是他们真正需要的功能。


    信道：人的输入输出包括5种感官，虽然通常电脑只与人通过视觉和听觉交互。


    直觉：人是靠直觉和模型(model)思考的，给人的信息不管是符号还是图形，应该容易在人脑中建立起直观的模型，这样人才能高效的操作它们。


    上下文：人脑的“高速缓存”的容量是很小的。试试你能同时想起7个人的名字吗？所以在任一特定时刻，应该只提供与当前被关注对象相关的操作，而不是提供所有情况下的所有操作供人选择。上下文菜单和依据上下文的键盘操作提示，貌似不错的主意。




   


   

<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-1331524016319584"
     data-ad-slot="6657867155">

   

      

      
   
   <ins class="adsbygoogle"
 style="display:block"
 data-ad-client="ca-pub-1331524016319584"
 data-ad-slot="2703393155"
 data-ad-format="auto">
   
      
  
     
 

    


